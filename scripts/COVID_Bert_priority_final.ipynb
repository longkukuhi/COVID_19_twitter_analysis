{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "COVID_Bert_priority_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MIc1sOkuTPxN"
      },
      "source": [
        "# Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjalNYr92Y3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Acknowlegement: Some codes used to initialise BERT are from BERT tutorial(https://colab.research.google.com/drive/1Y4o3jh3ZH70tl6mCd76vz_IxX23biCPP)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ILi74Hm1TSmu",
        "colab": {}
      },
      "source": [
        "# Import necessary libraries\n",
        "import re\n",
        "import string\n",
        "import os \n",
        "from collections import defaultdict\n",
        "from collections import Counter\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import datetime\n",
        "import copy\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from covid_tools import *\n",
        "from BERTs import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y7W1cd37iLNM",
        "colab": {}
      },
      "source": [
        "# load orginal data(COVID-19 TREC-IS 2020 task) from json file.\n",
        "import json\n",
        "import pandas as pd\n",
        "cv19_dc = pd.read_json('./Pythonbooks/Data/COVID/cv19_dc_test.json',lines=True,orient='records')\n",
        "cv19_ws = pd.read_json('./Pythonbooks/Data/COVID/cv19_washington_state_test.json',lines=True,orient='records')\n",
        "cv19_ny = pd.read_json('./Pythonbooks/Data/COVID/cv19_nyc_test.json',lines=True,orient='records')\n",
        "\n",
        "# Read lablled tweets from json file which contains all labels based on union of labels from all human assessors.\n",
        "all_labels  = read_union_labels_from_file()\n",
        "\n",
        "# Merge original dataset with lablled dataset based on id of tweets\n",
        "cv19_dc_labeled = pd.merge(cv19_dc,all_labels,on=['id'])\n",
        "cv19_ws_labeled = pd.merge(cv19_ws,all_labels,on=['id'])\n",
        "cv19_ny_labeled = pd.merge(cv19_ny,all_labels,on=['id'])\n",
        "\n",
        "# As for priorization task, we use majority vote of labels instead of union.\n",
        "'''More specifically, if one tweet is assessed by more than two assessors,\n",
        " we use the most common label as the priority label. And if one tweet is assessed by less than two assessors, \n",
        " we randomly choose one label as the true label. \n",
        " '''\n",
        "cv19_dc_labeled = extract_majority_vote_label(cv19_dc_labeled)\n",
        "cv19_ny_labeled = extract_majority_vote_label(cv19_ny_labeled)\n",
        "cv19_ws_labeled = extract_majority_vote_label(cv19_ws_labeled)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8s_sWbTHDuPb",
        "colab": {},
        "outputId": "5339f71b-fc91-42d6-c8cc-ae62b20c2730"
      },
      "source": [
        "cv19_ny_labeled"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>created_at</th>\n",
              "      <th>id</th>\n",
              "      <th>id_str</th>\n",
              "      <th>full_text</th>\n",
              "      <th>truncated</th>\n",
              "      <th>display_text_range</th>\n",
              "      <th>entities</th>\n",
              "      <th>extended_entities</th>\n",
              "      <th>metadata</th>\n",
              "      <th>source</th>\n",
              "      <th>...</th>\n",
              "      <th>retweeted</th>\n",
              "      <th>possibly_sensitive</th>\n",
              "      <th>lang</th>\n",
              "      <th>quoted_status_id</th>\n",
              "      <th>quoted_status_id_str</th>\n",
              "      <th>quoted_status</th>\n",
              "      <th>withheld_in_countries</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>priority</th>\n",
              "      <th>categories</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-05-03 14:57:57+00:00</td>\n",
              "      <td>1256961196525314048</td>\n",
              "      <td>1256961196525314048</td>\n",
              "      <td>Reopening states will cause 233,000 more peopl...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 278]</td>\n",
              "      <td>{'hashtags': [{'text': 'NYC', 'indices': [212,...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9758</td>\n",
              "      <td>Low</td>\n",
              "      <td>[Irrelevant]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-03-27 01:39:25+00:00</td>\n",
              "      <td>1243351890508701697</td>\n",
              "      <td>1243351890508701696</td>\n",
              "      <td>@samiglee @flash__delirium @michaelbd @mtracey...</td>\n",
              "      <td>False</td>\n",
              "      <td>[47, 322]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2807</td>\n",
              "      <td>Low</td>\n",
              "      <td>[News, ThirdPartyObservation, Sentiment, Conte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-03-28 18:42:47+00:00</td>\n",
              "      <td>1243971816131104768</td>\n",
              "      <td>1243971816131104768</td>\n",
              "      <td>We Met Up with Whalebone on Bleecker, and then...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 95]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3369</td>\n",
              "      <td>Low</td>\n",
              "      <td>[Irrelevant]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-03-28 15:43:43+00:00</td>\n",
              "      <td>1243926751073513473</td>\n",
              "      <td>1243926751073513472</td>\n",
              "      <td>‘White-Collar Quarantine’ Over Virus Spotlight...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 123]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>1.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2870</td>\n",
              "      <td>Low</td>\n",
              "      <td>[Irrelevant]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-03-29 03:17:45+00:00</td>\n",
              "      <td>1244101411899453441</td>\n",
              "      <td>1244101411899453440</td>\n",
              "      <td>The Lost Month: How a Failure to Test Blinded ...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 111]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8537</td>\n",
              "      <td>Low</td>\n",
              "      <td>[Irrelevant]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2020-03-27 03:05:35+00:00</td>\n",
              "      <td>1243373573798010887</td>\n",
              "      <td>1243373573798010880</td>\n",
              "      <td>Coronavirus: Governors Ball 2020 cancelled ami...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 107]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>{'media': [{'id': 1243373571554017286, 'id_str...</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://publicize.wp.com/\" rel=\"nofoll...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2633</td>\n",
              "      <td>High</td>\n",
              "      <td>[News, Sentiment, ContextualInformation, Multi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2020-04-07 13:17:53+00:00</td>\n",
              "      <td>1247513929703661569</td>\n",
              "      <td>1247513929703661568</td>\n",
              "      <td>Some coronavirus positivity this morning. http...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 65]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>1.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8281</td>\n",
              "      <td>Low</td>\n",
              "      <td>[Irrelevant]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2020-03-27 15:18:35+00:00</td>\n",
              "      <td>1243558040495960064</td>\n",
              "      <td>1243558040495960064</td>\n",
              "      <td>@MariaBartiromo @MorningsMaria @FoxBusiness A ...</td>\n",
              "      <td>False</td>\n",
              "      <td>[44, 296]</td>\n",
              "      <td>{'hashtags': [{'text': 'Covid19', 'indices': [...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2749</td>\n",
              "      <td>Low</td>\n",
              "      <td>[Sentiment, ContextualInformation, Irrelevant]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2020-03-27 09:28:35+00:00</td>\n",
              "      <td>1243469959017025536</td>\n",
              "      <td>1243469959017025536</td>\n",
              "      <td>» Correspondence from Dr Vladimir Zelenko on T...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 102]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2755</td>\n",
              "      <td>Low</td>\n",
              "      <td>[News, ContextualInformation, Irrelevant]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2020-03-28 16:16:04+00:00</td>\n",
              "      <td>1243934894302146560</td>\n",
              "      <td>1243934894302146560</td>\n",
              "      <td>Just a reminder that #nopantssubwayride across...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 129]</td>\n",
              "      <td>{'hashtags': [{'text': 'nopantssubwayride', 'i...</td>\n",
              "      <td>{'media': [{'id': 1243934889143087104, 'id_str...</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3484</td>\n",
              "      <td>Low</td>\n",
              "      <td>[ContextualInformation, Irrelevant, Hashtags]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2020-03-27 21:06:01+00:00</td>\n",
              "      <td>1243645475611455488</td>\n",
              "      <td>1243645475611455488</td>\n",
              "      <td>@realDonaldTrump @WhiteHouse DJT, more tempora...</td>\n",
              "      <td>False</td>\n",
              "      <td>[29, 137]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3222</td>\n",
              "      <td>Low</td>\n",
              "      <td>[News, ContextualInformation, Irrelevant, Sent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2020-03-24 04:20:01+00:00</td>\n",
              "      <td>1242305141786570752</td>\n",
              "      <td>1242305141786570752</td>\n",
              "      <td>Coronavirus Update: New York Health Officials ...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 200]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2702</td>\n",
              "      <td>Medium</td>\n",
              "      <td>[News, Official, ContextualInformation]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2020-03-27 13:27:02+00:00</td>\n",
              "      <td>1243529968828780544</td>\n",
              "      <td>1243529968828780544</td>\n",
              "      <td>Rihanna thanked for her contributions to the c...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 128]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://www.socialflow.com\" rel=\"nofol...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2815</td>\n",
              "      <td>Low</td>\n",
              "      <td>[News, Official, ContextualInformation, Irrele...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2020-03-29 08:36:01+00:00</td>\n",
              "      <td>1244181506286702593</td>\n",
              "      <td>1244181506286702592</td>\n",
              "      <td>Opinion | Why Telling People They Don’t Need M...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 105]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/#!/download/ipad\" ...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8784</td>\n",
              "      <td>Low</td>\n",
              "      <td>[Irrelevant]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2020-03-27 13:13:15+00:00</td>\n",
              "      <td>1243526497723387906</td>\n",
              "      <td>1243526497723387904</td>\n",
              "      <td>Trump Rejects New York’s Plea For Ventilators:...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 118]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3333</td>\n",
              "      <td>Low</td>\n",
              "      <td>[News, ContextualInformation, Irrelevant, Sent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2020-03-28 20:57:20+00:00</td>\n",
              "      <td>1244005677724577792</td>\n",
              "      <td>1244005677724577792</td>\n",
              "      <td>Trump's idea might work if NY, NJ and NYC had ...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 248]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>1.243960e+18</td>\n",
              "      <td>1.243960e+18</td>\n",
              "      <td>{'created_at': 'Sat Mar 28 17:57:03 +0000 2020...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3354</td>\n",
              "      <td>Low</td>\n",
              "      <td>[News, Official, Sentiment, ContextualInformat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2020-03-24 00:28:50+00:00</td>\n",
              "      <td>1242246962273017858</td>\n",
              "      <td>1242246962273017856</td>\n",
              "      <td>New York asks domain registrars to crack down ...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 105]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://www.echofon.com/\" rel=\"nofollo...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2965</td>\n",
              "      <td>Low</td>\n",
              "      <td>[News, ContextualInformation, Irrelevant, Advice]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2020-03-27 00:35:57+00:00</td>\n",
              "      <td>1243335918007848960</td>\n",
              "      <td>1243335918007848960</td>\n",
              "      <td>@ndrew_lawrence Replace New York with @BarackO...</td>\n",
              "      <td>False</td>\n",
              "      <td>[16, 223]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2561</td>\n",
              "      <td>Low</td>\n",
              "      <td>[Sentiment, ContextualInformation, Irrelevant]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2020-03-26 22:10:37+00:00</td>\n",
              "      <td>1243299343840534530</td>\n",
              "      <td>1243299343840534528</td>\n",
              "      <td>@NYTHealth Have you covered the hospital closu...</td>\n",
              "      <td>False</td>\n",
              "      <td>[11, 143]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3430</td>\n",
              "      <td>Low</td>\n",
              "      <td>[Irrelevant]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2020-03-28 16:50:00+00:00</td>\n",
              "      <td>1243943432999047168</td>\n",
              "      <td>1243943432999047168</td>\n",
              "      <td>BREAKING:Newyork reports 7681new cases of coro...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 170]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2728</td>\n",
              "      <td>Low</td>\n",
              "      <td>[Sentiment, ContextualInformation, Advice, Fac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2020-03-30 12:50:03+00:00</td>\n",
              "      <td>1244607825684332544</td>\n",
              "      <td>1244607825684332544</td>\n",
              "      <td>Wanted to do a #Covid_19 check in with some NY...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 208]</td>\n",
              "      <td>{'hashtags': [{'text': 'Covid_19', 'indices': ...</td>\n",
              "      <td>{'media': [{'id': 1244607819975884801, 'id_str...</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8771</td>\n",
              "      <td>Low</td>\n",
              "      <td>[Irrelevant]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2020-03-30 19:40:05+00:00</td>\n",
              "      <td>1244711011803938816</td>\n",
              "      <td>1244711011803938816</td>\n",
              "      <td>🇺🇸 Stay strong New York and stay safe!\\n\\n2 Co...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 175]</td>\n",
              "      <td>{'hashtags': [{'text': 'COVID19', 'indices': [...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9336</td>\n",
              "      <td>Low</td>\n",
              "      <td>[Irrelevant]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2020-03-28 16:31:02+00:00</td>\n",
              "      <td>1243938659549708290</td>\n",
              "      <td>1243938659549708288</td>\n",
              "      <td>N.Y.P.D. Has 500 Coronavirus Cases and 2nd Civ...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 115]</td>\n",
              "      <td>{'hashtags': [{'text': 'coronavirus', 'indices...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"https://www.hootsuite.com\" rel=\"nofol...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2853</td>\n",
              "      <td>Low</td>\n",
              "      <td>[News, ThirdPartyObservation, Sentiment, Conte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2020-03-28 17:10:28+00:00</td>\n",
              "      <td>1243948585558790144</td>\n",
              "      <td>1243948585558790144</td>\n",
              "      <td>A bit late you bumbling idiot! \\n\\nTrump says ...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 118]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2942</td>\n",
              "      <td>Critical</td>\n",
              "      <td>[News, Official, Sentiment, ContextualInformat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2020-03-27 02:45:49+00:00</td>\n",
              "      <td>1243368598187499520</td>\n",
              "      <td>1243368598187499520</td>\n",
              "      <td>Get Ready #NYPD - #NYC jail population will be...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 274]</td>\n",
              "      <td>{'hashtags': [{'text': 'NYPD', 'indices': [10,...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3027</td>\n",
              "      <td>Low</td>\n",
              "      <td>[News, Official, ThirdPartyObservation, Sentim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2020-03-26 21:36:23+00:00</td>\n",
              "      <td>1243290726441594880</td>\n",
              "      <td>1243290726441594880</td>\n",
              "      <td>Do @nytimes 13 Deaths in a Day: An ‘Apocalypti...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 112]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2745</td>\n",
              "      <td>Low</td>\n",
              "      <td>[News, Location, EmergingThreats, ThirdPartyOb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2020-03-28 17:47:43+00:00</td>\n",
              "      <td>1243957956938354688</td>\n",
              "      <td>1243957956938354688</td>\n",
              "      <td>Coronavirus Stimulus Package F.A.Q.: Checks, U...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 111]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/#!/download/ipad\" ...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3001</td>\n",
              "      <td>Low</td>\n",
              "      <td>[News, ContextualInformation, Factoid, Multime...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2020-03-28 19:57:10+00:00</td>\n",
              "      <td>1243990536865841152</td>\n",
              "      <td>1243990536865841152</td>\n",
              "      <td>Right now if you add up the New York and New J...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 123]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3017</td>\n",
              "      <td>Low</td>\n",
              "      <td>[ContextualInformation, Irrelevant, Factoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2020-03-28 19:28:44+00:00</td>\n",
              "      <td>1243983381207101440</td>\n",
              "      <td>1243983381207101440</td>\n",
              "      <td>@LuckythePomChi, me, &amp;amp; https://t.co/NJUa29...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 284]</td>\n",
              "      <td>{'hashtags': [{'text': 'SocialDistancing', 'in...</td>\n",
              "      <td>{'media': [{'id': 1243983371010744321, 'id_str...</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3035</td>\n",
              "      <td>Low</td>\n",
              "      <td>[Sentiment, Irrelevant, Hashtags]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2020-03-28 17:03:57+00:00</td>\n",
              "      <td>1243946945615364096</td>\n",
              "      <td>1243946945615364096</td>\n",
              "      <td>Just wonderful: \\nhttps://t.co/Si6Z5zhBqj</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 40]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3323</td>\n",
              "      <td>Low</td>\n",
              "      <td>[News, ContextualInformation, Irrelevant, Sent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2472</th>\n",
              "      <td>2020-03-30 16:06:46+00:00</td>\n",
              "      <td>1244657328307286019</td>\n",
              "      <td>1244657328307286016</td>\n",
              "      <td>Hospital Ship Arrives in N.Y. to Help \\n\\nMaje...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 272]</td>\n",
              "      <td>{'hashtags': [{'text': 'Covid19', 'indices': [...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9477</td>\n",
              "      <td>High</td>\n",
              "      <td>[News, EmergingThreats, ThirdPartyObservation,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2473</th>\n",
              "      <td>2020-03-25 05:24:34+00:00</td>\n",
              "      <td>1242683772711112706</td>\n",
              "      <td>1242683772711112704</td>\n",
              "      <td>Nyc is at 15,000 coronavirus cases🥴 I might be...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 97]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2683</td>\n",
              "      <td>Low</td>\n",
              "      <td>[Sentiment, Irrelevant, Factoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2474</th>\n",
              "      <td>2020-03-26 22:42:08+00:00</td>\n",
              "      <td>1243307273755095040</td>\n",
              "      <td>1243307273755095040</td>\n",
              "      <td>@elerianm The data from scientists show we'll ...</td>\n",
              "      <td>False</td>\n",
              "      <td>[10, 170]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2890</td>\n",
              "      <td>Low</td>\n",
              "      <td>[Sentiment, ContextualInformation, Irrelevant]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2475</th>\n",
              "      <td>2020-04-03 18:46:37+00:00</td>\n",
              "      <td>1246147105992949760</td>\n",
              "      <td>1246147105992949760</td>\n",
              "      <td>@SaneManyathi @eNCA And NYC is the worst hit b...</td>\n",
              "      <td>False</td>\n",
              "      <td>[20, 193]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8780</td>\n",
              "      <td>Low</td>\n",
              "      <td>[Irrelevant]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2476</th>\n",
              "      <td>2020-03-28 01:41:12+00:00</td>\n",
              "      <td>1243714724472078338</td>\n",
              "      <td>1243714724472078336</td>\n",
              "      <td>‘People Are Dying’: 72 Hours Inside a N.Y.C. H...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 237]</td>\n",
              "      <td>{'hashtags': [{'text': 'DeborahBirx', 'indices...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3159</td>\n",
              "      <td>Low</td>\n",
              "      <td>[News, Location, EmergingThreats, Sentiment, C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2477</th>\n",
              "      <td>2020-03-27 06:34:02+00:00</td>\n",
              "      <td>1243426033388253184</td>\n",
              "      <td>1243426033388253184</td>\n",
              "      <td>Because he’s been so  accurate with his other ...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 175]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3154</td>\n",
              "      <td>Low</td>\n",
              "      <td>[News, Sentiment, ContextualInformation, Multi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2478</th>\n",
              "      <td>2020-04-03 13:28:43+00:00</td>\n",
              "      <td>1246067105721712640</td>\n",
              "      <td>1246067105721712640</td>\n",
              "      <td>“The Monty Python version of Israeli Palestine...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 153]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9345</td>\n",
              "      <td>Low</td>\n",
              "      <td>[Irrelevant]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2479</th>\n",
              "      <td>2020-03-25 17:38:45+00:00</td>\n",
              "      <td>1242868539310120960</td>\n",
              "      <td>1242868539310120960</td>\n",
              "      <td>@criticalneuro @behrenstimb Also, the daily su...</td>\n",
              "      <td>False</td>\n",
              "      <td>[28, 306]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2760</td>\n",
              "      <td>Low</td>\n",
              "      <td>[News, Official, ThirdPartyObservation, Contex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2480</th>\n",
              "      <td>2020-03-24 04:43:34+00:00</td>\n",
              "      <td>1242311067511947264</td>\n",
              "      <td>1242311067511947264</td>\n",
              "      <td>@Alan78523817 @CNN Then YOU go to New York or ...</td>\n",
              "      <td>False</td>\n",
              "      <td>[19, 135]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>{'media': [{'id': 1242311051431022592, 'id_str...</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3251</td>\n",
              "      <td>Low</td>\n",
              "      <td>[Irrelevant]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2481</th>\n",
              "      <td>2020-03-25 21:13:50+00:00</td>\n",
              "      <td>1242922664701935624</td>\n",
              "      <td>1242922664701935616</td>\n",
              "      <td>Sikhs To The Rescue Again: Community Cooks Fre...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 118]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2687</td>\n",
              "      <td>Low</td>\n",
              "      <td>[News, ContextualInformation, ServiceAvailable...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2482</th>\n",
              "      <td>2020-04-03 11:51:07+00:00</td>\n",
              "      <td>1246042542141030400</td>\n",
              "      <td>1246042542141030400</td>\n",
              "      <td>LGBT activists slam New York COVID-19 field ho...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 128]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8916</td>\n",
              "      <td>Low</td>\n",
              "      <td>[Irrelevant]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2483</th>\n",
              "      <td>2020-03-30 07:04:01+00:00</td>\n",
              "      <td>1244520740730388482</td>\n",
              "      <td>1244520740730388480</td>\n",
              "      <td>Mayor Deblasio encourages everyone to go about...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 181]</td>\n",
              "      <td>{'hashtags': [{'text': 'NewYork', 'indices': [...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8717</td>\n",
              "      <td>Low</td>\n",
              "      <td>[Irrelevant, ContextualInformation, ThirdParty...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2484</th>\n",
              "      <td>2020-03-27 19:37:25+00:00</td>\n",
              "      <td>1243623176279556099</td>\n",
              "      <td>1243623176279556096</td>\n",
              "      <td>@AjaxMull @billtaggard @Manfredi1 @Jim71213440...</td>\n",
              "      <td>False</td>\n",
              "      <td>[85, 141]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3324</td>\n",
              "      <td>Low</td>\n",
              "      <td>[News, Location, EmergingThreats, ThirdPartyOb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2485</th>\n",
              "      <td>2020-03-27 12:55:27+00:00</td>\n",
              "      <td>1243522018219343875</td>\n",
              "      <td>1243522018219343872</td>\n",
              "      <td>Trump Rejects New York’s Plea For Ventilators:...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 107]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2990</td>\n",
              "      <td>Low</td>\n",
              "      <td>[News, Official, ContextualInformation, Irrele...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2486</th>\n",
              "      <td>2020-03-25 02:59:15+00:00</td>\n",
              "      <td>1242647205950808064</td>\n",
              "      <td>1242647205950808064</td>\n",
              "      <td>Coronavirus spreading in New York like 'a bull...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 79]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2787</td>\n",
              "      <td>Low</td>\n",
              "      <td>[News, ContextualInformation, Irrelevant]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2487</th>\n",
              "      <td>2020-03-27 03:52:22+00:00</td>\n",
              "      <td>1243385348299710465</td>\n",
              "      <td>1243385348299710464</td>\n",
              "      <td>Tucker: How New York's leaders failed their ci...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 108]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3420</td>\n",
              "      <td>Low</td>\n",
              "      <td>[News, Sentiment, ContextualInformation, Advic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2488</th>\n",
              "      <td>2020-05-03 16:07:06+00:00</td>\n",
              "      <td>1256978599242072065</td>\n",
              "      <td>1256978599242072064</td>\n",
              "      <td>@JoeNBC .@NYCMayor and @NYGovCuomo  @NYGovCuom...</td>\n",
              "      <td>False</td>\n",
              "      <td>[8, 239]</td>\n",
              "      <td>{'hashtags': [{'text': 'coronavirus', 'indices...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9293</td>\n",
              "      <td>Low</td>\n",
              "      <td>[Discussion, ContextualInformation, ThirdParty...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2489</th>\n",
              "      <td>2020-03-27 10:22:24+00:00</td>\n",
              "      <td>1243483502949130240</td>\n",
              "      <td>1243483502949130240</td>\n",
              "      <td>@realDonaldTrump has a personal vendetta again...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 283]</td>\n",
              "      <td>{'hashtags': [{'text': 'Covid19', 'indices': [...</td>\n",
              "      <td>{'media': [{'id': 1243482803905445888, 'id_str...</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2992</td>\n",
              "      <td>Low</td>\n",
              "      <td>[News, Official, Sentiment, ContextualInformat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2490</th>\n",
              "      <td>2020-03-27 13:05:09+00:00</td>\n",
              "      <td>1243524459610492935</td>\n",
              "      <td>1243524459610492928</td>\n",
              "      <td>Scenes of \"catastrophe\" as New York hospitals ...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 107]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"https://dlvrit.com/\" rel=\"nofollow\"&gt;d...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3470</td>\n",
              "      <td>Critical</td>\n",
              "      <td>[News, EmergingThreats, Sentiment, ContextualI...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2491</th>\n",
              "      <td>2020-03-25 14:04:57+00:00</td>\n",
              "      <td>1242814731938906113</td>\n",
              "      <td>1242814731938906112</td>\n",
              "      <td>The issue is Trump thinks Cuomo has been mean ...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 107]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2951</td>\n",
              "      <td>Low</td>\n",
              "      <td>[Irrelevant]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2492</th>\n",
              "      <td>2020-03-29 21:33:21+00:00</td>\n",
              "      <td>1244377127979532289</td>\n",
              "      <td>1244377127979532288</td>\n",
              "      <td>Knicks Owner, MSG Chairman James Dolan Has Cor...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 78]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9793</td>\n",
              "      <td>Low</td>\n",
              "      <td>[Irrelevant]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2493</th>\n",
              "      <td>2020-03-25 19:18:22+00:00</td>\n",
              "      <td>1242893608438640641</td>\n",
              "      <td>1242893608438640640</td>\n",
              "      <td>Finally, something that deserves the adjective...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 171]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3486</td>\n",
              "      <td>Low</td>\n",
              "      <td>[News, EmergingThreats, ThirdPartyObservation,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2494</th>\n",
              "      <td>2020-03-25 18:50:08+00:00</td>\n",
              "      <td>1242886501437861888</td>\n",
              "      <td>1242886501437861888</td>\n",
              "      <td>@TimVader3 @OffGuardian0 FEB 7, 2020:\\n\\n\"Ther...</td>\n",
              "      <td>False</td>\n",
              "      <td>[25, 303]</td>\n",
              "      <td>{'hashtags': [{'text': 'flu', 'indices': [66, ...</td>\n",
              "      <td>{'media': [{'id': 1242886310299226113, 'id_str...</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2806</td>\n",
              "      <td>Low</td>\n",
              "      <td>[News, Sentiment, ContextualInformation, Facto...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2495</th>\n",
              "      <td>2020-05-01 06:58:47+00:00</td>\n",
              "      <td>1256115835699167236</td>\n",
              "      <td>1256115835699167232</td>\n",
              "      <td>‘There’s No Way We Can Bury or Cremate Them Fa...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 80]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"https://paper.li\" rel=\"nofollow\"&gt;Pape...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8354</td>\n",
              "      <td>Low</td>\n",
              "      <td>[Irrelevant]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2496</th>\n",
              "      <td>2020-03-25 17:34:22+00:00</td>\n",
              "      <td>1242867433121165313</td>\n",
              "      <td>1242867433121165312</td>\n",
              "      <td>Coronavirus in NYC: Judges outraged after NYC ...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 84]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"https://bitly.com/\" rel=\"nofollow\"&gt;Bi...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2907</td>\n",
              "      <td>Low</td>\n",
              "      <td>[News, Official, Sentiment, ContextualInformat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2497</th>\n",
              "      <td>2020-03-27 10:26:56+00:00</td>\n",
              "      <td>1243484645267779585</td>\n",
              "      <td>1243484645267779584</td>\n",
              "      <td>Trump keeps touting an unproven coronavirus tr...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 140]</td>\n",
              "      <td>{'hashtags': [{'text': 'chloroquine', 'indices...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3074</td>\n",
              "      <td>Low</td>\n",
              "      <td>[News, Sentiment, ContextualInformation, Advic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2498</th>\n",
              "      <td>2020-03-27 09:38:35+00:00</td>\n",
              "      <td>1243472477784858625</td>\n",
              "      <td>1243472477784858624</td>\n",
              "      <td>Despicable human being\\nhttps://t.co/WVBvDmmsmm</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 46]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3197</td>\n",
              "      <td>Low</td>\n",
              "      <td>[News, Official, Sentiment, ContextualInformat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2499</th>\n",
              "      <td>2020-03-27 06:38:57+00:00</td>\n",
              "      <td>1243427271551016962</td>\n",
              "      <td>1243427271551016960</td>\n",
              "      <td>#ThisDay 1841 - \"First US steam fire engine te...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 63]</td>\n",
              "      <td>{'hashtags': [{'text': 'ThisDay', 'indices': [...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/#!/download/ipad\" ...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3031</td>\n",
              "      <td>Low</td>\n",
              "      <td>[Irrelevant]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2500</th>\n",
              "      <td>2020-03-26 21:00:00+00:00</td>\n",
              "      <td>1243281571957723136</td>\n",
              "      <td>1243281571957723136</td>\n",
              "      <td>New York City hospitals are already strained t...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 279]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>{'media': [{'id': 1243251435518787594, 'id_str...</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"https://studio.twitter.com\" rel=\"nofo...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3082</td>\n",
              "      <td>Low</td>\n",
              "      <td>[News, EmergingThreats, Sentiment, ContextualI...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2501</th>\n",
              "      <td>2020-03-27 15:17:01+00:00</td>\n",
              "      <td>1243557646399135753</td>\n",
              "      <td>1243557646399135744</td>\n",
              "      <td>New York City's #Elmhurst Hospital, located in...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 206]</td>\n",
              "      <td>{'hashtags': [{'text': 'Elmhurst', 'indices': ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"https://sproutsocial.com\" rel=\"nofoll...</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3002</td>\n",
              "      <td>Low</td>\n",
              "      <td>[News, Location, EmergingThreats, Sentiment, C...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2502 rows × 34 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                    created_at                   id               id_str  \\\n",
              "0    2020-05-03 14:57:57+00:00  1256961196525314048  1256961196525314048   \n",
              "1    2020-03-27 01:39:25+00:00  1243351890508701697  1243351890508701696   \n",
              "2    2020-03-28 18:42:47+00:00  1243971816131104768  1243971816131104768   \n",
              "3    2020-03-28 15:43:43+00:00  1243926751073513473  1243926751073513472   \n",
              "4    2020-03-29 03:17:45+00:00  1244101411899453441  1244101411899453440   \n",
              "...                        ...                  ...                  ...   \n",
              "2497 2020-03-27 10:26:56+00:00  1243484645267779585  1243484645267779584   \n",
              "2498 2020-03-27 09:38:35+00:00  1243472477784858625  1243472477784858624   \n",
              "2499 2020-03-27 06:38:57+00:00  1243427271551016962  1243427271551016960   \n",
              "2500 2020-03-26 21:00:00+00:00  1243281571957723136  1243281571957723136   \n",
              "2501 2020-03-27 15:17:01+00:00  1243557646399135753  1243557646399135744   \n",
              "\n",
              "                                              full_text  truncated  \\\n",
              "0     Reopening states will cause 233,000 more peopl...      False   \n",
              "1     @samiglee @flash__delirium @michaelbd @mtracey...      False   \n",
              "2     We Met Up with Whalebone on Bleecker, and then...      False   \n",
              "3     ‘White-Collar Quarantine’ Over Virus Spotlight...      False   \n",
              "4     The Lost Month: How a Failure to Test Blinded ...      False   \n",
              "...                                                 ...        ...   \n",
              "2497  Trump keeps touting an unproven coronavirus tr...      False   \n",
              "2498    Despicable human being\\nhttps://t.co/WVBvDmmsmm      False   \n",
              "2499  #ThisDay 1841 - \"First US steam fire engine te...      False   \n",
              "2500  New York City hospitals are already strained t...      False   \n",
              "2501  New York City's #Elmhurst Hospital, located in...      False   \n",
              "\n",
              "     display_text_range                                           entities  \\\n",
              "0              [0, 278]  {'hashtags': [{'text': 'NYC', 'indices': [212,...   \n",
              "1             [47, 322]  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
              "2               [0, 95]  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
              "3              [0, 123]  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
              "4              [0, 111]  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
              "...                 ...                                                ...   \n",
              "2497           [0, 140]  {'hashtags': [{'text': 'chloroquine', 'indices...   \n",
              "2498            [0, 46]  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
              "2499            [0, 63]  {'hashtags': [{'text': 'ThisDay', 'indices': [...   \n",
              "2500           [0, 279]  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
              "2501           [0, 206]  {'hashtags': [{'text': 'Elmhurst', 'indices': ...   \n",
              "\n",
              "                                      extended_entities  \\\n",
              "0                                                   NaN   \n",
              "1                                                   NaN   \n",
              "2                                                   NaN   \n",
              "3                                                   NaN   \n",
              "4                                                   NaN   \n",
              "...                                                 ...   \n",
              "2497                                                NaN   \n",
              "2498                                                NaN   \n",
              "2499                                                NaN   \n",
              "2500  {'media': [{'id': 1243251435518787594, 'id_str...   \n",
              "2501                                                NaN   \n",
              "\n",
              "                                               metadata  \\\n",
              "0     {'iso_language_code': 'en', 'result_type': 're...   \n",
              "1     {'iso_language_code': 'en', 'result_type': 're...   \n",
              "2     {'iso_language_code': 'en', 'result_type': 're...   \n",
              "3     {'iso_language_code': 'en', 'result_type': 're...   \n",
              "4     {'iso_language_code': 'en', 'result_type': 're...   \n",
              "...                                                 ...   \n",
              "2497  {'iso_language_code': 'en', 'result_type': 're...   \n",
              "2498  {'iso_language_code': 'en', 'result_type': 're...   \n",
              "2499  {'iso_language_code': 'en', 'result_type': 're...   \n",
              "2500  {'iso_language_code': 'en', 'result_type': 're...   \n",
              "2501  {'iso_language_code': 'en', 'result_type': 're...   \n",
              "\n",
              "                                                 source  ...  retweeted  \\\n",
              "0     <a href=\"https://mobile.twitter.com\" rel=\"nofo...  ...      False   \n",
              "1     <a href=\"http://twitter.com/download/android\" ...  ...      False   \n",
              "2     <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...  ...      False   \n",
              "3     <a href=\"http://twitter.com/download/iphone\" r...  ...      False   \n",
              "4     <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...  ...      False   \n",
              "...                                                 ...  ...        ...   \n",
              "2497  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...  ...      False   \n",
              "2498  <a href=\"https://mobile.twitter.com\" rel=\"nofo...  ...      False   \n",
              "2499  <a href=\"http://twitter.com/#!/download/ipad\" ...  ...      False   \n",
              "2500  <a href=\"https://studio.twitter.com\" rel=\"nofo...  ...      False   \n",
              "2501  <a href=\"https://sproutsocial.com\" rel=\"nofoll...  ...      False   \n",
              "\n",
              "      possibly_sensitive  lang  quoted_status_id quoted_status_id_str  \\\n",
              "0                    0.0    en               NaN                  NaN   \n",
              "1                    NaN    en               NaN                  NaN   \n",
              "2                    0.0    en               NaN                  NaN   \n",
              "3                    1.0    en               NaN                  NaN   \n",
              "4                    0.0    en               NaN                  NaN   \n",
              "...                  ...   ...               ...                  ...   \n",
              "2497                 0.0    en               NaN                  NaN   \n",
              "2498                 0.0    en               NaN                  NaN   \n",
              "2499                 NaN    en               NaN                  NaN   \n",
              "2500                 0.0    en               NaN                  NaN   \n",
              "2501                 0.0    en               NaN                  NaN   \n",
              "\n",
              "     quoted_status withheld_in_countries Unnamed: 0 priority  \\\n",
              "0              NaN                   NaN       9758      Low   \n",
              "1              NaN                   NaN       2807      Low   \n",
              "2              NaN                   NaN       3369      Low   \n",
              "3              NaN                   NaN       2870      Low   \n",
              "4              NaN                   NaN       8537      Low   \n",
              "...            ...                   ...        ...      ...   \n",
              "2497           NaN                   NaN       3074      Low   \n",
              "2498           NaN                   NaN       3197      Low   \n",
              "2499           NaN                   NaN       3031      Low   \n",
              "2500           NaN                   NaN       3082      Low   \n",
              "2501           NaN                   NaN       3002      Low   \n",
              "\n",
              "                                             categories  \n",
              "0                                          [Irrelevant]  \n",
              "1     [News, ThirdPartyObservation, Sentiment, Conte...  \n",
              "2                                          [Irrelevant]  \n",
              "3                                          [Irrelevant]  \n",
              "4                                          [Irrelevant]  \n",
              "...                                                 ...  \n",
              "2497  [News, Sentiment, ContextualInformation, Advic...  \n",
              "2498  [News, Official, Sentiment, ContextualInformat...  \n",
              "2499                                       [Irrelevant]  \n",
              "2500  [News, EmergingThreats, Sentiment, ContextualI...  \n",
              "2501  [News, Location, EmergingThreats, Sentiment, C...  \n",
              "\n",
              "[2502 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JBajnpdxkq15",
        "colab": {}
      },
      "source": [
        "def build_trainingset(trainSet):\n",
        "  # Extract training set\n",
        "  featureList = ['full_text','entities','favorite_count'] #,'favorited'\n",
        "  trainF = EF(trainSet,featureList)\n",
        "\n",
        "  labelList = ['priority']\n",
        "  trainL_temp = EF(trainSet,labelList)['priority']\n",
        "  trainF = Ehashtags(trainF)\n",
        "  \n",
        "  trainL = []\n",
        "  for label in trainL_temp:\n",
        "    if label == 'Low':\n",
        "      trainL.append(0)\n",
        "    elif label == 'Medium':\n",
        "      trainL.append(1)\n",
        "    elif label == 'High':\n",
        "      trainL.append(2)\n",
        "    elif label == 'Critical':\n",
        "      trainL.append(3)\n",
        "  return trainF, trainL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6ZCOSD2hh67P",
        "colab": {}
      },
      "source": [
        "def store_csv(df,location,val_ratio=0.2):\n",
        "    trainF, trainL = build_trainingset(df)\n",
        "    \n",
        "    idx = np.arange(df.shape[0])\n",
        "    np.random.shuffle(idx)\n",
        "    \n",
        "    val_size = int(len(idx) * val_ratio)\n",
        "    if not os.path.exists('priority/'+location):\n",
        "        os.makedirs('priority/'+location)\n",
        "    \n",
        "    print(len(trainL))\n",
        "    df = pd.DataFrame(trainF)\n",
        "    df['target'] = trainL\n",
        "    df[['full_text','hashtags','favorite_count', 'target']].to_csv('priority/'+location+'/dataset_all.csv',\n",
        "                   index=False)\n",
        "    \n",
        "    \n",
        "    \n",
        "    # df_tmp = df.iloc[idx[val_size:]\n",
        "    # df_test = df.iloc[idx[:val_size]\n",
        "    df.iloc[idx[val_size:], :][['full_text','hashtags','favorite_count','target']].to_csv('priority/'+location+'/dataset_test.csv',\n",
        "                   index=False)\n",
        "                      \n",
        "    df.iloc[idx[val_size:], :][['full_text','hashtags','favorite_count','target']].to_csv(\n",
        "        'priority/'+location+'/dataset_train.csv',index=False)\n",
        "    \n",
        "    # df.iloc[idx[:val_size], :][['full_text','entities','favorite_count', target]].to_csv(\n",
        "    #     'cache/dataset_val.csv', index=False\n",
        "    # )\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yiwCid50h_1b",
        "colab": {},
        "outputId": "0d9bb7cf-f135-438f-bf8f-4dd831469448"
      },
      "source": [
        "# Store training,  test set into csv file\n",
        "if not os.path.exists('/priority/'):\n",
        "  store_csv(cv19_ws_labeled,location='WS') \n",
        "  store_csv(cv19_dc_labeled,location='DC') \n",
        "  store_csv(cv19_ny_labeled,location='NY') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2577\n",
            "2504\n",
            "2502\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eKW6cvK2S1gO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 682
        },
        "outputId": "4d6a380e-9af9-4195-ba24-07ccc263d773"
      },
      "source": [
        "# check GPU situation\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Aug 30 12:53:17 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.87.00    Driver Version: 418.87.00    CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  TITAN RTX           Off  | 00000000:1A:00.0 Off |                  N/A |\n",
            "| 41%   46C    P8    10W / 280W |      0MiB / 24190MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_WMgHowZTSSS"
      },
      "source": [
        "# Pre-processing data set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PEK67bBooRRc",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "c0ab7966-01f2-490b-ec28-cc4df7056b1f"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 3.3MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting dataclasses; python_version < \"3.7\" (from transformers)\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/d2/6f02df2616fd4016075f60157c7a0452b38d8f7938ae94343911e0fb0b09/dataclasses-0.7-py3-none-any.whl\n",
            "Collecting regex!=2019.12.17 (from transformers)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/f2/b3af9ce9df4b7e121dfeece41fc95e37b14f0153821f35d08edb0b0813ff/regex-2020.7.14-cp36-cp36m-manylinux2010_x86_64.whl (660kB)\n",
            "\u001b[K     |████████████████████████████████| 665kB 15.0MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.22.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.0)\n",
            "Collecting tokenizers==0.8.1.rc1 (from transformers)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 9.4MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting sacremoses (from transformers)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 10.8MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting packaging (from transformers)\n",
            "  Downloading https://files.pythonhosted.org/packages/46/19/c5ab91b1b05cfe63cccd5cfc971db9214c6dd6ced54e33c30d5af1d2bc43/packaging-20.4-py2.py3-none-any.whl\n",
            "Collecting sentencepiece!=0.1.92 (from transformers)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 11.1MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.48.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.25.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.6.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Collecting click (from sacremoses->transformers)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/3d/fa76db83bf75c4f8d338c2fd15c8d33fdd7ad23a9b5e57eb6c5de26b430e/click-7.1.2-py2.py3-none-any.whl (82kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 17.1MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.13.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=bcbfd05d2b4b1597fe5d7207a7dd700ef2d65a2737f8f4c543f25d2dc356fcf5\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: dataclasses, regex, tokenizers, click, sacremoses, packaging, sentencepiece, transformers\n",
            "Successfully installed click-7.1.2 dataclasses-0.7 packaging-20.4 regex-2020.7.14 sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n",
            "\u001b[33mWARNING: You are using pip version 19.2.2, however version 20.2.2 is available.\n",
            "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rayB7Vg3LQi",
        "colab_type": "text"
      },
      "source": [
        "## Tokenization: Bert tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "exM0PU17oTCr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "32fe6f3f-14e7-4f69-ffaa-eed75368b54c"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I0831 04:09:08.217187 139633676007232 file_utils.py:39] PyTorch version 1.6.0+cu101 available.\n",
            "I0831 04:09:09.138132 139633676007232 file_utils.py:55] TensorFlow version 2.3.0 available.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0831 04:09:09.605131 139633676007232 tokenization_utils_base.py:1254] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZFr2zkR6UTWR",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "dataset_inputs = pd.read_csv('priority/NY/dataset_all.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Mcku0Wr0Ur8F",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "ac3bfe40-49bc-44bc-8b89-f54eaa486de7"
      },
      "source": [
        "dataset_inputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>full_text</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Reopening states will cause 233,000 more peopl...</td>\n",
              "      <td>NYC Georgia Florida Ohio California Michigan ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@samiglee @flash__delirium @michaelbd @mtracey...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>We Met Up with Whalebone on Bleecker, and then...</td>\n",
              "      <td></td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>‘White-Collar Quarantine’ Over Virus Spotlight...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Lost Month: How a Failure to Test Blinded ...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Coronavirus: Governors Ball 2020 cancelled ami...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Some coronavirus positivity this morning. http...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>@MariaBartiromo @MorningsMaria @FoxBusiness A ...</td>\n",
              "      <td>Covid19</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>» Correspondence from Dr Vladimir Zelenko on T...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Just a reminder that #nopantssubwayride across...</td>\n",
              "      <td>nopantssubwayride COVID19 nyc subway Covid_19...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>@realDonaldTrump @WhiteHouse DJT, more tempora...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Coronavirus Update: New York Health Officials ...</td>\n",
              "      <td></td>\n",
              "      <td>207</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Rihanna thanked for her contributions to the c...</td>\n",
              "      <td></td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Opinion | Why Telling People They Don’t Need M...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Trump Rejects New York’s Plea For Ventilators:...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Trump's idea might work if NY, NJ and NYC had ...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>New York asks domain registrars to crack down ...</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>@ndrew_lawrence Replace New York with @BarackO...</td>\n",
              "      <td></td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>@NYTHealth Have you covered the hospital closu...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>BREAKING:Newyork reports 7681new cases of coro...</td>\n",
              "      <td></td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Wanted to do a #Covid_19 check in with some NY...</td>\n",
              "      <td>Covid_19 teacherfriends remoteteaching Teache...</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>🇺🇸 Stay strong New York and stay safe!\\n\\n2 Co...</td>\n",
              "      <td>COVID19 coronausa CoronavirusUSA CoronaUpdate...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>N.Y.P.D. Has 500 Coronavirus Cases and 2nd Civ...</td>\n",
              "      <td>coronavirus NYPD</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>A bit late you bumbling idiot! \\n\\nTrump says ...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Get Ready #NYPD - #NYC jail population will be...</td>\n",
              "      <td>NYPD NYC coronavirus Dems GOP COVID19</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Do @nytimes 13 Deaths in a Day: An ‘Apocalypti...</td>\n",
              "      <td></td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Coronavirus Stimulus Package F.A.Q.: Checks, U...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Right now if you add up the New York and New J...</td>\n",
              "      <td></td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>@LuckythePomChi, me, &amp;amp; https://t.co/NJUa29...</td>\n",
              "      <td>SocialDistancing Netflix NewYork StayAtHomeAn...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Just wonderful: \\nhttps://t.co/Si6Z5zhBqj</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2472</th>\n",
              "      <td>Hospital Ship Arrives in N.Y. to Help \\n\\nMaje...</td>\n",
              "      <td>Covid19</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2473</th>\n",
              "      <td>Nyc is at 15,000 coronavirus cases🥴 I might be...</td>\n",
              "      <td></td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2474</th>\n",
              "      <td>@elerianm The data from scientists show we'll ...</td>\n",
              "      <td></td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2475</th>\n",
              "      <td>@SaneManyathi @eNCA And NYC is the worst hit b...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2476</th>\n",
              "      <td>‘People Are Dying’: 72 Hours Inside a N.Y.C. H...</td>\n",
              "      <td>DeborahBirx BloodOnYourHands TrumpLiedPeopleD...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2477</th>\n",
              "      <td>Because he’s been so  accurate with his other ...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2478</th>\n",
              "      <td>“The Monty Python version of Israeli Palestine...</td>\n",
              "      <td></td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2479</th>\n",
              "      <td>@criticalneuro @behrenstimb Also, the daily su...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2480</th>\n",
              "      <td>@Alan78523817 @CNN Then YOU go to New York or ...</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2481</th>\n",
              "      <td>Sikhs To The Rescue Again: Community Cooks Fre...</td>\n",
              "      <td></td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2482</th>\n",
              "      <td>LGBT activists slam New York COVID-19 field ho...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2483</th>\n",
              "      <td>Mayor Deblasio encourages everyone to go about...</td>\n",
              "      <td>NewYork coronavirus nyccoronavirus CoronaAler...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2484</th>\n",
              "      <td>@AjaxMull @billtaggard @Manfredi1 @Jim71213440...</td>\n",
              "      <td></td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2485</th>\n",
              "      <td>Trump Rejects New York’s Plea For Ventilators:...</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2486</th>\n",
              "      <td>Coronavirus spreading in New York like 'a bull...</td>\n",
              "      <td></td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2487</th>\n",
              "      <td>Tucker: How New York's leaders failed their ci...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2488</th>\n",
              "      <td>@JoeNBC .@NYCMayor and @NYGovCuomo  @NYGovCuom...</td>\n",
              "      <td>coronavirus Covid_19</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2489</th>\n",
              "      <td>@realDonaldTrump has a personal vendetta again...</td>\n",
              "      <td>Covid19 Coronavirus MAGA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2490</th>\n",
              "      <td>Scenes of \"catastrophe\" as New York hospitals ...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2491</th>\n",
              "      <td>The issue is Trump thinks Cuomo has been mean ...</td>\n",
              "      <td></td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2492</th>\n",
              "      <td>Knicks Owner, MSG Chairman James Dolan Has Cor...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2493</th>\n",
              "      <td>Finally, something that deserves the adjective...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2494</th>\n",
              "      <td>@TimVader3 @OffGuardian0 FEB 7, 2020:\\n\\n\"Ther...</td>\n",
              "      <td>flu NewYorkCity</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2495</th>\n",
              "      <td>‘There’s No Way We Can Bury or Cremate Them Fa...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2496</th>\n",
              "      <td>Coronavirus in NYC: Judges outraged after NYC ...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2497</th>\n",
              "      <td>Trump keeps touting an unproven coronavirus tr...</td>\n",
              "      <td>chloroquine</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2498</th>\n",
              "      <td>Despicable human being\\nhttps://t.co/WVBvDmmsmm</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2499</th>\n",
              "      <td>#ThisDay 1841 - \"First US steam fire engine te...</td>\n",
              "      <td>ThisDay</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2500</th>\n",
              "      <td>New York City hospitals are already strained t...</td>\n",
              "      <td></td>\n",
              "      <td>127</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2501</th>\n",
              "      <td>New York City's #Elmhurst Hospital, located in...</td>\n",
              "      <td>Elmhurst COVID19</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2502 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              full_text  \\\n",
              "0     Reopening states will cause 233,000 more peopl...   \n",
              "1     @samiglee @flash__delirium @michaelbd @mtracey...   \n",
              "2     We Met Up with Whalebone on Bleecker, and then...   \n",
              "3     ‘White-Collar Quarantine’ Over Virus Spotlight...   \n",
              "4     The Lost Month: How a Failure to Test Blinded ...   \n",
              "...                                                 ...   \n",
              "2497  Trump keeps touting an unproven coronavirus tr...   \n",
              "2498    Despicable human being\\nhttps://t.co/WVBvDmmsmm   \n",
              "2499  #ThisDay 1841 - \"First US steam fire engine te...   \n",
              "2500  New York City hospitals are already strained t...   \n",
              "2501  New York City's #Elmhurst Hospital, located in...   \n",
              "\n",
              "                                               hashtags  favorite_count  \\\n",
              "0      NYC Georgia Florida Ohio California Michigan ...               0   \n",
              "1                                                                     0   \n",
              "2                                                                    22   \n",
              "3                                                                     0   \n",
              "4                                                                     0   \n",
              "...                                                 ...             ...   \n",
              "2497                                       chloroquine                0   \n",
              "2498                                                                  0   \n",
              "2499                                           ThisDay                0   \n",
              "2500                                                                127   \n",
              "2501                                  Elmhurst COVID19                0   \n",
              "\n",
              "      target  \n",
              "0          0  \n",
              "1          0  \n",
              "2          0  \n",
              "3          0  \n",
              "4          0  \n",
              "...      ...  \n",
              "2497       0  \n",
              "2498       0  \n",
              "2499       0  \n",
              "2500       0  \n",
              "2501       0  \n",
              "\n",
              "[2502 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e7xSdCaDxEcZ",
        "colab": {}
      },
      "source": [
        "sentences = dataset_inputs.full_text.values\n",
        "labels = dataset_inputs.target.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B00Q6EqpAwPX",
        "colab": {}
      },
      "source": [
        "for idx in range(len(sentences)):\n",
        "  sentences[idx] = sentences[idx]  + ' '+ dataset_inputs.hashtags.values[idx] + ' ' + str(dataset_inputs.favorite_count.values[idx])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fRsXPrQSoghI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "9cc86b8f-d723-4580-b85c-74836fc58530"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  Reopening states will cause 233,000 more people to die from coronavirus, according to Wharton model: https://t.co/nYwBXFDVJR @realDonaldTrump @SpeakerPelosi @SenSchumer @AOC @RandPaul @SenSanders @RepKatiePorter #NYC #Georgia #Florida #Ohio #California #Michigan #Canada #London  NYC Georgia Florida Ohio California Michigan Canada London  0\n",
            "Tokenized:  ['re', '##open', '##ing', 'states', 'will', 'cause', '233', ',', '000', 'more', 'people', 'to', 'die', 'from', 'corona', '##virus', ',', 'according', 'to', 'wharton', 'model', ':', 'https', ':', '/', '/', 't', '.', 'co', '/', 'ny', '##w', '##b', '##x', '##f', '##d', '##v', '##j', '##r', '@', 'real', '##don', '##ald', '##trum', '##p', '@', 'speaker', '##pel', '##osi', '@', 'sen', '##sch', '##ume', '##r', '@', 'ao', '##c', '@', 'rand', '##pa', '##ul', '@', 'sen', '##san', '##ders', '@', 'rep', '##kat', '##ie', '##port', '##er', '#', 'nyc', '#', 'georgia', '#', 'florida', '#', 'ohio', '#', 'california', '#', 'michigan', '#', 'canada', '#', 'london', 'nyc', 'georgia', 'florida', 'ohio', 'california', 'michigan', 'canada', 'london', '0']\n",
            "Token IDs:  [2128, 26915, 2075, 2163, 2097, 3426, 22115, 1010, 2199, 2062, 2111, 2000, 3280, 2013, 21887, 23350, 1010, 2429, 2000, 24249, 2944, 1024, 16770, 1024, 1013, 1013, 1056, 1012, 2522, 1013, 6396, 2860, 2497, 2595, 2546, 2094, 2615, 3501, 2099, 1030, 2613, 5280, 19058, 24456, 2361, 1030, 5882, 11880, 20049, 1030, 12411, 11624, 17897, 2099, 1030, 20118, 2278, 1030, 14566, 4502, 5313, 1030, 12411, 8791, 13375, 1030, 16360, 24498, 2666, 6442, 2121, 1001, 16392, 1001, 4108, 1001, 3516, 1001, 4058, 1001, 2662, 1001, 4174, 1001, 2710, 1001, 2414, 16392, 4108, 3516, 4058, 2662, 4174, 2710, 2414, 1014]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_TBTr_m3xsxE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "9ef61b9b-149d-4ff6-b1e5-edd31e31a9ef"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    # If the length of token is over the bert limitation, cut off the back\n",
        "    if(len(encoded_sent)>144):\n",
        "        diff = int((len(encoded_sent) - 145)/2)\n",
        "        encoded_sent = encoded_sent[diff:144+diff]\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Reopening states will cause 233,000 more people to die from coronavirus, according to Wharton model: https://t.co/nYwBXFDVJR @realDonaldTrump @SpeakerPelosi @SenSchumer @AOC @RandPaul @SenSanders @RepKatiePorter #NYC #Georgia #Florida #Ohio #California #Michigan #Canada #London  NYC Georgia Florida Ohio California Michigan Canada London  0\n",
            "Token IDs: [101, 2128, 26915, 2075, 2163, 2097, 3426, 22115, 1010, 2199, 2062, 2111, 2000, 3280, 2013, 21887, 23350, 1010, 2429, 2000, 24249, 2944, 1024, 16770, 1024, 1013, 1013, 1056, 1012, 2522, 1013, 6396, 2860, 2497, 2595, 2546, 2094, 2615, 3501, 2099, 1030, 2613, 5280, 19058, 24456, 2361, 1030, 5882, 11880, 20049, 1030, 12411, 11624, 17897, 2099, 1030, 20118, 2278, 1030, 14566, 4502, 5313, 1030, 12411, 8791, 13375, 1030, 16360, 24498, 2666, 6442, 2121, 1001, 16392, 1001, 4108, 1001, 3516, 1001, 4058, 1001, 2662, 1001, 4174, 1001, 2710, 1001, 2414, 16392, 4108, 3516, 4058, 2662, 4174, 2710, 2414, 1014, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O1AE4zwVq0YY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "532ce0d0-f17e-4fdb-cc2e-fd7f8b1e8c29"
      },
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ndJtJ9KDDuQU",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "tmp = pd.Series([len(sen) for sen in input_ids])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v2knxh0EDuQW",
        "colab": {},
        "outputId": "7e711276-8176-401f-fab3-d2a950b096a6"
      },
      "source": [
        "# number of tweet which has over 144 tokens\n",
        "np.sum(tmp>144)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgiIOVfp3xaq",
        "colab_type": "text"
      },
      "source": [
        "## Padding\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LSodElwwq5I8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "f7069e6c-72c7-442f-bb07-6b03522f723d"
      },
      "source": [
        "\n",
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "\n",
        "MAX_LEN = 144\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 144 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d81bdiag3yTf",
        "colab_type": "text"
      },
      "source": [
        "## Attension mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a-Uy0tqMrP79",
        "colab": {}
      },
      "source": [
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0ZZCgHNyrfuV"
      },
      "source": [
        "## Training & Validation Split\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HhXzbVJMrhEo",
        "colab": {}
      },
      "source": [
        "# Use train_test_split to split our data into train and validation and test sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "temp_inputs, test_inputs,  temp_labels, test_labels = train_test_split(input_ids, labels, test_size=0.2)\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(temp_inputs, temp_labels, test_size=0.2)\n",
        "# Do the same for the masks.\n",
        "temp_masks, test_masks, temp_labels, _ = train_test_split(attention_masks, labels, test_size=0.2)\n",
        "\n",
        "train_masks, validation_masks, _, _ = train_test_split(temp_masks, temp_labels, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-BfLU6bRZM59"
      },
      "source": [
        "# Conduct the fine-tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6WR_3RiPrPLY",
        "colab": {}
      },
      "source": [
        "categories = {0:'Low',1:'Medium',2:'High',3:'Critical'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ne1MgAsnSdBd"
      },
      "source": [
        "## Search the best hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JMz5wA8hFeU8",
        "colab": {}
      },
      "source": [
        "# build the test batch\n",
        "testbatch = [test_inputs,test_labels,test_masks]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7bO-TypfDuQr",
        "scrolled": true,
        "colab": {},
        "outputId": "d10b785d-1ddf-4ba9-f3b0-0ee8997f9570"
      },
      "source": [
        "from collections import defaultdict\n",
        "all_metrics_search = defaultdict()\n",
        "for batch_size in [16]: #16,\n",
        "  for lr in [5e-5,3e-5,2e-5]:\n",
        "    print('Currently processing %s'%(str(batch_size) + '_' + str(lr)))\n",
        "    Bert = Bertnn(train_inputs,train_labels,train_masks, validation_inputs,validation_labels,validation_masks,testbatch,batch_size=batch_size,lr=lr)\n",
        "    all_metrics_one = Bert.searchUpsample(14)\n",
        "    filename = str(batch_size) + '_' + str(lr)\n",
        "    all_metrics_search[name] = all_metrics_one\n",
        "    \n",
        "    # store result into file\n",
        "    with open(filename,'w') as file_obj:\n",
        "      json.dump(all_metrics_one,file_obj)\n",
        "      print('Successfully save file %s'%(filename))\n",
        "    del Bert"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Currently processing 16_5e-05\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: TITAN RTX\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 09:27:57.691102 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 09:27:57.693360 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 09:27:58.577491 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 09:28:01.135404 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 09:28:01.137556 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current increase 0 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "(1600, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 09:28:01.846237 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 09:28:01.847458 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 09:28:01.886860 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 09:28:04.352188 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 09:28:04.352895 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    100.    Elapsed: 0:00:17.\n",
            "  Batch    80  of    100.    Elapsed: 0:00:34.\n",
            "\n",
            "  Average training loss: 0.56\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.84\n",
            "  Recall: 0.99\n",
            "  F1: 0.91\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "Category: 2\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.2101\n",
            "The average recall is: 0.2473\n",
            "The average f1 is: 0.2267\n",
            "  Training epcoh took: 0:00:43\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8486\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9146\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.2121\n",
            "The average recall is: 0.2500\n",
            "The average f1 is: 0.2286\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    100.    Elapsed: 0:00:17.\n",
            "  Batch    80  of    100.    Elapsed: 0:00:35.\n",
            "\n",
            "  Average training loss: 0.51\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.86\n",
            "  Recall: 0.99\n",
            "  F1: 0.92\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "Category: 2\n",
            "  Precision: 0.11\n",
            "  Recall: 0.06\n",
            "  F1: 0.07\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.2416\n",
            "The average recall is: 0.2625\n",
            "The average f1 is: 0.2472\n",
            "  Training epcoh took: 0:00:43\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8588\n",
            "  Recall: 0.9945\n",
            "  F1: 0.9193\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.1923\n",
            "  Recall: 0.1346\n",
            "  F1: 0.1538\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.2628\n",
            "The average recall is: 0.2823\n",
            "The average f1 is: 0.2683\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    100.    Elapsed: 0:00:18.\n",
            "  Batch    80  of    100.    Elapsed: 0:00:35.\n",
            "\n",
            "  Average training loss: 0.38\n",
            "  Accuracy: 0.89\n",
            "Category: 0\n",
            "  Precision: 0.91\n",
            "  Recall: 0.98\n",
            "  F1: 0.94\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "Category: 2\n",
            "  Precision: 0.53\n",
            "  Recall: 0.45\n",
            "  F1: 0.46\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.3619\n",
            "The average recall is: 0.3570\n",
            "The average f1 is: 0.3498\n",
            "  Training epcoh took: 0:00:45\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8886\n",
            "  Recall: 0.9595\n",
            "  F1: 0.9200\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.4103\n",
            "  Recall: 0.3385\n",
            "  F1: 0.3406\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3247\n",
            "The average recall is: 0.3245\n",
            "The average f1 is: 0.3152\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    100.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    100.    Elapsed: 0:00:39.\n",
            "\n",
            "  Average training loss: 0.25\n",
            "  Accuracy: 0.93\n",
            "Category: 0\n",
            "  Precision: 0.95\n",
            "  Recall: 0.99\n",
            "  F1: 0.97\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "Category: 2\n",
            "  Precision: 0.67\n",
            "  Recall: 0.66\n",
            "  F1: 0.64\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.4045\n",
            "The average recall is: 0.4124\n",
            "The average f1 is: 0.4023\n",
            "  Training epcoh took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8953\n",
            "  Recall: 0.9598\n",
            "  F1: 0.9237\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.4096\n",
            "  Recall: 0.4167\n",
            "  F1: 0.3834\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3262\n",
            "The average recall is: 0.3441\n",
            "The average f1 is: 0.3268\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n",
            "Current increase 1 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 1647 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 1647 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 1828 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 1828 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 1840 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.7391304347826086\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "94\n",
            "0.051086956521739134\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "362\n",
            "0.1967391304347826\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "24\n",
            "0.013043478260869565\n",
            "\n",
            "(1840, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 09:31:15.789645 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 09:31:15.791061 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 09:31:15.883257 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 09:31:18.419791 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 09:31:18.422670 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    115.    Elapsed: 0:00:20.\n",
            "  Batch    80  of    115.    Elapsed: 0:00:40.\n",
            "\n",
            "  Average training loss: 0.76\n",
            "  Accuracy: 0.74\n",
            "Category: 0\n",
            "  Precision: 0.75\n",
            "  Recall: 0.97\n",
            "  F1: 0.84\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "Category: 2\n",
            "  Precision: 0.13\n",
            "  Recall: 0.10\n",
            "  F1: 0.10\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.2203\n",
            "The average recall is: 0.2676\n",
            "The average f1 is: 0.2355\n",
            "  Training epcoh took: 0:00:57\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8861\n",
            "  Recall: 0.9540\n",
            "  F1: 0.9166\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3782\n",
            "  Recall: 0.3391\n",
            "  F1: 0.3298\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3161\n",
            "The average recall is: 0.3233\n",
            "The average f1 is: 0.3116\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    115.    Elapsed: 0:00:20.\n",
            "  Batch    80  of    115.    Elapsed: 0:00:41.\n",
            "\n",
            "  Average training loss: 0.53\n",
            "  Accuracy: 0.83\n",
            "Category: 0\n",
            "  Precision: 0.86\n",
            "  Recall: 0.97\n",
            "  F1: 0.91\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "Category: 2\n",
            "  Precision: 0.68\n",
            "  Recall: 0.58\n",
            "  F1: 0.59\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.3851\n",
            "The average recall is: 0.3860\n",
            "The average f1 is: 0.3736\n",
            "  Training epcoh took: 0:00:58\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.77\n",
            "Category: 0\n",
            "  Precision: 0.8716\n",
            "  Recall: 0.8311\n",
            "  F1: 0.8473\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3154\n",
            "  Recall: 0.5449\n",
            "  F1: 0.3879\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.2967\n",
            "The average recall is: 0.3440\n",
            "The average f1 is: 0.3088\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    115.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    115.    Elapsed: 0:00:43.\n",
            "\n",
            "  Average training loss: 0.29\n",
            "  Accuracy: 0.91\n",
            "Category: 0\n",
            "  Precision: 0.94\n",
            "  Recall: 0.98\n",
            "  F1: 0.96\n",
            "Category: 1\n",
            "  Precision: 0.08\n",
            "  Recall: 0.06\n",
            "  F1: 0.06\n",
            "Category: 2\n",
            "  Precision: 0.80\n",
            "  Recall: 0.90\n",
            "  F1: 0.83\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.4564\n",
            "The average recall is: 0.4839\n",
            "The average f1 is: 0.4631\n",
            "  Training epcoh took: 0:01:01\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8964\n",
            "  Recall: 0.9516\n",
            "  F1: 0.9207\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0192\n",
            "  F1: 0.0256\n",
            "Category: 2\n",
            "  Precision: 0.3295\n",
            "  Recall: 0.3429\n",
            "  F1: 0.3051\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3161\n",
            "The average recall is: 0.3284\n",
            "The average f1 is: 0.3129\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    115.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    115.    Elapsed: 0:00:43.\n",
            "\n",
            "  Average training loss: 0.13\n",
            "  Accuracy: 0.97\n",
            "Category: 0\n",
            "  Precision: 0.98\n",
            "  Recall: 1.00\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.42\n",
            "  Recall: 0.40\n",
            "  F1: 0.40\n",
            "Category: 2\n",
            "  Precision: 0.92\n",
            "  Recall: 0.95\n",
            "  F1: 0.93\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5806\n",
            "The average recall is: 0.5881\n",
            "The average f1 is: 0.5799\n",
            "  Training epcoh took: 0:01:02\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "Category: 0\n",
            "  Precision: 0.8611\n",
            "  Recall: 0.9278\n",
            "  F1: 0.8914\n",
            "Category: 1\n",
            "  Precision: 0.1154\n",
            "  Recall: 0.0897\n",
            "  F1: 0.0962\n",
            "Category: 2\n",
            "  Precision: 0.5705\n",
            "  Recall: 0.3942\n",
            "  F1: 0.4425\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3867\n",
            "The average recall is: 0.3529\n",
            "The average f1 is: 0.3575\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n",
            "Current increase 2 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 1694 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 1694 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 2056 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 2056 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 2080 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.6538461538461539\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "141\n",
            "0.06778846153846153\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "543\n",
            "0.2610576923076923\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "36\n",
            "0.01730769230769231\n",
            "\n",
            "(2080, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 09:35:31.058253 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 09:35:31.059537 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 09:35:31.201044 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 09:35:33.733349 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 09:35:33.734050 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    130.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    130.    Elapsed: 0:00:43.\n",
            "  Batch   120  of    130.    Elapsed: 0:01:05.\n",
            "\n",
            "  Average training loss: 0.81\n",
            "  Accuracy: 0.68\n",
            "Category: 0\n",
            "  Precision: 0.71\n",
            "  Recall: 0.93\n",
            "  F1: 0.79\n",
            "Category: 1\n",
            "  Precision: 0.01\n",
            "  Recall: 0.01\n",
            "  F1: 0.01\n",
            "Category: 2\n",
            "  Precision: 0.37\n",
            "  Recall: 0.29\n",
            "  F1: 0.29\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.2709\n",
            "The average recall is: 0.3059\n",
            "The average f1 is: 0.2725\n",
            "  Training epcoh took: 0:01:10\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8789\n",
            "  Recall: 0.9738\n",
            "  F1: 0.9218\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3397\n",
            "  Recall: 0.2385\n",
            "  F1: 0.2615\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3047\n",
            "The average recall is: 0.3031\n",
            "The average f1 is: 0.2958\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    130.    Elapsed: 0:00:22.\n",
            "  Batch    80  of    130.    Elapsed: 0:00:44.\n",
            "  Batch   120  of    130.    Elapsed: 0:01:07.\n",
            "\n",
            "  Average training loss: 0.40\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.89\n",
            "  Recall: 0.96\n",
            "  F1: 0.92\n",
            "Category: 1\n",
            "  Precision: 0.23\n",
            "  Recall: 0.19\n",
            "  F1: 0.20\n",
            "Category: 2\n",
            "  Precision: 0.85\n",
            "  Recall: 0.86\n",
            "  F1: 0.83\n",
            "Category: 3\n",
            "  Precision: 0.02\n",
            "  Recall: 0.02\n",
            "  F1: 0.02\n",
            "The average precision is: 0.4963\n",
            "The average recall is: 0.5062\n",
            "The average f1 is: 0.4924\n",
            "  Training epcoh took: 0:01:12\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "Category: 0\n",
            "  Precision: 0.8475\n",
            "  Recall: 0.9227\n",
            "  F1: 0.8809\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.4295\n",
            "  Recall: 0.3782\n",
            "  F1: 0.3782\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3192\n",
            "The average recall is: 0.3252\n",
            "The average f1 is: 0.3148\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    130.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    130.    Elapsed: 0:00:45.\n",
            "  Batch   120  of    130.    Elapsed: 0:01:07.\n",
            "\n",
            "  Average training loss: 0.10\n",
            "  Accuracy: 0.97\n",
            "Category: 0\n",
            "  Precision: 0.98\n",
            "  Recall: 0.99\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 0.63\n",
            "  Recall: 0.65\n",
            "  F1: 0.63\n",
            "Category: 2\n",
            "  Precision: 0.95\n",
            "  Recall: 0.96\n",
            "  F1: 0.95\n",
            "Category: 3\n",
            "  Precision: 0.14\n",
            "  Recall: 0.12\n",
            "  F1: 0.13\n",
            "The average precision is: 0.6741\n",
            "The average recall is: 0.6805\n",
            "The average f1 is: 0.6724\n",
            "  Training epcoh took: 0:01:13\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8958\n",
            "  Recall: 0.9275\n",
            "  F1: 0.9097\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.3974\n",
            "  Recall: 0.3795\n",
            "  F1: 0.3596\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3425\n",
            "The average recall is: 0.3460\n",
            "The average f1 is: 0.3365\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    130.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    130.    Elapsed: 0:00:45.\n",
            "  Batch   120  of    130.    Elapsed: 0:01:07.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.71\n",
            "  Recall: 0.71\n",
            "  F1: 0.71\n",
            "Category: 2\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 3\n",
            "  Precision: 0.24\n",
            "  Recall: 0.24\n",
            "  F1: 0.24\n",
            "The average precision is: 0.7343\n",
            "The average recall is: 0.7347\n",
            "The average f1 is: 0.7343\n",
            "  Training epcoh took: 0:01:13\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8932\n",
            "  Recall: 0.9497\n",
            "  F1: 0.9179\n",
            "Category: 1\n",
            "  Precision: 0.0577\n",
            "  Recall: 0.0513\n",
            "  F1: 0.0449\n",
            "Category: 2\n",
            "  Precision: 0.3808\n",
            "  Recall: 0.3167\n",
            "  F1: 0.3275\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3329\n",
            "The average recall is: 0.3294\n",
            "The average f1 is: 0.3226\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "Training complete!\n",
            "Current increase 3 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 1741 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 1741 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 2284 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 2284 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 2320 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.5862068965517241\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "188\n",
            "0.08103448275862069\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "724\n",
            "0.3120689655172414\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "48\n",
            "0.020689655172413793\n",
            "\n",
            "(2320, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 09:40:37.651795 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 09:40:37.653630 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 09:40:37.734997 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 09:40:40.389882 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 09:40:40.390894 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    145.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    145.    Elapsed: 0:00:45.\n",
            "  Batch   120  of    145.    Elapsed: 0:01:07.\n",
            "\n",
            "  Average training loss: 0.93\n",
            "  Accuracy: 0.63\n",
            "Category: 0\n",
            "  Precision: 0.65\n",
            "  Recall: 0.90\n",
            "  F1: 0.74\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "Category: 2\n",
            "  Precision: 0.36\n",
            "  Recall: 0.32\n",
            "  F1: 0.31\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.01\n",
            "  F1: 0.00\n",
            "The average precision is: 0.2544\n",
            "The average recall is: 0.3070\n",
            "The average f1 is: 0.2626\n",
            "  Training epcoh took: 0:01:22\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8766\n",
            "  Recall: 0.9741\n",
            "  F1: 0.9207\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3462\n",
            "  Recall: 0.2276\n",
            "  F1: 0.2637\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3057\n",
            "The average recall is: 0.3004\n",
            "The average f1 is: 0.2961\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    145.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    145.    Elapsed: 0:00:45.\n",
            "  Batch   120  of    145.    Elapsed: 0:01:08.\n",
            "\n",
            "  Average training loss: 0.60\n",
            "  Accuracy: 0.81\n",
            "Category: 0\n",
            "  Precision: 0.81\n",
            "  Recall: 0.95\n",
            "  F1: 0.87\n",
            "Category: 1\n",
            "  Precision: 0.07\n",
            "  Recall: 0.04\n",
            "  F1: 0.05\n",
            "Category: 2\n",
            "  Precision: 0.81\n",
            "  Recall: 0.79\n",
            "  F1: 0.78\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.4236\n",
            "The average recall is: 0.4442\n",
            "The average f1 is: 0.4234\n",
            "  Training epcoh took: 0:01:22\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8861\n",
            "  Recall: 0.9686\n",
            "  F1: 0.9225\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0385\n",
            "Category: 2\n",
            "  Precision: 0.4744\n",
            "  Recall: 0.3506\n",
            "  F1: 0.3718\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3497\n",
            "The average recall is: 0.3394\n",
            "The average f1 is: 0.3332\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    145.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    145.    Elapsed: 0:00:46.\n",
            "  Batch   120  of    145.    Elapsed: 0:01:09.\n",
            "\n",
            "  Average training loss: 0.34\n",
            "  Accuracy: 0.90\n",
            "Category: 0\n",
            "  Precision: 0.91\n",
            "  Recall: 0.97\n",
            "  F1: 0.94\n",
            "Category: 1\n",
            "  Precision: 0.43\n",
            "  Recall: 0.39\n",
            "  F1: 0.39\n",
            "Category: 2\n",
            "  Precision: 0.95\n",
            "  Recall: 0.93\n",
            "  F1: 0.93\n",
            "Category: 3\n",
            "  Precision: 0.01\n",
            "  Recall: 0.01\n",
            "  F1: 0.01\n",
            "The average precision is: 0.5730\n",
            "The average recall is: 0.5743\n",
            "The average f1 is: 0.5651\n",
            "  Training epcoh took: 0:01:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8994\n",
            "  Recall: 0.9673\n",
            "  F1: 0.9290\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0705\n",
            "Category: 2\n",
            "  Precision: 0.3782\n",
            "  Recall: 0.2596\n",
            "  F1: 0.2923\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3386\n",
            "The average recall is: 0.3260\n",
            "The average f1 is: 0.3230\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    145.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    145.    Elapsed: 0:00:47.\n",
            "  Batch   120  of    145.    Elapsed: 0:01:09.\n",
            "\n",
            "  Average training loss: 0.13\n",
            "  Accuracy: 0.97\n",
            "Category: 0\n",
            "  Precision: 0.96\n",
            "  Recall: 0.99\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 0.66\n",
            "  Recall: 0.64\n",
            "  F1: 0.64\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 0.98\n",
            "  F1: 0.98\n",
            "Category: 3\n",
            "  Precision: 0.19\n",
            "  Recall: 0.18\n",
            "  F1: 0.18\n",
            "The average precision is: 0.7007\n",
            "The average recall is: 0.6962\n",
            "The average f1 is: 0.6950\n",
            "  Training epcoh took: 0:01:24\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.9085\n",
            "  Recall: 0.9298\n",
            "  F1: 0.9153\n",
            "Category: 1\n",
            "  Precision: 0.0962\n",
            "  Recall: 0.1538\n",
            "  F1: 0.1154\n",
            "Category: 2\n",
            "  Precision: 0.4615\n",
            "  Recall: 0.3365\n",
            "  F1: 0.3628\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3665\n",
            "The average recall is: 0.3550\n",
            "The average f1 is: 0.3484\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "Training complete!\n",
            "Current increase 4 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 1788 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 1788 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 2512 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 2512 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 2560 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.53125\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "235\n",
            "0.091796875\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "905\n",
            "0.353515625\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "60\n",
            "0.0234375\n",
            "\n",
            "(2560, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 09:46:27.010036 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 09:46:27.011184 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 09:46:28.340270 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 09:46:30.929598 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 09:46:30.931146 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    160.    Elapsed: 0:00:22.\n",
            "  Batch    80  of    160.    Elapsed: 0:00:45.\n",
            "  Batch   120  of    160.    Elapsed: 0:01:08.\n",
            "\n",
            "  Average training loss: 0.80\n",
            "  Accuracy: 0.67\n",
            "Category: 0\n",
            "  Precision: 0.68\n",
            "  Recall: 0.85\n",
            "  F1: 0.73\n",
            "Category: 1\n",
            "  Precision: 0.17\n",
            "  Recall: 0.14\n",
            "  F1: 0.14\n",
            "Category: 2\n",
            "  Precision: 0.65\n",
            "  Recall: 0.59\n",
            "  F1: 0.57\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.3731\n",
            "The average recall is: 0.3941\n",
            "The average f1 is: 0.3615\n",
            "  Training epcoh took: 0:01:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.80\n",
            "Category: 0\n",
            "  Precision: 0.8853\n",
            "  Recall: 0.8789\n",
            "  F1: 0.8780\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.2404\n",
            "  Recall: 0.3114\n",
            "  F1: 0.2488\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.2814\n",
            "The average recall is: 0.2976\n",
            "The average f1 is: 0.2817\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    160.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    160.    Elapsed: 0:00:46.\n",
            "  Batch   120  of    160.    Elapsed: 0:01:09.\n",
            "\n",
            "  Average training loss: 0.19\n",
            "  Accuracy: 0.94\n",
            "Category: 0\n",
            "  Precision: 0.94\n",
            "  Recall: 0.97\n",
            "  F1: 0.95\n",
            "Category: 1\n",
            "  Precision: 0.67\n",
            "  Recall: 0.67\n",
            "  F1: 0.66\n",
            "Category: 2\n",
            "  Precision: 0.97\n",
            "  Recall: 0.96\n",
            "  F1: 0.96\n",
            "Category: 3\n",
            "  Precision: 0.14\n",
            "  Recall: 0.14\n",
            "  F1: 0.14\n",
            "The average precision is: 0.6810\n",
            "The average recall is: 0.6855\n",
            "The average f1 is: 0.6786\n",
            "  Training epcoh took: 0:01:32\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8967\n",
            "  Recall: 0.9656\n",
            "  F1: 0.9266\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.3910\n",
            "  Recall: 0.3263\n",
            "  F1: 0.3271\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3412\n",
            "The average recall is: 0.3422\n",
            "The average f1 is: 0.3327\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    160.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    160.    Elapsed: 0:00:46.\n",
            "  Batch   120  of    160.    Elapsed: 0:01:09.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.81\n",
            "  Recall: 0.80\n",
            "  F1: 0.81\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.30\n",
            "  Recall: 0.31\n",
            "  F1: 0.30\n",
            "The average precision is: 0.7763\n",
            "The average recall is: 0.7762\n",
            "The average f1 is: 0.7756\n",
            "  Training epcoh took: 0:01:32\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8875\n",
            "  Recall: 0.9683\n",
            "  F1: 0.9235\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.4295\n",
            "  Recall: 0.3173\n",
            "  F1: 0.3476\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3293\n",
            "The average recall is: 0.3214\n",
            "The average f1 is: 0.3178\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    160.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    160.    Elapsed: 0:00:46.\n",
            "  Batch   120  of    160.    Elapsed: 0:01:09.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.78\n",
            "  Recall: 0.78\n",
            "  F1: 0.78\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.31\n",
            "  Recall: 0.31\n",
            "  F1: 0.31\n",
            "The average precision is: 0.7701\n",
            "The average recall is: 0.7701\n",
            "The average f1 is: 0.7701\n",
            "  Training epcoh took: 0:01:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "Category: 0\n",
            "  Precision: 0.8600\n",
            "  Recall: 0.9272\n",
            "  F1: 0.8902\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3590\n",
            "  Recall: 0.3526\n",
            "  F1: 0.3312\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3048\n",
            "The average recall is: 0.3199\n",
            "The average f1 is: 0.3054\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "Training complete!\n",
            "Current increase 5 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 1835 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 1835 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 2740 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 2740 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 2800 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.4857142857142857\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "282\n",
            "0.10071428571428571\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1086\n",
            "0.38785714285714284\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "72\n",
            "0.025714285714285714\n",
            "\n",
            "(2800, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 09:52:52.565766 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 09:52:52.567144 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 09:52:52.654521 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 09:52:55.193542 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 09:52:55.194257 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:22.\n",
            "  Batch    80  of    175.    Elapsed: 0:00:44.\n",
            "  Batch   120  of    175.    Elapsed: 0:01:07.\n",
            "  Batch   160  of    175.    Elapsed: 0:01:28.\n",
            "\n",
            "  Average training loss: 0.76\n",
            "  Accuracy: 0.68\n",
            "Category: 0\n",
            "  Precision: 0.69\n",
            "  Recall: 0.84\n",
            "  F1: 0.73\n",
            "Category: 1\n",
            "  Precision: 0.18\n",
            "  Recall: 0.12\n",
            "  F1: 0.14\n",
            "Category: 2\n",
            "  Precision: 0.64\n",
            "  Recall: 0.65\n",
            "  F1: 0.61\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.3777\n",
            "The average recall is: 0.4020\n",
            "The average f1 is: 0.3692\n",
            "  Training epcoh took: 0:01:37\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "Category: 0\n",
            "  Precision: 0.9029\n",
            "  Recall: 0.9122\n",
            "  F1: 0.9044\n",
            "Category: 1\n",
            "  Precision: 0.0962\n",
            "  Recall: 0.0962\n",
            "  F1: 0.0962\n",
            "Category: 2\n",
            "  Precision: 0.3462\n",
            "  Recall: 0.3974\n",
            "  F1: 0.3568\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3363\n",
            "The average recall is: 0.3514\n",
            "The average f1 is: 0.3393\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:22.\n",
            "  Batch    80  of    175.    Elapsed: 0:00:43.\n",
            "  Batch   120  of    175.    Elapsed: 0:01:05.\n",
            "  Batch   160  of    175.    Elapsed: 0:01:26.\n",
            "\n",
            "  Average training loss: 0.11\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.96\n",
            "  Recall: 0.98\n",
            "  F1: 0.97\n",
            "Category: 1\n",
            "  Precision: 0.76\n",
            "  Recall: 0.76\n",
            "  F1: 0.76\n",
            "Category: 2\n",
            "  Precision: 0.97\n",
            "  Recall: 0.97\n",
            "  F1: 0.97\n",
            "Category: 3\n",
            "  Precision: 0.24\n",
            "  Recall: 0.24\n",
            "  F1: 0.24\n",
            "The average precision is: 0.7350\n",
            "The average recall is: 0.7375\n",
            "The average f1 is: 0.7329\n",
            "  Training epcoh took: 0:01:34\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "Category: 0\n",
            "  Precision: 0.8524\n",
            "  Recall: 0.9378\n",
            "  F1: 0.8901\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.4872\n",
            "  Recall: 0.3103\n",
            "  F1: 0.3449\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3541\n",
            "The average recall is: 0.3313\n",
            "The average f1 is: 0.3280\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:22.\n",
            "  Batch    80  of    175.    Elapsed: 0:00:44.\n",
            "  Batch   120  of    175.    Elapsed: 0:01:06.\n",
            "  Batch   160  of    175.    Elapsed: 0:01:28.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.81\n",
            "  Recall: 0.81\n",
            "  F1: 0.81\n",
            "Category: 2\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 3\n",
            "  Precision: 0.33\n",
            "  Recall: 0.33\n",
            "  F1: 0.33\n",
            "The average precision is: 0.7804\n",
            "The average recall is: 0.7796\n",
            "The average f1 is: 0.7795\n",
            "  Training epcoh took: 0:01:37\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8929\n",
            "  Recall: 0.9545\n",
            "  F1: 0.9204\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0577\n",
            "  F1: 0.0641\n",
            "Category: 2\n",
            "  Precision: 0.3942\n",
            "  Recall: 0.3013\n",
            "  F1: 0.3311\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3410\n",
            "The average recall is: 0.3284\n",
            "The average f1 is: 0.3289\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    175.    Elapsed: 0:00:46.\n",
            "  Batch   120  of    175.    Elapsed: 0:01:08.\n",
            "  Batch   160  of    175.    Elapsed: 0:01:31.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.81\n",
            "  Recall: 0.81\n",
            "  F1: 0.81\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.34\n",
            "  Recall: 0.34\n",
            "  F1: 0.34\n",
            "The average precision is: 0.7869\n",
            "The average recall is: 0.7870\n",
            "The average f1 is: 0.7870\n",
            "  Training epcoh took: 0:01:40\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8899\n",
            "  Recall: 0.9653\n",
            "  F1: 0.9248\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0577\n",
            "  F1: 0.0641\n",
            "Category: 2\n",
            "  Precision: 0.3654\n",
            "  Recall: 0.2821\n",
            "  F1: 0.3064\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3330\n",
            "The average recall is: 0.3263\n",
            "The average f1 is: 0.3238\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "Training complete!\n",
            "Current increase 6 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 1882 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 1882 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 2968 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 2968 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 3040 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.4473684210526316\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "329\n",
            "0.10822368421052632\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1267\n",
            "0.41677631578947366\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "84\n",
            "0.02763157894736842\n",
            "\n",
            "(3040, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 09:59:37.650783 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 09:59:37.652463 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 09:59:42.755590 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 09:59:45.377846 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 09:59:45.378887 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    190.    Elapsed: 0:00:20.\n",
            "  Batch    80  of    190.    Elapsed: 0:00:43.\n",
            "  Batch   120  of    190.    Elapsed: 0:01:06.\n",
            "  Batch   160  of    190.    Elapsed: 0:01:29.\n",
            "\n",
            "  Average training loss: 0.83\n",
            "  Accuracy: 0.65\n",
            "Category: 0\n",
            "  Precision: 0.61\n",
            "  Recall: 0.76\n",
            "  F1: 0.65\n",
            "Category: 1\n",
            "  Precision: 0.13\n",
            "  Recall: 0.13\n",
            "  F1: 0.12\n",
            "Category: 2\n",
            "  Precision: 0.67\n",
            "  Recall: 0.69\n",
            "  F1: 0.66\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.3528\n",
            "The average recall is: 0.3943\n",
            "The average f1 is: 0.3577\n",
            "  Training epcoh took: 0:01:47\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "Category: 0\n",
            "  Precision: 0.9045\n",
            "  Recall: 0.9128\n",
            "  F1: 0.9049\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0128\n",
            "  F1: 0.0192\n",
            "Category: 2\n",
            "  Precision: 0.3455\n",
            "  Recall: 0.4391\n",
            "  F1: 0.3638\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3221\n",
            "The average recall is: 0.3412\n",
            "The average f1 is: 0.3220\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    190.    Elapsed: 0:00:24.\n",
            "  Batch    80  of    190.    Elapsed: 0:00:47.\n",
            "  Batch   120  of    190.    Elapsed: 0:01:09.\n",
            "  Batch   160  of    190.    Elapsed: 0:01:31.\n",
            "\n",
            "  Average training loss: 0.13\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.96\n",
            "  Recall: 0.97\n",
            "  F1: 0.96\n",
            "Category: 1\n",
            "  Precision: 0.76\n",
            "  Recall: 0.76\n",
            "  F1: 0.75\n",
            "Category: 2\n",
            "  Precision: 0.97\n",
            "  Recall: 0.98\n",
            "  F1: 0.97\n",
            "Category: 3\n",
            "  Precision: 0.25\n",
            "  Recall: 0.25\n",
            "  F1: 0.25\n",
            "The average precision is: 0.7359\n",
            "The average recall is: 0.7384\n",
            "The average f1 is: 0.7329\n",
            "  Training epcoh took: 0:01:47\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8800\n",
            "  Recall: 0.9793\n",
            "  F1: 0.9253\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.4615\n",
            "  Recall: 0.3237\n",
            "  F1: 0.3641\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3354\n",
            "The average recall is: 0.3258\n",
            "The average f1 is: 0.3224\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    190.    Elapsed: 0:00:22.\n",
            "  Batch    80  of    190.    Elapsed: 0:00:44.\n",
            "  Batch   120  of    190.    Elapsed: 0:01:05.\n",
            "  Batch   160  of    190.    Elapsed: 0:01:27.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.85\n",
            "  Recall: 0.86\n",
            "  F1: 0.85\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.36\n",
            "  Recall: 0.36\n",
            "  F1: 0.36\n",
            "The average precision is: 0.8026\n",
            "The average recall is: 0.8031\n",
            "The average f1 is: 0.8024\n",
            "  Training epcoh took: 0:01:43\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8788\n",
            "  Recall: 0.9790\n",
            "  F1: 0.9239\n",
            "Category: 1\n",
            "  Precision: 0.0192\n",
            "  Recall: 0.0192\n",
            "  F1: 0.0192\n",
            "Category: 2\n",
            "  Precision: 0.3558\n",
            "  Recall: 0.2628\n",
            "  F1: 0.2814\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3135\n",
            "The average recall is: 0.3153\n",
            "The average f1 is: 0.3061\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    190.    Elapsed: 0:00:22.\n",
            "  Batch    80  of    190.    Elapsed: 0:00:44.\n",
            "  Batch   120  of    190.    Elapsed: 0:01:06.\n",
            "  Batch   160  of    190.    Elapsed: 0:01:28.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.86\n",
            "  Recall: 0.86\n",
            "  F1: 0.86\n",
            "Category: 2\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 3\n",
            "  Precision: 0.37\n",
            "  Recall: 0.37\n",
            "  F1: 0.37\n",
            "The average precision is: 0.8064\n",
            "The average recall is: 0.8064\n",
            "The average f1 is: 0.8064\n",
            "  Training epcoh took: 0:01:45\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8859\n",
            "  Recall: 0.9777\n",
            "  F1: 0.9268\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0192\n",
            "  F1: 0.0256\n",
            "Category: 2\n",
            "  Precision: 0.4808\n",
            "  Recall: 0.3378\n",
            "  F1: 0.3692\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3513\n",
            "The average recall is: 0.3337\n",
            "The average f1 is: 0.3304\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "Training complete!\n",
            "Current increase 7 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 1929 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 1929 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 3196 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 3196 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 3280 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.4146341463414634\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "376\n",
            "0.11463414634146342\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1448\n",
            "0.44146341463414634\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "96\n",
            "0.02926829268292683\n",
            "\n",
            "(3280, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 10:07:03.948285 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 10:07:03.949814 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 10:07:04.067914 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 10:07:06.600249 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 10:07:06.600967 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    205.    Elapsed: 0:00:22.\n",
            "  Batch    80  of    205.    Elapsed: 0:00:45.\n",
            "  Batch   120  of    205.    Elapsed: 0:01:08.\n",
            "  Batch   160  of    205.    Elapsed: 0:01:31.\n",
            "  Batch   200  of    205.    Elapsed: 0:01:54.\n",
            "\n",
            "  Average training loss: 0.89\n",
            "  Accuracy: 0.62\n",
            "Category: 0\n",
            "  Precision: 0.61\n",
            "  Recall: 0.65\n",
            "  F1: 0.59\n",
            "Category: 1\n",
            "  Precision: 0.14\n",
            "  Recall: 0.09\n",
            "  F1: 0.10\n",
            "Category: 2\n",
            "  Precision: 0.63\n",
            "  Recall: 0.75\n",
            "  F1: 0.66\n",
            "Category: 3\n",
            "  Precision: 0.07\n",
            "  Recall: 0.06\n",
            "  F1: 0.07\n",
            "The average precision is: 0.3623\n",
            "The average recall is: 0.3886\n",
            "The average f1 is: 0.3553\n",
            "  Training epcoh took: 0:01:57\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.8980\n",
            "  Recall: 0.9238\n",
            "  F1: 0.9085\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3596\n",
            "  Recall: 0.3910\n",
            "  F1: 0.3495\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3144\n",
            "The average recall is: 0.3287\n",
            "The average f1 is: 0.3145\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    205.    Elapsed: 0:00:24.\n",
            "  Batch    80  of    205.    Elapsed: 0:00:48.\n",
            "  Batch   120  of    205.    Elapsed: 0:01:10.\n",
            "  Batch   160  of    205.    Elapsed: 0:01:34.\n",
            "  Batch   200  of    205.    Elapsed: 0:01:58.\n",
            "\n",
            "  Average training loss: 0.21\n",
            "  Accuracy: 0.93\n",
            "Category: 0\n",
            "  Precision: 0.92\n",
            "  Recall: 0.95\n",
            "  F1: 0.93\n",
            "Category: 1\n",
            "  Precision: 0.72\n",
            "  Recall: 0.69\n",
            "  F1: 0.68\n",
            "Category: 2\n",
            "  Precision: 0.95\n",
            "  Recall: 0.96\n",
            "  F1: 0.95\n",
            "Category: 3\n",
            "  Precision: 0.30\n",
            "  Recall: 0.29\n",
            "  F1: 0.29\n",
            "The average precision is: 0.7222\n",
            "The average recall is: 0.7210\n",
            "The average f1 is: 0.7135\n",
            "  Training epcoh took: 0:02:01\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8765\n",
            "  Recall: 0.9911\n",
            "  F1: 0.9275\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.2500\n",
            "  Recall: 0.1455\n",
            "  F1: 0.1740\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3008\n",
            "The average recall is: 0.3034\n",
            "The average f1 is: 0.2946\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    205.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    205.    Elapsed: 0:00:46.\n",
            "  Batch   120  of    205.    Elapsed: 0:01:08.\n",
            "  Batch   160  of    205.    Elapsed: 0:01:30.\n",
            "  Batch   200  of    205.    Elapsed: 0:01:51.\n",
            "\n",
            "  Average training loss: 0.03\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.86\n",
            "  Recall: 0.86\n",
            "  F1: 0.86\n",
            "Category: 2\n",
            "  Precision: 0.99\n",
            "  Recall: 1.00\n",
            "  F1: 0.99\n",
            "Category: 3\n",
            "  Precision: 0.37\n",
            "  Recall: 0.38\n",
            "  F1: 0.37\n",
            "The average precision is: 0.8035\n",
            "The average recall is: 0.8041\n",
            "The average f1 is: 0.8033\n",
            "  Training epcoh took: 0:01:54\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.8483\n",
            "  Recall: 0.9477\n",
            "  F1: 0.8938\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0385\n",
            "Category: 2\n",
            "  Precision: 0.4615\n",
            "  Recall: 0.2641\n",
            "  F1: 0.3205\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3371\n",
            "The average recall is: 0.3126\n",
            "The average f1 is: 0.3132\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    205.    Elapsed: 0:00:22.\n",
            "  Batch    80  of    205.    Elapsed: 0:00:44.\n",
            "  Batch   120  of    205.    Elapsed: 0:01:07.\n",
            "  Batch   160  of    205.    Elapsed: 0:01:29.\n",
            "  Batch   200  of    205.    Elapsed: 0:01:52.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.86\n",
            "  Recall: 0.86\n",
            "  F1: 0.86\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.37\n",
            "  Recall: 0.37\n",
            "  F1: 0.37\n",
            "The average precision is: 0.8072\n",
            "The average recall is: 0.8071\n",
            "The average f1 is: 0.8071\n",
            "  Training epcoh took: 0:01:55\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "Category: 0\n",
            "  Precision: 0.8915\n",
            "  Recall: 0.9832\n",
            "  F1: 0.9333\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0513\n",
            "  F1: 0.0577\n",
            "Category: 2\n",
            "  Precision: 0.4038\n",
            "  Recall: 0.2596\n",
            "  F1: 0.3009\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3431\n",
            "The average recall is: 0.3235\n",
            "The average f1 is: 0.3230\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "Training complete!\n",
            "Current increase 8 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 1976 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 1976 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 3424 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 3424 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 3520 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.38636363636363635\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "423\n",
            "0.12017045454545454\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1629\n",
            "0.4627840909090909\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "108\n",
            "0.03068181818181818\n",
            "\n",
            "(3520, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 10:15:08.566228 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 10:15:08.568160 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 10:15:09.474665 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 10:15:11.948635 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 10:15:11.949390 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    220.    Elapsed: 0:00:22.\n",
            "  Batch    80  of    220.    Elapsed: 0:00:45.\n",
            "  Batch   120  of    220.    Elapsed: 0:01:09.\n",
            "  Batch   160  of    220.    Elapsed: 0:01:32.\n",
            "  Batch   200  of    220.    Elapsed: 0:01:55.\n",
            "\n",
            "  Average training loss: 0.74\n",
            "  Accuracy: 0.72\n",
            "Category: 0\n",
            "  Precision: 0.68\n",
            "  Recall: 0.77\n",
            "  F1: 0.69\n",
            "Category: 1\n",
            "  Precision: 0.30\n",
            "  Recall: 0.23\n",
            "  F1: 0.24\n",
            "Category: 2\n",
            "  Precision: 0.77\n",
            "  Recall: 0.83\n",
            "  F1: 0.77\n",
            "Category: 3\n",
            "  Precision: 0.05\n",
            "  Recall: 0.04\n",
            "  F1: 0.04\n",
            "The average precision is: 0.4517\n",
            "The average recall is: 0.4651\n",
            "The average f1 is: 0.4369\n",
            "  Training epcoh took: 0:02:07\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "Category: 0\n",
            "  Precision: 0.9022\n",
            "  Recall: 0.9109\n",
            "  F1: 0.9041\n",
            "Category: 1\n",
            "  Precision: 0.1538\n",
            "  Recall: 0.1154\n",
            "  F1: 0.1282\n",
            "Category: 2\n",
            "  Precision: 0.3974\n",
            "  Recall: 0.4167\n",
            "  F1: 0.3731\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3634\n",
            "The average recall is: 0.3607\n",
            "The average f1 is: 0.3513\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    220.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    220.    Elapsed: 0:00:47.\n",
            "  Batch   120  of    220.    Elapsed: 0:01:10.\n",
            "  Batch   160  of    220.    Elapsed: 0:01:32.\n",
            "  Batch   200  of    220.    Elapsed: 0:01:52.\n",
            "\n",
            "  Average training loss: 0.08\n",
            "  Accuracy: 0.98\n",
            "Category: 0\n",
            "  Precision: 0.98\n",
            "  Recall: 0.98\n",
            "  F1: 0.97\n",
            "Category: 1\n",
            "  Precision: 0.82\n",
            "  Recall: 0.81\n",
            "  F1: 0.81\n",
            "Category: 2\n",
            "  Precision: 0.98\n",
            "  Recall: 0.99\n",
            "  F1: 0.98\n",
            "Category: 3\n",
            "  Precision: 0.36\n",
            "  Recall: 0.35\n",
            "  F1: 0.35\n",
            "The average precision is: 0.7846\n",
            "The average recall is: 0.7832\n",
            "The average f1 is: 0.7813\n",
            "  Training epcoh took: 0:02:02\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.9096\n",
            "  Recall: 0.9383\n",
            "  F1: 0.9211\n",
            "Category: 1\n",
            "  Precision: 0.1538\n",
            "  Recall: 0.0962\n",
            "  F1: 0.1154\n",
            "Category: 2\n",
            "  Precision: 0.4327\n",
            "  Recall: 0.4449\n",
            "  F1: 0.3835\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3740\n",
            "The average recall is: 0.3698\n",
            "The average f1 is: 0.3550\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    220.    Elapsed: 0:00:20.\n",
            "  Batch    80  of    220.    Elapsed: 0:00:40.\n",
            "  Batch   120  of    220.    Elapsed: 0:01:00.\n",
            "  Batch   160  of    220.    Elapsed: 0:01:20.\n",
            "  Batch   200  of    220.    Elapsed: 0:01:41.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.85\n",
            "  Recall: 0.85\n",
            "  F1: 0.85\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.40\n",
            "  Recall: 0.40\n",
            "  F1: 0.40\n",
            "The average precision is: 0.8103\n",
            "The average recall is: 0.8106\n",
            "The average f1 is: 0.8103\n",
            "  Training epcoh took: 0:01:51\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8978\n",
            "  Recall: 0.9535\n",
            "  F1: 0.9227\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0577\n",
            "  F1: 0.0641\n",
            "Category: 2\n",
            "  Precision: 0.4372\n",
            "  Recall: 0.4135\n",
            "  F1: 0.4071\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3530\n",
            "The average recall is: 0.3562\n",
            "The average f1 is: 0.3485\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    220.    Elapsed: 0:00:22.\n",
            "  Batch    80  of    220.    Elapsed: 0:00:43.\n",
            "  Batch   120  of    220.    Elapsed: 0:01:06.\n",
            "  Batch   160  of    220.    Elapsed: 0:01:28.\n",
            "  Batch   200  of    220.    Elapsed: 0:01:51.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.88\n",
            "  Recall: 0.88\n",
            "  F1: 0.88\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.39\n",
            "  Recall: 0.39\n",
            "  F1: 0.39\n",
            "The average precision is: 0.8153\n",
            "The average recall is: 0.8152\n",
            "The average f1 is: 0.8152\n",
            "  Training epcoh took: 0:02:02\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8923\n",
            "  Recall: 0.9667\n",
            "  F1: 0.9238\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0577\n",
            "  F1: 0.0641\n",
            "Category: 2\n",
            "  Precision: 0.3429\n",
            "  Recall: 0.3359\n",
            "  F1: 0.3130\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3280\n",
            "The average recall is: 0.3401\n",
            "The average f1 is: 0.3252\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "Training complete!\n",
            "Current increase 9 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 2023 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 2023 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 3652 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 3652 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 3760 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.3617021276595745\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "470\n",
            "0.125\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1810\n",
            "0.48138297872340424\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "120\n",
            "0.031914893617021274\n",
            "\n",
            "(3760, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 10:23:28.735487 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 10:23:28.737442 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 10:23:28.851315 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 10:23:31.374525 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 10:23:31.375323 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    235.    Elapsed: 0:00:22.\n",
            "  Batch    80  of    235.    Elapsed: 0:00:45.\n",
            "  Batch   120  of    235.    Elapsed: 0:01:08.\n",
            "  Batch   160  of    235.    Elapsed: 0:01:31.\n",
            "  Batch   200  of    235.    Elapsed: 0:01:54.\n",
            "\n",
            "  Average training loss: 0.70\n",
            "  Accuracy: 0.72\n",
            "Category: 0\n",
            "  Precision: 0.66\n",
            "  Recall: 0.66\n",
            "  F1: 0.63\n",
            "Category: 1\n",
            "  Precision: 0.40\n",
            "  Recall: 0.36\n",
            "  F1: 0.36\n",
            "Category: 2\n",
            "  Precision: 0.75\n",
            "  Recall: 0.87\n",
            "  F1: 0.78\n",
            "Category: 3\n",
            "  Precision: 0.09\n",
            "  Recall: 0.09\n",
            "  F1: 0.08\n",
            "The average precision is: 0.4741\n",
            "The average recall is: 0.4949\n",
            "The average f1 is: 0.4651\n",
            "  Training epcoh took: 0:02:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.9018\n",
            "  Recall: 0.9359\n",
            "  F1: 0.9165\n",
            "Category: 1\n",
            "  Precision: 0.0192\n",
            "  Recall: 0.0128\n",
            "  F1: 0.0154\n",
            "Category: 2\n",
            "  Precision: 0.4218\n",
            "  Recall: 0.3827\n",
            "  F1: 0.3868\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3357\n",
            "The average recall is: 0.3329\n",
            "The average f1 is: 0.3297\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    235.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    235.    Elapsed: 0:00:46.\n",
            "  Batch   120  of    235.    Elapsed: 0:01:08.\n",
            "  Batch   160  of    235.    Elapsed: 0:01:29.\n",
            "  Batch   200  of    235.    Elapsed: 0:01:49.\n",
            "\n",
            "  Average training loss: 0.08\n",
            "  Accuracy: 0.98\n",
            "Category: 0\n",
            "  Precision: 0.98\n",
            "  Recall: 0.97\n",
            "  F1: 0.97\n",
            "Category: 1\n",
            "  Precision: 0.84\n",
            "  Recall: 0.86\n",
            "  F1: 0.84\n",
            "Category: 2\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 3\n",
            "  Precision: 0.38\n",
            "  Recall: 0.38\n",
            "  F1: 0.38\n",
            "The average precision is: 0.7956\n",
            "The average recall is: 0.7978\n",
            "The average f1 is: 0.7944\n",
            "  Training epcoh took: 0:02:07\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8807\n",
            "  Recall: 0.9774\n",
            "  F1: 0.9243\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0192\n",
            "  F1: 0.0256\n",
            "Category: 2\n",
            "  Precision: 0.3013\n",
            "  Recall: 0.2115\n",
            "  F1: 0.2269\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3051\n",
            "The average recall is: 0.3020\n",
            "The average f1 is: 0.2942\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    235.    Elapsed: 0:00:20.\n",
            "  Batch    80  of    235.    Elapsed: 0:00:40.\n",
            "  Batch   120  of    235.    Elapsed: 0:01:00.\n",
            "  Batch   160  of    235.    Elapsed: 0:01:21.\n",
            "  Batch   200  of    235.    Elapsed: 0:01:42.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.88\n",
            "  Recall: 0.88\n",
            "  F1: 0.88\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.41\n",
            "  Recall: 0.41\n",
            "  F1: 0.41\n",
            "The average precision is: 0.8215\n",
            "The average recall is: 0.8212\n",
            "The average f1 is: 0.8213\n",
            "  Training epcoh took: 0:02:02\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.8489\n",
            "  Recall: 0.9452\n",
            "  F1: 0.8919\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0385\n",
            "Category: 2\n",
            "  Precision: 0.3718\n",
            "  Recall: 0.2949\n",
            "  F1: 0.2987\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3148\n",
            "The average recall is: 0.3196\n",
            "The average f1 is: 0.3073\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    235.    Elapsed: 0:00:22.\n",
            "  Batch    80  of    235.    Elapsed: 0:00:44.\n",
            "  Batch   120  of    235.    Elapsed: 0:01:07.\n",
            "  Batch   160  of    235.    Elapsed: 0:01:30.\n",
            "  Batch   200  of    235.    Elapsed: 0:01:53.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.87\n",
            "  Recall: 0.87\n",
            "  F1: 0.87\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.40\n",
            "  Recall: 0.40\n",
            "  F1: 0.40\n",
            "The average precision is: 0.8188\n",
            "The average recall is: 0.8186\n",
            "The average f1 is: 0.8186\n",
            "  Training epcoh took: 0:02:13\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8850\n",
            "  Recall: 0.9780\n",
            "  F1: 0.9272\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0192\n",
            "  F1: 0.0256\n",
            "Category: 2\n",
            "  Precision: 0.4038\n",
            "  Recall: 0.2596\n",
            "  F1: 0.2962\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3318\n",
            "The average recall is: 0.3142\n",
            "The average f1 is: 0.3122\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "Training complete!\n",
            "Current increase 10 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 2070 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 2070 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 3880 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 3880 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 4000 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.34\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "517\n",
            "0.12925\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1991\n",
            "0.49775\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "132\n",
            "0.033\n",
            "\n",
            "(4000, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 10:32:21.454788 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 10:32:21.456148 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 10:32:25.568048 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 10:32:27.989590 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 10:32:27.990351 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    250.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    250.    Elapsed: 0:00:43.\n",
            "  Batch   120  of    250.    Elapsed: 0:01:08.\n",
            "  Batch   160  of    250.    Elapsed: 0:01:30.\n",
            "  Batch   200  of    250.    Elapsed: 0:01:53.\n",
            "  Batch   240  of    250.    Elapsed: 0:02:16.\n",
            "\n",
            "  Average training loss: 0.63\n",
            "  Accuracy: 0.75\n",
            "Category: 0\n",
            "  Precision: 0.68\n",
            "  Recall: 0.68\n",
            "  F1: 0.66\n",
            "Category: 1\n",
            "  Precision: 0.35\n",
            "  Recall: 0.32\n",
            "  F1: 0.32\n",
            "Category: 2\n",
            "  Precision: 0.78\n",
            "  Recall: 0.92\n",
            "  F1: 0.83\n",
            "Category: 3\n",
            "  Precision: 0.15\n",
            "  Recall: 0.15\n",
            "  F1: 0.15\n",
            "The average precision is: 0.4893\n",
            "The average recall is: 0.5158\n",
            "The average f1 is: 0.4878\n",
            "  Training epcoh took: 0:02:22\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "Category: 0\n",
            "  Precision: 0.9027\n",
            "  Recall: 0.8943\n",
            "  F1: 0.8946\n",
            "Category: 1\n",
            "  Precision: 0.0705\n",
            "  Recall: 0.1346\n",
            "  F1: 0.0910\n",
            "Category: 2\n",
            "  Precision: 0.3942\n",
            "  Recall: 0.3654\n",
            "  F1: 0.3571\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3419\n",
            "The average recall is: 0.3486\n",
            "The average f1 is: 0.3357\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    250.    Elapsed: 0:00:24.\n",
            "  Batch    80  of    250.    Elapsed: 0:00:48.\n",
            "  Batch   120  of    250.    Elapsed: 0:01:11.\n",
            "  Batch   160  of    250.    Elapsed: 0:01:34.\n",
            "  Batch   200  of    250.    Elapsed: 0:01:58.\n",
            "  Batch   240  of    250.    Elapsed: 0:02:21.\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 0.98\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.86\n",
            "  Recall: 0.87\n",
            "  F1: 0.86\n",
            "Category: 2\n",
            "  Precision: 0.99\n",
            "  Recall: 1.00\n",
            "  F1: 0.99\n",
            "Category: 3\n",
            "  Precision: 0.43\n",
            "  Recall: 0.43\n",
            "  F1: 0.43\n",
            "The average precision is: 0.8175\n",
            "The average recall is: 0.8186\n",
            "The average f1 is: 0.8167\n",
            "  Training epcoh took: 0:02:27\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8867\n",
            "  Recall: 0.9543\n",
            "  F1: 0.9175\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0385\n",
            "Category: 2\n",
            "  Precision: 0.3910\n",
            "  Recall: 0.3205\n",
            "  F1: 0.3244\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3291\n",
            "The average recall is: 0.3283\n",
            "The average f1 is: 0.3201\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    250.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    250.    Elapsed: 0:00:46.\n",
            "  Batch   120  of    250.    Elapsed: 0:01:10.\n",
            "  Batch   160  of    250.    Elapsed: 0:01:33.\n",
            "  Batch   200  of    250.    Elapsed: 0:01:57.\n",
            "  Batch   240  of    250.    Elapsed: 0:02:21.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.87\n",
            "  Recall: 0.87\n",
            "  F1: 0.87\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.43\n",
            "  Recall: 0.43\n",
            "  F1: 0.43\n",
            "The average precision is: 0.8241\n",
            "The average recall is: 0.8238\n",
            "The average f1 is: 0.8238\n",
            "  Training epcoh took: 0:02:27\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "Category: 0\n",
            "  Precision: 0.8457\n",
            "  Recall: 0.9299\n",
            "  F1: 0.8836\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0192\n",
            "  F1: 0.0256\n",
            "Category: 2\n",
            "  Precision: 0.3718\n",
            "  Recall: 0.2865\n",
            "  F1: 0.2936\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3140\n",
            "The average recall is: 0.3089\n",
            "The average f1 is: 0.3007\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    250.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    250.    Elapsed: 0:00:46.\n",
            "  Batch   120  of    250.    Elapsed: 0:01:07.\n",
            "  Batch   160  of    250.    Elapsed: 0:01:29.\n",
            "  Batch   200  of    250.    Elapsed: 0:01:51.\n",
            "  Batch   240  of    250.    Elapsed: 0:02:12.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.92\n",
            "  Recall: 0.92\n",
            "  F1: 0.92\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.42\n",
            "  Recall: 0.42\n",
            "  F1: 0.42\n",
            "The average precision is: 0.8327\n",
            "The average recall is: 0.8327\n",
            "The average f1 is: 0.8327\n",
            "  Training epcoh took: 0:02:17\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8822\n",
            "  Recall: 0.9681\n",
            "  F1: 0.9205\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0385\n",
            "Category: 2\n",
            "  Precision: 0.3846\n",
            "  Recall: 0.2718\n",
            "  F1: 0.3013\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3263\n",
            "The average recall is: 0.3196\n",
            "The average f1 is: 0.3151\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n",
            "Current increase 11 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 2117 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 2117 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 4108 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 4108 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 4240 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.32075471698113206\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "564\n",
            "0.1330188679245283\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "2172\n",
            "0.5122641509433963\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "144\n",
            "0.033962264150943396\n",
            "\n",
            "(4240, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 10:42:17.934973 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 10:42:17.936150 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 10:42:18.863680 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 10:42:21.294099 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 10:42:21.295409 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    265.    Elapsed: 0:00:20.\n",
            "  Batch    80  of    265.    Elapsed: 0:00:42.\n",
            "  Batch   120  of    265.    Elapsed: 0:01:04.\n",
            "  Batch   160  of    265.    Elapsed: 0:01:26.\n",
            "  Batch   200  of    265.    Elapsed: 0:01:48.\n",
            "  Batch   240  of    265.    Elapsed: 0:02:10.\n",
            "\n",
            "  Average training loss: 0.60\n",
            "  Accuracy: 0.77\n",
            "Category: 0\n",
            "  Precision: 0.69\n",
            "  Recall: 0.75\n",
            "  F1: 0.69\n",
            "Category: 1\n",
            "  Precision: 0.39\n",
            "  Recall: 0.35\n",
            "  F1: 0.36\n",
            "Category: 2\n",
            "  Precision: 0.84\n",
            "  Recall: 0.91\n",
            "  F1: 0.86\n",
            "Category: 3\n",
            "  Precision: 0.11\n",
            "  Recall: 0.11\n",
            "  F1: 0.11\n",
            "The average precision is: 0.5085\n",
            "The average recall is: 0.5301\n",
            "The average f1 is: 0.5034\n",
            "  Training epcoh took: 0:02:25\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8804\n",
            "  Recall: 0.9770\n",
            "  F1: 0.9238\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0256\n",
            "  F1: 0.0308\n",
            "Category: 2\n",
            "  Precision: 0.2885\n",
            "  Recall: 0.2051\n",
            "  F1: 0.2321\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3018\n",
            "The average recall is: 0.3019\n",
            "The average f1 is: 0.2967\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    265.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    265.    Elapsed: 0:00:46.\n",
            "  Batch   120  of    265.    Elapsed: 0:01:09.\n",
            "  Batch   160  of    265.    Elapsed: 0:01:32.\n",
            "  Batch   200  of    265.    Elapsed: 0:01:56.\n",
            "  Batch   240  of    265.    Elapsed: 0:02:19.\n",
            "\n",
            "  Average training loss: 0.05\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.98\n",
            "  Recall: 0.98\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 0.87\n",
            "  Recall: 0.87\n",
            "  F1: 0.87\n",
            "Category: 2\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 3\n",
            "  Precision: 0.39\n",
            "  Recall: 0.39\n",
            "  F1: 0.39\n",
            "The average precision is: 0.8102\n",
            "The average recall is: 0.8086\n",
            "The average f1 is: 0.8079\n",
            "  Training epcoh took: 0:02:34\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "Category: 0\n",
            "  Precision: 0.8544\n",
            "  Recall: 0.9353\n",
            "  F1: 0.8916\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0192\n",
            "  F1: 0.0256\n",
            "Category: 2\n",
            "  Precision: 0.4359\n",
            "  Recall: 0.3333\n",
            "  F1: 0.3502\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3322\n",
            "The average recall is: 0.3220\n",
            "The average f1 is: 0.3169\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    265.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    265.    Elapsed: 0:00:45.\n",
            "  Batch   120  of    265.    Elapsed: 0:01:06.\n",
            "  Batch   160  of    265.    Elapsed: 0:01:26.\n",
            "  Batch   200  of    265.    Elapsed: 0:01:46.\n",
            "  Batch   240  of    265.    Elapsed: 0:02:06.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 0.99\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.90\n",
            "  Recall: 0.90\n",
            "  F1: 0.90\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.45\n",
            "  Recall: 0.45\n",
            "  F1: 0.45\n",
            "The average precision is: 0.8366\n",
            "The average recall is: 0.8359\n",
            "The average f1 is: 0.8361\n",
            "  Training epcoh took: 0:02:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "Category: 0\n",
            "  Precision: 0.8612\n",
            "  Recall: 0.9245\n",
            "  F1: 0.8894\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0385\n",
            "Category: 2\n",
            "  Precision: 0.4519\n",
            "  Recall: 0.4449\n",
            "  F1: 0.4106\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3379\n",
            "The average recall is: 0.3520\n",
            "The average f1 is: 0.3346\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    265.    Elapsed: 0:00:20.\n",
            "  Batch    80  of    265.    Elapsed: 0:00:42.\n",
            "  Batch   120  of    265.    Elapsed: 0:01:03.\n",
            "  Batch   160  of    265.    Elapsed: 0:01:25.\n",
            "  Batch   200  of    265.    Elapsed: 0:01:47.\n",
            "  Batch   240  of    265.    Elapsed: 0:02:10.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.91\n",
            "  Recall: 0.91\n",
            "  F1: 0.91\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.46\n",
            "  Recall: 0.46\n",
            "  F1: 0.46\n",
            "The average precision is: 0.8403\n",
            "The average recall is: 0.8402\n",
            "The average f1 is: 0.8403\n",
            "  Training epcoh took: 0:02:24\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "Category: 0\n",
            "  Precision: 0.8898\n",
            "  Recall: 0.9799\n",
            "  F1: 0.9303\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0385\n",
            "Category: 2\n",
            "  Precision: 0.4038\n",
            "  Recall: 0.3237\n",
            "  F1: 0.3410\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3330\n",
            "The average recall is: 0.3355\n",
            "The average f1 is: 0.3275\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "Training complete!\n",
            "Current increase 12 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 2164 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 2164 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 4336 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 4336 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 4480 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.30357142857142855\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "611\n",
            "0.13638392857142856\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "2353\n",
            "0.5252232142857143\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "156\n",
            "0.03482142857142857\n",
            "\n",
            "(4480, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 10:52:19.189773 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 10:52:19.191030 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 10:52:19.295124 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 10:52:21.859989 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 10:52:21.860712 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    280.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    280.    Elapsed: 0:00:44.\n",
            "  Batch   120  of    280.    Elapsed: 0:01:07.\n",
            "  Batch   160  of    280.    Elapsed: 0:01:30.\n",
            "  Batch   200  of    280.    Elapsed: 0:01:53.\n",
            "  Batch   240  of    280.    Elapsed: 0:02:16.\n",
            "\n",
            "  Average training loss: 0.50\n",
            "  Accuracy: 0.80\n",
            "Category: 0\n",
            "  Precision: 0.73\n",
            "  Recall: 0.74\n",
            "  F1: 0.71\n",
            "Category: 1\n",
            "  Precision: 0.54\n",
            "  Recall: 0.54\n",
            "  F1: 0.52\n",
            "Category: 2\n",
            "  Precision: 0.85\n",
            "  Recall: 0.92\n",
            "  F1: 0.87\n",
            "Category: 3\n",
            "  Precision: 0.16\n",
            "  Recall: 0.15\n",
            "  F1: 0.15\n",
            "The average precision is: 0.5677\n",
            "The average recall is: 0.5900\n",
            "The average f1 is: 0.5637\n",
            "  Training epcoh took: 0:02:40\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8658\n",
            "  Recall: 0.8999\n",
            "  F1: 0.8808\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0385\n",
            "Category: 2\n",
            "  Precision: 0.4071\n",
            "  Recall: 0.3942\n",
            "  F1: 0.3862\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3278\n",
            "The average recall is: 0.3332\n",
            "The average f1 is: 0.3264\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    280.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    280.    Elapsed: 0:00:46.\n",
            "  Batch   120  of    280.    Elapsed: 0:01:10.\n",
            "  Batch   160  of    280.    Elapsed: 0:01:33.\n",
            "  Batch   200  of    280.    Elapsed: 0:01:55.\n",
            "  Batch   240  of    280.    Elapsed: 0:02:17.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.98\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.89\n",
            "  Recall: 0.89\n",
            "  F1: 0.89\n",
            "Category: 2\n",
            "  Precision: 0.99\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.42\n",
            "  Recall: 0.42\n",
            "  F1: 0.42\n",
            "The average precision is: 0.8244\n",
            "The average recall is: 0.8235\n",
            "The average f1 is: 0.8233\n",
            "  Training epcoh took: 0:02:39\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8916\n",
            "  Recall: 0.9475\n",
            "  F1: 0.9159\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3750\n",
            "  Recall: 0.4038\n",
            "  F1: 0.3615\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3167\n",
            "The average recall is: 0.3378\n",
            "The average f1 is: 0.3194\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    280.    Elapsed: 0:00:22.\n",
            "  Batch    80  of    280.    Elapsed: 0:00:44.\n",
            "  Batch   120  of    280.    Elapsed: 0:01:06.\n",
            "  Batch   160  of    280.    Elapsed: 0:01:29.\n",
            "  Batch   200  of    280.    Elapsed: 0:01:52.\n",
            "  Batch   240  of    280.    Elapsed: 0:02:15.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.92\n",
            "  Recall: 0.92\n",
            "  F1: 0.92\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.42\n",
            "  Recall: 0.42\n",
            "  F1: 0.42\n",
            "The average precision is: 0.8335\n",
            "The average recall is: 0.8335\n",
            "The average f1 is: 0.8335\n",
            "  Training epcoh took: 0:02:38\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "Category: 0\n",
            "  Precision: 0.8534\n",
            "  Recall: 0.9221\n",
            "  F1: 0.8836\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3269\n",
            "  Recall: 0.4154\n",
            "  F1: 0.3432\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.2951\n",
            "The average recall is: 0.3344\n",
            "The average f1 is: 0.3067\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    280.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    280.    Elapsed: 0:00:46.\n",
            "  Batch   120  of    280.    Elapsed: 0:01:09.\n",
            "  Batch   160  of    280.    Elapsed: 0:01:32.\n",
            "  Batch   200  of    280.    Elapsed: 0:01:55.\n",
            "  Batch   240  of    280.    Elapsed: 0:02:20.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.90\n",
            "  Recall: 0.90\n",
            "  F1: 0.90\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.47\n",
            "  Recall: 0.47\n",
            "  F1: 0.47\n",
            "The average precision is: 0.8419\n",
            "The average recall is: 0.8417\n",
            "The average f1 is: 0.8418\n",
            "  Training epcoh took: 0:02:44\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8908\n",
            "  Recall: 0.9645\n",
            "  F1: 0.9237\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3141\n",
            "  Recall: 0.3244\n",
            "  F1: 0.3022\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3012\n",
            "The average recall is: 0.3222\n",
            "The average f1 is: 0.3065\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "Training complete!\n",
            "Current increase 13 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 2211 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 2211 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 4564 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 4564 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 4720 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.288135593220339\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "658\n",
            "0.13940677966101694\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "2534\n",
            "0.536864406779661\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "168\n",
            "0.03559322033898305\n",
            "\n",
            "(4720, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 11:03:18.057673 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 11:03:18.059162 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 11:03:18.935292 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 11:03:21.456883 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 11:03:21.457762 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    295.    Elapsed: 0:00:22.\n",
            "  Batch    80  of    295.    Elapsed: 0:00:44.\n",
            "  Batch   120  of    295.    Elapsed: 0:01:07.\n",
            "  Batch   160  of    295.    Elapsed: 0:01:29.\n",
            "  Batch   200  of    295.    Elapsed: 0:01:50.\n",
            "  Batch   240  of    295.    Elapsed: 0:02:10.\n",
            "  Batch   280  of    295.    Elapsed: 0:02:31.\n",
            "\n",
            "  Average training loss: 0.66\n",
            "  Accuracy: 0.74\n",
            "Category: 0\n",
            "  Precision: 0.61\n",
            "  Recall: 0.60\n",
            "  F1: 0.57\n",
            "Category: 1\n",
            "  Precision: 0.41\n",
            "  Recall: 0.44\n",
            "  F1: 0.40\n",
            "Category: 2\n",
            "  Precision: 0.81\n",
            "  Recall: 0.91\n",
            "  F1: 0.84\n",
            "Category: 3\n",
            "  Precision: 0.09\n",
            "  Recall: 0.09\n",
            "  F1: 0.09\n",
            "The average precision is: 0.4796\n",
            "The average recall is: 0.5098\n",
            "The average f1 is: 0.4755\n",
            "  Training epcoh took: 0:02:39\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.79\n",
            "Category: 0\n",
            "  Precision: 0.9171\n",
            "  Recall: 0.8537\n",
            "  F1: 0.8796\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3147\n",
            "  Recall: 0.4327\n",
            "  F1: 0.3496\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3080\n",
            "The average recall is: 0.3216\n",
            "The average f1 is: 0.3073\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    295.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    295.    Elapsed: 0:00:43.\n",
            "  Batch   120  of    295.    Elapsed: 0:01:05.\n",
            "  Batch   160  of    295.    Elapsed: 0:01:27.\n",
            "  Batch   200  of    295.    Elapsed: 0:01:49.\n",
            "  Batch   240  of    295.    Elapsed: 0:02:12.\n",
            "  Batch   280  of    295.    Elapsed: 0:02:34.\n",
            "\n",
            "  Average training loss: 0.07\n",
            "  Accuracy: 0.98\n",
            "Category: 0\n",
            "  Precision: 0.98\n",
            "  Recall: 0.97\n",
            "  F1: 0.97\n",
            "Category: 1\n",
            "  Precision: 0.89\n",
            "  Recall: 0.90\n",
            "  F1: 0.89\n",
            "Category: 2\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 3\n",
            "  Precision: 0.41\n",
            "  Recall: 0.41\n",
            "  F1: 0.41\n",
            "The average precision is: 0.8167\n",
            "The average recall is: 0.8187\n",
            "The average f1 is: 0.8160\n",
            "  Training epcoh took: 0:02:43\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8712\n",
            "  Recall: 0.9832\n",
            "  F1: 0.9223\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.2885\n",
            "  Recall: 0.1603\n",
            "  F1: 0.1987\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.2899\n",
            "The average recall is: 0.2859\n",
            "The average f1 is: 0.2802\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    295.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    295.    Elapsed: 0:00:47.\n",
            "  Batch   120  of    295.    Elapsed: 0:01:09.\n",
            "  Batch   160  of    295.    Elapsed: 0:01:33.\n",
            "  Batch   200  of    295.    Elapsed: 0:01:57.\n",
            "  Batch   240  of    295.    Elapsed: 0:02:19.\n",
            "  Batch   280  of    295.    Elapsed: 0:02:42.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.98\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 0.93\n",
            "  Recall: 0.93\n",
            "  F1: 0.93\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.44\n",
            "  Recall: 0.44\n",
            "  F1: 0.44\n",
            "The average precision is: 0.8401\n",
            "The average recall is: 0.8395\n",
            "The average f1 is: 0.8396\n",
            "  Training epcoh took: 0:02:51\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8693\n",
            "  Recall: 0.9698\n",
            "  F1: 0.9141\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.2756\n",
            "  Recall: 0.2237\n",
            "  F1: 0.2310\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.2862\n",
            "The average recall is: 0.2984\n",
            "The average f1 is: 0.2863\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    295.    Elapsed: 0:00:24.\n",
            "  Batch    80  of    295.    Elapsed: 0:00:46.\n",
            "  Batch   120  of    295.    Elapsed: 0:01:09.\n",
            "  Batch   160  of    295.    Elapsed: 0:01:31.\n",
            "  Batch   200  of    295.    Elapsed: 0:01:53.\n",
            "  Batch   240  of    295.    Elapsed: 0:02:14.\n",
            "  Batch   280  of    295.    Elapsed: 0:02:36.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.89\n",
            "  Recall: 0.89\n",
            "  F1: 0.89\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.44\n",
            "  Recall: 0.44\n",
            "  F1: 0.44\n",
            "The average precision is: 0.8319\n",
            "The average recall is: 0.8316\n",
            "The average f1 is: 0.8317\n",
            "  Training epcoh took: 0:02:44\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8723\n",
            "  Recall: 0.9807\n",
            "  F1: 0.9204\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3654\n",
            "  Recall: 0.2308\n",
            "  F1: 0.2744\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3094\n",
            "The average recall is: 0.3029\n",
            "The average f1 is: 0.2987\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "Training complete!\n",
            "Successfully save file BertSearchResult/16_5e-05\n",
            "Currently processing 16_3e-05\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: TITAN RTX\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 11:14:34.367384 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 11:14:34.369335 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 11:14:34.426483 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 11:14:36.892013 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 11:14:36.892753 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current increase 0 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "(1600, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 11:14:37.545617 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 11:14:37.546787 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 11:14:37.605537 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 11:14:40.006009 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 11:14:40.006952 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    100.    Elapsed: 0:00:20.\n",
            "  Batch    80  of    100.    Elapsed: 0:00:41.\n",
            "\n",
            "  Average training loss: 0.58\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.85\n",
            "  Recall: 0.99\n",
            "  F1: 0.91\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "Category: 2\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.2126\n",
            "The average recall is: 0.2475\n",
            "The average f1 is: 0.2277\n",
            "  Training epcoh took: 0:00:52\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8486\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9147\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.2121\n",
            "The average recall is: 0.2500\n",
            "The average f1 is: 0.2287\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    100.    Elapsed: 0:00:22.\n",
            "  Batch    80  of    100.    Elapsed: 0:00:45.\n",
            "\n",
            "  Average training loss: 0.48\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.86\n",
            "  Recall: 0.99\n",
            "  F1: 0.92\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "Category: 2\n",
            "  Precision: 0.18\n",
            "  Recall: 0.11\n",
            "  F1: 0.13\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.2601\n",
            "The average recall is: 0.2754\n",
            "The average f1 is: 0.2615\n",
            "  Training epcoh took: 0:00:56\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8689\n",
            "  Recall: 0.9921\n",
            "  F1: 0.9236\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.2500\n",
            "  Recall: 0.1667\n",
            "  F1: 0.1936\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.2797\n",
            "The average recall is: 0.2897\n",
            "The average f1 is: 0.2793\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    100.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    100.    Elapsed: 0:00:45.\n",
            "\n",
            "  Average training loss: 0.38\n",
            "  Accuracy: 0.89\n",
            "Category: 0\n",
            "  Precision: 0.92\n",
            "  Recall: 0.97\n",
            "  F1: 0.94\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "Category: 2\n",
            "  Precision: 0.55\n",
            "  Recall: 0.46\n",
            "  F1: 0.47\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.3660\n",
            "The average recall is: 0.3596\n",
            "The average f1 is: 0.3543\n",
            "  Training epcoh took: 0:00:57\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8706\n",
            "  Recall: 0.9918\n",
            "  F1: 0.9251\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3654\n",
            "  Recall: 0.2372\n",
            "  F1: 0.2756\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3090\n",
            "The average recall is: 0.3072\n",
            "The average f1 is: 0.3002\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    100.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    100.    Elapsed: 0:00:45.\n",
            "\n",
            "  Average training loss: 0.28\n",
            "  Accuracy: 0.92\n",
            "Category: 0\n",
            "  Precision: 0.93\n",
            "  Recall: 0.99\n",
            "  F1: 0.96\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "Category: 2\n",
            "  Precision: 0.64\n",
            "  Recall: 0.57\n",
            "  F1: 0.57\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.3936\n",
            "The average recall is: 0.3902\n",
            "The average f1 is: 0.3840\n",
            "  Training epcoh took: 0:00:56\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8909\n",
            "  Recall: 0.9582\n",
            "  F1: 0.9208\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.4199\n",
            "  Recall: 0.3994\n",
            "  F1: 0.3818\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3277\n",
            "The average recall is: 0.3394\n",
            "The average f1 is: 0.3257\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "Training complete!\n",
            "Current increase 1 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 1647 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 1647 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 1828 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 1828 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 1840 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.7391304347826086\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "94\n",
            "0.051086956521739134\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "362\n",
            "0.1967391304347826\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "24\n",
            "0.013043478260869565\n",
            "\n",
            "(1840, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 11:18:36.883417 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 11:18:36.886062 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 11:18:37.026151 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 11:18:39.496166 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 11:18:39.503035 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    115.    Elapsed: 0:00:22.\n",
            "  Batch    80  of    115.    Elapsed: 0:00:45.\n",
            "\n",
            "  Average training loss: 0.78\n",
            "  Accuracy: 0.73\n",
            "Category: 0\n",
            "  Precision: 0.74\n",
            "  Recall: 0.99\n",
            "  F1: 0.83\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "Category: 2\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.1855\n",
            "The average recall is: 0.2475\n",
            "The average f1 is: 0.2095\n",
            "  Training epcoh took: 0:01:05\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8486\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9138\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.2121\n",
            "The average recall is: 0.2500\n",
            "The average f1 is: 0.2284\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    115.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    115.    Elapsed: 0:00:46.\n",
            "\n",
            "  Average training loss: 0.64\n",
            "  Accuracy: 0.78\n",
            "Category: 0\n",
            "  Precision: 0.81\n",
            "  Recall: 0.95\n",
            "  F1: 0.87\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "Category: 2\n",
            "  Precision: 0.53\n",
            "  Recall: 0.38\n",
            "  F1: 0.39\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.3359\n",
            "The average recall is: 0.3339\n",
            "The average f1 is: 0.3153\n",
            "  Training epcoh took: 0:01:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8820\n",
            "  Recall: 0.9666\n",
            "  F1: 0.9206\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.2628\n",
            "  Recall: 0.2051\n",
            "  F1: 0.2141\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.2862\n",
            "The average recall is: 0.2929\n",
            "The average f1 is: 0.2837\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    115.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    115.    Elapsed: 0:00:45.\n",
            "\n",
            "  Average training loss: 0.41\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.91\n",
            "  Recall: 0.97\n",
            "  F1: 0.94\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "Category: 2\n",
            "  Precision: 0.71\n",
            "  Recall: 0.74\n",
            "  F1: 0.70\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.4042\n",
            "The average recall is: 0.4287\n",
            "The average f1 is: 0.4083\n",
            "  Training epcoh took: 0:01:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.9038\n",
            "  Recall: 0.9315\n",
            "  F1: 0.9159\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3590\n",
            "  Recall: 0.4487\n",
            "  F1: 0.3701\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3157\n",
            "The average recall is: 0.3450\n",
            "The average f1 is: 0.3215\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    115.    Elapsed: 0:00:24.\n",
            "  Batch    80  of    115.    Elapsed: 0:00:46.\n",
            "\n",
            "  Average training loss: 0.27\n",
            "  Accuracy: 0.92\n",
            "Category: 0\n",
            "  Precision: 0.95\n",
            "  Recall: 0.99\n",
            "  F1: 0.97\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "Category: 2\n",
            "  Precision: 0.78\n",
            "  Recall: 0.91\n",
            "  F1: 0.83\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.4336\n",
            "The average recall is: 0.4756\n",
            "The average f1 is: 0.4487\n",
            "  Training epcoh took: 0:01:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8949\n",
            "  Recall: 0.9532\n",
            "  F1: 0.9210\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3846\n",
            "  Recall: 0.2981\n",
            "  F1: 0.3192\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3199\n",
            "The average recall is: 0.3128\n",
            "The average f1 is: 0.3101\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "Training complete!\n",
            "Current increase 2 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 1694 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 1694 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 2056 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 2056 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 2080 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.6538461538461539\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "141\n",
            "0.06778846153846153\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "543\n",
            "0.2610576923076923\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "36\n",
            "0.01730769230769231\n",
            "\n",
            "(2080, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 11:23:19.216536 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 11:23:19.217864 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 11:23:19.327399 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 11:23:21.958952 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 11:23:21.960213 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    130.    Elapsed: 0:00:22.\n",
            "  Batch    80  of    130.    Elapsed: 0:00:46.\n",
            "  Batch   120  of    130.    Elapsed: 0:01:09.\n",
            "\n",
            "  Average training loss: 0.82\n",
            "  Accuracy: 0.69\n",
            "Category: 0\n",
            "  Precision: 0.70\n",
            "  Recall: 0.95\n",
            "  F1: 0.80\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "Category: 2\n",
            "  Precision: 0.33\n",
            "  Recall: 0.23\n",
            "  F1: 0.24\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.01\n",
            "  F1: 0.00\n",
            "The average precision is: 0.2586\n",
            "The average recall is: 0.2975\n",
            "The average f1 is: 0.2598\n",
            "  Training epcoh took: 0:01:15\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8766\n",
            "  Recall: 0.9759\n",
            "  F1: 0.9211\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3269\n",
            "  Recall: 0.2756\n",
            "  F1: 0.2782\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3009\n",
            "The average recall is: 0.3129\n",
            "The average f1 is: 0.2998\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    130.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    130.    Elapsed: 0:00:47.\n",
            "  Batch   120  of    130.    Elapsed: 0:01:10.\n",
            "\n",
            "  Average training loss: 0.53\n",
            "  Accuracy: 0.83\n",
            "Category: 0\n",
            "  Precision: 0.87\n",
            "  Recall: 0.94\n",
            "  F1: 0.90\n",
            "Category: 1\n",
            "  Precision: 0.02\n",
            "  Recall: 0.01\n",
            "  F1: 0.01\n",
            "Category: 2\n",
            "  Precision: 0.74\n",
            "  Recall: 0.79\n",
            "  F1: 0.73\n",
            "Category: 3\n",
            "  Precision: 0.02\n",
            "  Recall: 0.01\n",
            "  F1: 0.01\n",
            "The average precision is: 0.4104\n",
            "The average recall is: 0.4382\n",
            "The average f1 is: 0.4134\n",
            "  Training epcoh took: 0:01:16\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8901\n",
            "  Recall: 0.9470\n",
            "  F1: 0.9157\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0192\n",
            "  F1: 0.0256\n",
            "Category: 2\n",
            "  Precision: 0.2788\n",
            "  Recall: 0.3244\n",
            "  F1: 0.2912\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3018\n",
            "The average recall is: 0.3226\n",
            "The average f1 is: 0.3081\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    130.    Elapsed: 0:00:24.\n",
            "  Batch    80  of    130.    Elapsed: 0:00:48.\n",
            "  Batch   120  of    130.    Elapsed: 0:01:11.\n",
            "\n",
            "  Average training loss: 0.24\n",
            "  Accuracy: 0.92\n",
            "Category: 0\n",
            "  Precision: 0.94\n",
            "  Recall: 0.99\n",
            "  F1: 0.96\n",
            "Category: 1\n",
            "  Precision: 0.38\n",
            "  Recall: 0.33\n",
            "  F1: 0.34\n",
            "Category: 2\n",
            "  Precision: 0.87\n",
            "  Recall: 0.92\n",
            "  F1: 0.89\n",
            "Category: 3\n",
            "  Precision: 0.04\n",
            "  Recall: 0.04\n",
            "  F1: 0.04\n",
            "The average precision is: 0.5594\n",
            "The average recall is: 0.5671\n",
            "The average f1 is: 0.5558\n",
            "  Training epcoh took: 0:01:17\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.8980\n",
            "  Recall: 0.9233\n",
            "  F1: 0.9080\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0192\n",
            "  F1: 0.0256\n",
            "Category: 2\n",
            "  Precision: 0.3468\n",
            "  Recall: 0.3564\n",
            "  F1: 0.3216\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3208\n",
            "The average recall is: 0.3247\n",
            "The average f1 is: 0.3138\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    130.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    130.    Elapsed: 0:00:47.\n",
            "  Batch   120  of    130.    Elapsed: 0:01:09.\n",
            "\n",
            "  Average training loss: 0.09\n",
            "  Accuracy: 0.97\n",
            "Category: 0\n",
            "  Precision: 0.98\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.63\n",
            "  Recall: 0.63\n",
            "  F1: 0.62\n",
            "Category: 2\n",
            "  Precision: 0.96\n",
            "  Recall: 0.98\n",
            "  F1: 0.96\n",
            "Category: 3\n",
            "  Precision: 0.11\n",
            "  Recall: 0.10\n",
            "  F1: 0.10\n",
            "The average precision is: 0.6681\n",
            "The average recall is: 0.6752\n",
            "The average f1 is: 0.6677\n",
            "  Training epcoh took: 0:01:15\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.8932\n",
            "  Recall: 0.9308\n",
            "  F1: 0.9088\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0385\n",
            "Category: 2\n",
            "  Precision: 0.4744\n",
            "  Recall: 0.4231\n",
            "  F1: 0.4189\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3515\n",
            "The average recall is: 0.3481\n",
            "The average f1 is: 0.3415\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "Training complete!\n",
            "Current increase 3 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 1741 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 1741 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 2284 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 2284 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 2320 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.5862068965517241\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "188\n",
            "0.08103448275862069\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "724\n",
            "0.3120689655172414\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "48\n",
            "0.020689655172413793\n",
            "\n",
            "(2320, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 11:28:40.570392 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 11:28:40.571987 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 11:28:40.677933 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 11:28:43.133379 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 11:28:43.134109 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    145.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    145.    Elapsed: 0:00:41.\n",
            "  Batch   120  of    145.    Elapsed: 0:01:01.\n",
            "\n",
            "  Average training loss: 0.89\n",
            "  Accuracy: 0.64\n",
            "Category: 0\n",
            "  Precision: 0.67\n",
            "  Recall: 0.90\n",
            "  F1: 0.75\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "Category: 2\n",
            "  Precision: 0.44\n",
            "  Recall: 0.37\n",
            "  F1: 0.36\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.2781\n",
            "The average recall is: 0.3162\n",
            "The average f1 is: 0.2768\n",
            "  Training epcoh took: 0:01:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "Category: 0\n",
            "  Precision: 0.8613\n",
            "  Recall: 0.9085\n",
            "  F1: 0.8823\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.4359\n",
            "  Recall: 0.4705\n",
            "  F1: 0.4247\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3243\n",
            "The average recall is: 0.3447\n",
            "The average f1 is: 0.3267\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    145.    Elapsed: 0:00:20.\n",
            "  Batch    80  of    145.    Elapsed: 0:00:40.\n",
            "  Batch   120  of    145.    Elapsed: 0:01:00.\n",
            "\n",
            "  Average training loss: 0.48\n",
            "  Accuracy: 0.83\n",
            "Category: 0\n",
            "  Precision: 0.85\n",
            "  Recall: 0.94\n",
            "  F1: 0.89\n",
            "Category: 1\n",
            "  Precision: 0.16\n",
            "  Recall: 0.12\n",
            "  F1: 0.13\n",
            "Category: 2\n",
            "  Precision: 0.81\n",
            "  Recall: 0.86\n",
            "  F1: 0.82\n",
            "Category: 3\n",
            "  Precision: 0.01\n",
            "  Recall: 0.01\n",
            "  F1: 0.01\n",
            "The average precision is: 0.4598\n",
            "The average recall is: 0.4826\n",
            "The average f1 is: 0.4614\n",
            "  Training epcoh took: 0:01:12\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8983\n",
            "  Recall: 0.9507\n",
            "  F1: 0.9201\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0385\n",
            "Category: 2\n",
            "  Precision: 0.4397\n",
            "  Recall: 0.3750\n",
            "  F1: 0.3640\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3441\n",
            "The average recall is: 0.3410\n",
            "The average f1 is: 0.3306\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    145.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    145.    Elapsed: 0:00:43.\n",
            "  Batch   120  of    145.    Elapsed: 0:01:05.\n",
            "\n",
            "  Average training loss: 0.15\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.97\n",
            "  Recall: 0.99\n",
            "  F1: 0.97\n",
            "Category: 1\n",
            "  Precision: 0.63\n",
            "  Recall: 0.63\n",
            "  F1: 0.62\n",
            "Category: 2\n",
            "  Precision: 0.97\n",
            "  Recall: 0.98\n",
            "  F1: 0.97\n",
            "Category: 3\n",
            "  Precision: 0.07\n",
            "  Recall: 0.06\n",
            "  F1: 0.07\n",
            "The average precision is: 0.6572\n",
            "The average recall is: 0.6657\n",
            "The average f1 is: 0.6569\n",
            "  Training epcoh took: 0:01:18\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.8949\n",
            "  Recall: 0.9308\n",
            "  F1: 0.9112\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0385\n",
            "Category: 2\n",
            "  Precision: 0.3647\n",
            "  Recall: 0.4199\n",
            "  F1: 0.3713\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3245\n",
            "The average recall is: 0.3473\n",
            "The average f1 is: 0.3302\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    145.    Elapsed: 0:00:22.\n",
            "  Batch    80  of    145.    Elapsed: 0:00:44.\n",
            "  Batch   120  of    145.    Elapsed: 0:01:08.\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 1.00\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.76\n",
            "  Recall: 0.77\n",
            "  F1: 0.76\n",
            "Category: 2\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 3\n",
            "  Precision: 0.15\n",
            "  Recall: 0.14\n",
            "  F1: 0.14\n",
            "The average precision is: 0.7211\n",
            "The average recall is: 0.7252\n",
            "The average f1 is: 0.7219\n",
            "  Training epcoh took: 0:01:22\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.9008\n",
            "  Recall: 0.9526\n",
            "  F1: 0.9225\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0385\n",
            "Category: 2\n",
            "  Precision: 0.4167\n",
            "  Recall: 0.3750\n",
            "  F1: 0.3432\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3390\n",
            "The average recall is: 0.3415\n",
            "The average f1 is: 0.3260\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "Training complete!\n",
            "Current increase 4 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 1788 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 1788 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 2512 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 2512 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 2560 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.53125\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "235\n",
            "0.091796875\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "905\n",
            "0.353515625\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "60\n",
            "0.0234375\n",
            "\n",
            "(2560, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 11:34:03.566000 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 11:34:03.574103 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 11:34:06.089287 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 11:34:08.554096 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 11:34:08.555109 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    160.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    160.    Elapsed: 0:00:44.\n",
            "  Batch   120  of    160.    Elapsed: 0:01:07.\n",
            "\n",
            "  Average training loss: 0.86\n",
            "  Accuracy: 0.64\n",
            "Category: 0\n",
            "  Precision: 0.67\n",
            "  Recall: 0.86\n",
            "  F1: 0.73\n",
            "Category: 1\n",
            "  Precision: 0.15\n",
            "  Recall: 0.10\n",
            "  F1: 0.12\n",
            "Category: 2\n",
            "  Precision: 0.54\n",
            "  Recall: 0.48\n",
            "  F1: 0.47\n",
            "Category: 3\n",
            "  Precision: 0.01\n",
            "  Recall: 0.01\n",
            "  F1: 0.01\n",
            "The average precision is: 0.3423\n",
            "The average recall is: 0.3637\n",
            "The average f1 is: 0.3302\n",
            "  Training epcoh took: 0:01:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.75\n",
            "Category: 0\n",
            "  Precision: 0.9130\n",
            "  Recall: 0.7878\n",
            "  F1: 0.8429\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0577\n",
            "  F1: 0.0641\n",
            "Category: 2\n",
            "  Precision: 0.2396\n",
            "  Recall: 0.5051\n",
            "  F1: 0.3127\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3074\n",
            "The average recall is: 0.3376\n",
            "The average f1 is: 0.3049\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    160.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    160.    Elapsed: 0:00:46.\n",
            "  Batch   120  of    160.    Elapsed: 0:01:09.\n",
            "\n",
            "  Average training loss: 0.27\n",
            "  Accuracy: 0.92\n",
            "Category: 0\n",
            "  Precision: 0.92\n",
            "  Recall: 0.95\n",
            "  F1: 0.93\n",
            "Category: 1\n",
            "  Precision: 0.73\n",
            "  Recall: 0.71\n",
            "  F1: 0.71\n",
            "Category: 2\n",
            "  Precision: 0.91\n",
            "  Recall: 0.93\n",
            "  F1: 0.91\n",
            "Category: 3\n",
            "  Precision: 0.03\n",
            "  Recall: 0.03\n",
            "  F1: 0.03\n",
            "The average precision is: 0.6493\n",
            "The average recall is: 0.6554\n",
            "The average f1 is: 0.6460\n",
            "  Training epcoh took: 0:01:32\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.9019\n",
            "  Recall: 0.9397\n",
            "  F1: 0.9184\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3878\n",
            "  Recall: 0.4519\n",
            "  F1: 0.3966\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3224\n",
            "The average recall is: 0.3479\n",
            "The average f1 is: 0.3288\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    160.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    160.    Elapsed: 0:00:41.\n",
            "  Batch   120  of    160.    Elapsed: 0:01:01.\n",
            "\n",
            "  Average training loss: 0.05\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.74\n",
            "  Recall: 0.75\n",
            "  F1: 0.74\n",
            "Category: 2\n",
            "  Precision: 0.99\n",
            "  Recall: 1.00\n",
            "  F1: 0.99\n",
            "Category: 3\n",
            "  Precision: 0.21\n",
            "  Recall: 0.21\n",
            "  F1: 0.21\n",
            "The average precision is: 0.7325\n",
            "The average recall is: 0.7374\n",
            "The average f1 is: 0.7335\n",
            "  Training epcoh took: 0:01:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8818\n",
            "  Recall: 0.9676\n",
            "  F1: 0.9201\n",
            "Category: 1\n",
            "  Precision: 0.0192\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0256\n",
            "Category: 2\n",
            "  Precision: 0.4231\n",
            "  Recall: 0.2756\n",
            "  F1: 0.3189\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3310\n",
            "The average recall is: 0.3204\n",
            "The average f1 is: 0.3161\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    160.    Elapsed: 0:00:20.\n",
            "  Batch    80  of    160.    Elapsed: 0:00:40.\n",
            "  Batch   120  of    160.    Elapsed: 0:01:00.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.82\n",
            "  Recall: 0.82\n",
            "  F1: 0.82\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.29\n",
            "  Recall: 0.29\n",
            "  F1: 0.29\n",
            "The average precision is: 0.7793\n",
            "The average recall is: 0.7791\n",
            "The average f1 is: 0.7791\n",
            "  Training epcoh took: 0:01:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8950\n",
            "  Recall: 0.9594\n",
            "  F1: 0.9242\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0385\n",
            "Category: 2\n",
            "  Precision: 0.4231\n",
            "  Recall: 0.3718\n",
            "  F1: 0.3758\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3391\n",
            "The average recall is: 0.3424\n",
            "The average f1 is: 0.3346\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n",
            "Current increase 5 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 1835 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 1835 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 2740 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 2740 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 2800 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.4857142857142857\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "282\n",
            "0.10071428571428571\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1086\n",
            "0.38785714285714284\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "72\n",
            "0.025714285714285714\n",
            "\n",
            "(2800, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 11:40:07.610087 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 11:40:07.611428 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 11:40:07.689909 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 11:40:10.274213 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 11:40:10.274944 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    175.    Elapsed: 0:00:43.\n",
            "  Batch   120  of    175.    Elapsed: 0:01:06.\n",
            "  Batch   160  of    175.    Elapsed: 0:01:28.\n",
            "\n",
            "  Average training loss: 0.82\n",
            "  Accuracy: 0.66\n",
            "Category: 0\n",
            "  Precision: 0.70\n",
            "  Recall: 0.82\n",
            "  F1: 0.73\n",
            "Category: 1\n",
            "  Precision: 0.10\n",
            "  Recall: 0.08\n",
            "  F1: 0.08\n",
            "Category: 2\n",
            "  Precision: 0.62\n",
            "  Recall: 0.66\n",
            "  F1: 0.61\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.3541\n",
            "The average recall is: 0.3898\n",
            "The average f1 is: 0.3538\n",
            "  Training epcoh took: 0:01:36\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "Category: 0\n",
            "  Precision: 0.8546\n",
            "  Recall: 0.9181\n",
            "  F1: 0.8811\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0385\n",
            "Category: 2\n",
            "  Precision: 0.3558\n",
            "  Recall: 0.2929\n",
            "  F1: 0.2808\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3122\n",
            "The average recall is: 0.3124\n",
            "The average f1 is: 0.3001\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    175.    Elapsed: 0:00:45.\n",
            "  Batch   120  of    175.    Elapsed: 0:01:09.\n",
            "  Batch   160  of    175.    Elapsed: 0:01:32.\n",
            "\n",
            "  Average training loss: 0.20\n",
            "  Accuracy: 0.94\n",
            "Category: 0\n",
            "  Precision: 0.94\n",
            "  Recall: 0.96\n",
            "  F1: 0.94\n",
            "Category: 1\n",
            "  Precision: 0.68\n",
            "  Recall: 0.69\n",
            "  F1: 0.67\n",
            "Category: 2\n",
            "  Precision: 0.95\n",
            "  Recall: 0.98\n",
            "  F1: 0.96\n",
            "Category: 3\n",
            "  Precision: 0.08\n",
            "  Recall: 0.07\n",
            "  F1: 0.07\n",
            "The average precision is: 0.6624\n",
            "The average recall is: 0.6735\n",
            "The average f1 is: 0.6625\n",
            "  Training epcoh took: 0:01:40\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8811\n",
            "  Recall: 0.9722\n",
            "  F1: 0.9224\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3654\n",
            "  Recall: 0.2853\n",
            "  F1: 0.3103\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3116\n",
            "The average recall is: 0.3144\n",
            "The average f1 is: 0.3082\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:22.\n",
            "  Batch    80  of    175.    Elapsed: 0:00:44.\n",
            "  Batch   120  of    175.    Elapsed: 0:01:05.\n",
            "  Batch   160  of    175.    Elapsed: 0:01:26.\n",
            "\n",
            "  Average training loss: 0.03\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.83\n",
            "  Recall: 0.83\n",
            "  F1: 0.83\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.33\n",
            "  Recall: 0.33\n",
            "  F1: 0.33\n",
            "The average precision is: 0.7862\n",
            "The average recall is: 0.7865\n",
            "The average f1 is: 0.7861\n",
            "  Training epcoh took: 0:01:35\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8805\n",
            "  Recall: 0.9713\n",
            "  F1: 0.9220\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3910\n",
            "  Recall: 0.2609\n",
            "  F1: 0.2939\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3179\n",
            "The average recall is: 0.3080\n",
            "The average f1 is: 0.3040\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:22.\n",
            "  Batch    80  of    175.    Elapsed: 0:00:45.\n",
            "  Batch   120  of    175.    Elapsed: 0:01:07.\n",
            "  Batch   160  of    175.    Elapsed: 0:01:29.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.85\n",
            "  Recall: 0.85\n",
            "  F1: 0.85\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.35\n",
            "  Recall: 0.35\n",
            "  F1: 0.35\n",
            "The average precision is: 0.7983\n",
            "The average recall is: 0.7984\n",
            "The average f1 is: 0.7984\n",
            "  Training epcoh took: 0:01:38\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8822\n",
            "  Recall: 0.9633\n",
            "  F1: 0.9179\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3750\n",
            "  Recall: 0.2564\n",
            "  F1: 0.2897\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3143\n",
            "The average recall is: 0.3049\n",
            "The average f1 is: 0.3019\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "Training complete!\n",
            "Current increase 6 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 1882 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 1882 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 2968 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 2968 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 3040 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.4473684210526316\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "329\n",
            "0.10822368421052632\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1267\n",
            "0.41677631578947366\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "84\n",
            "0.02763157894736842\n",
            "\n",
            "(3040, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 11:46:54.808687 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 11:46:54.809833 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 11:46:54.907822 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 11:46:57.468899 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 11:46:57.469692 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    190.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    190.    Elapsed: 0:00:44.\n",
            "  Batch   120  of    190.    Elapsed: 0:01:07.\n",
            "  Batch   160  of    190.    Elapsed: 0:01:31.\n",
            "\n",
            "  Average training loss: 0.82\n",
            "  Accuracy: 0.66\n",
            "Category: 0\n",
            "  Precision: 0.64\n",
            "  Recall: 0.77\n",
            "  F1: 0.68\n",
            "Category: 1\n",
            "  Precision: 0.11\n",
            "  Recall: 0.09\n",
            "  F1: 0.10\n",
            "Category: 2\n",
            "  Precision: 0.68\n",
            "  Recall: 0.73\n",
            "  F1: 0.67\n",
            "Category: 3\n",
            "  Precision: 0.02\n",
            "  Recall: 0.02\n",
            "  F1: 0.02\n",
            "The average precision is: 0.3633\n",
            "The average recall is: 0.4023\n",
            "The average f1 is: 0.3654\n",
            "  Training epcoh took: 0:01:48\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.77\n",
            "Category: 0\n",
            "  Precision: 0.9190\n",
            "  Recall: 0.8167\n",
            "  F1: 0.8590\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.2642\n",
            "  Recall: 0.5128\n",
            "  F1: 0.3237\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3150\n",
            "The average recall is: 0.3516\n",
            "The average f1 is: 0.3149\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    190.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    190.    Elapsed: 0:00:46.\n",
            "  Batch   120  of    190.    Elapsed: 0:01:09.\n",
            "  Batch   160  of    190.    Elapsed: 0:01:33.\n",
            "\n",
            "  Average training loss: 0.14\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.96\n",
            "  Recall: 0.97\n",
            "  F1: 0.96\n",
            "Category: 1\n",
            "  Precision: 0.72\n",
            "  Recall: 0.74\n",
            "  F1: 0.72\n",
            "Category: 2\n",
            "  Precision: 0.96\n",
            "  Recall: 0.97\n",
            "  F1: 0.96\n",
            "Category: 3\n",
            "  Precision: 0.26\n",
            "  Recall: 0.25\n",
            "  F1: 0.25\n",
            "The average precision is: 0.7274\n",
            "The average recall is: 0.7306\n",
            "The average f1 is: 0.7244\n",
            "  Training epcoh took: 0:01:50\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.9014\n",
            "  Recall: 0.9697\n",
            "  F1: 0.9313\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0128\n",
            "  F1: 0.0192\n",
            "Category: 2\n",
            "  Precision: 0.5000\n",
            "  Recall: 0.4359\n",
            "  F1: 0.4423\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3600\n",
            "The average recall is: 0.3546\n",
            "The average f1 is: 0.3482\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    190.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    190.    Elapsed: 0:00:46.\n",
            "  Batch   120  of    190.    Elapsed: 0:01:10.\n",
            "  Batch   160  of    190.    Elapsed: 0:01:33.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 0.99\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.83\n",
            "  Recall: 0.83\n",
            "  F1: 0.83\n",
            "Category: 2\n",
            "  Precision: 0.99\n",
            "  Recall: 1.00\n",
            "  F1: 0.99\n",
            "Category: 3\n",
            "  Precision: 0.36\n",
            "  Recall: 0.36\n",
            "  F1: 0.36\n",
            "The average precision is: 0.7956\n",
            "The average recall is: 0.7952\n",
            "The average f1 is: 0.7948\n",
            "  Training epcoh took: 0:01:51\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.9071\n",
            "  Recall: 0.9264\n",
            "  F1: 0.9136\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0096\n",
            "  F1: 0.0154\n",
            "Category: 2\n",
            "  Precision: 0.3750\n",
            "  Recall: 0.4628\n",
            "  F1: 0.3650\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3301\n",
            "The average recall is: 0.3497\n",
            "The average f1 is: 0.3235\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    190.    Elapsed: 0:00:24.\n",
            "  Batch    80  of    190.    Elapsed: 0:00:47.\n",
            "  Batch   120  of    190.    Elapsed: 0:01:08.\n",
            "  Batch   160  of    190.    Elapsed: 0:01:30.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.86\n",
            "  Recall: 0.86\n",
            "  F1: 0.86\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.38\n",
            "  Recall: 0.38\n",
            "  F1: 0.38\n",
            "The average precision is: 0.8080\n",
            "The average recall is: 0.8083\n",
            "The average f1 is: 0.8080\n",
            "  Training epcoh took: 0:01:47\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "Category: 0\n",
            "  Precision: 0.8969\n",
            "  Recall: 0.9805\n",
            "  F1: 0.9329\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0192\n",
            "  F1: 0.0256\n",
            "Category: 2\n",
            "  Precision: 0.4103\n",
            "  Recall: 0.3333\n",
            "  F1: 0.3500\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3364\n",
            "The average recall is: 0.3333\n",
            "The average f1 is: 0.3271\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "Training complete!\n",
            "Current increase 7 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 1929 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 1929 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 3196 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 3196 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 3280 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.4146341463414634\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "376\n",
            "0.11463414634146342\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1448\n",
            "0.44146341463414634\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "96\n",
            "0.02926829268292683\n",
            "\n",
            "(3280, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 11:54:29.928223 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 11:54:29.929541 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 11:54:30.028445 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 11:54:32.527729 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 11:54:32.528469 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    205.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    205.    Elapsed: 0:00:43.\n",
            "  Batch   120  of    205.    Elapsed: 0:01:05.\n",
            "  Batch   160  of    205.    Elapsed: 0:01:26.\n",
            "  Batch   200  of    205.    Elapsed: 0:01:48.\n",
            "\n",
            "  Average training loss: 0.81\n",
            "  Accuracy: 0.66\n",
            "Category: 0\n",
            "  Precision: 0.61\n",
            "  Recall: 0.71\n",
            "  F1: 0.63\n",
            "Category: 1\n",
            "  Precision: 0.07\n",
            "  Recall: 0.05\n",
            "  F1: 0.05\n",
            "Category: 2\n",
            "  Precision: 0.72\n",
            "  Recall: 0.83\n",
            "  F1: 0.74\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.3519\n",
            "The average recall is: 0.3975\n",
            "The average f1 is: 0.3562\n",
            "  Training epcoh took: 0:01:50\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "Category: 0\n",
            "  Precision: 0.8270\n",
            "  Recall: 0.9312\n",
            "  F1: 0.8733\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.2179\n",
            "  Recall: 0.1795\n",
            "  F1: 0.1718\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.2612\n",
            "The average recall is: 0.2777\n",
            "The average f1 is: 0.2613\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    205.    Elapsed: 0:00:22.\n",
            "  Batch    80  of    205.    Elapsed: 0:00:44.\n",
            "  Batch   120  of    205.    Elapsed: 0:01:07.\n",
            "  Batch   160  of    205.    Elapsed: 0:01:29.\n",
            "  Batch   200  of    205.    Elapsed: 0:01:51.\n",
            "\n",
            "  Average training loss: 0.16\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.94\n",
            "  Recall: 0.95\n",
            "  F1: 0.94\n",
            "Category: 1\n",
            "  Precision: 0.74\n",
            "  Recall: 0.74\n",
            "  F1: 0.73\n",
            "Category: 2\n",
            "  Precision: 0.97\n",
            "  Recall: 0.98\n",
            "  F1: 0.97\n",
            "Category: 3\n",
            "  Precision: 0.27\n",
            "  Recall: 0.27\n",
            "  F1: 0.27\n",
            "The average precision is: 0.7299\n",
            "The average recall is: 0.7351\n",
            "The average f1 is: 0.7275\n",
            "  Training epcoh took: 0:01:54\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.8907\n",
            "  Recall: 0.9329\n",
            "  F1: 0.9078\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0385\n",
            "Category: 2\n",
            "  Precision: 0.2718\n",
            "  Recall: 0.2891\n",
            "  F1: 0.2582\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3003\n",
            "The average recall is: 0.3151\n",
            "The average f1 is: 0.3011\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    205.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    205.    Elapsed: 0:00:46.\n",
            "  Batch   120  of    205.    Elapsed: 0:01:08.\n",
            "  Batch   160  of    205.    Elapsed: 0:01:30.\n",
            "  Batch   200  of    205.    Elapsed: 0:01:53.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.89\n",
            "  Recall: 0.89\n",
            "  F1: 0.89\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.36\n",
            "  Recall: 0.36\n",
            "  F1: 0.36\n",
            "The average precision is: 0.8106\n",
            "The average recall is: 0.8110\n",
            "The average f1 is: 0.8106\n",
            "  Training epcoh took: 0:01:56\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8771\n",
            "  Recall: 0.9686\n",
            "  F1: 0.9183\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0385\n",
            "Category: 2\n",
            "  Precision: 0.2436\n",
            "  Recall: 0.1968\n",
            "  F1: 0.1919\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.2898\n",
            "The average recall is: 0.3010\n",
            "The average f1 is: 0.2872\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    205.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    205.    Elapsed: 0:00:46.\n",
            "  Batch   120  of    205.    Elapsed: 0:01:09.\n",
            "  Batch   160  of    205.    Elapsed: 0:01:32.\n",
            "  Batch   200  of    205.    Elapsed: 0:01:55.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.83\n",
            "  Recall: 0.83\n",
            "  F1: 0.83\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.39\n",
            "  Recall: 0.39\n",
            "  F1: 0.39\n",
            "The average precision is: 0.8047\n",
            "The average recall is: 0.8046\n",
            "The average f1 is: 0.8047\n",
            "  Training epcoh took: 0:01:58\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8773\n",
            "  Recall: 0.9530\n",
            "  F1: 0.9097\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0077\n",
            "  F1: 0.0128\n",
            "Category: 2\n",
            "  Precision: 0.3429\n",
            "  Recall: 0.2962\n",
            "  F1: 0.2803\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3147\n",
            "The average recall is: 0.3142\n",
            "The average f1 is: 0.3007\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "Training complete!\n",
            "Current increase 8 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 1976 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 1976 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 3424 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 3424 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 3520 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.38636363636363635\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "423\n",
            "0.12017045454545454\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1629\n",
            "0.4627840909090909\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "108\n",
            "0.03068181818181818\n",
            "\n",
            "(3520, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 12:02:27.361306 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 12:02:27.362771 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 12:02:27.488239 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 12:02:30.022622 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 12:02:30.023328 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    220.    Elapsed: 0:00:22.\n",
            "  Batch    80  of    220.    Elapsed: 0:00:44.\n",
            "  Batch   120  of    220.    Elapsed: 0:01:07.\n",
            "  Batch   160  of    220.    Elapsed: 0:01:30.\n",
            "  Batch   200  of    220.    Elapsed: 0:01:54.\n",
            "\n",
            "  Average training loss: 0.75\n",
            "  Accuracy: 0.69\n",
            "Category: 0\n",
            "  Precision: 0.67\n",
            "  Recall: 0.72\n",
            "  F1: 0.66\n",
            "Category: 1\n",
            "  Precision: 0.25\n",
            "  Recall: 0.22\n",
            "  F1: 0.22\n",
            "Category: 2\n",
            "  Precision: 0.74\n",
            "  Recall: 0.83\n",
            "  F1: 0.76\n",
            "Category: 3\n",
            "  Precision: 0.01\n",
            "  Recall: 0.01\n",
            "  F1: 0.01\n",
            "The average precision is: 0.4172\n",
            "The average recall is: 0.4459\n",
            "The average f1 is: 0.4116\n",
            "  Training epcoh took: 0:02:05\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.62\n",
            "Category: 0\n",
            "  Precision: 0.9520\n",
            "  Recall: 0.6288\n",
            "  F1: 0.7436\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.1714\n",
            "  Recall: 0.6590\n",
            "  F1: 0.2579\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.2809\n",
            "The average recall is: 0.3220\n",
            "The average f1 is: 0.2504\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    220.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    220.    Elapsed: 0:00:47.\n",
            "  Batch   120  of    220.    Elapsed: 0:01:10.\n",
            "  Batch   160  of    220.    Elapsed: 0:01:33.\n",
            "  Batch   200  of    220.    Elapsed: 0:01:56.\n",
            "\n",
            "  Average training loss: 0.10\n",
            "  Accuracy: 0.97\n",
            "Category: 0\n",
            "  Precision: 0.96\n",
            "  Recall: 0.96\n",
            "  F1: 0.96\n",
            "Category: 1\n",
            "  Precision: 0.80\n",
            "  Recall: 0.81\n",
            "  F1: 0.80\n",
            "Category: 2\n",
            "  Precision: 0.98\n",
            "  Recall: 0.99\n",
            "  F1: 0.98\n",
            "Category: 3\n",
            "  Precision: 0.30\n",
            "  Recall: 0.29\n",
            "  F1: 0.29\n",
            "The average precision is: 0.7603\n",
            "The average recall is: 0.7654\n",
            "The average f1 is: 0.7594\n",
            "  Training epcoh took: 0:02:08\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8633\n",
            "  Recall: 0.9198\n",
            "  F1: 0.8882\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0513\n",
            "Category: 2\n",
            "  Precision: 0.4615\n",
            "  Recall: 0.3814\n",
            "  F1: 0.4040\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3504\n",
            "The average recall is: 0.3349\n",
            "The average f1 is: 0.3359\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    220.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    220.    Elapsed: 0:00:46.\n",
            "  Batch   120  of    220.    Elapsed: 0:01:09.\n",
            "  Batch   160  of    220.    Elapsed: 0:01:32.\n",
            "  Batch   200  of    220.    Elapsed: 0:01:55.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.81\n",
            "  Recall: 0.81\n",
            "  F1: 0.81\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.43\n",
            "  Recall: 0.43\n",
            "  F1: 0.43\n",
            "The average precision is: 0.8092\n",
            "The average recall is: 0.8094\n",
            "The average f1 is: 0.8092\n",
            "  Training epcoh took: 0:02:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "Category: 0\n",
            "  Precision: 0.8507\n",
            "  Recall: 0.9367\n",
            "  F1: 0.8891\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0385\n",
            "Category: 2\n",
            "  Precision: 0.4423\n",
            "  Recall: 0.3333\n",
            "  F1: 0.3496\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3329\n",
            "The average recall is: 0.3271\n",
            "The average f1 is: 0.3193\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    220.    Elapsed: 0:00:24.\n",
            "  Batch    80  of    220.    Elapsed: 0:00:47.\n",
            "  Batch   120  of    220.    Elapsed: 0:01:10.\n",
            "  Batch   160  of    220.    Elapsed: 0:01:33.\n",
            "  Batch   200  of    220.    Elapsed: 0:01:56.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.85\n",
            "  Recall: 0.85\n",
            "  F1: 0.85\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.39\n",
            "  Recall: 0.39\n",
            "  F1: 0.39\n",
            "The average precision is: 0.8098\n",
            "The average recall is: 0.8099\n",
            "The average f1 is: 0.8098\n",
            "  Training epcoh took: 0:02:08\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8817\n",
            "  Recall: 0.9748\n",
            "  F1: 0.9231\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0385\n",
            "Category: 2\n",
            "  Precision: 0.3590\n",
            "  Recall: 0.2676\n",
            "  F1: 0.2873\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3198\n",
            "The average recall is: 0.3202\n",
            "The average f1 is: 0.3122\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "Training complete!\n",
            "Current increase 9 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 2023 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 2023 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 3652 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 3652 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 3760 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.3617021276595745\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "470\n",
            "0.125\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1810\n",
            "0.48138297872340424\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "120\n",
            "0.031914893617021274\n",
            "\n",
            "(3760, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 12:11:13.596107 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 12:11:13.597431 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 12:11:13.683410 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 12:11:16.207567 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 12:11:16.208325 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    235.    Elapsed: 0:00:22.\n",
            "  Batch    80  of    235.    Elapsed: 0:00:46.\n",
            "  Batch   120  of    235.    Elapsed: 0:01:09.\n",
            "  Batch   160  of    235.    Elapsed: 0:01:32.\n",
            "  Batch   200  of    235.    Elapsed: 0:01:55.\n",
            "\n",
            "  Average training loss: 0.80\n",
            "  Accuracy: 0.67\n",
            "Category: 0\n",
            "  Precision: 0.59\n",
            "  Recall: 0.55\n",
            "  F1: 0.54\n",
            "Category: 1\n",
            "  Precision: 0.34\n",
            "  Recall: 0.31\n",
            "  F1: 0.30\n",
            "Category: 2\n",
            "  Precision: 0.69\n",
            "  Recall: 0.87\n",
            "  F1: 0.74\n",
            "Category: 3\n",
            "  Precision: 0.03\n",
            "  Recall: 0.02\n",
            "  F1: 0.03\n",
            "The average precision is: 0.4122\n",
            "The average recall is: 0.4396\n",
            "The average f1 is: 0.4025\n",
            "  Training epcoh took: 0:02:15\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.79\n",
            "Category: 0\n",
            "  Precision: 0.9054\n",
            "  Recall: 0.8625\n",
            "  F1: 0.8780\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.2810\n",
            "  Recall: 0.5128\n",
            "  F1: 0.3407\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.2966\n",
            "The average recall is: 0.3438\n",
            "The average f1 is: 0.3047\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    235.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    235.    Elapsed: 0:00:47.\n",
            "  Batch   120  of    235.    Elapsed: 0:01:10.\n",
            "  Batch   160  of    235.    Elapsed: 0:01:33.\n",
            "  Batch   200  of    235.    Elapsed: 0:01:56.\n",
            "\n",
            "  Average training loss: 0.12\n",
            "  Accuracy: 0.97\n",
            "Category: 0\n",
            "  Precision: 0.96\n",
            "  Recall: 0.96\n",
            "  F1: 0.95\n",
            "Category: 1\n",
            "  Precision: 0.88\n",
            "  Recall: 0.89\n",
            "  F1: 0.88\n",
            "Category: 2\n",
            "  Precision: 0.97\n",
            "  Recall: 0.98\n",
            "  F1: 0.98\n",
            "Category: 3\n",
            "  Precision: 0.28\n",
            "  Recall: 0.26\n",
            "  F1: 0.27\n",
            "The average precision is: 0.7718\n",
            "The average recall is: 0.7743\n",
            "The average f1 is: 0.7697\n",
            "  Training epcoh took: 0:02:16\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8856\n",
            "  Recall: 0.9483\n",
            "  F1: 0.9124\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0096\n",
            "  F1: 0.0154\n",
            "Category: 2\n",
            "  Precision: 0.3731\n",
            "  Recall: 0.3404\n",
            "  F1: 0.3212\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3243\n",
            "The average recall is: 0.3246\n",
            "The average f1 is: 0.3122\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    235.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    235.    Elapsed: 0:00:46.\n",
            "  Batch   120  of    235.    Elapsed: 0:01:09.\n",
            "  Batch   160  of    235.    Elapsed: 0:01:32.\n",
            "  Batch   200  of    235.    Elapsed: 0:01:55.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.90\n",
            "  Recall: 0.91\n",
            "  F1: 0.90\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.40\n",
            "  Recall: 0.40\n",
            "  F1: 0.40\n",
            "The average precision is: 0.8244\n",
            "The average recall is: 0.8247\n",
            "The average f1 is: 0.8242\n",
            "  Training epcoh took: 0:02:16\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "Category: 0\n",
            "  Precision: 0.8351\n",
            "  Recall: 0.9468\n",
            "  F1: 0.8852\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3526\n",
            "  Recall: 0.2083\n",
            "  F1: 0.2462\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.2969\n",
            "The average recall is: 0.2888\n",
            "The average f1 is: 0.2828\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    235.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    235.    Elapsed: 0:00:46.\n",
            "  Batch   120  of    235.    Elapsed: 0:01:09.\n",
            "  Batch   160  of    235.    Elapsed: 0:01:33.\n",
            "  Batch   200  of    235.    Elapsed: 0:01:56.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.91\n",
            "  Recall: 0.91\n",
            "  F1: 0.91\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.43\n",
            "  Recall: 0.43\n",
            "  F1: 0.43\n",
            "The average precision is: 0.8339\n",
            "The average recall is: 0.8339\n",
            "The average f1 is: 0.8339\n",
            "  Training epcoh took: 0:02:16\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8761\n",
            "  Recall: 0.9744\n",
            "  F1: 0.9206\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.4423\n",
            "  Recall: 0.3205\n",
            "  F1: 0.3423\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3296\n",
            "The average recall is: 0.3237\n",
            "The average f1 is: 0.3157\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "Training complete!\n",
            "Current increase 10 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 2070 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 2070 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 3880 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 3880 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 4000 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.34\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "517\n",
            "0.12925\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1991\n",
            "0.49775\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "132\n",
            "0.033\n",
            "\n",
            "(4000, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 12:20:35.245908 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 12:20:35.247252 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 12:20:35.340623 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 12:20:37.833090 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 12:20:37.833958 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    80  of    250.    Elapsed: 0:00:44.\n",
            "  Batch   120  of    250.    Elapsed: 0:01:07.\n",
            "  Batch   160  of    250.    Elapsed: 0:01:29.\n",
            "  Batch   200  of    250.    Elapsed: 0:01:51.\n",
            "  Batch   240  of    250.    Elapsed: 0:02:13.\n",
            "\n",
            "  Average training loss: 0.67\n",
            "  Accuracy: 0.73\n",
            "Category: 0\n",
            "  Precision: 0.66\n",
            "  Recall: 0.68\n",
            "  F1: 0.64\n",
            "Category: 1\n",
            "  Precision: 0.38\n",
            "  Recall: 0.34\n",
            "  F1: 0.34\n",
            "Category: 2\n",
            "  Precision: 0.78\n",
            "  Recall: 0.91\n",
            "  F1: 0.82\n",
            "Category: 3\n",
            "  Precision: 0.01\n",
            "  Recall: 0.01\n",
            "  F1: 0.01\n",
            "The average precision is: 0.4551\n",
            "The average recall is: 0.4858\n",
            "The average f1 is: 0.4531\n",
            "  Training epcoh took: 0:02:18\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "Category: 0\n",
            "  Precision: 0.8905\n",
            "  Recall: 0.9150\n",
            "  F1: 0.8992\n",
            "Category: 1\n",
            "  Precision: 0.1538\n",
            "  Recall: 0.1090\n",
            "  F1: 0.1218\n",
            "Category: 2\n",
            "  Precision: 0.2936\n",
            "  Recall: 0.2647\n",
            "  F1: 0.2564\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3345\n",
            "The average recall is: 0.3222\n",
            "The average f1 is: 0.3193\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    80  of    250.    Elapsed: 0:00:44.\n",
            "  Batch   120  of    250.    Elapsed: 0:01:07.\n",
            "  Batch   160  of    250.    Elapsed: 0:01:29.\n",
            "  Batch   200  of    250.    Elapsed: 0:01:52.\n",
            "  Batch   240  of    250.    Elapsed: 0:02:14.\n",
            "\n",
            "  Average training loss: 0.06\n",
            "  Accuracy: 0.98\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.98\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 0.87\n",
            "  Recall: 0.89\n",
            "  F1: 0.88\n",
            "Category: 2\n",
            "  Precision: 0.99\n",
            "  Recall: 1.00\n",
            "  F1: 0.99\n",
            "Category: 3\n",
            "  Precision: 0.36\n",
            "  Recall: 0.35\n",
            "  F1: 0.36\n",
            "The average precision is: 0.8020\n",
            "The average recall is: 0.8041\n",
            "The average f1 is: 0.8010\n",
            "  Training epcoh took: 0:02:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8839\n",
            "  Recall: 0.9548\n",
            "  F1: 0.9143\n",
            "Category: 1\n",
            "  Precision: 0.0192\n",
            "  Recall: 0.0192\n",
            "  F1: 0.0192\n",
            "Category: 2\n",
            "  Precision: 0.3692\n",
            "  Recall: 0.2724\n",
            "  F1: 0.2968\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3181\n",
            "The average recall is: 0.3116\n",
            "The average f1 is: 0.3076\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    250.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    250.    Elapsed: 0:00:47.\n",
            "  Batch   120  of    250.    Elapsed: 0:01:10.\n",
            "  Batch   160  of    250.    Elapsed: 0:01:34.\n",
            "  Batch   200  of    250.    Elapsed: 0:01:57.\n",
            "  Batch   240  of    250.    Elapsed: 0:02:19.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.86\n",
            "  Recall: 0.86\n",
            "  F1: 0.86\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.43\n",
            "  Recall: 0.43\n",
            "  F1: 0.43\n",
            "The average precision is: 0.8217\n",
            "The average recall is: 0.8219\n",
            "The average f1 is: 0.8216\n",
            "  Training epcoh took: 0:02:24\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8797\n",
            "  Recall: 0.9500\n",
            "  F1: 0.9115\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0192\n",
            "  F1: 0.0256\n",
            "Category: 2\n",
            "  Precision: 0.3654\n",
            "  Recall: 0.3365\n",
            "  F1: 0.3117\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3209\n",
            "The average recall is: 0.3265\n",
            "The average f1 is: 0.3122\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    250.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    250.    Elapsed: 0:00:45.\n",
            "  Batch   120  of    250.    Elapsed: 0:01:06.\n",
            "  Batch   160  of    250.    Elapsed: 0:01:28.\n",
            "  Batch   200  of    250.    Elapsed: 0:01:50.\n",
            "  Batch   240  of    250.    Elapsed: 0:02:12.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.91\n",
            "  Recall: 0.91\n",
            "  F1: 0.91\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.40\n",
            "  Recall: 0.40\n",
            "  F1: 0.40\n",
            "The average precision is: 0.8255\n",
            "The average recall is: 0.8253\n",
            "The average f1 is: 0.8253\n",
            "  Training epcoh took: 0:02:17\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8797\n",
            "  Recall: 0.9534\n",
            "  F1: 0.9124\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0128\n",
            "  F1: 0.0192\n",
            "Category: 2\n",
            "  Precision: 0.3474\n",
            "  Recall: 0.2756\n",
            "  F1: 0.2880\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3164\n",
            "The average recall is: 0.3105\n",
            "The average f1 is: 0.3049\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "Training complete!\n",
            "Current increase 11 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 2117 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 2117 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 4108 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 4108 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 4240 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.32075471698113206\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "564\n",
            "0.1330188679245283\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "2172\n",
            "0.5122641509433963\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "144\n",
            "0.033962264150943396\n",
            "\n",
            "(4240, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 12:30:12.540664 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 12:30:12.541936 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 12:30:12.639696 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 12:30:15.082347 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 12:30:15.083066 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    265.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    265.    Elapsed: 0:00:43.\n",
            "  Batch   120  of    265.    Elapsed: 0:01:07.\n",
            "  Batch   160  of    265.    Elapsed: 0:01:30.\n",
            "  Batch   200  of    265.    Elapsed: 0:01:53.\n",
            "  Batch   240  of    265.    Elapsed: 0:02:16.\n",
            "\n",
            "  Average training loss: 0.64\n",
            "  Accuracy: 0.75\n",
            "Category: 0\n",
            "  Precision: 0.64\n",
            "  Recall: 0.73\n",
            "  F1: 0.66\n",
            "Category: 1\n",
            "  Precision: 0.37\n",
            "  Recall: 0.30\n",
            "  F1: 0.32\n",
            "Category: 2\n",
            "  Precision: 0.82\n",
            "  Recall: 0.91\n",
            "  F1: 0.85\n",
            "Category: 3\n",
            "  Precision: 0.03\n",
            "  Recall: 0.03\n",
            "  F1: 0.03\n",
            "The average precision is: 0.4651\n",
            "The average recall is: 0.4936\n",
            "The average f1 is: 0.4641\n",
            "  Training epcoh took: 0:02:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8452\n",
            "  Recall: 0.9257\n",
            "  F1: 0.8819\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0513\n",
            "  F1: 0.0577\n",
            "Category: 2\n",
            "  Precision: 0.3558\n",
            "  Recall: 0.2500\n",
            "  F1: 0.2744\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3195\n",
            "The average recall is: 0.3068\n",
            "The average f1 is: 0.3035\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    265.    Elapsed: 0:00:24.\n",
            "  Batch    80  of    265.    Elapsed: 0:00:47.\n",
            "  Batch   120  of    265.    Elapsed: 0:01:11.\n",
            "  Batch   160  of    265.    Elapsed: 0:01:34.\n",
            "  Batch   200  of    265.    Elapsed: 0:01:57.\n",
            "  Batch   240  of    265.    Elapsed: 0:02:20.\n",
            "\n",
            "  Average training loss: 0.05\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.98\n",
            "  Recall: 0.97\n",
            "  F1: 0.97\n",
            "Category: 1\n",
            "  Precision: 0.85\n",
            "  Recall: 0.85\n",
            "  F1: 0.85\n",
            "Category: 2\n",
            "  Precision: 0.99\n",
            "  Recall: 1.00\n",
            "  F1: 0.99\n",
            "Category: 3\n",
            "  Precision: 0.40\n",
            "  Recall: 0.40\n",
            "  F1: 0.40\n",
            "The average precision is: 0.8054\n",
            "The average recall is: 0.8058\n",
            "The average f1 is: 0.8037\n",
            "  Training epcoh took: 0:02:34\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8860\n",
            "  Recall: 0.9635\n",
            "  F1: 0.9213\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0513\n",
            "  F1: 0.0577\n",
            "Category: 2\n",
            "  Precision: 0.3462\n",
            "  Recall: 0.2500\n",
            "  F1: 0.2804\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3273\n",
            "The average recall is: 0.3162\n",
            "The average f1 is: 0.3149\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    265.    Elapsed: 0:00:24.\n",
            "  Batch    80  of    265.    Elapsed: 0:00:47.\n",
            "  Batch   120  of    265.    Elapsed: 0:01:11.\n",
            "  Batch   160  of    265.    Elapsed: 0:01:34.\n",
            "  Batch   200  of    265.    Elapsed: 0:01:58.\n",
            "  Batch   240  of    265.    Elapsed: 0:02:21.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.90\n",
            "  Recall: 0.91\n",
            "  F1: 0.91\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.43\n",
            "  Recall: 0.43\n",
            "  F1: 0.43\n",
            "The average precision is: 0.8344\n",
            "The average recall is: 0.8344\n",
            "The average f1 is: 0.8344\n",
            "  Training epcoh took: 0:02:36\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8889\n",
            "  Recall: 0.9495\n",
            "  F1: 0.9154\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.3654\n",
            "  Recall: 0.3269\n",
            "  F1: 0.3179\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3328\n",
            "The average recall is: 0.3383\n",
            "The average f1 is: 0.3276\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    265.    Elapsed: 0:00:24.\n",
            "  Batch    80  of    265.    Elapsed: 0:00:48.\n",
            "  Batch   120  of    265.    Elapsed: 0:01:11.\n",
            "  Batch   160  of    265.    Elapsed: 0:01:33.\n",
            "  Batch   200  of    265.    Elapsed: 0:01:54.\n",
            "  Batch   240  of    265.    Elapsed: 0:02:15.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.88\n",
            "  Recall: 0.88\n",
            "  F1: 0.88\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.44\n",
            "  Recall: 0.44\n",
            "  F1: 0.44\n",
            "The average precision is: 0.8281\n",
            "The average recall is: 0.8280\n",
            "The average f1 is: 0.8280\n",
            "  Training epcoh took: 0:02:28\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8870\n",
            "  Recall: 0.9591\n",
            "  F1: 0.9187\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0513\n",
            "Category: 2\n",
            "  Precision: 0.4103\n",
            "  Recall: 0.3333\n",
            "  F1: 0.3526\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3435\n",
            "The average recall is: 0.3327\n",
            "The average f1 is: 0.3306\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n",
            "Current increase 12 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 2164 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 2164 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 4336 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 4336 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 4480 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.30357142857142855\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "611\n",
            "0.13638392857142856\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "2353\n",
            "0.5252232142857143\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "156\n",
            "0.03482142857142857\n",
            "\n",
            "(4480, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 12:40:38.381674 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 12:40:38.383005 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 12:40:40.111168 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 12:40:42.553178 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 12:40:42.554023 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    280.    Elapsed: 0:00:20.\n",
            "  Batch    80  of    280.    Elapsed: 0:00:40.\n",
            "  Batch   120  of    280.    Elapsed: 0:01:01.\n",
            "  Batch   160  of    280.    Elapsed: 0:01:23.\n",
            "  Batch   200  of    280.    Elapsed: 0:01:45.\n",
            "  Batch   240  of    280.    Elapsed: 0:02:07.\n",
            "\n",
            "  Average training loss: 0.62\n",
            "  Accuracy: 0.76\n",
            "Category: 0\n",
            "  Precision: 0.68\n",
            "  Recall: 0.66\n",
            "  F1: 0.63\n",
            "Category: 1\n",
            "  Precision: 0.48\n",
            "  Recall: 0.46\n",
            "  F1: 0.45\n",
            "Category: 2\n",
            "  Precision: 0.80\n",
            "  Recall: 0.91\n",
            "  F1: 0.84\n",
            "Category: 3\n",
            "  Precision: 0.08\n",
            "  Recall: 0.07\n",
            "  F1: 0.07\n",
            "The average precision is: 0.5093\n",
            "The average recall is: 0.5268\n",
            "The average f1 is: 0.4983\n",
            "  Training epcoh took: 0:02:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "Category: 0\n",
            "  Precision: 0.8900\n",
            "  Recall: 0.9259\n",
            "  F1: 0.9025\n",
            "Category: 1\n",
            "  Precision: 0.0577\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0641\n",
            "Category: 2\n",
            "  Precision: 0.3301\n",
            "  Recall: 0.2795\n",
            "  F1: 0.2681\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3195\n",
            "The average recall is: 0.3206\n",
            "The average f1 is: 0.3087\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    280.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    280.    Elapsed: 0:00:46.\n",
            "  Batch   120  of    280.    Elapsed: 0:01:09.\n",
            "  Batch   160  of    280.    Elapsed: 0:01:31.\n",
            "  Batch   200  of    280.    Elapsed: 0:01:54.\n",
            "  Batch   240  of    280.    Elapsed: 0:02:18.\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.97\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 0.89\n",
            "  Recall: 0.90\n",
            "  F1: 0.89\n",
            "Category: 2\n",
            "  Precision: 0.99\n",
            "  Recall: 1.00\n",
            "  F1: 0.99\n",
            "Category: 3\n",
            "  Precision: 0.45\n",
            "  Recall: 0.45\n",
            "  F1: 0.45\n",
            "The average precision is: 0.8318\n",
            "The average recall is: 0.8307\n",
            "The average f1 is: 0.8303\n",
            "  Training epcoh took: 0:02:41\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8831\n",
            "  Recall: 0.9810\n",
            "  F1: 0.9261\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0096\n",
            "  F1: 0.0154\n",
            "Category: 2\n",
            "  Precision: 0.4231\n",
            "  Recall: 0.2404\n",
            "  F1: 0.2846\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3362\n",
            "The average recall is: 0.3078\n",
            "The average f1 is: 0.3065\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    280.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    280.    Elapsed: 0:00:43.\n",
            "  Batch   120  of    280.    Elapsed: 0:01:04.\n",
            "  Batch   160  of    280.    Elapsed: 0:01:25.\n",
            "  Batch   200  of    280.    Elapsed: 0:01:45.\n",
            "  Batch   240  of    280.    Elapsed: 0:02:06.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.94\n",
            "  Recall: 0.94\n",
            "  F1: 0.94\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.43\n",
            "  Recall: 0.43\n",
            "  F1: 0.43\n",
            "The average precision is: 0.8404\n",
            "The average recall is: 0.8400\n",
            "The average f1 is: 0.8401\n",
            "  Training epcoh took: 0:02:27\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8770\n",
            "  Recall: 0.9733\n",
            "  F1: 0.9206\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3141\n",
            "  Recall: 0.2577\n",
            "  F1: 0.2538\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.2978\n",
            "The average recall is: 0.3077\n",
            "The average f1 is: 0.2936\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    280.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    280.    Elapsed: 0:00:44.\n",
            "  Batch   120  of    280.    Elapsed: 0:01:05.\n",
            "  Batch   160  of    280.    Elapsed: 0:01:28.\n",
            "  Batch   200  of    280.    Elapsed: 0:01:50.\n",
            "  Batch   240  of    280.    Elapsed: 0:02:12.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.92\n",
            "  Recall: 0.92\n",
            "  F1: 0.92\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.43\n",
            "  Recall: 0.43\n",
            "  F1: 0.43\n",
            "The average precision is: 0.8382\n",
            "The average recall is: 0.8381\n",
            "The average f1 is: 0.8381\n",
            "  Training epcoh took: 0:02:36\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "Category: 0\n",
            "  Precision: 0.8498\n",
            "  Recall: 0.9310\n",
            "  F1: 0.8859\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0192\n",
            "  F1: 0.0256\n",
            "Category: 2\n",
            "  Precision: 0.4423\n",
            "  Recall: 0.3429\n",
            "  F1: 0.3397\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3326\n",
            "The average recall is: 0.3233\n",
            "The average f1 is: 0.3128\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "Training complete!\n",
            "Current increase 13 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 2211 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 2211 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 4564 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 4564 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 4720 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.288135593220339\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "658\n",
            "0.13940677966101694\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "2534\n",
            "0.536864406779661\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "168\n",
            "0.03559322033898305\n",
            "\n",
            "(4720, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 12:51:13.316338 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 12:51:13.318897 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 12:51:14.365057 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 12:51:16.812530 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 12:51:16.819433 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    295.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    295.    Elapsed: 0:00:44.\n",
            "  Batch   120  of    295.    Elapsed: 0:01:07.\n",
            "  Batch   160  of    295.    Elapsed: 0:01:30.\n",
            "  Batch   200  of    295.    Elapsed: 0:01:52.\n",
            "  Batch   240  of    295.    Elapsed: 0:02:13.\n",
            "  Batch   280  of    295.    Elapsed: 0:02:34.\n",
            "\n",
            "  Average training loss: 0.65\n",
            "  Accuracy: 0.74\n",
            "Category: 0\n",
            "  Precision: 0.57\n",
            "  Recall: 0.53\n",
            "  F1: 0.52\n",
            "Category: 1\n",
            "  Precision: 0.56\n",
            "  Recall: 0.55\n",
            "  F1: 0.54\n",
            "Category: 2\n",
            "  Precision: 0.76\n",
            "  Recall: 0.91\n",
            "  F1: 0.81\n",
            "Category: 3\n",
            "  Precision: 0.12\n",
            "  Recall: 0.11\n",
            "  F1: 0.11\n",
            "The average precision is: 0.5015\n",
            "The average recall is: 0.5237\n",
            "The average f1 is: 0.4938\n",
            "  Training epcoh took: 0:02:42\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.75\n",
            "Category: 0\n",
            "  Precision: 0.8949\n",
            "  Recall: 0.8139\n",
            "  F1: 0.8478\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0192\n",
            "  F1: 0.0256\n",
            "Category: 2\n",
            "  Precision: 0.2331\n",
            "  Recall: 0.4904\n",
            "  F1: 0.2914\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.2916\n",
            "The average recall is: 0.3309\n",
            "The average f1 is: 0.2912\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    295.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    295.    Elapsed: 0:00:44.\n",
            "  Batch   120  of    295.    Elapsed: 0:01:06.\n",
            "  Batch   160  of    295.    Elapsed: 0:01:28.\n",
            "  Batch   200  of    295.    Elapsed: 0:01:51.\n",
            "  Batch   240  of    295.    Elapsed: 0:02:14.\n",
            "  Batch   280  of    295.    Elapsed: 0:02:37.\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.98\n",
            "  Recall: 0.96\n",
            "  F1: 0.97\n",
            "Category: 1\n",
            "  Precision: 0.89\n",
            "  Recall: 0.89\n",
            "  F1: 0.89\n",
            "Category: 2\n",
            "  Precision: 0.99\n",
            "  Recall: 1.00\n",
            "  F1: 0.99\n",
            "Category: 3\n",
            "  Precision: 0.43\n",
            "  Recall: 0.43\n",
            "  F1: 0.43\n",
            "The average precision is: 0.8214\n",
            "The average recall is: 0.8193\n",
            "The average f1 is: 0.8193\n",
            "  Training epcoh took: 0:02:46\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "Category: 0\n",
            "  Precision: 0.8878\n",
            "  Recall: 0.9228\n",
            "  F1: 0.9023\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0577\n",
            "  F1: 0.0641\n",
            "Category: 2\n",
            "  Precision: 0.3013\n",
            "  Recall: 0.3141\n",
            "  F1: 0.2873\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3165\n",
            "The average recall is: 0.3237\n",
            "The average f1 is: 0.3134\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    295.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    295.    Elapsed: 0:00:46.\n",
            "  Batch   120  of    295.    Elapsed: 0:01:09.\n",
            "  Batch   160  of    295.    Elapsed: 0:01:32.\n",
            "  Batch   200  of    295.    Elapsed: 0:01:55.\n",
            "  Batch   240  of    295.    Elapsed: 0:02:18.\n",
            "  Batch   280  of    295.    Elapsed: 0:02:41.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.93\n",
            "  Recall: 0.94\n",
            "  F1: 0.94\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.44\n",
            "  Recall: 0.44\n",
            "  F1: 0.44\n",
            "The average precision is: 0.8408\n",
            "The average recall is: 0.8405\n",
            "The average f1 is: 0.8405\n",
            "  Training epcoh took: 0:02:50\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8800\n",
            "  Recall: 0.9749\n",
            "  F1: 0.9221\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0192\n",
            "  F1: 0.0256\n",
            "Category: 2\n",
            "  Precision: 0.3333\n",
            "  Recall: 0.2853\n",
            "  F1: 0.2769\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3130\n",
            "The average recall is: 0.3198\n",
            "The average f1 is: 0.3062\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    295.    Elapsed: 0:00:24.\n",
            "  Batch    80  of    295.    Elapsed: 0:00:48.\n",
            "  Batch   120  of    295.    Elapsed: 0:01:11.\n",
            "  Batch   160  of    295.    Elapsed: 0:01:34.\n",
            "  Batch   200  of    295.    Elapsed: 0:01:58.\n",
            "  Batch   240  of    295.    Elapsed: 0:02:22.\n",
            "  Batch   280  of    295.    Elapsed: 0:02:46.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.92\n",
            "  Recall: 0.92\n",
            "  F1: 0.92\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.43\n",
            "  Recall: 0.43\n",
            "  F1: 0.43\n",
            "The average precision is: 0.8361\n",
            "The average recall is: 0.8358\n",
            "The average f1 is: 0.8358\n",
            "  Training epcoh took: 0:02:54\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8845\n",
            "  Recall: 0.9675\n",
            "  F1: 0.9216\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0192\n",
            "  F1: 0.0256\n",
            "Category: 2\n",
            "  Precision: 0.3750\n",
            "  Recall: 0.3186\n",
            "  F1: 0.3200\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3245\n",
            "The average recall is: 0.3263\n",
            "The average f1 is: 0.3168\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "Training complete!\n",
            "Successfully save file BertSearchResult/16_3e-05\n",
            "Currently processing 16_2e-05\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: TITAN RTX\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 13:02:45.046353 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 13:02:45.047671 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 13:02:45.127681 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 13:02:47.619441 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 13:02:47.620645 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current increase 0 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "(1600, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 13:02:48.299823 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 13:02:48.301322 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 13:02:50.022338 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 13:02:52.538448 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 13:02:52.539134 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    100.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    100.    Elapsed: 0:00:44.\n",
            "\n",
            "  Average training loss: 0.58\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.85\n",
            "  Recall: 0.99\n",
            "  F1: 0.91\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "Category: 2\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.2131\n",
            "The average recall is: 0.2470\n",
            "The average f1 is: 0.2270\n",
            "  Training epcoh took: 0:00:55\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8486\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9157\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.2121\n",
            "The average recall is: 0.2500\n",
            "The average f1 is: 0.2289\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    100.    Elapsed: 0:00:25.\n",
            "  Batch    80  of    100.    Elapsed: 0:00:48.\n",
            "\n",
            "  Average training loss: 0.47\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.85\n",
            "  Recall: 1.00\n",
            "  F1: 0.92\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "Category: 2\n",
            "  Precision: 0.05\n",
            "  Recall: 0.02\n",
            "  F1: 0.03\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.2256\n",
            "The average recall is: 0.2553\n",
            "The average f1 is: 0.2366\n",
            "  Training epcoh took: 0:01:00\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8562\n",
            "  Recall: 0.9945\n",
            "  F1: 0.9183\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.1154\n",
            "  Recall: 0.0577\n",
            "  F1: 0.0756\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.2429\n",
            "The average recall is: 0.2630\n",
            "The average f1 is: 0.2485\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    100.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    100.    Elapsed: 0:00:46.\n",
            "\n",
            "  Average training loss: 0.37\n",
            "  Accuracy: 0.89\n",
            "Category: 0\n",
            "  Precision: 0.90\n",
            "  Recall: 0.99\n",
            "  F1: 0.94\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "Category: 2\n",
            "  Precision: 0.45\n",
            "  Recall: 0.34\n",
            "  F1: 0.37\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.3370\n",
            "The average recall is: 0.3334\n",
            "The average f1 is: 0.3279\n",
            "  Training epcoh took: 0:00:57\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8979\n",
            "  Recall: 0.9466\n",
            "  F1: 0.9188\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3846\n",
            "  Recall: 0.3558\n",
            "  F1: 0.3333\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3206\n",
            "The average recall is: 0.3256\n",
            "The average f1 is: 0.3130\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    100.    Elapsed: 0:00:22.\n",
            "  Batch    80  of    100.    Elapsed: 0:00:44.\n",
            "\n",
            "  Average training loss: 0.29\n",
            "  Accuracy: 0.92\n",
            "Category: 0\n",
            "  Precision: 0.93\n",
            "  Recall: 0.99\n",
            "  F1: 0.96\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "Category: 2\n",
            "  Precision: 0.67\n",
            "  Recall: 0.60\n",
            "  F1: 0.61\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.4011\n",
            "The average recall is: 0.3976\n",
            "The average f1 is: 0.3914\n",
            "  Training epcoh took: 0:00:56\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8880\n",
            "  Recall: 0.9559\n",
            "  F1: 0.9171\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3526\n",
            "  Recall: 0.3647\n",
            "  F1: 0.3335\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3101\n",
            "The average recall is: 0.3302\n",
            "The average f1 is: 0.3127\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "Training complete!\n",
            "Current increase 1 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 1647 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 1647 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 1828 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 1828 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 1840 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.7391304347826086\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "94\n",
            "0.051086956521739134\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "362\n",
            "0.1967391304347826\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "24\n",
            "0.013043478260869565\n",
            "\n",
            "(1840, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 13:06:56.584931 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 13:06:56.586400 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 13:06:56.641108 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 13:06:59.292816 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 13:06:59.293761 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    115.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    115.    Elapsed: 0:00:43.\n",
            "\n",
            "  Average training loss: 0.73\n",
            "  Accuracy: 0.74\n",
            "Category: 0\n",
            "  Precision: 0.76\n",
            "  Recall: 0.96\n",
            "  F1: 0.83\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "Category: 2\n",
            "  Precision: 0.16\n",
            "  Recall: 0.12\n",
            "  F1: 0.12\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.2281\n",
            "The average recall is: 0.2706\n",
            "The average f1 is: 0.2377\n",
            "  Training epcoh took: 0:01:02\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.75\n",
            "Category: 0\n",
            "  Precision: 0.9163\n",
            "  Recall: 0.8124\n",
            "  F1: 0.8567\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.2924\n",
            "  Recall: 0.5474\n",
            "  F1: 0.3407\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3022\n",
            "The average recall is: 0.3400\n",
            "The average f1 is: 0.2994\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    115.    Elapsed: 0:00:22.\n",
            "  Batch    80  of    115.    Elapsed: 0:00:45.\n",
            "\n",
            "  Average training loss: 0.51\n",
            "  Accuracy: 0.82\n",
            "Category: 0\n",
            "  Precision: 0.87\n",
            "  Recall: 0.95\n",
            "  F1: 0.90\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "Category: 2\n",
            "  Precision: 0.65\n",
            "  Recall: 0.62\n",
            "  F1: 0.59\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.3793\n",
            "The average recall is: 0.3913\n",
            "The average f1 is: 0.3722\n",
            "  Training epcoh took: 0:01:03\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "Category: 0\n",
            "  Precision: 0.8877\n",
            "  Recall: 0.9350\n",
            "  F1: 0.9085\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3006\n",
            "  Recall: 0.3154\n",
            "  F1: 0.2767\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.2971\n",
            "The average recall is: 0.3126\n",
            "The average f1 is: 0.2963\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    115.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    115.    Elapsed: 0:00:45.\n",
            "\n",
            "  Average training loss: 0.31\n",
            "  Accuracy: 0.90\n",
            "Category: 0\n",
            "  Precision: 0.94\n",
            "  Recall: 0.98\n",
            "  F1: 0.96\n",
            "Category: 1\n",
            "  Precision: 0.03\n",
            "  Recall: 0.02\n",
            "  F1: 0.03\n",
            "Category: 2\n",
            "  Precision: 0.71\n",
            "  Recall: 0.84\n",
            "  F1: 0.75\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.4219\n",
            "The average recall is: 0.4614\n",
            "The average f1 is: 0.4330\n",
            "  Training epcoh took: 0:01:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "Category: 0\n",
            "  Precision: 0.9012\n",
            "  Recall: 0.9051\n",
            "  F1: 0.9003\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3359\n",
            "  Recall: 0.5179\n",
            "  F1: 0.3930\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3093\n",
            "The average recall is: 0.3558\n",
            "The average f1 is: 0.3233\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    115.    Elapsed: 0:00:24.\n",
            "  Batch    80  of    115.    Elapsed: 0:00:47.\n",
            "\n",
            "  Average training loss: 0.20\n",
            "  Accuracy: 0.93\n",
            "Category: 0\n",
            "  Precision: 0.97\n",
            "  Recall: 0.99\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 0.08\n",
            "  Recall: 0.07\n",
            "  F1: 0.07\n",
            "Category: 2\n",
            "  Precision: 0.77\n",
            "  Recall: 0.92\n",
            "  F1: 0.82\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.4545\n",
            "The average recall is: 0.4947\n",
            "The average f1 is: 0.4683\n",
            "  Training epcoh took: 0:01:07\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.8870\n",
            "  Recall: 0.9305\n",
            "  F1: 0.9054\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3654\n",
            "  Recall: 0.3846\n",
            "  F1: 0.3480\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3131\n",
            "The average recall is: 0.3288\n",
            "The average f1 is: 0.3133\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "Training complete!\n",
            "Current increase 2 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 1694 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 1694 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 2056 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 2056 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 2080 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.6538461538461539\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "141\n",
            "0.06778846153846153\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "543\n",
            "0.2610576923076923\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "36\n",
            "0.01730769230769231\n",
            "\n",
            "(2080, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 13:11:32.509752 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 13:11:32.510760 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 13:11:32.631560 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 13:11:35.176595 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 13:11:35.178166 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    130.    Elapsed: 0:00:22.\n",
            "  Batch    80  of    130.    Elapsed: 0:00:45.\n",
            "  Batch   120  of    130.    Elapsed: 0:01:09.\n",
            "\n",
            "  Average training loss: 0.86\n",
            "  Accuracy: 0.66\n",
            "Category: 0\n",
            "  Precision: 0.67\n",
            "  Recall: 0.98\n",
            "  F1: 0.79\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "Category: 2\n",
            "  Precision: 0.17\n",
            "  Recall: 0.09\n",
            "  F1: 0.10\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.2109\n",
            "The average recall is: 0.2670\n",
            "The average f1 is: 0.2227\n",
            "  Training epcoh took: 0:01:15\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "Category: 0\n",
            "  Precision: 0.8796\n",
            "  Recall: 0.9151\n",
            "  F1: 0.8935\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.2692\n",
            "  Recall: 0.3244\n",
            "  F1: 0.2613\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.2872\n",
            "The average recall is: 0.3099\n",
            "The average f1 is: 0.2887\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    130.    Elapsed: 0:00:22.\n",
            "  Batch    80  of    130.    Elapsed: 0:00:43.\n",
            "  Batch   120  of    130.    Elapsed: 0:01:05.\n",
            "\n",
            "  Average training loss: 0.63\n",
            "  Accuracy: 0.78\n",
            "Category: 0\n",
            "  Precision: 0.81\n",
            "  Recall: 0.94\n",
            "  F1: 0.86\n",
            "Category: 1\n",
            "  Precision: 0.01\n",
            "  Recall: 0.00\n",
            "  F1: 0.01\n",
            "Category: 2\n",
            "  Precision: 0.67\n",
            "  Recall: 0.62\n",
            "  F1: 0.60\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.3713\n",
            "The average recall is: 0.3903\n",
            "The average f1 is: 0.3664\n",
            "  Training epcoh took: 0:01:10\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "Category: 0\n",
            "  Precision: 0.8707\n",
            "  Recall: 0.8398\n",
            "  F1: 0.8523\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3297\n",
            "  Recall: 0.5654\n",
            "  F1: 0.3799\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3001\n",
            "The average recall is: 0.3513\n",
            "The average f1 is: 0.3080\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    130.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    130.    Elapsed: 0:00:43.\n",
            "  Batch   120  of    130.    Elapsed: 0:01:06.\n",
            "\n",
            "  Average training loss: 0.37\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.90\n",
            "  Recall: 0.96\n",
            "  F1: 0.93\n",
            "Category: 1\n",
            "  Precision: 0.12\n",
            "  Recall: 0.08\n",
            "  F1: 0.09\n",
            "Category: 2\n",
            "  Precision: 0.78\n",
            "  Recall: 0.88\n",
            "  F1: 0.81\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.4519\n",
            "The average recall is: 0.4803\n",
            "The average f1 is: 0.4573\n",
            "  Training epcoh took: 0:01:11\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8869\n",
            "  Recall: 0.9631\n",
            "  F1: 0.9210\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3750\n",
            "  Recall: 0.3397\n",
            "  F1: 0.3327\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3155\n",
            "The average recall is: 0.3257\n",
            "The average f1 is: 0.3134\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    130.    Elapsed: 0:00:22.\n",
            "  Batch    80  of    130.    Elapsed: 0:00:45.\n",
            "  Batch   120  of    130.    Elapsed: 0:01:08.\n",
            "\n",
            "  Average training loss: 0.22\n",
            "  Accuracy: 0.93\n",
            "Category: 0\n",
            "  Precision: 0.96\n",
            "  Recall: 0.99\n",
            "  F1: 0.97\n",
            "Category: 1\n",
            "  Precision: 0.41\n",
            "  Recall: 0.32\n",
            "  F1: 0.35\n",
            "Category: 2\n",
            "  Precision: 0.87\n",
            "  Recall: 0.97\n",
            "  F1: 0.90\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5593\n",
            "The average recall is: 0.5695\n",
            "The average f1 is: 0.5554\n",
            "  Training epcoh took: 0:01:13\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8991\n",
            "  Recall: 0.9487\n",
            "  F1: 0.9206\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.4615\n",
            "  Recall: 0.3942\n",
            "  F1: 0.3833\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3402\n",
            "The average recall is: 0.3357\n",
            "The average f1 is: 0.3260\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "Training complete!\n",
            "Current increase 3 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 1741 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 1741 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 2284 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 2284 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 2320 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.5862068965517241\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "188\n",
            "0.08103448275862069\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "724\n",
            "0.3120689655172414\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "48\n",
            "0.020689655172413793\n",
            "\n",
            "(2320, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 13:16:39.614026 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 13:16:39.621438 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 13:16:39.701393 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 13:16:42.155827 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 13:16:42.156976 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    145.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    145.    Elapsed: 0:00:46.\n",
            "  Batch   120  of    145.    Elapsed: 0:01:09.\n",
            "\n",
            "  Average training loss: 0.89\n",
            "  Accuracy: 0.63\n",
            "Category: 0\n",
            "  Precision: 0.67\n",
            "  Recall: 0.87\n",
            "  F1: 0.73\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.02\n",
            "  F1: 0.01\n",
            "Category: 2\n",
            "  Precision: 0.41\n",
            "  Recall: 0.36\n",
            "  F1: 0.35\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.2720\n",
            "The average recall is: 0.3135\n",
            "The average f1 is: 0.2707\n",
            "  Training epcoh took: 0:01:24\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.8965\n",
            "  Recall: 0.9376\n",
            "  F1: 0.9137\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3731\n",
            "  Recall: 0.4103\n",
            "  F1: 0.3573\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3174\n",
            "The average recall is: 0.3370\n",
            "The average f1 is: 0.3178\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    145.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    145.    Elapsed: 0:00:47.\n",
            "  Batch   120  of    145.    Elapsed: 0:01:08.\n",
            "\n",
            "  Average training loss: 0.57\n",
            "  Accuracy: 0.79\n",
            "Category: 0\n",
            "  Precision: 0.84\n",
            "  Recall: 0.93\n",
            "  F1: 0.87\n",
            "Category: 1\n",
            "  Precision: 0.11\n",
            "  Recall: 0.07\n",
            "  F1: 0.08\n",
            "Category: 2\n",
            "  Precision: 0.72\n",
            "  Recall: 0.79\n",
            "  F1: 0.72\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.4170\n",
            "The average recall is: 0.4472\n",
            "The average f1 is: 0.4192\n",
            "  Training epcoh took: 0:01:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "Category: 0\n",
            "  Precision: 0.9068\n",
            "  Recall: 0.8861\n",
            "  F1: 0.8926\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3000\n",
            "  Recall: 0.4141\n",
            "  F1: 0.3314\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3017\n",
            "The average recall is: 0.3251\n",
            "The average f1 is: 0.3060\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    145.    Elapsed: 0:00:20.\n",
            "  Batch    80  of    145.    Elapsed: 0:00:40.\n",
            "  Batch   120  of    145.    Elapsed: 0:01:00.\n",
            "\n",
            "  Average training loss: 0.29\n",
            "  Accuracy: 0.91\n",
            "Category: 0\n",
            "  Precision: 0.92\n",
            "  Recall: 0.97\n",
            "  F1: 0.94\n",
            "Category: 1\n",
            "  Precision: 0.53\n",
            "  Recall: 0.46\n",
            "  F1: 0.48\n",
            "Category: 2\n",
            "  Precision: 0.89\n",
            "  Recall: 0.93\n",
            "  F1: 0.90\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5873\n",
            "The average recall is: 0.5906\n",
            "The average f1 is: 0.5808\n",
            "  Training epcoh took: 0:01:12\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "Category: 0\n",
            "  Precision: 0.9156\n",
            "  Recall: 0.8772\n",
            "  F1: 0.8925\n",
            "Category: 1\n",
            "  Precision: 0.0321\n",
            "  Recall: 0.0577\n",
            "  F1: 0.0410\n",
            "Category: 2\n",
            "  Precision: 0.3359\n",
            "  Recall: 0.4679\n",
            "  F1: 0.3673\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3209\n",
            "The average recall is: 0.3507\n",
            "The average f1 is: 0.3252\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    145.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    145.    Elapsed: 0:00:39.\n",
            "  Batch   120  of    145.    Elapsed: 0:00:58.\n",
            "\n",
            "  Average training loss: 0.14\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.96\n",
            "  Recall: 0.99\n",
            "  F1: 0.97\n",
            "Category: 1\n",
            "  Precision: 0.68\n",
            "  Recall: 0.66\n",
            "  F1: 0.67\n",
            "Category: 2\n",
            "  Precision: 0.97\n",
            "  Recall: 1.00\n",
            "  F1: 0.98\n",
            "Category: 3\n",
            "  Precision: 0.02\n",
            "  Recall: 0.01\n",
            "  F1: 0.01\n",
            "The average precision is: 0.6578\n",
            "The average recall is: 0.6657\n",
            "The average f1 is: 0.6597\n",
            "  Training epcoh took: 0:01:10\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "Category: 0\n",
            "  Precision: 0.9028\n",
            "  Recall: 0.9183\n",
            "  F1: 0.9043\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0385\n",
            "Category: 2\n",
            "  Precision: 0.4096\n",
            "  Recall: 0.4494\n",
            "  F1: 0.3773\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3377\n",
            "The average recall is: 0.3515\n",
            "The average f1 is: 0.3300\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n",
            "Current increase 4 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 1788 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 1788 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 2512 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 2512 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 2560 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.53125\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "235\n",
            "0.091796875\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "905\n",
            "0.353515625\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "60\n",
            "0.0234375\n",
            "\n",
            "(2560, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 13:22:02.250670 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 13:22:02.253075 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 13:22:02.361022 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 13:22:04.851763 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 13:22:04.853086 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    160.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    160.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    160.    Elapsed: 0:00:56.\n",
            "\n",
            "  Average training loss: 0.96\n",
            "  Accuracy: 0.59\n",
            "Category: 0\n",
            "  Precision: 0.60\n",
            "  Recall: 0.88\n",
            "  F1: 0.70\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "Category: 2\n",
            "  Precision: 0.46\n",
            "  Recall: 0.35\n",
            "  F1: 0.36\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.2642\n",
            "The average recall is: 0.3081\n",
            "The average f1 is: 0.2640\n",
            "  Training epcoh took: 0:01:15\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.8650\n",
            "  Recall: 0.9629\n",
            "  F1: 0.9093\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.2500\n",
            "  Recall: 0.1731\n",
            "  F1: 0.1885\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.2787\n",
            "The average recall is: 0.2840\n",
            "The average f1 is: 0.2744\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    160.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    160.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    160.    Elapsed: 0:00:57.\n",
            "\n",
            "  Average training loss: 0.58\n",
            "  Accuracy: 0.79\n",
            "Category: 0\n",
            "  Precision: 0.80\n",
            "  Recall: 0.92\n",
            "  F1: 0.85\n",
            "Category: 1\n",
            "  Precision: 0.01\n",
            "  Recall: 0.01\n",
            "  F1: 0.01\n",
            "Category: 2\n",
            "  Precision: 0.81\n",
            "  Recall: 0.85\n",
            "  F1: 0.81\n",
            "Category: 3\n",
            "  Precision: 0.06\n",
            "  Recall: 0.05\n",
            "  F1: 0.05\n",
            "The average precision is: 0.4194\n",
            "The average recall is: 0.4571\n",
            "The average f1 is: 0.4280\n",
            "  Training epcoh took: 0:01:16\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8799\n",
            "  Recall: 0.9621\n",
            "  F1: 0.9173\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0192\n",
            "  F1: 0.0256\n",
            "Category: 2\n",
            "  Precision: 0.3269\n",
            "  Recall: 0.3019\n",
            "  F1: 0.3045\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3113\n",
            "The average recall is: 0.3208\n",
            "The average f1 is: 0.3119\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    160.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    160.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    160.    Elapsed: 0:00:57.\n",
            "\n",
            "  Average training loss: 0.23\n",
            "  Accuracy: 0.93\n",
            "Category: 0\n",
            "  Precision: 0.92\n",
            "  Recall: 0.98\n",
            "  F1: 0.95\n",
            "Category: 1\n",
            "  Precision: 0.51\n",
            "  Recall: 0.44\n",
            "  F1: 0.46\n",
            "Category: 2\n",
            "  Precision: 0.95\n",
            "  Recall: 0.96\n",
            "  F1: 0.95\n",
            "Category: 3\n",
            "  Precision: 0.21\n",
            "  Recall: 0.20\n",
            "  F1: 0.20\n",
            "The average precision is: 0.6472\n",
            "The average recall is: 0.6463\n",
            "The average f1 is: 0.6392\n",
            "  Training epcoh took: 0:01:16\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "Category: 0\n",
            "  Precision: 0.8997\n",
            "  Recall: 0.9071\n",
            "  F1: 0.9004\n",
            "Category: 1\n",
            "  Precision: 0.1282\n",
            "  Recall: 0.1282\n",
            "  F1: 0.1154\n",
            "Category: 2\n",
            "  Precision: 0.4038\n",
            "  Recall: 0.3462\n",
            "  F1: 0.3526\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3579\n",
            "The average recall is: 0.3454\n",
            "The average f1 is: 0.3421\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    160.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    160.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    160.    Elapsed: 0:00:57.\n",
            "\n",
            "  Average training loss: 0.07\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.77\n",
            "  Recall: 0.75\n",
            "  F1: 0.75\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.31\n",
            "  Recall: 0.30\n",
            "  F1: 0.30\n",
            "The average precision is: 0.7640\n",
            "The average recall is: 0.7618\n",
            "The average f1 is: 0.7612\n",
            "  Training epcoh took: 0:01:16\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.9018\n",
            "  Recall: 0.9246\n",
            "  F1: 0.9087\n",
            "Category: 1\n",
            "  Precision: 0.0962\n",
            "  Recall: 0.0897\n",
            "  F1: 0.0872\n",
            "Category: 2\n",
            "  Precision: 0.3558\n",
            "  Recall: 0.3301\n",
            "  F1: 0.3115\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3384\n",
            "The average recall is: 0.3361\n",
            "The average f1 is: 0.3269\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n",
            "Current increase 5 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 1835 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 1835 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 2740 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 2740 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 2800 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.4857142857142857\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "282\n",
            "0.10071428571428571\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1086\n",
            "0.38785714285714284\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "72\n",
            "0.025714285714285714\n",
            "\n",
            "(2800, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 13:27:20.170661 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 13:27:20.172531 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 13:27:20.276863 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 13:27:22.729799 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 13:27:22.730551 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    175.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    175.    Elapsed: 0:00:57.\n",
            "  Batch   160  of    175.    Elapsed: 0:01:16.\n",
            "\n",
            "  Average training loss: 0.94\n",
            "  Accuracy: 0.61\n",
            "Category: 0\n",
            "  Precision: 0.63\n",
            "  Recall: 0.80\n",
            "  F1: 0.68\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "Category: 2\n",
            "  Precision: 0.59\n",
            "  Recall: 0.57\n",
            "  F1: 0.53\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.3057\n",
            "The average recall is: 0.3416\n",
            "The average f1 is: 0.3037\n",
            "  Training epcoh took: 0:01:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "Category: 0\n",
            "  Precision: 0.8947\n",
            "  Recall: 0.9109\n",
            "  F1: 0.8984\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3462\n",
            "  Recall: 0.4224\n",
            "  F1: 0.3382\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3102\n",
            "The average recall is: 0.3333\n",
            "The average f1 is: 0.3092\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    175.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    175.    Elapsed: 0:00:57.\n",
            "  Batch   160  of    175.    Elapsed: 0:01:16.\n",
            "\n",
            "  Average training loss: 0.44\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.85\n",
            "  Recall: 0.94\n",
            "  F1: 0.88\n",
            "Category: 1\n",
            "  Precision: 0.30\n",
            "  Recall: 0.24\n",
            "  F1: 0.25\n",
            "Category: 2\n",
            "  Precision: 0.87\n",
            "  Recall: 0.95\n",
            "  F1: 0.90\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5034\n",
            "The average recall is: 0.5313\n",
            "The average f1 is: 0.5077\n",
            "  Training epcoh took: 0:01:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.9004\n",
            "  Recall: 0.9214\n",
            "  F1: 0.9087\n",
            "Category: 1\n",
            "  Precision: 0.1154\n",
            "  Recall: 0.0897\n",
            "  F1: 0.0962\n",
            "Category: 2\n",
            "  Precision: 0.4455\n",
            "  Recall: 0.4647\n",
            "  F1: 0.4090\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3653\n",
            "The average recall is: 0.3690\n",
            "The average f1 is: 0.3535\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    175.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    175.    Elapsed: 0:00:57.\n",
            "  Batch   160  of    175.    Elapsed: 0:01:16.\n",
            "\n",
            "  Average training loss: 0.13\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.95\n",
            "  Recall: 0.99\n",
            "  F1: 0.97\n",
            "Category: 1\n",
            "  Precision: 0.77\n",
            "  Recall: 0.79\n",
            "  F1: 0.77\n",
            "Category: 2\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 3\n",
            "  Precision: 0.03\n",
            "  Recall: 0.03\n",
            "  F1: 0.03\n",
            "The average precision is: 0.6870\n",
            "The average recall is: 0.6995\n",
            "The average f1 is: 0.6908\n",
            "  Training epcoh took: 0:01:24\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.9030\n",
            "  Recall: 0.9236\n",
            "  F1: 0.9113\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0705\n",
            "Category: 2\n",
            "  Precision: 0.3885\n",
            "  Recall: 0.3583\n",
            "  F1: 0.3416\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3421\n",
            "The average recall is: 0.3397\n",
            "The average f1 is: 0.3309\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    175.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    175.    Elapsed: 0:00:57.\n",
            "  Batch   160  of    175.    Elapsed: 0:01:16.\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.98\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.82\n",
            "  Recall: 0.82\n",
            "  F1: 0.82\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.21\n",
            "  Recall: 0.20\n",
            "  F1: 0.20\n",
            "The average precision is: 0.7497\n",
            "The average recall is: 0.7540\n",
            "The average f1 is: 0.7510\n",
            "  Training epcoh took: 0:01:24\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.9023\n",
            "  Recall: 0.9323\n",
            "  F1: 0.9155\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0577\n",
            "  F1: 0.0641\n",
            "Category: 2\n",
            "  Precision: 0.3782\n",
            "  Recall: 0.3654\n",
            "  F1: 0.3641\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3394\n",
            "The average recall is: 0.3388\n",
            "The average f1 is: 0.3359\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n",
            "Current increase 6 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 1882 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 1882 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 2968 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 2968 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 3040 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.4473684210526316\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "329\n",
            "0.10822368421052632\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1267\n",
            "0.41677631578947366\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "84\n",
            "0.02763157894736842\n",
            "\n",
            "(3040, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 13:33:08.799887 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 13:33:08.801239 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 13:33:13.711501 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 13:33:16.160465 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 13:33:16.161791 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    190.    Elapsed: 0:00:18.\n",
            "  Batch    80  of    190.    Elapsed: 0:00:37.\n",
            "  Batch   120  of    190.    Elapsed: 0:00:56.\n",
            "  Batch   160  of    190.    Elapsed: 0:01:16.\n",
            "\n",
            "  Average training loss: 0.88\n",
            "  Accuracy: 0.62\n",
            "Category: 0\n",
            "  Precision: 0.60\n",
            "  Recall: 0.70\n",
            "  F1: 0.62\n",
            "Category: 1\n",
            "  Precision: 0.01\n",
            "  Recall: 0.02\n",
            "  F1: 0.01\n",
            "Category: 2\n",
            "  Precision: 0.64\n",
            "  Recall: 0.72\n",
            "  F1: 0.64\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.3142\n",
            "The average recall is: 0.3600\n",
            "The average f1 is: 0.3183\n",
            "  Training epcoh took: 0:01:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "Category: 0\n",
            "  Precision: 0.8825\n",
            "  Recall: 0.9157\n",
            "  F1: 0.8939\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3391\n",
            "  Recall: 0.4244\n",
            "  F1: 0.3473\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3054\n",
            "The average recall is: 0.3350\n",
            "The average f1 is: 0.3103\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    190.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    190.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    190.    Elapsed: 0:00:58.\n",
            "  Batch   160  of    190.    Elapsed: 0:01:17.\n",
            "\n",
            "  Average training loss: 0.26\n",
            "  Accuracy: 0.91\n",
            "Category: 0\n",
            "  Precision: 0.90\n",
            "  Recall: 0.95\n",
            "  F1: 0.92\n",
            "Category: 1\n",
            "  Precision: 0.68\n",
            "  Recall: 0.61\n",
            "  F1: 0.63\n",
            "Category: 2\n",
            "  Precision: 0.94\n",
            "  Recall: 0.96\n",
            "  F1: 0.95\n",
            "Category: 3\n",
            "  Precision: 0.10\n",
            "  Recall: 0.09\n",
            "  F1: 0.09\n",
            "The average precision is: 0.6555\n",
            "The average recall is: 0.6535\n",
            "The average f1 is: 0.6459\n",
            "  Training epcoh took: 0:01:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.8832\n",
            "  Recall: 0.9399\n",
            "  F1: 0.9062\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0192\n",
            "  F1: 0.0256\n",
            "Category: 2\n",
            "  Precision: 0.3654\n",
            "  Recall: 0.2429\n",
            "  F1: 0.2632\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3217\n",
            "The average recall is: 0.3005\n",
            "The average f1 is: 0.2988\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    190.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    190.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    190.    Elapsed: 0:00:57.\n",
            "  Batch   160  of    190.    Elapsed: 0:01:17.\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.80\n",
            "  Recall: 0.80\n",
            "  F1: 0.80\n",
            "Category: 2\n",
            "  Precision: 0.99\n",
            "  Recall: 1.00\n",
            "  F1: 0.99\n",
            "Category: 3\n",
            "  Precision: 0.32\n",
            "  Recall: 0.32\n",
            "  F1: 0.32\n",
            "The average precision is: 0.7747\n",
            "The average recall is: 0.7758\n",
            "The average f1 is: 0.7741\n",
            "  Training epcoh took: 0:01:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "Category: 0\n",
            "  Precision: 0.8937\n",
            "  Recall: 0.9254\n",
            "  F1: 0.9068\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0128\n",
            "  F1: 0.0192\n",
            "Category: 2\n",
            "  Precision: 0.3397\n",
            "  Recall: 0.3590\n",
            "  F1: 0.3115\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3180\n",
            "The average recall is: 0.3243\n",
            "The average f1 is: 0.3094\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    190.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    190.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    190.    Elapsed: 0:00:57.\n",
            "  Batch   160  of    190.    Elapsed: 0:01:17.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.81\n",
            "  Recall: 0.81\n",
            "  F1: 0.81\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.36\n",
            "  Recall: 0.36\n",
            "  F1: 0.36\n",
            "The average precision is: 0.7916\n",
            "The average recall is: 0.7915\n",
            "The average f1 is: 0.7915\n",
            "  Training epcoh took: 0:01:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.8888\n",
            "  Recall: 0.9447\n",
            "  F1: 0.9136\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0385\n",
            "Category: 2\n",
            "  Precision: 0.3462\n",
            "  Recall: 0.2077\n",
            "  F1: 0.2501\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3184\n",
            "The average recall is: 0.2977\n",
            "The average f1 is: 0.3005\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n",
            "Current increase 7 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 1929 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 1929 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 3196 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 3196 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 3280 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.4146341463414634\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "376\n",
            "0.11463414634146342\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1448\n",
            "0.44146341463414634\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "96\n",
            "0.02926829268292683\n",
            "\n",
            "(3280, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 13:39:31.955502 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 13:39:31.956916 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 13:39:31.996488 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 13:39:34.473473 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 13:39:34.474688 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    205.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    205.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    205.    Elapsed: 0:00:57.\n",
            "  Batch   160  of    205.    Elapsed: 0:01:16.\n",
            "  Batch   200  of    205.    Elapsed: 0:01:36.\n",
            "\n",
            "  Average training loss: 0.86\n",
            "  Accuracy: 0.63\n",
            "Category: 0\n",
            "  Precision: 0.61\n",
            "  Recall: 0.71\n",
            "  F1: 0.63\n",
            "Category: 1\n",
            "  Precision: 0.05\n",
            "  Recall: 0.03\n",
            "  F1: 0.04\n",
            "Category: 2\n",
            "  Precision: 0.67\n",
            "  Recall: 0.76\n",
            "  F1: 0.68\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.3330\n",
            "The average recall is: 0.3768\n",
            "The average f1 is: 0.3391\n",
            "  Training epcoh took: 0:01:38\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "Category: 0\n",
            "  Precision: 0.8828\n",
            "  Recall: 0.9158\n",
            "  F1: 0.8972\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.2705\n",
            "  Recall: 0.2885\n",
            "  F1: 0.2585\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.2883\n",
            "The average recall is: 0.3011\n",
            "The average f1 is: 0.2889\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    205.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    205.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    205.    Elapsed: 0:00:58.\n",
            "  Batch   160  of    205.    Elapsed: 0:01:17.\n",
            "  Batch   200  of    205.    Elapsed: 0:01:36.\n",
            "\n",
            "  Average training loss: 0.22\n",
            "  Accuracy: 0.93\n",
            "Category: 0\n",
            "  Precision: 0.92\n",
            "  Recall: 0.95\n",
            "  F1: 0.92\n",
            "Category: 1\n",
            "  Precision: 0.78\n",
            "  Recall: 0.75\n",
            "  F1: 0.75\n",
            "Category: 2\n",
            "  Precision: 0.94\n",
            "  Recall: 0.98\n",
            "  F1: 0.96\n",
            "Category: 3\n",
            "  Precision: 0.05\n",
            "  Recall: 0.04\n",
            "  F1: 0.05\n",
            "The average precision is: 0.6728\n",
            "The average recall is: 0.6811\n",
            "The average f1 is: 0.6701\n",
            "  Training epcoh took: 0:01:38\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8417\n",
            "  Recall: 0.9454\n",
            "  F1: 0.8873\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.4167\n",
            "  Recall: 0.3186\n",
            "  F1: 0.3282\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3146\n",
            "The average recall is: 0.3160\n",
            "The average f1 is: 0.3039\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    205.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    205.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    205.    Elapsed: 0:00:57.\n",
            "  Batch   160  of    205.    Elapsed: 0:01:16.\n",
            "  Batch   200  of    205.    Elapsed: 0:01:35.\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.86\n",
            "  Recall: 0.87\n",
            "  F1: 0.86\n",
            "Category: 2\n",
            "  Precision: 0.99\n",
            "  Recall: 1.00\n",
            "  F1: 0.99\n",
            "Category: 3\n",
            "  Precision: 0.29\n",
            "  Recall: 0.27\n",
            "  F1: 0.28\n",
            "The average precision is: 0.7819\n",
            "The average recall is: 0.7816\n",
            "The average f1 is: 0.7802\n",
            "  Training epcoh took: 0:01:37\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8863\n",
            "  Recall: 0.9694\n",
            "  F1: 0.9236\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3910\n",
            "  Recall: 0.2981\n",
            "  F1: 0.3192\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3193\n",
            "The average recall is: 0.3169\n",
            "The average f1 is: 0.3107\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    205.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    205.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    205.    Elapsed: 0:00:58.\n",
            "  Batch   160  of    205.    Elapsed: 0:01:17.\n",
            "  Batch   200  of    205.    Elapsed: 0:01:37.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.85\n",
            "  Recall: 0.85\n",
            "  F1: 0.85\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.39\n",
            "  Recall: 0.39\n",
            "  F1: 0.39\n",
            "The average precision is: 0.8086\n",
            "The average recall is: 0.8090\n",
            "The average f1 is: 0.8086\n",
            "  Training epcoh took: 0:01:39\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8856\n",
            "  Recall: 0.9539\n",
            "  F1: 0.9157\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.4103\n",
            "  Recall: 0.3013\n",
            "  F1: 0.3310\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3240\n",
            "The average recall is: 0.3138\n",
            "The average f1 is: 0.3117\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n",
            "Current increase 8 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 1976 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 1976 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 3424 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 3424 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 3520 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.38636363636363635\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "423\n",
            "0.12017045454545454\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1629\n",
            "0.4627840909090909\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "108\n",
            "0.03068181818181818\n",
            "\n",
            "(3520, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 13:46:19.946569 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 13:46:19.948237 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 13:46:20.060602 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 13:46:22.774024 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 13:46:22.774843 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    220.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    220.    Elapsed: 0:00:39.\n",
            "  Batch   120  of    220.    Elapsed: 0:00:59.\n",
            "  Batch   160  of    220.    Elapsed: 0:01:19.\n",
            "  Batch   200  of    220.    Elapsed: 0:01:39.\n",
            "\n",
            "  Average training loss: 0.84\n",
            "  Accuracy: 0.64\n",
            "Category: 0\n",
            "  Precision: 0.62\n",
            "  Recall: 0.65\n",
            "  F1: 0.60\n",
            "Category: 1\n",
            "  Precision: 0.21\n",
            "  Recall: 0.13\n",
            "  F1: 0.15\n",
            "Category: 2\n",
            "  Precision: 0.66\n",
            "  Recall: 0.81\n",
            "  F1: 0.71\n",
            "Category: 3\n",
            "  Precision: 0.01\n",
            "  Recall: 0.01\n",
            "  F1: 0.01\n",
            "The average precision is: 0.3737\n",
            "The average recall is: 0.3987\n",
            "The average f1 is: 0.3662\n",
            "  Training epcoh took: 0:01:50\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.74\n",
            "Category: 0\n",
            "  Precision: 0.9111\n",
            "  Recall: 0.7940\n",
            "  F1: 0.8429\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.2190\n",
            "  Recall: 0.4397\n",
            "  F1: 0.2796\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.2825\n",
            "The average recall is: 0.3084\n",
            "The average f1 is: 0.2806\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    220.    Elapsed: 0:00:20.\n",
            "  Batch    80  of    220.    Elapsed: 0:00:40.\n",
            "  Batch   120  of    220.    Elapsed: 0:01:00.\n",
            "  Batch   160  of    220.    Elapsed: 0:01:21.\n",
            "  Batch   200  of    220.    Elapsed: 0:01:41.\n",
            "\n",
            "  Average training loss: 0.19\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.93\n",
            "  Recall: 0.95\n",
            "  F1: 0.93\n",
            "Category: 1\n",
            "  Precision: 0.76\n",
            "  Recall: 0.75\n",
            "  F1: 0.75\n",
            "Category: 2\n",
            "  Precision: 0.96\n",
            "  Recall: 0.98\n",
            "  F1: 0.97\n",
            "Category: 3\n",
            "  Precision: 0.18\n",
            "  Recall: 0.17\n",
            "  F1: 0.18\n",
            "The average precision is: 0.7076\n",
            "The average recall is: 0.7147\n",
            "The average f1 is: 0.7061\n",
            "  Training epcoh took: 0:01:51\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8714\n",
            "  Recall: 0.9687\n",
            "  F1: 0.9158\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3462\n",
            "  Recall: 0.2083\n",
            "  F1: 0.2423\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3044\n",
            "The average recall is: 0.2942\n",
            "The average f1 is: 0.2895\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    220.    Elapsed: 0:00:20.\n",
            "  Batch    80  of    220.    Elapsed: 0:00:41.\n",
            "  Batch   120  of    220.    Elapsed: 0:01:01.\n",
            "  Batch   160  of    220.    Elapsed: 0:01:22.\n",
            "  Batch   200  of    220.    Elapsed: 0:01:43.\n",
            "\n",
            "  Average training loss: 0.03\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.87\n",
            "  Recall: 0.89\n",
            "  F1: 0.88\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.38\n",
            "  Recall: 0.38\n",
            "  F1: 0.38\n",
            "The average precision is: 0.8116\n",
            "The average recall is: 0.8138\n",
            "The average f1 is: 0.8115\n",
            "  Training epcoh took: 0:01:54\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "Category: 0\n",
            "  Precision: 0.8860\n",
            "  Recall: 0.9148\n",
            "  F1: 0.8981\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0385\n",
            "Category: 2\n",
            "  Precision: 0.3173\n",
            "  Recall: 0.3205\n",
            "  F1: 0.3011\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3104\n",
            "The average recall is: 0.3184\n",
            "The average f1 is: 0.3094\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    220.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    220.    Elapsed: 0:00:42.\n",
            "  Batch   120  of    220.    Elapsed: 0:01:02.\n",
            "  Batch   160  of    220.    Elapsed: 0:01:23.\n",
            "  Batch   200  of    220.    Elapsed: 0:01:43.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.89\n",
            "  Recall: 0.89\n",
            "  F1: 0.89\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.37\n",
            "  Recall: 0.37\n",
            "  F1: 0.37\n",
            "The average precision is: 0.8145\n",
            "The average recall is: 0.8145\n",
            "The average f1 is: 0.8145\n",
            "  Training epcoh took: 0:01:54\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.8910\n",
            "  Recall: 0.9455\n",
            "  F1: 0.9131\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0128\n",
            "  F1: 0.0192\n",
            "Category: 2\n",
            "  Precision: 0.3974\n",
            "  Recall: 0.3359\n",
            "  F1: 0.3322\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3317\n",
            "The average recall is: 0.3235\n",
            "The average f1 is: 0.3161\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n",
            "Current increase 9 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 2023 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 2023 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 3652 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 3652 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 3760 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.3617021276595745\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "470\n",
            "0.125\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1810\n",
            "0.48138297872340424\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "120\n",
            "0.031914893617021274\n",
            "\n",
            "(3760, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 13:54:04.523058 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 13:54:04.528029 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 13:54:05.402371 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 13:54:07.967453 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 13:54:07.968240 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    235.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    235.    Elapsed: 0:00:39.\n",
            "  Batch   120  of    235.    Elapsed: 0:00:58.\n",
            "  Batch   160  of    235.    Elapsed: 0:01:17.\n",
            "  Batch   200  of    235.    Elapsed: 0:01:37.\n",
            "\n",
            "  Average training loss: 0.88\n",
            "  Accuracy: 0.61\n",
            "Category: 0\n",
            "  Precision: 0.53\n",
            "  Recall: 0.53\n",
            "  F1: 0.49\n",
            "Category: 1\n",
            "  Precision: 0.26\n",
            "  Recall: 0.22\n",
            "  F1: 0.22\n",
            "Category: 2\n",
            "  Precision: 0.65\n",
            "  Recall: 0.81\n",
            "  F1: 0.69\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.3604\n",
            "The average recall is: 0.3902\n",
            "The average f1 is: 0.3527\n",
            "  Training epcoh took: 0:01:53\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.65\n",
            "Category: 0\n",
            "  Precision: 0.8949\n",
            "  Recall: 0.6830\n",
            "  F1: 0.7690\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.1772\n",
            "  Recall: 0.5064\n",
            "  F1: 0.2476\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.2680\n",
            "The average recall is: 0.2973\n",
            "The average f1 is: 0.2541\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    235.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    235.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    235.    Elapsed: 0:00:57.\n",
            "  Batch   160  of    235.    Elapsed: 0:01:16.\n",
            "  Batch   200  of    235.    Elapsed: 0:01:35.\n",
            "\n",
            "  Average training loss: 0.17\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.92\n",
            "  Recall: 0.94\n",
            "  F1: 0.92\n",
            "Category: 1\n",
            "  Precision: 0.84\n",
            "  Recall: 0.84\n",
            "  F1: 0.84\n",
            "Category: 2\n",
            "  Precision: 0.96\n",
            "  Recall: 0.98\n",
            "  F1: 0.97\n",
            "Category: 3\n",
            "  Precision: 0.15\n",
            "  Recall: 0.14\n",
            "  F1: 0.14\n",
            "The average precision is: 0.7173\n",
            "The average recall is: 0.7253\n",
            "The average f1 is: 0.7173\n",
            "  Training epcoh took: 0:01:52\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "Category: 0\n",
            "  Precision: 0.8967\n",
            "  Recall: 0.9156\n",
            "  F1: 0.9034\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0192\n",
            "  F1: 0.0256\n",
            "Category: 2\n",
            "  Precision: 0.3654\n",
            "  Recall: 0.3814\n",
            "  F1: 0.3438\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3251\n",
            "The average recall is: 0.3291\n",
            "The average f1 is: 0.3182\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    235.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    235.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    235.    Elapsed: 0:00:57.\n",
            "  Batch   160  of    235.    Elapsed: 0:01:16.\n",
            "  Batch   200  of    235.    Elapsed: 0:01:35.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.88\n",
            "  Recall: 0.89\n",
            "  F1: 0.88\n",
            "Category: 2\n",
            "  Precision: 0.99\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.39\n",
            "  Recall: 0.40\n",
            "  F1: 0.39\n",
            "The average precision is: 0.8174\n",
            "The average recall is: 0.8174\n",
            "The average f1 is: 0.8171\n",
            "  Training epcoh took: 0:01:51\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8866\n",
            "  Recall: 0.9714\n",
            "  F1: 0.9245\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.4551\n",
            "  Recall: 0.3526\n",
            "  F1: 0.3769\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3547\n",
            "The average recall is: 0.3502\n",
            "The average f1 is: 0.3446\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    235.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    235.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    235.    Elapsed: 0:00:57.\n",
            "  Batch   160  of    235.    Elapsed: 0:01:16.\n",
            "  Batch   200  of    235.    Elapsed: 0:01:35.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.88\n",
            "  Recall: 0.88\n",
            "  F1: 0.88\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.43\n",
            "  Recall: 0.43\n",
            "  F1: 0.43\n",
            "The average precision is: 0.8263\n",
            "The average recall is: 0.8262\n",
            "The average f1 is: 0.8262\n",
            "  Training epcoh took: 0:01:51\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8939\n",
            "  Recall: 0.9640\n",
            "  F1: 0.9250\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0577\n",
            "  F1: 0.0641\n",
            "Category: 2\n",
            "  Precision: 0.3878\n",
            "  Recall: 0.3109\n",
            "  F1: 0.3175\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3397\n",
            "The average recall is: 0.3332\n",
            "The average f1 is: 0.3267\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n",
            "Current increase 10 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 2070 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 2070 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 3880 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 3880 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 4000 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.34\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "517\n",
            "0.12925\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1991\n",
            "0.49775\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "132\n",
            "0.033\n",
            "\n",
            "(4000, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 14:01:48.585154 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 14:01:48.586208 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 14:01:48.625671 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 14:01:51.087654 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 14:01:51.088398 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    250.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    250.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    250.    Elapsed: 0:00:57.\n",
            "  Batch   160  of    250.    Elapsed: 0:01:16.\n",
            "  Batch   200  of    250.    Elapsed: 0:01:35.\n",
            "  Batch   240  of    250.    Elapsed: 0:01:54.\n",
            "\n",
            "  Average training loss: 0.82\n",
            "  Accuracy: 0.68\n",
            "Category: 0\n",
            "  Precision: 0.63\n",
            "  Recall: 0.65\n",
            "  F1: 0.60\n",
            "Category: 1\n",
            "  Precision: 0.15\n",
            "  Recall: 0.09\n",
            "  F1: 0.11\n",
            "Category: 2\n",
            "  Precision: 0.70\n",
            "  Recall: 0.90\n",
            "  F1: 0.77\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.3722\n",
            "The average recall is: 0.4094\n",
            "The average f1 is: 0.3709\n",
            "  Training epcoh took: 0:01:58\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.78\n",
            "Category: 0\n",
            "  Precision: 0.8559\n",
            "  Recall: 0.8593\n",
            "  F1: 0.8543\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.3256\n",
            "  Recall: 0.3244\n",
            "  F1: 0.2906\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3146\n",
            "The average recall is: 0.3152\n",
            "The average f1 is: 0.3054\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    250.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    250.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    250.    Elapsed: 0:00:57.\n",
            "  Batch   160  of    250.    Elapsed: 0:01:16.\n",
            "  Batch   200  of    250.    Elapsed: 0:01:35.\n",
            "  Batch   240  of    250.    Elapsed: 0:01:54.\n",
            "\n",
            "  Average training loss: 0.16\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.94\n",
            "  Recall: 0.96\n",
            "  F1: 0.94\n",
            "Category: 1\n",
            "  Precision: 0.83\n",
            "  Recall: 0.82\n",
            "  F1: 0.81\n",
            "Category: 2\n",
            "  Precision: 0.96\n",
            "  Recall: 0.99\n",
            "  F1: 0.98\n",
            "Category: 3\n",
            "  Precision: 0.18\n",
            "  Recall: 0.18\n",
            "  F1: 0.18\n",
            "The average precision is: 0.7281\n",
            "The average recall is: 0.7369\n",
            "The average f1 is: 0.7280\n",
            "  Training epcoh took: 0:01:59\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "Category: 0\n",
            "  Precision: 0.8491\n",
            "  Recall: 0.9253\n",
            "  F1: 0.8836\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0385\n",
            "Category: 2\n",
            "  Precision: 0.4455\n",
            "  Recall: 0.3686\n",
            "  F1: 0.3907\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3333\n",
            "The average recall is: 0.3331\n",
            "The average f1 is: 0.3282\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    250.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    250.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    250.    Elapsed: 0:00:57.\n",
            "  Batch   160  of    250.    Elapsed: 0:01:16.\n",
            "  Batch   200  of    250.    Elapsed: 0:01:35.\n",
            "  Batch   240  of    250.    Elapsed: 0:01:54.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.87\n",
            "  Recall: 0.87\n",
            "  F1: 0.87\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.41\n",
            "  Recall: 0.41\n",
            "  F1: 0.41\n",
            "The average precision is: 0.8177\n",
            "The average recall is: 0.8177\n",
            "The average f1 is: 0.8175\n",
            "  Training epcoh took: 0:01:59\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.9041\n",
            "  Recall: 0.9347\n",
            "  F1: 0.9163\n",
            "Category: 1\n",
            "  Precision: 0.1154\n",
            "  Recall: 0.0962\n",
            "  F1: 0.1026\n",
            "Category: 2\n",
            "  Precision: 0.4231\n",
            "  Recall: 0.5122\n",
            "  F1: 0.4068\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3606\n",
            "The average recall is: 0.3858\n",
            "The average f1 is: 0.3564\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    250.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    250.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    250.    Elapsed: 0:00:57.\n",
            "  Batch   160  of    250.    Elapsed: 0:01:16.\n",
            "  Batch   200  of    250.    Elapsed: 0:01:35.\n",
            "  Batch   240  of    250.    Elapsed: 0:01:53.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.87\n",
            "  Recall: 0.87\n",
            "  F1: 0.87\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.46\n",
            "  Recall: 0.46\n",
            "  F1: 0.46\n",
            "The average precision is: 0.8317\n",
            "The average recall is: 0.8316\n",
            "The average f1 is: 0.8316\n",
            "  Training epcoh took: 0:01:58\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.9029\n",
            "  Recall: 0.9473\n",
            "  F1: 0.9215\n",
            "Category: 1\n",
            "  Precision: 0.1154\n",
            "  Recall: 0.1026\n",
            "  F1: 0.1077\n",
            "Category: 2\n",
            "  Precision: 0.4013\n",
            "  Recall: 0.4199\n",
            "  F1: 0.3829\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3549\n",
            "The average recall is: 0.3674\n",
            "The average f1 is: 0.3530\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n",
            "Current increase 11 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 2117 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 2117 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 4108 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 4108 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 4240 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.32075471698113206\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "564\n",
            "0.1330188679245283\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "2172\n",
            "0.5122641509433963\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "144\n",
            "0.033962264150943396\n",
            "\n",
            "(4240, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 14:09:58.002557 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 14:09:58.003567 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 14:09:59.697041 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 14:10:02.252990 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 14:10:02.253716 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    265.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    265.    Elapsed: 0:00:37.\n",
            "  Batch   120  of    265.    Elapsed: 0:00:56.\n",
            "  Batch   160  of    265.    Elapsed: 0:01:15.\n",
            "  Batch   200  of    265.    Elapsed: 0:01:35.\n",
            "  Batch   240  of    265.    Elapsed: 0:01:54.\n",
            "\n",
            "  Average training loss: 0.81\n",
            "  Accuracy: 0.67\n",
            "Category: 0\n",
            "  Precision: 0.59\n",
            "  Recall: 0.58\n",
            "  F1: 0.55\n",
            "Category: 1\n",
            "  Precision: 0.17\n",
            "  Recall: 0.12\n",
            "  F1: 0.14\n",
            "Category: 2\n",
            "  Precision: 0.70\n",
            "  Recall: 0.92\n",
            "  F1: 0.78\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.3682\n",
            "The average recall is: 0.4063\n",
            "The average f1 is: 0.3659\n",
            "  Training epcoh took: 0:02:05\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.72\n",
            "Category: 0\n",
            "  Precision: 0.9211\n",
            "  Recall: 0.7626\n",
            "  F1: 0.8274\n",
            "Category: 1\n",
            "  Precision: 0.1538\n",
            "  Recall: 0.1346\n",
            "  F1: 0.1410\n",
            "Category: 2\n",
            "  Precision: 0.2234\n",
            "  Recall: 0.5147\n",
            "  F1: 0.2880\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3246\n",
            "The average recall is: 0.3530\n",
            "The average f1 is: 0.3141\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    265.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    265.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    265.    Elapsed: 0:00:57.\n",
            "  Batch   160  of    265.    Elapsed: 0:01:16.\n",
            "  Batch   200  of    265.    Elapsed: 0:01:35.\n",
            "  Batch   240  of    265.    Elapsed: 0:01:54.\n",
            "\n",
            "  Average training loss: 0.14\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.93\n",
            "  Recall: 0.95\n",
            "  F1: 0.93\n",
            "Category: 1\n",
            "  Precision: 0.86\n",
            "  Recall: 0.86\n",
            "  F1: 0.86\n",
            "Category: 2\n",
            "  Precision: 0.98\n",
            "  Recall: 0.99\n",
            "  F1: 0.98\n",
            "Category: 3\n",
            "  Precision: 0.30\n",
            "  Recall: 0.29\n",
            "  F1: 0.30\n",
            "The average precision is: 0.7692\n",
            "The average recall is: 0.7731\n",
            "The average f1 is: 0.7676\n",
            "  Training epcoh took: 0:02:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.8939\n",
            "  Recall: 0.9378\n",
            "  F1: 0.9127\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0192\n",
            "  F1: 0.0256\n",
            "Category: 2\n",
            "  Precision: 0.3590\n",
            "  Recall: 0.3795\n",
            "  F1: 0.3321\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3228\n",
            "The average recall is: 0.3341\n",
            "The average f1 is: 0.3176\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    265.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    265.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    265.    Elapsed: 0:00:57.\n",
            "  Batch   160  of    265.    Elapsed: 0:01:16.\n",
            "  Batch   200  of    265.    Elapsed: 0:01:35.\n",
            "  Batch   240  of    265.    Elapsed: 0:01:54.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 0.98\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.88\n",
            "  Recall: 0.89\n",
            "  F1: 0.88\n",
            "Category: 2\n",
            "  Precision: 0.99\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.42\n",
            "  Recall: 0.43\n",
            "  F1: 0.43\n",
            "The average precision is: 0.8241\n",
            "The average recall is: 0.8242\n",
            "The average f1 is: 0.8234\n",
            "  Training epcoh took: 0:02:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8522\n",
            "  Recall: 0.9276\n",
            "  F1: 0.8861\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0385\n",
            "Category: 2\n",
            "  Precision: 0.3462\n",
            "  Recall: 0.3071\n",
            "  F1: 0.3015\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3092\n",
            "The average recall is: 0.3183\n",
            "The average f1 is: 0.3065\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    265.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    265.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    265.    Elapsed: 0:00:57.\n",
            "  Batch   160  of    265.    Elapsed: 0:01:16.\n",
            "  Batch   200  of    265.    Elapsed: 0:01:35.\n",
            "  Batch   240  of    265.    Elapsed: 0:01:54.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.89\n",
            "  Recall: 0.89\n",
            "  F1: 0.89\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.40\n",
            "  Recall: 0.40\n",
            "  F1: 0.40\n",
            "The average precision is: 0.8228\n",
            "The average recall is: 0.8225\n",
            "The average f1 is: 0.8225\n",
            "  Training epcoh took: 0:02:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8957\n",
            "  Recall: 0.9490\n",
            "  F1: 0.9187\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0256\n",
            "  F1: 0.0308\n",
            "Category: 2\n",
            "  Precision: 0.3744\n",
            "  Recall: 0.3846\n",
            "  F1: 0.3641\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3271\n",
            "The average recall is: 0.3398\n",
            "The average f1 is: 0.3284\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n",
            "Current increase 12 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 2164 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 2164 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 4336 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 4336 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 4480 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.30357142857142855\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "611\n",
            "0.13638392857142856\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "2353\n",
            "0.5252232142857143\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "156\n",
            "0.03482142857142857\n",
            "\n",
            "(4480, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 14:18:37.821583 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 14:18:37.822580 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 14:18:37.930921 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 14:18:40.470172 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 14:18:40.471070 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    280.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    280.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    280.    Elapsed: 0:00:57.\n",
            "  Batch   160  of    280.    Elapsed: 0:01:16.\n",
            "  Batch   200  of    280.    Elapsed: 0:01:35.\n",
            "  Batch   240  of    280.    Elapsed: 0:01:54.\n",
            "\n",
            "  Average training loss: 0.64\n",
            "  Accuracy: 0.75\n",
            "Category: 0\n",
            "  Precision: 0.64\n",
            "  Recall: 0.63\n",
            "  F1: 0.61\n",
            "Category: 1\n",
            "  Precision: 0.53\n",
            "  Recall: 0.46\n",
            "  F1: 0.48\n",
            "Category: 2\n",
            "  Precision: 0.78\n",
            "  Recall: 0.93\n",
            "  F1: 0.84\n",
            "Category: 3\n",
            "  Precision: 0.03\n",
            "  Recall: 0.03\n",
            "  F1: 0.03\n",
            "The average precision is: 0.4967\n",
            "The average recall is: 0.5133\n",
            "The average f1 is: 0.4870\n",
            "  Training epcoh took: 0:02:13\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8837\n",
            "  Recall: 0.9591\n",
            "  F1: 0.9168\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0192\n",
            "  F1: 0.0256\n",
            "Category: 2\n",
            "  Precision: 0.3333\n",
            "  Recall: 0.3077\n",
            "  F1: 0.2963\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3139\n",
            "The average recall is: 0.3215\n",
            "The average f1 is: 0.3097\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    280.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    280.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    280.    Elapsed: 0:00:57.\n",
            "  Batch   160  of    280.    Elapsed: 0:01:16.\n",
            "  Batch   200  of    280.    Elapsed: 0:01:35.\n",
            "  Batch   240  of    280.    Elapsed: 0:01:54.\n",
            "\n",
            "  Average training loss: 0.07\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.97\n",
            "  Recall: 0.96\n",
            "  F1: 0.96\n",
            "Category: 1\n",
            "  Precision: 0.89\n",
            "  Recall: 0.89\n",
            "  F1: 0.89\n",
            "Category: 2\n",
            "  Precision: 0.99\n",
            "  Recall: 1.00\n",
            "  F1: 0.99\n",
            "Category: 3\n",
            "  Precision: 0.40\n",
            "  Recall: 0.39\n",
            "  F1: 0.39\n",
            "The average precision is: 0.8101\n",
            "The average recall is: 0.8074\n",
            "The average f1 is: 0.8072\n",
            "  Training epcoh took: 0:02:13\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8935\n",
            "  Recall: 0.9492\n",
            "  F1: 0.9182\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.3878\n",
            "  Recall: 0.3782\n",
            "  F1: 0.3597\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3396\n",
            "The average recall is: 0.3511\n",
            "The average f1 is: 0.3387\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    280.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    280.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    280.    Elapsed: 0:00:57.\n",
            "  Batch   160  of    280.    Elapsed: 0:01:16.\n",
            "  Batch   200  of    280.    Elapsed: 0:01:35.\n",
            "  Batch   240  of    280.    Elapsed: 0:01:54.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.91\n",
            "  Recall: 0.91\n",
            "  F1: 0.91\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.44\n",
            "  Recall: 0.44\n",
            "  F1: 0.44\n",
            "The average precision is: 0.8364\n",
            "The average recall is: 0.8363\n",
            "The average f1 is: 0.8363\n",
            "  Training epcoh took: 0:02:13\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8907\n",
            "  Recall: 0.9543\n",
            "  F1: 0.9181\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0128\n",
            "  F1: 0.0192\n",
            "Category: 2\n",
            "  Precision: 0.3718\n",
            "  Recall: 0.3718\n",
            "  F1: 0.3359\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3252\n",
            "The average recall is: 0.3347\n",
            "The average f1 is: 0.3183\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    280.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    280.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    280.    Elapsed: 0:00:57.\n",
            "  Batch   160  of    280.    Elapsed: 0:01:16.\n",
            "  Batch   200  of    280.    Elapsed: 0:01:35.\n",
            "  Batch   240  of    280.    Elapsed: 0:01:54.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.92\n",
            "  Recall: 0.92\n",
            "  F1: 0.92\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.39\n",
            "  Recall: 0.39\n",
            "  F1: 0.39\n",
            "The average precision is: 0.8273\n",
            "The average recall is: 0.8273\n",
            "The average f1 is: 0.8273\n",
            "  Training epcoh took: 0:02:13\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8847\n",
            "  Recall: 0.9652\n",
            "  F1: 0.9214\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0385\n",
            "Category: 2\n",
            "  Precision: 0.4295\n",
            "  Recall: 0.3077\n",
            "  F1: 0.3397\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3382\n",
            "The average recall is: 0.3278\n",
            "The average f1 is: 0.3249\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n",
            "Current increase 13 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1360 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 47 sampled in this category.\n",
            "After up-sample, there are 2211 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 2211 samples\n",
            "There are 181 sampled in this category.\n",
            "After up-sample, there are 4564 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 4564 samples\n",
            "There are 12 sampled in this category.\n",
            "After up-sample, there are 4720 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.85\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1360\n",
            "0.288135593220339\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "47\n",
            "0.029375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "658\n",
            "0.13940677966101694\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "181\n",
            "0.113125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "2534\n",
            "0.536864406779661\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "12\n",
            "0.0075\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "168\n",
            "0.03559322033898305\n",
            "\n",
            "(4720, 330)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 14:27:45.625660 140115351164736 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0827 14:27:45.626669 140115351164736 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0827 14:27:45.684038 140115351164736 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0827 14:27:48.144415 140115351164736 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0827 14:27:48.145146 140115351164736 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    295.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    295.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    295.    Elapsed: 0:00:57.\n",
            "  Batch   160  of    295.    Elapsed: 0:01:16.\n",
            "  Batch   200  of    295.    Elapsed: 0:01:35.\n",
            "  Batch   240  of    295.    Elapsed: 0:01:54.\n",
            "  Batch   280  of    295.    Elapsed: 0:02:13.\n",
            "\n",
            "  Average training loss: 0.65\n",
            "  Accuracy: 0.75\n",
            "Category: 0\n",
            "  Precision: 0.62\n",
            "  Recall: 0.56\n",
            "  F1: 0.56\n",
            "Category: 1\n",
            "  Precision: 0.54\n",
            "  Recall: 0.48\n",
            "  F1: 0.49\n",
            "Category: 2\n",
            "  Precision: 0.77\n",
            "  Recall: 0.94\n",
            "  F1: 0.83\n",
            "Category: 3\n",
            "  Precision: 0.10\n",
            "  Recall: 0.09\n",
            "  F1: 0.09\n",
            "The average precision is: 0.5073\n",
            "The average recall is: 0.5199\n",
            "The average f1 is: 0.4951\n",
            "  Training epcoh took: 0:02:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "Category: 0\n",
            "  Precision: 0.8995\n",
            "  Recall: 0.9153\n",
            "  F1: 0.9040\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0385\n",
            "Category: 2\n",
            "  Precision: 0.2615\n",
            "  Recall: 0.3417\n",
            "  F1: 0.2859\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.2999\n",
            "The average recall is: 0.3239\n",
            "The average f1 is: 0.3071\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    295.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    295.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    295.    Elapsed: 0:00:57.\n",
            "  Batch   160  of    295.    Elapsed: 0:01:16.\n",
            "  Batch   200  of    295.    Elapsed: 0:01:35.\n",
            "  Batch   240  of    295.    Elapsed: 0:01:54.\n",
            "  Batch   280  of    295.    Elapsed: 0:02:13.\n",
            "\n",
            "  Average training loss: 0.07\n",
            "  Accuracy: 0.98\n",
            "Category: 0\n",
            "  Precision: 0.97\n",
            "  Recall: 0.94\n",
            "  F1: 0.95\n",
            "Category: 1\n",
            "  Precision: 0.89\n",
            "  Recall: 0.90\n",
            "  F1: 0.89\n",
            "Category: 2\n",
            "  Precision: 0.98\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 3\n",
            "  Precision: 0.40\n",
            "  Recall: 0.39\n",
            "  F1: 0.40\n",
            "The average precision is: 0.8085\n",
            "The average recall is: 0.8058\n",
            "The average f1 is: 0.8051\n",
            "  Training epcoh took: 0:02:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8877\n",
            "  Recall: 0.9595\n",
            "  F1: 0.9198\n",
            "Category: 1\n",
            "  Precision: 0.0192\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0256\n",
            "Category: 2\n",
            "  Precision: 0.3173\n",
            "  Recall: 0.2981\n",
            "  F1: 0.2942\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3061\n",
            "The average recall is: 0.3240\n",
            "The average f1 is: 0.3099\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    295.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    295.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    295.    Elapsed: 0:00:57.\n",
            "  Batch   160  of    295.    Elapsed: 0:01:16.\n",
            "  Batch   200  of    295.    Elapsed: 0:01:35.\n",
            "  Batch   240  of    295.    Elapsed: 0:01:54.\n",
            "  Batch   280  of    295.    Elapsed: 0:02:13.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.92\n",
            "  Recall: 0.92\n",
            "  F1: 0.92\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.45\n",
            "  Recall: 0.45\n",
            "  F1: 0.45\n",
            "The average precision is: 0.8406\n",
            "The average recall is: 0.8391\n",
            "The average f1 is: 0.8395\n",
            "  Training epcoh took: 0:02:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8572\n",
            "  Recall: 0.9057\n",
            "  F1: 0.8782\n",
            "Category: 1\n",
            "  Precision: 0.1154\n",
            "  Recall: 0.0865\n",
            "  F1: 0.0923\n",
            "Category: 2\n",
            "  Precision: 0.3782\n",
            "  Recall: 0.3346\n",
            "  F1: 0.3370\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3377\n",
            "The average recall is: 0.3317\n",
            "The average f1 is: 0.3269\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    295.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    295.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    295.    Elapsed: 0:00:57.\n",
            "  Batch   160  of    295.    Elapsed: 0:01:16.\n",
            "  Batch   200  of    295.    Elapsed: 0:01:35.\n",
            "  Batch   240  of    295.    Elapsed: 0:01:54.\n",
            "  Batch   280  of    295.    Elapsed: 0:02:13.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.91\n",
            "  Recall: 0.91\n",
            "  F1: 0.91\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.46\n",
            "  Recall: 0.46\n",
            "  F1: 0.46\n",
            "The average precision is: 0.8420\n",
            "The average recall is: 0.8414\n",
            "The average f1 is: 0.8416\n",
            "  Training epcoh took: 0:02:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8855\n",
            "  Recall: 0.9478\n",
            "  F1: 0.9134\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0321\n",
            "  F1: 0.0449\n",
            "Category: 2\n",
            "  Precision: 0.2949\n",
            "  Recall: 0.2506\n",
            "  F1: 0.2490\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3143\n",
            "The average recall is: 0.3076\n",
            "The average f1 is: 0.3018\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n",
            "Successfully save file BertSearchResult/16_2e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "InOjhBGFDuQt",
        "scrolled": true,
        "colab": {},
        "outputId": "4a2ae14f-cec7-4d23-8e08-18348fbc9b47"
      },
      "source": [
        "all_metrics_search"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(None,\n",
              "            {'16_5e-05': {0: defaultdict(None,\n",
              "                          {'train_loss_values': [0.5641749259829522,\n",
              "                            0.5641749259829522,\n",
              "                            0.5090744014829397,\n",
              "                            0.5090744014829397,\n",
              "                            0.3772193490900099,\n",
              "                            0.3772193490900099,\n",
              "                            0.24945555636659264,\n",
              "                            0.24945555636659264],\n",
              "                           'train_acc_all': [0.84, 0.85375, 0.890625, 0.9325],\n",
              "                           'train_precision_all': [{0: 0.8405416666666667,\n",
              "                             1: 0.0,\n",
              "                             2: 0.0,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8588214285714286, 1: 0.0, 2: 0.1075, 3: 0.0},\n",
              "                            {0: 0.9147370684870684,\n",
              "                             1: 0.0,\n",
              "                             2: 0.533047619047619,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9514869713619716,\n",
              "                             1: 0.0,\n",
              "                             2: 0.6666666666666665,\n",
              "                             3: 0.0}],\n",
              "                           'train_recall_all': [{0: 0.9892857142857143,\n",
              "                             1: 0.0,\n",
              "                             2: 0.0,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9931476856476857,\n",
              "                             1: 0.0,\n",
              "                             2: 0.05666666666666667,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9776612137862136,\n",
              "                             1: 0.0,\n",
              "                             2: 0.45050000000000007,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9929020146520148,\n",
              "                             1: 0.0,\n",
              "                             2: 0.6568333333333333,\n",
              "                             3: 0.0}],\n",
              "                           'train_f1_all': [{0: 0.9067169128815407,\n",
              "                             1: 0.0,\n",
              "                             2: 0.0,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9186649612646905,\n",
              "                             1: 0.0,\n",
              "                             2: 0.07002380952380953,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9426997799380359,\n",
              "                             1: 0.0,\n",
              "                             2: 0.4565187590187589,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9708082828588468,\n",
              "                             1: 0.0,\n",
              "                             2: 0.6385432900432896,\n",
              "                             3: 0.0}],\n",
              "                           'val_acc_all': [0.8485576923076923,\n",
              "                            0.8557692307692307,\n",
              "                            0.8605769230769231,\n",
              "                            0.8629807692307693],\n",
              "                           'val_precision_all': [{0: 0.8485576923076923,\n",
              "                             1: 0.0,\n",
              "                             2: 0.0,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8588141025641026,\n",
              "                             1: 0.0,\n",
              "                             2: 0.19230769230769232,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8886464497041421,\n",
              "                             1: 0.0,\n",
              "                             2: 0.41025641025641024,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8953043751120675,\n",
              "                             1: 0.0,\n",
              "                             2: 0.40961538461538455,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 1.0, 1: 0.0, 2: 0.0, 3: 0.0},\n",
              "                            {0: 0.9944773175542406,\n",
              "                             1: 0.0,\n",
              "                             2: 0.1346153846153846,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9595423806962268,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3384615384615384,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.959767422748192,\n",
              "                             1: 0.0,\n",
              "                             2: 0.41666666666666663,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.914592843402632,\n",
              "                             1: 0.0,\n",
              "                             2: 0.0,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9193489463105275,\n",
              "                             1: 0.0,\n",
              "                             2: 0.15384615384615383,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9200310219998762,\n",
              "                             1: 0.0,\n",
              "                             2: 0.34059829059829055,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9237425136145936,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3833943833943833,\n",
              "                             3: 0.0}]}),\n",
              "              1: defaultdict(None,\n",
              "                          {'train_loss_values': [0.7563958971396737,\n",
              "                            0.7563958971396737,\n",
              "                            0.5269831243416537,\n",
              "                            0.5269831243416537,\n",
              "                            0.292568089246102,\n",
              "                            0.292568089246102,\n",
              "                            0.12545022583040205,\n",
              "                            0.12545022583040205],\n",
              "                           'train_acc_all': [0.7407608695652174,\n",
              "                            0.8347826086956521,\n",
              "                            0.9097826086956522,\n",
              "                            0.966304347826087],\n",
              "                           'train_precision_all': [{0: 0.7493307417220458,\n",
              "                             1: 0.0,\n",
              "                             2: 0.13173913043478258,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8594939118852158,\n",
              "                             1: 0.0,\n",
              "                             2: 0.681086956521739,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9449999879347701,\n",
              "                             1: 0.0782608695652174,\n",
              "                             2: 0.8022532781228432,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9812204100247579,\n",
              "                             1: 0.417391304347826,\n",
              "                             2: 0.9238819875776398,\n",
              "                             3: 0.0}],\n",
              "                           'train_recall_all': [{0: 0.9738872721481417,\n",
              "                             1: 0.0,\n",
              "                             2: 0.09652173913043477,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9653786792917226,\n",
              "                             1: 0.0,\n",
              "                             2: 0.5785714285714285,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9821949548036503,\n",
              "                             1: 0.05507246376811594,\n",
              "                             2: 0.8984057971014492,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.996824769433465,\n",
              "                             1: 0.4043478260869565,\n",
              "                             2: 0.9511594202898551,\n",
              "                             3: 0.0}],\n",
              "                           'train_f1_all': [{0: 0.8410897402605089,\n",
              "                             1: 0.0,\n",
              "                             2: 0.10097786271699316,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9053455468089403,\n",
              "                             1: 0.0,\n",
              "                             2: 0.5891241608632909,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9616152183966428,\n",
              "                             1: 0.06231884057971014,\n",
              "                             2: 0.8284278040799777,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9885304945465118,\n",
              "                             1: 0.39971014492753615,\n",
              "                             2: 0.9314115353245788,\n",
              "                             3: 0.0}],\n",
              "                           'val_acc_all': [0.8533653846153846,\n",
              "                            0.7692307692307693,\n",
              "                            0.8557692307692307,\n",
              "                            0.875],\n",
              "                           'val_precision_all': [{0: 0.8861228515074671,\n",
              "                             1: 0.0,\n",
              "                             2: 0.37820512820512825,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8715777811931661,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3153846153846154,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8963573285688671,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.32948717948717954,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8610805860805861,\n",
              "                             1: 0.11538461538461539,\n",
              "                             2: 0.5705128205128205,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.9540478752017214,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3391025641025642,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.83107213299521,\n",
              "                             1: 0.0,\n",
              "                             2: 0.5448717948717949,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9515594981941136,\n",
              "                             1: 0.019230769230769232,\n",
              "                             2: 0.342948717948718,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9277771907579601,\n",
              "                             1: 0.08974358974358974,\n",
              "                             2: 0.3942307692307692,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.9166335544298796,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3297619047619048,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8473395320762331,\n",
              "                             1: 0.0,\n",
              "                             2: 0.387912087912088,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9207278551224817,\n",
              "                             1: 0.02564102564102564,\n",
              "                             2: 0.30512820512820515,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8914038644457059,\n",
              "                             1: 0.09615384615384616,\n",
              "                             2: 0.4424908424908425,\n",
              "                             3: 0.0}]}),\n",
              "              2: defaultdict(None,\n",
              "                          {'train_loss_values': [0.8120485097169876,\n",
              "                            0.8120485097169876,\n",
              "                            0.39523249578017455,\n",
              "                            0.39523249578017455,\n",
              "                            0.10190205309325112,\n",
              "                            0.10190205309325112,\n",
              "                            0.013689104664640931,\n",
              "                            0.013689104664640931],\n",
              "                           'train_acc_all': [0.6836538461538462,\n",
              "                            0.8701923076923077,\n",
              "                            0.9673076923076923,\n",
              "                            0.9961538461538462],\n",
              "                           'train_precision_all': [{0: 0.7094587570549105,\n",
              "                             1: 0.007692307692307693,\n",
              "                             2: 0.36645854145854134,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8917949571795728,\n",
              "                             1: 0.23205128205128206,\n",
              "                             2: 0.8460164835164834,\n",
              "                             3: 0.015384615384615385},\n",
              "                            {0: 0.9800866227789304,\n",
              "                             1: 0.6324358974358973,\n",
              "                             2: 0.9454945054945054,\n",
              "                             3: 0.13846153846153847},\n",
              "                            {0: 0.9974844599844599,\n",
              "                             1: 0.7134615384615385,\n",
              "                             2: 0.9877472527472526,\n",
              "                             3: 0.23846153846153847}],\n",
              "                           'train_recall_all': [{0: 0.929923644731337,\n",
              "                             1: 0.007692307692307693,\n",
              "                             2: 0.28609890109890107,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9598375342606114,\n",
              "                             1: 0.1905128205128205,\n",
              "                             2: 0.8590842490842487,\n",
              "                             3: 0.015384615384615385},\n",
              "                            {0: 0.9867008205469745,\n",
              "                             1: 0.6493589743589744,\n",
              "                             2: 0.9613919413919412,\n",
              "                             3: 0.12435897435897435},\n",
              "                            {0: 0.9970629370629371,\n",
              "                             1: 0.7128205128205128,\n",
              "                             2: 0.9903846153846154,\n",
              "                             3: 0.23846153846153847}],\n",
              "                           'train_f1_all': [{0: 0.7948676213972901,\n",
              "                             1: 0.007692307692307693,\n",
              "                             2: 0.28736319236319235,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9208681210351829,\n",
              "                             1: 0.20012820512820512,\n",
              "                             2: 0.8332430176660942,\n",
              "                             3: 0.015384615384615385},\n",
              "                            {0: 0.9824359214152175,\n",
              "                             1: 0.6302808302808303,\n",
              "                             2: 0.9477696662312046,\n",
              "                             3: 0.1292307692307692},\n",
              "                            {0: 0.9971260731013053,\n",
              "                             1: 0.7127472527472527,\n",
              "                             2: 0.9887367333521179,\n",
              "                             3: 0.23846153846153847}],\n",
              "                           'val_acc_all': [0.8629807692307693,\n",
              "                            0.8173076923076923,\n",
              "                            0.8461538461538461,\n",
              "                            0.8605769230769231],\n",
              "                           'val_precision_all': [{0: 0.8789218794026487,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3397435897435897,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8474658354466048,\n",
              "                             1: 0.0,\n",
              "                             2: 0.4294871794871795,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8957681741335589,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.39743589743589747,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8931584441199826,\n",
              "                             1: 0.057692307692307696,\n",
              "                             2: 0.3807692307692307,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.9737602141448296,\n",
              "                             1: 0.0,\n",
              "                             2: 0.23846153846153847,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9226894899971824,\n",
              "                             1: 0.0,\n",
              "                             2: 0.37820512820512814,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9275396078280694,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.3794871794871794,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9496814083352546,\n",
              "                             1: 0.05128205128205128,\n",
              "                             2: 0.3166666666666667,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.9217755000102911,\n",
              "                             1: 0.0,\n",
              "                             2: 0.26153846153846155,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8809012090179201,\n",
              "                             1: 0.0,\n",
              "                             2: 0.37820512820512825,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9096606710021466,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.3596153846153846,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9179261747903047,\n",
              "                             1: 0.044871794871794865,\n",
              "                             2: 0.3274725274725275,\n",
              "                             3: 0.0}]}),\n",
              "              3: defaultdict(None,\n",
              "                          {'train_loss_values': [0.9272878918154487,\n",
              "                            0.9272878918154487,\n",
              "                            0.5953739961673473,\n",
              "                            0.5953739961673473,\n",
              "                            0.34239864489384764,\n",
              "                            0.34239864489384764,\n",
              "                            0.12762673871655916,\n",
              "                            0.12762673871655916],\n",
              "                           'train_acc_all': [0.628448275862069,\n",
              "                            0.8112068965517242,\n",
              "                            0.9025862068965518,\n",
              "                            0.969396551724138],\n",
              "                           'train_precision_all': [{0: 0.6539215573698332,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3633228840125393,\n",
              "                             3: 0.0004597701149425287},\n",
              "                            {0: 0.8100260850260846,\n",
              "                             1: 0.07241379310344828,\n",
              "                             2: 0.8120184604667361,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9064502547261164,\n",
              "                             1: 0.4302298850574713,\n",
              "                             2: 0.9482320744389711,\n",
              "                             3: 0.006896551724137931},\n",
              "                            {0: 0.9622273129169677,\n",
              "                             1: 0.6586206896551725,\n",
              "                             2: 0.9957307060755336,\n",
              "                             3: 0.18620689655172415}],\n",
              "                           'train_recall_all': [{0: 0.9001451804900082,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3209195402298851,\n",
              "                             3: 0.006896551724137931},\n",
              "                            {0: 0.946517639448674,\n",
              "                             1: 0.0396551724137931,\n",
              "                             2: 0.7904625068418171,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9738639330018641,\n",
              "                             1: 0.3879310344827587,\n",
              "                             2: 0.9283251231527092,\n",
              "                             3: 0.006896551724137931},\n",
              "                            {0: 0.9910212201591511,\n",
              "                             1: 0.635632183908046,\n",
              "                             2: 0.9755117679255613,\n",
              "                             3: 0.18275862068965518}],\n",
              "                           'train_f1_all': [{0: 0.7371487539684656,\n",
              "                             1: 0.0,\n",
              "                             2: 0.31237521312892297,\n",
              "                             3: 0.0008620689655172414},\n",
              "                            {0: 0.8658834338053188,\n",
              "                             1: 0.046108374384236456,\n",
              "                             2: 0.7815424204278689,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9361671028830385,\n",
              "                             1: 0.3873399014778323,\n",
              "                             2: 0.9299101732164607,\n",
              "                             3: 0.006896551724137931},\n",
              "                            {0: 0.9750618281347754,\n",
              "                             1: 0.6374384236453202,\n",
              "                             2: 0.9837701896931104,\n",
              "                             3: 0.1839080459770115}],\n",
              "                           'val_acc_all': [0.8605769230769231,\n",
              "                            0.8653846153846154,\n",
              "                            0.8677884615384616,\n",
              "                            0.84375],\n",
              "                           'val_precision_all': [{0: 0.8765691039729501,\n",
              "                             1: 0.0,\n",
              "                             2: 0.34615384615384615,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8860524091293324,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.47435897435897434,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8994452662721893,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.37820512820512825,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9084796613642769,\n",
              "                             1: 0.09615384615384616,\n",
              "                             2: 0.46153846153846156,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.9740746433054126,\n",
              "                             1: 0.0,\n",
              "                             2: 0.22756410256410253,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9686488191295884,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.35064102564102567,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9673253029022261,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.25961538461538464,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9298094533671457,\n",
              "                             1: 0.15384615384615385,\n",
              "                             2: 0.33653846153846156,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.9207372636332164,\n",
              "                             1: 0.0,\n",
              "                             2: 0.26373626373626374,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9224987732004075,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.37179487179487175,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9289796283154382,\n",
              "                             1: 0.0705128205128205,\n",
              "                             2: 0.29230769230769227,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9153360776172447,\n",
              "                             1: 0.11538461538461536,\n",
              "                             2: 0.36282051282051275,\n",
              "                             3: 0.0}]}),\n",
              "              4: defaultdict(None,\n",
              "                          {'train_loss_values': [0.8042804157827049,\n",
              "                            0.8042804157827049,\n",
              "                            0.19045693601365202,\n",
              "                            0.19045693601365202,\n",
              "                            0.021089057145582048,\n",
              "                            0.021089057145582048,\n",
              "                            0.004306394483865006,\n",
              "                            0.004306394483865006],\n",
              "                           'train_acc_all': [0.666796875,\n",
              "                            0.94453125,\n",
              "                            0.99453125,\n",
              "                            0.999609375],\n",
              "                           'train_precision_all': [{0: 0.6798476436757688,\n",
              "                             1: 0.165625,\n",
              "                             2: 0.647050917832168,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9420302787490286,\n",
              "                             1: 0.6670833333333334,\n",
              "                             2: 0.9711681547619048,\n",
              "                             3: 0.14375},\n",
              "                            {0: 0.9949526515151514,\n",
              "                             1: 0.8104166666666668,\n",
              "                             2: 0.9967013888888889,\n",
              "                             3: 0.303125},\n",
              "                            {0: 1.0, 1: 0.775, 2: 0.99921875, 3: 0.30625}],\n",
              "                           'train_recall_all': [{0: 0.8506830322455323,\n",
              "                             1: 0.135625,\n",
              "                             2: 0.5900173611111111,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.971515238233988,\n",
              "                             1: 0.6713541666666666,\n",
              "                             2: 0.9618226911976911,\n",
              "                             3: 0.1375},\n",
              "                            {0: 0.9979139610389611,\n",
              "                             1: 0.8046875,\n",
              "                             2: 0.9957738095238096,\n",
              "                             3: 0.30625},\n",
              "                            {0: 0.9991071428571429,\n",
              "                             1: 0.775,\n",
              "                             2: 1.0,\n",
              "                             3: 0.30625}],\n",
              "                           'train_f1_all': [{0: 0.7303913352329838,\n",
              "                             1: 0.14220238095238097,\n",
              "                             2: 0.5733164412019864,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9535245043012613,\n",
              "                             1: 0.6585714285714285,\n",
              "                             2: 0.9626791325504559,\n",
              "                             3: 0.13958333333333334},\n",
              "                            {0: 0.99620010043351,\n",
              "                             1: 0.8061904761904763,\n",
              "                             2: 0.9957461003049237,\n",
              "                             3: 0.30416666666666664},\n",
              "                            {0: 0.9995192307692307,\n",
              "                             1: 0.775,\n",
              "                             2: 0.9995833333333334,\n",
              "                             3: 0.30625}],\n",
              "                           'val_acc_all': [0.8004807692307693,\n",
              "                            0.8629807692307693,\n",
              "                            0.8629807692307693,\n",
              "                            0.8245192307692307],\n",
              "                           'val_precision_all': [{0: 0.8853370987986373,\n",
              "                             1: 0.0,\n",
              "                             2: 0.2403846153846154,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8966944914060299,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.391025641025641,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8875140884756271,\n",
              "                             1: 0.0,\n",
              "                             2: 0.4294871794871794,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8600397999436461,\n",
              "                             1: 0.0,\n",
              "                             2: 0.358974358974359,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.8788584812623276,\n",
              "                             1: 0.0,\n",
              "                             2: 0.31135531135531136,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9655749699018928,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.32628205128205134,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9682649081687542,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3173076923076923,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9271872358410819,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3525641025641026,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.8780148045130858,\n",
              "                             1: 0.0,\n",
              "                             2: 0.24881784881784877,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9266023824028445,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.32710622710622705,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9234843403398206,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3476190476190476,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.890235825546855,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3311965811965812,\n",
              "                             3: 0.0}]}),\n",
              "              5: defaultdict(None,\n",
              "                          {'train_loss_values': [0.7618252955164229,\n",
              "                            0.7618252955164229,\n",
              "                            0.11060153808444738,\n",
              "                            0.11060153808444738,\n",
              "                            0.011829958499874919,\n",
              "                            0.011829958499874919,\n",
              "                            0.002956317888373243,\n",
              "                            0.002956317888373243],\n",
              "                           'train_acc_all': [0.6785714285714286,\n",
              "                            0.9632142857142857,\n",
              "                            0.9964285714285714,\n",
              "                            0.9996428571428572],\n",
              "                           'train_precision_all': [{0: 0.6925100930815216,\n",
              "                             1: 0.17714285714285716,\n",
              "                             2: 0.6413384234812803,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9635978148835291,\n",
              "                             1: 0.762952380952381,\n",
              "                             2: 0.9733623995052566,\n",
              "                             3: 0.24},\n",
              "                            {0: 0.9969413919413921,\n",
              "                             1: 0.8066666666666668,\n",
              "                             2: 0.9922951334379905,\n",
              "                             3: 0.32571428571428573},\n",
              "                            {0: 1.0,\n",
              "                             1: 0.8114285714285714,\n",
              "                             2: 0.9991836734693877,\n",
              "                             3: 0.33714285714285713}],\n",
              "                           'train_recall_all': [{0: 0.838886098028955,\n",
              "                             1: 0.12142857142857143,\n",
              "                             2: 0.6476163677592244,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9752440733869306,\n",
              "                             1: 0.759047619047619,\n",
              "                             2: 0.9727233560090703,\n",
              "                             3: 0.24285714285714285},\n",
              "                            {0: 0.9939455782312925,\n",
              "                             1: 0.8095238095238094,\n",
              "                             2: 0.9890816326530613,\n",
              "                             3: 0.32571428571428573},\n",
              "                            {0: 0.9994285714285714,\n",
              "                             1: 0.8114285714285714,\n",
              "                             2: 1.0,\n",
              "                             3: 0.33714285714285713}],\n",
              "                           'train_f1_all': [{0: 0.7307545295704205,\n",
              "                             1: 0.13844897959183672,\n",
              "                             2: 0.6077801019070364,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9666582077316268,\n",
              "                             1: 0.7551383219954648,\n",
              "                             2: 0.9699348048960185,\n",
              "                             3: 0.24},\n",
              "                            {0: 0.9948099138956282,\n",
              "                             1: 0.8072380952380952,\n",
              "                             2: 0.9903512725648063,\n",
              "                             3: 0.32571428571428573},\n",
              "                            {0: 0.9996992481203008,\n",
              "                             1: 0.8114285714285714,\n",
              "                             2: 0.9995604395604395,\n",
              "                             3: 0.33714285714285713}],\n",
              "                           'val_acc_all': [0.8269230769230769,\n",
              "                            0.8293269230769231,\n",
              "                            0.8581730769230769,\n",
              "                            0.8629807692307693],\n",
              "                           'val_precision_all': [{0: 0.9028538768923385,\n",
              "                             1: 0.09615384615384616,\n",
              "                             2: 0.34615384615384615,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8524496336996338,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.4871794871794872,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.892867869310177,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.3942307692307692,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8898774302620457,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.36538461538461536,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.9121858910320448,\n",
              "                             1: 0.09615384615384616,\n",
              "                             2: 0.3974358974358974,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9378381234150465,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.31025641025641026,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9544889405466328,\n",
              "                             1: 0.057692307692307696,\n",
              "                             2: 0.30128205128205127,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9653476331360948,\n",
              "                             1: 0.057692307692307696,\n",
              "                             2: 0.28205128205128205,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.9044046890787603,\n",
              "                             1: 0.09615384615384616,\n",
              "                             2: 0.35677655677655673,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.890134094218975,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.3448717948717948,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9203640114744799,\n",
              "                             1: 0.0641025641025641,\n",
              "                             2: 0.3311355311355312,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9247784517122244,\n",
              "                             1: 0.0641025641025641,\n",
              "                             2: 0.30641025641025643,\n",
              "                             3: 0.0}]}),\n",
              "              6: defaultdict(None,\n",
              "                          {'train_loss_values': [0.8343528047988289,\n",
              "                            0.8343528047988289,\n",
              "                            0.1285538630535532,\n",
              "                            0.1285538630535532,\n",
              "                            0.012691995951861731,\n",
              "                            0.012691995951861731,\n",
              "                            0.003489097827236707,\n",
              "                            0.003489097827236707],\n",
              "                           'train_acc_all': [0.6453947368421052,\n",
              "                            0.9601973684210526,\n",
              "                            0.9973684210526316,\n",
              "                            0.999671052631579],\n",
              "                           'train_precision_all': [{0: 0.6134181242733876,\n",
              "                             1: 0.13187134502923975,\n",
              "                             2: 0.6660525439472803,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9603795473532315,\n",
              "                             1: 0.7629824561403509,\n",
              "                             2: 0.9674705703653074,\n",
              "                             3: 0.25263157894736843},\n",
              "                            {0: 0.9978070175438596,\n",
              "                             1: 0.8526315789473684,\n",
              "                             2: 0.9968796992481203,\n",
              "                             3: 0.3631578947368421},\n",
              "                            {0: 1.0,\n",
              "                             1: 0.8631578947368421,\n",
              "                             2: 0.9940789473684211,\n",
              "                             3: 0.3684210526315789}],\n",
              "                           'train_recall_all': [{0: 0.755223475355054,\n",
              "                             1: 0.12807017543859647,\n",
              "                             2: 0.6937221842484996,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.970327523353839,\n",
              "                             1: 0.7561403508771929,\n",
              "                             2: 0.9816622996886155,\n",
              "                             3: 0.2456140350877193},\n",
              "                            {0: 0.9959064327485381,\n",
              "                             1: 0.856140350877193,\n",
              "                             2: 1.0,\n",
              "                             3: 0.3605263157894737},\n",
              "                            {0: 0.9991228070175439,\n",
              "                             1: 0.8631578947368421,\n",
              "                             2: 0.9947368421052631,\n",
              "                             3: 0.3684210526315789}],\n",
              "                           'train_f1_all': [{0: 0.6527930175816268,\n",
              "                             1: 0.1216883116883117,\n",
              "                             2: 0.656294809665133,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9624064560977156,\n",
              "                             1: 0.749262550315182,\n",
              "                             2: 0.9720571663956051,\n",
              "                             3: 0.2480701754385965},\n",
              "                            {0: 0.9965780762065591,\n",
              "                             1: 0.8533333333333333,\n",
              "                             2: 0.9982584666795192,\n",
              "                             3: 0.3614035087719298},\n",
              "                            {0: 0.9995215311004785,\n",
              "                             1: 0.8631578947368421,\n",
              "                             2: 0.9943859649122807,\n",
              "                             3: 0.3684210526315789}],\n",
              "                           'val_acc_all': [0.8317307692307693,\n",
              "                            0.8677884615384616,\n",
              "                            0.8677884615384616,\n",
              "                            0.8725961538461539],\n",
              "                           'val_precision_all': [{0: 0.9045039896001434,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.34551282051282056,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8800084530853762,\n",
              "                             1: 0.0,\n",
              "                             2: 0.46153846153846156,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8788197379543534,\n",
              "                             1: 0.019230769230769232,\n",
              "                             2: 0.3557692307692308,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8859432234432235,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.4807692307692308,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.9128363623555932,\n",
              "                             1: 0.01282051282051282,\n",
              "                             2: 0.4391025641025641,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9793394105894104,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3237179487179488,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9789682539682539,\n",
              "                             1: 0.019230769230769232,\n",
              "                             2: 0.26282051282051283,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9776566382335614,\n",
              "                             1: 0.019230769230769232,\n",
              "                             2: 0.33782051282051284,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.9048853510918943,\n",
              "                             1: 0.019230769230769232,\n",
              "                             2: 0.3637973137973138,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9253053465965249,\n",
              "                             1: 0.0,\n",
              "                             2: 0.36410256410256403,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9239450894345222,\n",
              "                             1: 0.019230769230769232,\n",
              "                             2: 0.2814102564102564,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9267945167534457,\n",
              "                             1: 0.02564102564102564,\n",
              "                             2: 0.3692307692307693,\n",
              "                             3: 0.0}]}),\n",
              "              7: defaultdict(None,\n",
              "                          {'train_loss_values': [0.8927743290982595,\n",
              "                            0.8927743290982595,\n",
              "                            0.2138525109533675,\n",
              "                            0.2138525109533675,\n",
              "                            0.0318571242361852,\n",
              "                            0.0318571242361852,\n",
              "                            0.0033057010088047784,\n",
              "                            0.0033057010088047784],\n",
              "                           'train_acc_all': [0.6170731707317073,\n",
              "                            0.9320121951219512,\n",
              "                            0.9942073170731708,\n",
              "                            0.9996951219512196],\n",
              "                           'train_precision_all': [{0: 0.6099306655404214,\n",
              "                             1: 0.1410569105691057,\n",
              "                             2: 0.6298573039426695,\n",
              "                             3: 0.06829268292682927},\n",
              "                            {0: 0.9232203568788936,\n",
              "                             1: 0.7162601626016261,\n",
              "                             2: 0.9516349910252351,\n",
              "                             3: 0.2975609756097561},\n",
              "                            {0: 0.9910569105691058,\n",
              "                             1: 0.8560975609756097,\n",
              "                             2: 0.9937722169429486,\n",
              "                             3: 0.37317073170731707},\n",
              "                            {0: 1.0,\n",
              "                             1: 0.8634146341463415,\n",
              "                             2: 0.9994579945799458,\n",
              "                             3: 0.36585365853658536}],\n",
              "                           'train_recall_all': [{0: 0.6478837152007882,\n",
              "                             1: 0.09398373983739838,\n",
              "                             2: 0.7492515749832824,\n",
              "                             3: 0.06341463414634146},\n",
              "                            {0: 0.9455474606694119,\n",
              "                             1: 0.6884552845528454,\n",
              "                             2: 0.9644326540668003,\n",
              "                             3: 0.28536585365853656},\n",
              "                            {0: 0.9852245451025938,\n",
              "                             1: 0.8585365853658536,\n",
              "                             2: 0.9968834688346884,\n",
              "                             3: 0.375609756097561},\n",
              "                            {0: 0.9991869918699187,\n",
              "                             1: 0.8634146341463415,\n",
              "                             2: 1.0,\n",
              "                             3: 0.36585365853658536}],\n",
              "                           'train_f1_all': [{0: 0.5940021514504339,\n",
              "                             1: 0.1045993031358885,\n",
              "                             2: 0.6576931731979156,\n",
              "                             3: 0.06504065040650407},\n",
              "                            {0: 0.9280016942457479,\n",
              "                             1: 0.6827001724562699,\n",
              "                             2: 0.9539075817803875,\n",
              "                             3: 0.2894308943089431},\n",
              "                            {0: 0.987344742481796,\n",
              "                             1: 0.8569105691056912,\n",
              "                             2: 0.9948678604991376,\n",
              "                             3: 0.37398373983739835},\n",
              "                            {0: 0.9995565410199556,\n",
              "                             1: 0.8634146341463415,\n",
              "                             2: 0.999713055954089,\n",
              "                             3: 0.36585365853658536}],\n",
              "                           'val_acc_all': [0.8389423076923077,\n",
              "                            0.8701923076923077,\n",
              "                            0.8389423076923077,\n",
              "                            0.8774038461538461],\n",
              "                           'val_precision_all': [{0: 0.897954609493071,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3596153846153846,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8764652014652015,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.25,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8483181882220344,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.46153846153846156,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8915011270780503,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.40384615384615385,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.9238071223648148,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3910256410256411,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9911242603550297,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.1455128205128205,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9477458438996901,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.2641025641025641,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.983225908706678,\n",
              "                             1: 0.05128205128205128,\n",
              "                             2: 0.25961538461538464,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.9084792672482448,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3495421245421245,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9275404728564316,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.17399267399267399,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.893783356089765,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.32051282051282054,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9332908514845711,\n",
              "                             1: 0.057692307692307696,\n",
              "                             2: 0.3009157509157509,\n",
              "                             3: 0.0}]}),\n",
              "              8: defaultdict(None,\n",
              "                          {'train_loss_values': [0.7412119466811419,\n",
              "                            0.7412119466811419,\n",
              "                            0.08006206192975779,\n",
              "                            0.08006206192975779,\n",
              "                            0.006991453834714114,\n",
              "                            0.006991453834714114,\n",
              "                            0.0035168622128284453,\n",
              "                            0.0035168622128284453],\n",
              "                           'train_acc_all': [0.7164772727272727,\n",
              "                            0.9795454545454545,\n",
              "                            0.9982954545454545,\n",
              "                            0.9988636363636364],\n",
              "                           'train_precision_all': [{0: 0.6842170455806819,\n",
              "                             1: 0.2981601731601731,\n",
              "                             2: 0.7745740433808618,\n",
              "                             3: 0.05},\n",
              "                            {0: 0.976089466089466,\n",
              "                             1: 0.8203030303030303,\n",
              "                             2: 0.9830299750754297,\n",
              "                             3: 0.35909090909090907},\n",
              "                            {0: 1.0,\n",
              "                             1: 0.85,\n",
              "                             2: 0.9957070707070708,\n",
              "                             3: 0.39545454545454545},\n",
              "                            {0: 1.0,\n",
              "                             1: 0.8772727272727273,\n",
              "                             2: 0.9977272727272727,\n",
              "                             3: 0.38636363636363635}],\n",
              "                           'train_recall_all': [{0: 0.7663216581398399,\n",
              "                             1: 0.22553030303030303,\n",
              "                             2: 0.8274465559692832,\n",
              "                             3: 0.04090909090909091},\n",
              "                            {0: 0.9784991145218418,\n",
              "                             1: 0.8142424242424242,\n",
              "                             2: 0.9887210895165441,\n",
              "                             3: 0.35151515151515156},\n",
              "                            {0: 0.9968540928768203,\n",
              "                             1: 0.85,\n",
              "                             2: 1.0,\n",
              "                             3: 0.39545454545454545},\n",
              "                            {0: 0.9972294372294372,\n",
              "                             1: 0.8772727272727273,\n",
              "                             2: 1.0,\n",
              "                             3: 0.38636363636363635}],\n",
              "                           'train_f1_all': [{0: 0.6905626081293982,\n",
              "                             1: 0.2402390791027154,\n",
              "                             2: 0.7728777813874762,\n",
              "                             3: 0.04393939393939394},\n",
              "                            {0: 0.9742717286388128,\n",
              "                             1: 0.8123192968647512,\n",
              "                             2: 0.9844265266964761,\n",
              "                             3: 0.35424242424242425},\n",
              "                            {0: 0.998295307633543,\n",
              "                             1: 0.85,\n",
              "                             2: 0.997501215362178,\n",
              "                             3: 0.39545454545454545},\n",
              "                            {0: 0.9984928415550425,\n",
              "                             1: 0.8772727272727273,\n",
              "                             2: 0.9987846378220709,\n",
              "                             3: 0.38636363636363635}],\n",
              "                           'val_acc_all': [0.8293269230769231,\n",
              "                            0.8557692307692307,\n",
              "                            0.8629807692307693,\n",
              "                            0.8653846153846154],\n",
              "                           'val_precision_all': [{0: 0.9022014844130228,\n",
              "                             1: 0.15384615384615385,\n",
              "                             2: 0.3974358974358974,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9096189067342915,\n",
              "                             1: 0.15384615384615385,\n",
              "                             2: 0.4326923076923077,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8977573708342939,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.4371794871794872,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8923094533671458,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.342948717948718,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.9109080022541561,\n",
              "                             1: 0.11538461538461539,\n",
              "                             2: 0.41666666666666663,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9382502113271344,\n",
              "                             1: 0.09615384615384616,\n",
              "                             2: 0.44487179487179485,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9535451727759419,\n",
              "                             1: 0.057692307692307696,\n",
              "                             2: 0.41346153846153844,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9667371090448014,\n",
              "                             1: 0.057692307692307696,\n",
              "                             2: 0.33589743589743587,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.9040579329946185,\n",
              "                             1: 0.1282051282051282,\n",
              "                             2: 0.37307692307692303,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9210663227831878,\n",
              "                             1: 0.11538461538461536,\n",
              "                             2: 0.38351648351648354,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9226577485880836,\n",
              "                             1: 0.0641025641025641,\n",
              "                             2: 0.40714285714285714,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9238142739469001,\n",
              "                             1: 0.0641025641025641,\n",
              "                             2: 0.313003663003663,\n",
              "                             3: 0.0}]}),\n",
              "              9: defaultdict(None,\n",
              "                          {'train_loss_values': [0.696914042373921,\n",
              "                            0.696914042373921,\n",
              "                            0.07507714509042575,\n",
              "                            0.07507714509042575,\n",
              "                            0.009679940697598331,\n",
              "                            0.009679940697598331,\n",
              "                            0.0031863253423696425,\n",
              "                            0.0031863253423696425],\n",
              "                           'train_acc_all': [0.7172872340425532,\n",
              "                            0.9797872340425532,\n",
              "                            0.9984042553191489,\n",
              "                            0.9992021276595745],\n",
              "                           'train_precision_all': [{0: 0.6556888265398902,\n",
              "                             1: 0.4000709219858157,\n",
              "                             2: 0.753262476294391,\n",
              "                             3: 0.08723404255319149},\n",
              "                            {0: 0.9806450523471801,\n",
              "                             1: 0.8356737588652482,\n",
              "                             2: 0.9850980461618762,\n",
              "                             3: 0.38085106382978723},\n",
              "                            {0: 1.0,\n",
              "                             1: 0.88,\n",
              "                             2: 0.9975059101654846,\n",
              "                             3: 0.4085106382978723},\n",
              "                            {0: 1.0,\n",
              "                             1: 0.8723404255319149,\n",
              "                             2: 0.9985493230174081,\n",
              "                             3: 0.40425531914893614}],\n",
              "                           'train_recall_all': [{0: 0.664420650271714,\n",
              "                             1: 0.36114488348530904,\n",
              "                             2: 0.8669839262392455,\n",
              "                             3: 0.08723404255319149},\n",
              "                            {0: 0.9681844278652788,\n",
              "                             1: 0.8567375886524822,\n",
              "                             2: 0.9873875533450004,\n",
              "                             3: 0.37872340425531914},\n",
              "                            {0: 0.995518252433146,\n",
              "                             1: 0.8808510638297873,\n",
              "                             2: 1.0,\n",
              "                             3: 0.4085106382978723},\n",
              "                            {0: 0.9976950354609929,\n",
              "                             1: 0.8723404255319149,\n",
              "                             2: 1.0,\n",
              "                             3: 0.40425531914893614}],\n",
              "                           'train_f1_all': [{0: 0.631345858743564,\n",
              "                             1: 0.3605047434834669,\n",
              "                             2: 0.7842071252581263,\n",
              "                             3: 0.08419452887537994},\n",
              "                            {0: 0.9721346905076566,\n",
              "                             1: 0.841533265788585,\n",
              "                             2: 0.9852669204984942,\n",
              "                             3: 0.37872340425531914},\n",
              "                            {0: 0.997477066112861,\n",
              "                             1: 0.8803782505910165,\n",
              "                             2: 0.998634132264328,\n",
              "                             3: 0.4085106382978723},\n",
              "                            {0: 0.9987215621258174,\n",
              "                             1: 0.8723404255319149,\n",
              "                             2: 0.9992299898682878,\n",
              "                             3: 0.40425531914893614}],\n",
              "                           'val_acc_all': [0.8485576923076923,\n",
              "                            0.8629807692307693,\n",
              "                            0.8365384615384616,\n",
              "                            0.8701923076923077],\n",
              "                           'val_precision_all': [{0: 0.901822696534235,\n",
              "                             1: 0.019230769230769232,\n",
              "                             2: 0.4217948717948718,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8807357706396169,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.30128205128205127,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8488676387714851,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.37179487179487175,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8850274725274727,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.40384615384615385,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.9358897512743665,\n",
              "                             1: 0.01282051282051282,\n",
              "                             2: 0.38269230769230766,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9773527754296985,\n",
              "                             1: 0.019230769230769232,\n",
              "                             2: 0.2115384615384615,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9451817413355875,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.2948717948717948,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9780343054381516,\n",
              "                             1: 0.019230769230769232,\n",
              "                             2: 0.2596153846153846,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.9164706219029676,\n",
              "                             1: 0.015384615384615385,\n",
              "                             2: 0.3868131868131868,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9243274660430475,\n",
              "                             1: 0.02564102564102564,\n",
              "                             2: 0.22692307692307695,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8918840730366357,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.29871794871794877,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9271692789113855,\n",
              "                             1: 0.02564102564102564,\n",
              "                             2: 0.2961538461538462,\n",
              "                             3: 0.0}]}),\n",
              "              10: defaultdict(None,\n",
              "                          {'train_loss_values': [0.6286283227987588,\n",
              "                            0.6286283227987588,\n",
              "                            0.041895744491368535,\n",
              "                            0.041895744491368535,\n",
              "                            0.006659671639557928,\n",
              "                            0.006659671639557928,\n",
              "                            0.0015203668005997315,\n",
              "                            0.0015203668005997315],\n",
              "                           'train_acc_all': [0.747, 0.99, 0.99825, 0.9995],\n",
              "                           'train_precision_all': [{0: 0.6768784992784987,\n",
              "                             1: 0.3505904761904762,\n",
              "                             2: 0.7798111555111554,\n",
              "                             3: 0.15},\n",
              "                            {0: 0.9950190476190477,\n",
              "                             1: 0.8582,\n",
              "                             2: 0.9909473304473305,\n",
              "                             3: 0.426},\n",
              "                            {0: 0.9985333333333333,\n",
              "                             1: 0.868,\n",
              "                             2: 0.997669696969697,\n",
              "                             3: 0.432},\n",
              "                            {0: 1.0,\n",
              "                             1: 0.916,\n",
              "                             2: 0.9989333333333333,\n",
              "                             3: 0.416}],\n",
              "                           'train_recall_all': [{0: 0.681442857142857,\n",
              "                             1: 0.3187333333333333,\n",
              "                             2: 0.9156202020202019,\n",
              "                             3: 0.14733333333333334},\n",
              "                            {0: 0.9820698412698413,\n",
              "                             1: 0.8703333333333333,\n",
              "                             2: 0.9961854256854257,\n",
              "                             3: 0.426},\n",
              "                            {0: 0.9964571428571428,\n",
              "                             1: 0.868,\n",
              "                             2: 0.9988333333333334,\n",
              "                             3: 0.432},\n",
              "                            {0: 0.9987619047619049,\n",
              "                             1: 0.916,\n",
              "                             2: 1.0,\n",
              "                             3: 0.416}],\n",
              "                           'train_f1_all': [{0: 0.6552017956931265,\n",
              "                             1: 0.3233396825396825,\n",
              "                             2: 0.8260472792553409,\n",
              "                             3: 0.1466666666666667},\n",
              "                            {0: 0.9871407638113523,\n",
              "                             1: 0.8613460317460317,\n",
              "                             2: 0.9930223838828497,\n",
              "                             3: 0.42533333333333334},\n",
              "                            {0: 0.9972023718971087,\n",
              "                             1: 0.868,\n",
              "                             2: 0.9981044733044734,\n",
              "                             3: 0.432},\n",
              "                            {0: 0.9993286713286713,\n",
              "                             1: 0.916,\n",
              "                             2: 0.9994258373205741,\n",
              "                             3: 0.416}],\n",
              "                           'val_acc_all': [0.8125,\n",
              "                            0.8485576923076923,\n",
              "                            0.8221153846153846,\n",
              "                            0.8605769230769231],\n",
              "                           'val_precision_all': [{0: 0.90274917390302,\n",
              "                             1: 0.0705128205128205,\n",
              "                             2: 0.3942307692307692,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8867286559594252,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.3910256410256411,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8457188644688644,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.37179487179487186,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8821868836291914,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.38461538461538464,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.8942751159097313,\n",
              "                             1: 0.1346153846153846,\n",
              "                             2: 0.36538461538461536,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9543075514229362,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.3205128205128205,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9298677284254209,\n",
              "                             1: 0.019230769230769232,\n",
              "                             2: 0.2865384615384615,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9680995286764518,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.2717948717948718,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.8946322283384832,\n",
              "                             1: 0.09102564102564102,\n",
              "                             2: 0.35705128205128206,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9174781748774218,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.3243589743589744,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8836331672827816,\n",
              "                             1: 0.02564102564102564,\n",
              "                             2: 0.2935897435897436,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9205279594862037,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.30128205128205127,\n",
              "                             3: 0.0}]}),\n",
              "              11: defaultdict(None,\n",
              "                          {'train_loss_values': [0.5965202573124531,\n",
              "                            0.5965202573124531,\n",
              "                            0.05126349642424721,\n",
              "                            0.05126349642424721,\n",
              "                            0.008799287039492244,\n",
              "                            0.008799287039492244,\n",
              "                            0.002263326487363369,\n",
              "                            0.002263326487363369],\n",
              "                           'train_acc_all': [0.7681603773584905,\n",
              "                            0.9860849056603773,\n",
              "                            0.9976415094339622,\n",
              "                            0.9995283018867924],\n",
              "                           'train_precision_all': [{0: 0.6932309619102072,\n",
              "                             1: 0.38811320754716977,\n",
              "                             2: 0.8395931322346415,\n",
              "                             3: 0.11320754716981132},\n",
              "                            {0: 0.9840251572327043,\n",
              "                             1: 0.870754716981132,\n",
              "                             2: 0.9917367747556429,\n",
              "                             3: 0.39433962264150946},\n",
              "                            {0: 0.9978885893980232,\n",
              "                             1: 0.9018867924528302,\n",
              "                             2: 0.9976265348906859,\n",
              "                             3: 0.4490566037735849},\n",
              "                            {0: 1.0,\n",
              "                             1: 0.9056603773584906,\n",
              "                             2: 0.9991090146750525,\n",
              "                             3: 0.45660377358490567}],\n",
              "                           'train_recall_all': [{0: 0.7482045522611562,\n",
              "                             1: 0.3549685534591195,\n",
              "                             2: 0.9064441428592372,\n",
              "                             3: 0.11069182389937106},\n",
              "                            {0: 0.9830008984725964,\n",
              "                             1: 0.8659119496855346,\n",
              "                             2: 0.992933376895641,\n",
              "                             3: 0.39245283018867927},\n",
              "                            {0: 0.9948950420648535,\n",
              "                             1: 0.9018867924528302,\n",
              "                             2: 0.9991090146750525,\n",
              "                             3: 0.4477987421383648},\n",
              "                            {0: 0.9986163522012579,\n",
              "                             1: 0.9056603773584906,\n",
              "                             2: 1.0,\n",
              "                             3: 0.45660377358490567}],\n",
              "                           'train_f1_all': [{0: 0.6867607768843238,\n",
              "                             1: 0.3584497263742546,\n",
              "                             2: 0.8584099670682137,\n",
              "                             3: 0.11006289308176102},\n",
              "                            {0: 0.9809660151169582,\n",
              "                             1: 0.8663102725366877,\n",
              "                             2: 0.9917133999892923,\n",
              "                             3: 0.39245283018867927},\n",
              "                            {0: 0.9958330977198903,\n",
              "                             1: 0.9018867924528302,\n",
              "                             2: 0.9982555063363827,\n",
              "                             3: 0.4483018867924528},\n",
              "                            {0: 0.9992376596150181,\n",
              "                             1: 0.9056603773584906,\n",
              "                             2: 0.99952645209027,\n",
              "                             3: 0.45660377358490567}],\n",
              "                           'val_acc_all': [0.8605769230769231,\n",
              "                            0.8341346153846154,\n",
              "                            0.8317307692307693,\n",
              "                            0.875],\n",
              "                           'val_precision_all': [{0: 0.880443434770358,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.28846153846153844,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8544484361792056,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.4358974358974359,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.861247886728656,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.4519230769230769,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8897893772893772,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.40384615384615385,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.9770216962524655,\n",
              "                             1: 0.02564102564102564,\n",
              "                             2: 0.20512820512820515,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9353031583800816,\n",
              "                             1: 0.019230769230769232,\n",
              "                             2: 0.33333333333333337,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9244691206229667,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.44487179487179485,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9798887010425472,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.3237179487179487,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.9238416262408735,\n",
              "                             1: 0.03076923076923077,\n",
              "                             2: 0.23205128205128206,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8915762338368652,\n",
              "                             1: 0.02564102564102564,\n",
              "                             2: 0.35018315018315016,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8894267103080313,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.4106227106227106,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9303222710504305,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.34102564102564104,\n",
              "                             3: 0.0}]}),\n",
              "              12: defaultdict(None,\n",
              "                          {'train_loss_values': [0.49705120720734286,\n",
              "                            0.49705120720734286,\n",
              "                            0.0230391575397724,\n",
              "                            0.0230391575397724,\n",
              "                            0.005648303979874722,\n",
              "                            0.005648303979874722,\n",
              "                            0.0013890152384452188,\n",
              "                            0.0013890152384452188],\n",
              "                           'train_acc_all': [0.8049107142857143,\n",
              "                            0.9935267857142858,\n",
              "                            0.9991071428571429,\n",
              "                            0.9997767857142857],\n",
              "                           'train_precision_all': [{0: 0.7269520459699029,\n",
              "                             1: 0.5359523809523811,\n",
              "                             2: 0.8479761260564831,\n",
              "                             3: 0.15982142857142856},\n",
              "                            {0: 0.9949702380952382,\n",
              "                             1: 0.885297619047619,\n",
              "                             2: 0.9946500325071753,\n",
              "                             3: 0.4226190476190476},\n",
              "                            {0: 0.9923469387755103,\n",
              "                             1: 0.9214285714285714,\n",
              "                             2: 0.9986862244897959,\n",
              "                             3: 0.42142857142857143},\n",
              "                            {0: 1.0,\n",
              "                             1: 0.9,\n",
              "                             2: 0.9996031746031747,\n",
              "                             3: 0.46785714285714286}],\n",
              "                           'train_recall_all': [{0: 0.7444671201814057,\n",
              "                             1: 0.5391666666666667,\n",
              "                             2: 0.9247044423830139,\n",
              "                             3: 0.15178571428571427},\n",
              "                            {0: 0.9846541950113379,\n",
              "                             1: 0.8875,\n",
              "                             2: 0.9967727015048443,\n",
              "                             3: 0.425},\n",
              "                            {0: 0.9912500000000001,\n",
              "                             1: 0.9214285714285714,\n",
              "                             2: 1.0,\n",
              "                             3: 0.42142857142857143},\n",
              "                            {0: 0.9991071428571429,\n",
              "                             1: 0.9,\n",
              "                             2: 1.0,\n",
              "                             3: 0.46785714285714286}],\n",
              "                           'train_f1_all': [{0: 0.7092332134669597,\n",
              "                             1: 0.5210881776953205,\n",
              "                             2: 0.8701277167880386,\n",
              "                             3: 0.15425170068027214},\n",
              "                            {0: 0.9884249119228112,\n",
              "                             1: 0.8857596371882087,\n",
              "                             2: 0.9954348773247491,\n",
              "                             3: 0.42357142857142854},\n",
              "                            {0: 0.9917094017094018,\n",
              "                             1: 0.9214285714285714,\n",
              "                             2: 0.9992992095623675,\n",
              "                             3: 0.42142857142857143},\n",
              "                            {0: 0.9994897959183675,\n",
              "                             1: 0.9,\n",
              "                             2: 0.9997899159663866,\n",
              "                             3: 0.46785714285714286}],\n",
              "                           'val_acc_all': [0.8509615384615384,\n",
              "                            0.8509615384615384,\n",
              "                            0.8197115384615384,\n",
              "                            0.8629807692307693],\n",
              "                           'val_precision_all': [{0: 0.865847934117165,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.407051282051282,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8916120738236124, 1: 0.0, 2: 0.375, 3: 0.0},\n",
              "                            {0: 0.8533777120315583,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3269230769230769,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8907808537616231,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3141025641025641,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.8999324393555164,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.3942307692307692,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9474644479452172,\n",
              "                             1: 0.0,\n",
              "                             2: 0.40384615384615385,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9220881682420143,\n",
              "                             1: 0.0,\n",
              "                             2: 0.4153846153846154,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9644944798790954,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3243589743589744,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.8808211525029358,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.3861721611721612,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9159397295326106,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3615384615384615,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8836349425208841,\n",
              "                             1: 0.0,\n",
              "                             2: 0.34316239316239316,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9237086907120129,\n",
              "                             1: 0.0,\n",
              "                             2: 0.30219780219780223,\n",
              "                             3: 0.0}]}),\n",
              "              13: defaultdict(None,\n",
              "                          {'train_loss_values': [0.6574318859473629,\n",
              "                            0.6574318859473629,\n",
              "                            0.06662685794763709,\n",
              "                            0.06662685794763709,\n",
              "                            0.016107130948438356,\n",
              "                            0.016107130948438356,\n",
              "                            0.004007331020952502,\n",
              "                            0.004007331020952502],\n",
              "                           'train_acc_all': [0.7389830508474576,\n",
              "                            0.9830508474576272,\n",
              "                            0.997457627118644,\n",
              "                            0.999364406779661],\n",
              "                           'train_precision_all': [{0: 0.6133182918776141,\n",
              "                             1: 0.4058192090395481,\n",
              "                             2: 0.8093317558148068,\n",
              "                             3: 0.08983050847457627},\n",
              "                            {0: 0.9796139359698681,\n",
              "                             1: 0.8897175141242937,\n",
              "                             2: 0.9871693936948175,\n",
              "                             3: 0.4101694915254237},\n",
              "                            {0: 0.9863276836158191,\n",
              "                             1: 0.9322033898305084,\n",
              "                             2: 0.9979905217193352,\n",
              "                             3: 0.4440677966101695},\n",
              "                            {0: 0.9932203389830508,\n",
              "                             1: 0.8949152542372881,\n",
              "                             2: 0.9989830508474576,\n",
              "                             3: 0.4406779661016949}],\n",
              "                           'train_recall_all': [{0: 0.6037812752219536,\n",
              "                             1: 0.4359887005649718,\n",
              "                             2: 0.9139195644280387,\n",
              "                             3: 0.08559322033898305},\n",
              "                            {0: 0.9661191821361316,\n",
              "                             1: 0.9014689265536723,\n",
              "                             2: 0.9936249532012245,\n",
              "                             3: 0.4135593220338983},\n",
              "                            {0: 0.9841767554479419,\n",
              "                             1: 0.9315254237288136,\n",
              "                             2: 0.9982351358622543,\n",
              "                             3: 0.4440677966101695},\n",
              "                            {0: 0.9909281678773204,\n",
              "                             1: 0.8949152542372881,\n",
              "                             2: 1.0,\n",
              "                             3: 0.4406779661016949}],\n",
              "                           'train_f1_all': [{0: 0.5741369873589008,\n",
              "                             1: 0.39765769070853807,\n",
              "                             2: 0.84356459419556,\n",
              "                             3: 0.08652138821630348},\n",
              "                            {0: 0.9692588457294341,\n",
              "                             1: 0.8937207425343019,\n",
              "                             2: 0.9895985693631477,\n",
              "                             3: 0.41129943502824856},\n",
              "                            {0: 0.9845128882417018,\n",
              "                             1: 0.9318267419962336,\n",
              "                             2: 0.9979933578412103,\n",
              "                             3: 0.4440677966101695},\n",
              "                            {0: 0.9919049688541215,\n",
              "                             1: 0.8949152542372881,\n",
              "                             2: 0.9994449400337002,\n",
              "                             3: 0.4406779661016949}],\n",
              "                           'val_acc_all': [0.7884615384615384,\n",
              "                            0.8605769230769231,\n",
              "                            0.8533653846153846,\n",
              "                            0.8605769230769231],\n",
              "                           'val_precision_all': [{0: 0.9171450344527268,\n",
              "                             1: 0.0,\n",
              "                             2: 0.31474358974358974,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8712471823048747,\n",
              "                             1: 0.0,\n",
              "                             2: 0.28846153846153844,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8693487602141448,\n",
              "                             1: 0.0,\n",
              "                             2: 0.27564102564102566,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8722527472527472,\n",
              "                             1: 0.0,\n",
              "                             2: 0.36538461538461536,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.8537414508568356,\n",
              "                             1: 0.0,\n",
              "                             2: 0.4326923076923077,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9831906875176106,\n",
              "                             1: 0.0,\n",
              "                             2: 0.16025641025641024,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9698224852071006,\n",
              "                             1: 0.0,\n",
              "                             2: 0.22371794871794876,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9806618061425753,\n",
              "                             1: 0.0,\n",
              "                             2: 0.23076923076923078,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.8796179220899554,\n",
              "                             1: 0.0,\n",
              "                             2: 0.34963369963369967,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9222755310825668,\n",
              "                             1: 0.0,\n",
              "                             2: 0.19871794871794873,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9140785466406278,\n",
              "                             1: 0.0,\n",
              "                             2: 0.2309523809523809,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9204456969623391,\n",
              "                             1: 0.0,\n",
              "                             2: 0.2743589743589744,\n",
              "                             3: 0.0}]})},\n",
              "             '16_3e-05': {0: defaultdict(None,\n",
              "                          {'train_loss_values': [0.5806161037087441,\n",
              "                            0.5806161037087441,\n",
              "                            0.48055647730827333,\n",
              "                            0.48055647730827333,\n",
              "                            0.3751270946487784,\n",
              "                            0.3751270946487784,\n",
              "                            0.2781859637610614,\n",
              "                            0.2781859637610614],\n",
              "                           'train_acc_all': [0.841875,\n",
              "                            0.858125,\n",
              "                            0.893125,\n",
              "                            0.92],\n",
              "                           'train_precision_all': [{0: 0.8504583333333333,\n",
              "                             1: 0.0,\n",
              "                             2: 0.0,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.862851648351648, 1: 0.0, 2: 0.1775, 3: 0.0},\n",
              "                            {0: 0.9181126373626368,\n",
              "                             1: 0.0,\n",
              "                             2: 0.5458333333333333,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9345910617160617,\n",
              "                             1: 0.0,\n",
              "                             2: 0.6399047619047619,\n",
              "                             3: 0.0}],\n",
              "                           'train_recall_all': [{0: 0.9901666666666666,\n",
              "                             1: 0.0,\n",
              "                             2: 0.0,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9920572760572759,\n",
              "                             1: 0.0,\n",
              "                             2: 0.10950000000000001,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9741618797868797,\n",
              "                             1: 0.0,\n",
              "                             2: 0.4641666666666666,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9933663003663004,\n",
              "                             1: 0.0,\n",
              "                             2: 0.5674047619047619,\n",
              "                             3: 0.0}],\n",
              "                           'train_f1_all': [{0: 0.9106565531366424,\n",
              "                             1: 0.0,\n",
              "                             2: 0.0,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9208249474498641,\n",
              "                             1: 0.0,\n",
              "                             2: 0.12533333333333332,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9429530601472276,\n",
              "                             1: 0.0,\n",
              "                             2: 0.4740952380952377,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9616629598397344,\n",
              "                             1: 0.0,\n",
              "                             2: 0.5745238095238093,\n",
              "                             3: 0.0}],\n",
              "                           'val_acc_all': [0.8485576923076923,\n",
              "                            0.8653846153846154,\n",
              "                            0.8677884615384616,\n",
              "                            0.8629807692307693],\n",
              "                           'val_precision_all': [{0: 0.8485576923076923,\n",
              "                             1: 0.0,\n",
              "                             2: 0.0,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8688591856861088, 1: 0.0, 2: 0.25, 3: 0.0},\n",
              "                            {0: 0.8705815018315021,\n",
              "                             1: 0.0,\n",
              "                             2: 0.36538461538461536,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.890900605804452,\n",
              "                             1: 0.0,\n",
              "                             2: 0.4198717948717948,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 1.0, 1: 0.0, 2: 0.0, 3: 0.0},\n",
              "                            {0: 0.9920734714003945,\n",
              "                             1: 0.0,\n",
              "                             2: 0.16666666666666669,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9917582417582417,\n",
              "                             1: 0.0,\n",
              "                             2: 0.23717948717948717,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9582464544003007,\n",
              "                             1: 0.0,\n",
              "                             2: 0.39935897435897433,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.9147311782684421,\n",
              "                             1: 0.0,\n",
              "                             2: 0.0,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9235968625272982,\n",
              "                             1: 0.0,\n",
              "                             2: 0.1935897435897436,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.925055340319309,\n",
              "                             1: 0.0,\n",
              "                             2: 0.27564102564102566,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9208228029563925,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3818181818181819,\n",
              "                             3: 0.0}]}),\n",
              "              1: defaultdict(None,\n",
              "                          {'train_loss_values': [0.7804474206074424,\n",
              "                            0.7804474206074424,\n",
              "                            0.6377162470765736,\n",
              "                            0.6377162470765736,\n",
              "                            0.40928745240620945,\n",
              "                            0.40928745240620945,\n",
              "                            0.26707066695975223,\n",
              "                            0.26707066695975223],\n",
              "                           'train_acc_all': [0.7277173913043479,\n",
              "                            0.783695652173913,\n",
              "                            0.8722826086956522,\n",
              "                            0.9173913043478261],\n",
              "                           'train_precision_all': [{0: 0.739241917502787,\n",
              "                             1: 0.0,\n",
              "                             2: 0.002898550724637681,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8109012485099439,\n",
              "                             1: 0.0,\n",
              "                             2: 0.5328778467908903,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9062656667004491,\n",
              "                             1: 0.0,\n",
              "                             2: 0.7105590062111798,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9528931816975297,\n",
              "                             1: 0.0,\n",
              "                             2: 0.7813768115942028,\n",
              "                             3: 0.0}],\n",
              "                           'train_recall_all': [{0: 0.9857142857142858,\n",
              "                             1: 0.0,\n",
              "                             2: 0.004347826086956522,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9521545362849709,\n",
              "                             1: 0.0,\n",
              "                             2: 0.38343685300207037,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9734379630031803,\n",
              "                             1: 0.0,\n",
              "                             2: 0.741366459627329,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9885432441954181,\n",
              "                             1: 0.0,\n",
              "                             2: 0.9137681159420289,\n",
              "                             3: 0.0}],\n",
              "                           'train_f1_all': [{0: 0.8345126933576609,\n",
              "                             1: 0.0,\n",
              "                             2: 0.0034782608695652175,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8694570988908237,\n",
              "                             1: 0.0,\n",
              "                             2: 0.39186933839107724,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.936454196095267,\n",
              "                             1: 0.0,\n",
              "                             2: 0.6966292644553511,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9691603564428491,\n",
              "                             1: 0.0,\n",
              "                             2: 0.8255498125063341,\n",
              "                             3: 0.0}],\n",
              "                           'val_acc_all': [0.8485576923076923,\n",
              "                            0.8581730769230769,\n",
              "                            0.8461538461538461,\n",
              "                            0.8533653846153846],\n",
              "                           'val_precision_all': [{0: 0.8485576923076923,\n",
              "                             1: 0.0,\n",
              "                             2: 0.0,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.882045998872922,\n",
              "                             1: 0.0,\n",
              "                             2: 0.26282051282051283,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9038162158354468,\n",
              "                             1: 0.0,\n",
              "                             2: 0.358974358974359,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8949263877148492,\n",
              "                             1: 0.0,\n",
              "                             2: 0.38461538461538464,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 1.0, 1: 0.0, 2: 0.0, 3: 0.0},\n",
              "                            {0: 0.9665592420400113,\n",
              "                             1: 0.0,\n",
              "                             2: 0.20512820512820512,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9314816593662746,\n",
              "                             1: 0.0,\n",
              "                             2: 0.4487179487179487,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9531892786700479,\n",
              "                             1: 0.0,\n",
              "                             2: 0.298076923076923,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.9137825821029382,\n",
              "                             1: 0.0,\n",
              "                             2: 0.0,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9205905219614994,\n",
              "                             1: 0.0,\n",
              "                             2: 0.2141025641025641,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9159088484764729,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3701465201465201,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9209881919643046,\n",
              "                             1: 0.0,\n",
              "                             2: 0.31923076923076926,\n",
              "                             3: 0.0}]}),\n",
              "              2: defaultdict(None,\n",
              "                          {'train_loss_values': [0.8235574830036897,\n",
              "                            0.8235574830036897,\n",
              "                            0.533735631692868,\n",
              "                            0.533735631692868,\n",
              "                            0.24166067522019147,\n",
              "                            0.24166067522019147,\n",
              "                            0.08990652887150645,\n",
              "                            0.08990652887150645],\n",
              "                           'train_acc_all': [0.6855769230769231,\n",
              "                            0.8283653846153847,\n",
              "                            0.9230769230769231,\n",
              "                            0.9735576923076923],\n",
              "                           'train_precision_all': [{0: 0.7049657820811666,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3283699633699633,\n",
              "                             3: 0.001098901098901099},\n",
              "                            {0: 0.8739287208517973,\n",
              "                             1: 0.015384615384615385,\n",
              "                             2: 0.7370970695970694,\n",
              "                             3: 0.015384615384615385},\n",
              "                            {0: 0.9428343664882123,\n",
              "                             1: 0.3828205128205128,\n",
              "                             2: 0.8735256410256409,\n",
              "                             3: 0.038461538461538464},\n",
              "                            {0: 0.981235196427504,\n",
              "                             1: 0.6282051282051282,\n",
              "                             2: 0.9552380952380953,\n",
              "                             3: 0.1076923076923077}],\n",
              "                           'train_recall_all': [{0: 0.9540263262378648,\n",
              "                             1: 0.0,\n",
              "                             2: 0.2282875457875458,\n",
              "                             3: 0.007692307692307693},\n",
              "                            {0: 0.9398352075275153,\n",
              "                             1: 0.007692307692307693,\n",
              "                             2: 0.7938095238095239,\n",
              "                             3: 0.011538461538461539},\n",
              "                            {0: 0.9857064516679902,\n",
              "                             1: 0.3260256410256411,\n",
              "                             2: 0.9181868131868133,\n",
              "                             3: 0.038461538461538464},\n",
              "                            {0: 0.9926646643954335,\n",
              "                             1: 0.6288461538461538,\n",
              "                             2: 0.9769230769230769,\n",
              "                             3: 0.10256410256410256}],\n",
              "                           'train_f1_all': [{0: 0.7978366464607678,\n",
              "                             1: 0.0,\n",
              "                             2: 0.23932819317434711,\n",
              "                             3: 0.0019230769230769232},\n",
              "                            {0: 0.9012358464915695,\n",
              "                             1: 0.010256410256410256,\n",
              "                             2: 0.7294340928051332,\n",
              "                             3: 0.01282051282051282},\n",
              "                            {0: 0.9618221266999633,\n",
              "                             1: 0.33619658119658113,\n",
              "                             2: 0.8867693417693414,\n",
              "                             3: 0.038461538461538464},\n",
              "                            {0: 0.9862003449736912,\n",
              "                             1: 0.6191575091575091,\n",
              "                             2: 0.9617913710221401,\n",
              "                             3: 0.10384615384615385}],\n",
              "                           'val_acc_all': [0.8581730769230769,\n",
              "                            0.8533653846153846,\n",
              "                            0.8389423076923077,\n",
              "                            0.8413461538461539],\n",
              "                           'val_precision_all': [{0: 0.8765796703296703,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3269230769230769,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8900781910397296,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.27884615384615385,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8979565306488385,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.3467948717948718,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8931758946182023,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.4743589743589744,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.9759291990061221,\n",
              "                             1: 0.0,\n",
              "                             2: 0.2756410256410256,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9469525666641052,\n",
              "                             1: 0.019230769230769232,\n",
              "                             2: 0.3243589743589744,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9233305156382081,\n",
              "                             1: 0.019230769230769232,\n",
              "                             2: 0.3564102564102564,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9308356707395169,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.4230769230769231,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.9210920617913895,\n",
              "                             1: 0.0,\n",
              "                             2: 0.2782051282051282,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9157459187644716,\n",
              "                             1: 0.02564102564102564,\n",
              "                             2: 0.2912087912087912,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9079938089063616,\n",
              "                             1: 0.02564102564102564,\n",
              "                             2: 0.32161172161172163,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9087755654918539,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.4188644688644689,\n",
              "                             3: 0.0}]}),\n",
              "              3: defaultdict(None,\n",
              "                          {'train_loss_values': [0.8927682835480263,\n",
              "                            0.8927682835480263,\n",
              "                            0.4782398639054134,\n",
              "                            0.4782398639054134,\n",
              "                            0.14690299677694665,\n",
              "                            0.14690299677694665,\n",
              "                            0.04119276339669937,\n",
              "                            0.04119276339669937],\n",
              "                           'train_acc_all': [0.6439655172413793,\n",
              "                            0.8323275862068965,\n",
              "                            0.9586206896551724,\n",
              "                            0.9870689655172413],\n",
              "                           'train_precision_all': [{0: 0.6689225046983666,\n",
              "                             1: 0.0,\n",
              "                             2: 0.4432838234562371,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8489208109897759,\n",
              "                             1: 0.16183908045977013,\n",
              "                             2: 0.8147892720306511,\n",
              "                             3: 0.013793103448275862},\n",
              "                            {0: 0.9650254726116793,\n",
              "                             1: 0.6281609195402299,\n",
              "                             2: 0.9666582076926904,\n",
              "                             3: 0.06896551724137931},\n",
              "                            {0: 0.9881574364332986,\n",
              "                             1: 0.7572413793103449,\n",
              "                             2: 0.9873481116584564,\n",
              "                             3: 0.15172413793103448}],\n",
              "                           'train_recall_all': [{0: 0.8989299589299586,\n",
              "                             1: 0.0,\n",
              "                             2: 0.36593247748420155,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9403621857070132,\n",
              "                             1: 0.11666666666666667,\n",
              "                             2: 0.8595183360700602,\n",
              "                             3: 0.013793103448275862},\n",
              "                            {0: 0.986108221280635,\n",
              "                             1: 0.6285057471264368,\n",
              "                             2: 0.9838314176245211,\n",
              "                             3: 0.06436781609195402},\n",
              "                            {0: 0.9962556600487632,\n",
              "                             1: 0.7724137931034483,\n",
              "                             2: 0.9919540229885057,\n",
              "                             3: 0.14022988505747125}],\n",
              "                           'train_f1_all': [{0: 0.7472056546836183,\n",
              "                             1: 0.0,\n",
              "                             2: 0.36004180966655597,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8853685686447228,\n",
              "                             1: 0.12675424192665571,\n",
              "                             2: 0.8194973630096931,\n",
              "                             3: 0.013793103448275862},\n",
              "                            {0: 0.9738141746429533,\n",
              "                             1: 0.6175588396278052,\n",
              "                             2: 0.9707984934060517,\n",
              "                             3: 0.06551724137931035},\n",
              "                            {0: 0.9917591636412101,\n",
              "                             1: 0.762911877394636,\n",
              "                             2: 0.9893266886370333,\n",
              "                             3: 0.14367816091954022}],\n",
              "                           'val_acc_all': [0.8173076923076923,\n",
              "                            0.8581730769230769,\n",
              "                            0.84375,\n",
              "                            0.8581730769230769],\n",
              "                           'val_precision_all': [{0: 0.861334178641871,\n",
              "                             1: 0.0,\n",
              "                             2: 0.4358974358974359,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.898272400676247,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.43974358974358974,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8948586669740516,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.3647435897435898,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9008083262890956,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.41666666666666663,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.9084601296139757,\n",
              "                             1: 0.0,\n",
              "                             2: 0.4705128205128205,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.950654313635083,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.375,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9308353505468892,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.41987179487179493,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9526460718768411,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.37500000000000006,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.8822682877590039,\n",
              "                             1: 0.0,\n",
              "                             2: 0.4247252747252747,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9200517033647864,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.36401931401931403,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9111821304268319,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.3713369963369963,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9224870099936413,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.3432234432234433,\n",
              "                             3: 0.0}]}),\n",
              "              4: defaultdict(None,\n",
              "                          {'train_loss_values': [0.8569251367822289,\n",
              "                            0.8569251367822289,\n",
              "                            0.2680280445958488,\n",
              "                            0.2680280445958488,\n",
              "                            0.04845602441491792,\n",
              "                            0.04845602441491792,\n",
              "                            0.011097426683409139,\n",
              "                            0.011097426683409139],\n",
              "                           'train_acc_all': [0.6390625,\n",
              "                            0.916796875,\n",
              "                            0.98671875,\n",
              "                            0.99921875],\n",
              "                           'train_precision_all': [{0: 0.6703930010961259,\n",
              "                             1: 0.15,\n",
              "                             2: 0.542674166111666,\n",
              "                             3: 0.00625},\n",
              "                            {0: 0.9185219988344988,\n",
              "                             1: 0.7326041666666667,\n",
              "                             2: 0.9149452110389609,\n",
              "                             3: 0.03125},\n",
              "                            {0: 0.9892780483405484,\n",
              "                             1: 0.7385416666666667,\n",
              "                             2: 0.9896552579365079,\n",
              "                             3: 0.2125},\n",
              "                            {0: 0.9993055555555556,\n",
              "                             1: 0.825,\n",
              "                             2: 0.9991071428571429,\n",
              "                             3: 0.29375}],\n",
              "                           'train_recall_all': [{0: 0.8605735236985235,\n",
              "                             1: 0.10416666666666666,\n",
              "                             2: 0.4837977994227992,\n",
              "                             3: 0.00625},\n",
              "                            {0: 0.9536528402153401,\n",
              "                             1: 0.7145833333333333,\n",
              "                             2: 0.9253321158008656,\n",
              "                             3: 0.028125},\n",
              "                            {0: 0.9949377705627706,\n",
              "                             1: 0.753125,\n",
              "                             2: 0.9954464285714287,\n",
              "                             3: 0.20625},\n",
              "                            {0: 0.99921875,\n",
              "                             1: 0.825,\n",
              "                             2: 0.9984375,\n",
              "                             3: 0.29375}],\n",
              "                           'train_f1_all': [{0: 0.7294030791907734,\n",
              "                             1: 0.115625,\n",
              "                             2: 0.4697040467594837,\n",
              "                             3: 0.00625},\n",
              "                            {0: 0.9313113595406415,\n",
              "                             1: 0.7117162698412698,\n",
              "                             2: 0.9119493339907423,\n",
              "                             3: 0.029166666666666664},\n",
              "                            {0: 0.9915862944768248,\n",
              "                             1: 0.7424999999999999,\n",
              "                             2: 0.9917303828352588,\n",
              "                             3: 0.20833333333333334},\n",
              "                            {0: 0.9992156862745099,\n",
              "                             1: 0.825,\n",
              "                             2: 0.9986263736263735,\n",
              "                             3: 0.29375}],\n",
              "                           'val_acc_all': [0.7475961538461539,\n",
              "                            0.8557692307692307,\n",
              "                            0.8629807692307693,\n",
              "                            0.8677884615384616],\n",
              "                           'val_precision_all': [{0: 0.9130055841594302,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.23960622710622712,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9019434091549476,\n",
              "                             1: 0.0,\n",
              "                             2: 0.38782051282051283,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.881839954916878,\n",
              "                             1: 0.019230769230769232,\n",
              "                             2: 0.4230769230769231,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8950014728860881,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.4230769230769231,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.7877696021926793,\n",
              "                             1: 0.057692307692307696,\n",
              "                             2: 0.5051282051282051,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9396609800455953,\n",
              "                             1: 0.0,\n",
              "                             2: 0.4519230769230769,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9675947449985911,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.2756410256410256,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9593600309946464,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.37179487179487186,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.8429251690103958,\n",
              "                             1: 0.0641025641025641,\n",
              "                             2: 0.3127400377400378,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9183883894423477,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3966117216117216,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9200787666424699,\n",
              "                             1: 0.02564102564102564,\n",
              "                             2: 0.3188644688644689,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9242176172614117,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.37582417582417577,\n",
              "                             3: 0.0}]}),\n",
              "              5: defaultdict(None,\n",
              "                          {'train_loss_values': [0.8227378991671971,\n",
              "                            0.8227378991671971,\n",
              "                            0.19576065921889885,\n",
              "                            0.19576065921889885,\n",
              "                            0.02563081485352346,\n",
              "                            0.02563081485352346,\n",
              "                            0.00634986740869603,\n",
              "                            0.00634986740869603],\n",
              "                           'train_acc_all': [0.6635714285714286,\n",
              "                            0.9375,\n",
              "                            0.9957142857142857,\n",
              "                            0.9996428571428572],\n",
              "                           'train_precision_all': [{0: 0.6955307628879052,\n",
              "                             1: 0.09619047619047619,\n",
              "                             2: 0.6245499104070527,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9375000396428967,\n",
              "                             1: 0.6812380952380952,\n",
              "                             2: 0.950891156462585,\n",
              "                             3: 0.08},\n",
              "                            {0: 0.9971201814058956,\n",
              "                             1: 0.8266666666666668,\n",
              "                             2: 0.9951743970315399,\n",
              "                             3: 0.32571428571428573},\n",
              "                            {0: 1.0,\n",
              "                             1: 0.8457142857142858,\n",
              "                             2: 0.9990476190476191,\n",
              "                             3: 0.3485714285714286}],\n",
              "                           'train_recall_all': [{0: 0.8214764124764122,\n",
              "                             1: 0.07666666666666666,\n",
              "                             2: 0.6609934034219747,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9588000412286127,\n",
              "                             1: 0.6898095238095239,\n",
              "                             2: 0.9753854875283445,\n",
              "                             3: 0.07},\n",
              "                            {0: 0.9932312925170069,\n",
              "                             1: 0.8285714285714286,\n",
              "                             2: 0.9985714285714286,\n",
              "                             3: 0.32571428571428573},\n",
              "                            {0: 0.9994805194805194,\n",
              "                             1: 0.8457142857142858,\n",
              "                             2: 1.0,\n",
              "                             3: 0.3485714285714286}],\n",
              "                           'train_f1_all': [{0: 0.727233086647897,\n",
              "                             1: 0.08095238095238094,\n",
              "                             2: 0.6069225513785443,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9441492024362511,\n",
              "                             1: 0.6741698618841476,\n",
              "                             2: 0.9590262564601353,\n",
              "                             3: 0.07276190476190476},\n",
              "                            {0: 0.9947989741351086,\n",
              "                             1: 0.8274285714285715,\n",
              "                             2: 0.996577010291296,\n",
              "                             3: 0.32571428571428573},\n",
              "                            {0: 0.9997278911564627,\n",
              "                             1: 0.8457142857142858,\n",
              "                             2: 0.9994805194805194,\n",
              "                             3: 0.3485714285714286}],\n",
              "                           'val_acc_all': [0.8100961538461539,\n",
              "                            0.8605769230769231,\n",
              "                            0.8605769230769231,\n",
              "                            0.8533653846153846],\n",
              "                           'val_precision_all': [{0: 0.8545734714003945,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.3557692307692308,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8811267258382642,\n",
              "                             1: 0.0,\n",
              "                             2: 0.36538461538461536,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.880496266553959,\n",
              "                             1: 0.0,\n",
              "                             2: 0.391025641025641,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8822467596506058, 1: 0.0, 2: 0.375, 3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.9181336291913217,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.29294871794871796,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9722245703014933,\n",
              "                             1: 0.0,\n",
              "                             2: 0.28525641025641024,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9712649529957224,\n",
              "                             1: 0.0,\n",
              "                             2: 0.2608974358974359,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9633417864187094,\n",
              "                             1: 0.0,\n",
              "                             2: 0.2564102564102564,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.8810731423994025,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.28076923076923077,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9223601496665584,\n",
              "                             1: 0.0,\n",
              "                             2: 0.31025641025641026,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9219552601334104,\n",
              "                             1: 0.0,\n",
              "                             2: 0.2938644688644689,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9179393334672707,\n",
              "                             1: 0.0,\n",
              "                             2: 0.28974358974358977,\n",
              "                             3: 0.0}]}),\n",
              "              6: defaultdict(None,\n",
              "                          {'train_loss_values': [0.8197334594632449,\n",
              "                            0.8197334594632449,\n",
              "                            0.14410205587965288,\n",
              "                            0.14410205587965288,\n",
              "                            0.02214015133519608,\n",
              "                            0.02214015133519608,\n",
              "                            0.011004074387203314,\n",
              "                            0.011004074387203314],\n",
              "                           'train_acc_all': [0.6578947368421053,\n",
              "                            0.95625,\n",
              "                            0.9957236842105263,\n",
              "                            0.9983552631578947],\n",
              "                           'train_precision_all': [{0: 0.6449803047829361,\n",
              "                             1: 0.1087719298245614,\n",
              "                             2: 0.678270786231312,\n",
              "                             3: 0.021052631578947368},\n",
              "                            {0: 0.9635252904989746,\n",
              "                             1: 0.721578947368421,\n",
              "                             2: 0.9639910382015645,\n",
              "                             3: 0.26052631578947366},\n",
              "                            {0: 0.9992481203007519,\n",
              "                             1: 0.8315789473684211,\n",
              "                             2: 0.99110883268778,\n",
              "                             3: 0.3605263157894737},\n",
              "                            {0: 1.0,\n",
              "                             1: 0.8578947368421053,\n",
              "                             2: 0.9978446115288222,\n",
              "                             3: 0.3763157894736842}],\n",
              "                           'train_recall_all': [{0: 0.7670570365307209,\n",
              "                             1: 0.09429824561403508,\n",
              "                             2: 0.7321863370547578,\n",
              "                             3: 0.015789473684210527},\n",
              "                            {0: 0.9659474443684971,\n",
              "                             1: 0.7384210526315789,\n",
              "                             2: 0.9706180223285488,\n",
              "                             3: 0.24736842105263157},\n",
              "                            {0: 0.9925835421888053,\n",
              "                             1: 0.8258771929824562,\n",
              "                             2: 0.9991228070175439,\n",
              "                             3: 0.3631578947368421},\n",
              "                            {0: 0.9963032581453635,\n",
              "                             1: 0.8578947368421053,\n",
              "                             2: 1.0,\n",
              "                             3: 0.37894736842105264}],\n",
              "                           'train_f1_all': [{0: 0.6783559587900331,\n",
              "                             1: 0.09664160401002507,\n",
              "                             2: 0.6689364880120697,\n",
              "                             3: 0.017543859649122806},\n",
              "                            {0: 0.9619715828670954,\n",
              "                             1: 0.7206265664160401,\n",
              "                             2: 0.9643252206124943,\n",
              "                             3: 0.2507017543859649},\n",
              "                            {0: 0.9954960593513632,\n",
              "                             1: 0.8280200501253133,\n",
              "                             2: 0.9943967154819362,\n",
              "                             3: 0.36140350877192984},\n",
              "                            {0: 0.9980100601153234,\n",
              "                             1: 0.8578947368421053,\n",
              "                             2: 0.9988396644906341,\n",
              "                             3: 0.37719298245614036}],\n",
              "                           'val_acc_all': [0.7668269230769231,\n",
              "                            0.8725961538461539,\n",
              "                            0.8413461538461539,\n",
              "                            0.8774038461538461],\n",
              "                           'val_precision_all': [{0: 0.9190213632521324,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.2641941391941392,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9014211749788673,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.5,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9071298893414278,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.375,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8969216680755143,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.41025641025641024,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.8166794743717821,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.5128205128205129,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9697238658777121,\n",
              "                             1: 0.01282051282051282,\n",
              "                             2: 0.43589743589743585,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.926436384128692,\n",
              "                             1: 0.009615384615384616,\n",
              "                             2: 0.4628205128205129,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9804610453648915,\n",
              "                             1: 0.019230769230769232,\n",
              "                             2: 0.3333333333333333,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.8590021139092758,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.32368742368742376,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9312533249655692,\n",
              "                             1: 0.019230769230769232,\n",
              "                             2: 0.4423076923076923,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9136156427422643,\n",
              "                             1: 0.015384615384615385,\n",
              "                             2: 0.365018315018315,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9329127057085475,\n",
              "                             1: 0.02564102564102564,\n",
              "                             2: 0.35000000000000003,\n",
              "                             3: 0.0}]}),\n",
              "              7: defaultdict(None,\n",
              "                          {'train_loss_values': [0.8126069467242171,\n",
              "                            0.8126069467242171,\n",
              "                            0.16363289383262758,\n",
              "                            0.16363289383262758,\n",
              "                            0.014203061207720056,\n",
              "                            0.014203061207720056,\n",
              "                            0.0033907254098732844,\n",
              "                            0.0033907254098732844],\n",
              "                           'train_acc_all': [0.6588414634146341,\n",
              "                            0.9484756097560976,\n",
              "                            0.9975609756097561,\n",
              "                            0.9996951219512196],\n",
              "                           'train_precision_all': [{0: 0.6142114457358357,\n",
              "                             1: 0.07073170731707316,\n",
              "                             2: 0.7179785526126988,\n",
              "                             3: 0.004878048780487805},\n",
              "                            {0: 0.9397733431879775,\n",
              "                             1: 0.7414634146341463,\n",
              "                             2: 0.9677177700348433,\n",
              "                             3: 0.2707317073170732},\n",
              "                            {0: 0.9991869918699188,\n",
              "                             1: 0.8853658536585366,\n",
              "                             2: 0.9984146341463416,\n",
              "                             3: 0.359349593495935},\n",
              "                            {0: 1.0,\n",
              "                             1: 0.8341463414634146,\n",
              "                             2: 0.9994579945799458,\n",
              "                             3: 0.3853658536585366}],\n",
              "                           'train_recall_all': [{0: 0.7123696899306655,\n",
              "                             1: 0.047235772357723575,\n",
              "                             2: 0.8254248055467569,\n",
              "                             3: 0.004878048780487805},\n",
              "                            {0: 0.9528648857917152,\n",
              "                             1: 0.7389430894308944,\n",
              "                             2: 0.980975257804526,\n",
              "                             3: 0.267479674796748},\n",
              "                            {0: 0.9959620596205961,\n",
              "                             1: 0.8878048780487805,\n",
              "                             2: 0.9993031358885017,\n",
              "                             3: 0.36097560975609755},\n",
              "                            {0: 0.9990243902439025,\n",
              "                             1: 0.8341463414634146,\n",
              "                             2: 1.0,\n",
              "                             3: 0.3853658536585366}],\n",
              "                           'train_f1_all': [{0: 0.6292719207337756,\n",
              "                             1: 0.0524390243902439,\n",
              "                             2: 0.7381348826043481,\n",
              "                             3: 0.004878048780487805},\n",
              "                            {0: 0.9404124579619588,\n",
              "                             1: 0.7297909407665504,\n",
              "                             2: 0.971782906538364,\n",
              "                             3: 0.2679674796747967},\n",
              "                            {0: 0.9973769866603817,\n",
              "                             1: 0.8861788617886178,\n",
              "                             2: 0.9987575568063374,\n",
              "                             3: 0.36},\n",
              "                            {0: 0.9994579945799458,\n",
              "                             1: 0.8341463414634146,\n",
              "                             2: 0.999713055954089,\n",
              "                             3: 0.3853658536585366}],\n",
              "                           'val_acc_all': [0.8052884615384616,\n",
              "                            0.8365384615384616,\n",
              "                            0.8509615384615384,\n",
              "                            0.8485576923076923],\n",
              "                           'val_precision_all': [{0: 0.8269917582417583,\n",
              "                             1: 0.0,\n",
              "                             2: 0.21794871794871795,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8907491546914625,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.27179487179487183,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8771414482952944,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.24358974358974358,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.877268244575937,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.34294871794871795,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.9312341504649196,\n",
              "                             1: 0.0,\n",
              "                             2: 0.17948717948717946,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.932883462691155,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.2891025641025641,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.968568770972617,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.19679487179487182,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9530129592629593,\n",
              "                             1: 0.007692307692307693,\n",
              "                             2: 0.2961538461538461,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.8733365159950253,\n",
              "                             1: 0.0,\n",
              "                             2: 0.17179487179487177,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9077690581066127,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.2581501831501832,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9183156610113916,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.19194139194139195,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9097481433410243,\n",
              "                             1: 0.012820512820512822,\n",
              "                             2: 0.28034188034188035,\n",
              "                             3: 0.0}]}),\n",
              "              8: defaultdict(None,\n",
              "                          {'train_loss_values': [0.752625182914463,\n",
              "                            0.752625182914463,\n",
              "                            0.10280547412535683,\n",
              "                            0.10280547412535683,\n",
              "                            0.00813901071828282,\n",
              "                            0.00813901071828282,\n",
              "                            0.004659782563050447,\n",
              "                            0.004659782563050447],\n",
              "                           'train_acc_all': [0.6926136363636364,\n",
              "                            0.9696022727272727,\n",
              "                            0.9988636363636364,\n",
              "                            0.9994318181818181],\n",
              "                           'train_precision_all': [{0: 0.6742780578007854,\n",
              "                             1: 0.2479978354978355,\n",
              "                             2: 0.737361394918213,\n",
              "                             3: 0.00909090909090909},\n",
              "                            {0: 0.9643795093795094,\n",
              "                             1: 0.8018506493506493,\n",
              "                             2: 0.9793418576373122,\n",
              "                             3: 0.29545454545454547},\n",
              "                            {0: 0.9954545454545455,\n",
              "                             1: 0.8136363636363636,\n",
              "                             2: 0.9983279220779221,\n",
              "                             3: 0.42954545454545456},\n",
              "                            {0: 1.0,\n",
              "                             1: 0.8545454545454545,\n",
              "                             2: 0.9993506493506493,\n",
              "                             3: 0.38522727272727275}],\n",
              "                           'train_recall_all': [{0: 0.7244123048668504,\n",
              "                             1: 0.22121212121212122,\n",
              "                             2: 0.8310217434081071,\n",
              "                             3: 0.006818181818181818},\n",
              "                            {0: 0.9648683261183261,\n",
              "                             1: 0.8131818181818182,\n",
              "                             2: 0.9924581857536403,\n",
              "                             3: 0.2909090909090909},\n",
              "                            {0: 0.9921212121212121,\n",
              "                             1: 0.8136363636363636,\n",
              "                             2: 1.0,\n",
              "                             3: 0.4318181818181818},\n",
              "                            {0: 0.9985227272727273,\n",
              "                             1: 0.8545454545454545,\n",
              "                             2: 1.0,\n",
              "                             3: 0.38636363636363635}],\n",
              "                           'train_f1_all': [{0: 0.657717460052046,\n",
              "                             1: 0.2244841269841269,\n",
              "                             2: 0.7564271732255896,\n",
              "                             3: 0.007575757575757575},\n",
              "                            {0: 0.9602572187405427,\n",
              "                             1: 0.8002705123159669,\n",
              "                             2: 0.9846353372581942,\n",
              "                             3: 0.2924242424242424},\n",
              "                            {0: 0.9936179981634526,\n",
              "                             1: 0.8136363636363636,\n",
              "                             2: 0.9991080848975586,\n",
              "                             3: 0.43030303030303024},\n",
              "                            {0: 0.9991919191919192,\n",
              "                             1: 0.8545454545454545,\n",
              "                             2: 0.9996503496503496,\n",
              "                             3: 0.38571428571428573}],\n",
              "                           'val_acc_all': [0.6153846153846154,\n",
              "                            0.8653846153846154,\n",
              "                            0.8341346153846154,\n",
              "                            0.8701923076923077],\n",
              "                           'val_precision_all': [{0: 0.9520175337483029,\n",
              "                             1: 0.0,\n",
              "                             2: 0.17141469641469642,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8632836714567484,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.46153846153846156,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.850729078613694,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.4423076923076923,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8817222841261303,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.3589743589743589,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.628831905274213,\n",
              "                             1: 0.0,\n",
              "                             2: 0.658974358974359,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9198383347421809,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.3814102564102564,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9366775852352774,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.3333333333333333,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9748291772330233,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.2676282051282051,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.7435819869986392,\n",
              "                             1: 0.0,\n",
              "                             2: 0.2579211386903694,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8881784533190219,\n",
              "                             1: 0.05128205128205128,\n",
              "                             2: 0.40402930402930404,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.889128884530185,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.3496336996336996,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9230700399049849,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.28727810650887575,\n",
              "                             3: 0.0}]}),\n",
              "              9: defaultdict(None,\n",
              "                          {'train_loss_values': [0.7957468336566965,\n",
              "                            0.7957468336566965,\n",
              "                            0.11538581018474825,\n",
              "                            0.11538581018474825,\n",
              "                            0.011107368636975421,\n",
              "                            0.011107368636975421,\n",
              "                            0.0014223970220166636,\n",
              "                            0.0014223970220166636],\n",
              "                           'train_acc_all': [0.6680851063829787,\n",
              "                            0.9659574468085106,\n",
              "                            0.9968085106382979,\n",
              "                            0.9997340425531915],\n",
              "                           'train_precision_all': [{0: 0.5893671576650299,\n",
              "                             1: 0.3358156028368794,\n",
              "                             2: 0.689637194956344,\n",
              "                             3: 0.03404255319148936},\n",
              "                            {0: 0.9564419268674587,\n",
              "                             1: 0.8773049645390071,\n",
              "                             2: 0.9748285284455496,\n",
              "                             3: 0.27872340425531916},\n",
              "                            {0: 0.9936170212765958,\n",
              "                             1: 0.9042553191489362,\n",
              "                             2: 0.9954913880445795,\n",
              "                             3: 0.40425531914893614},\n",
              "                            {0: 1.0,\n",
              "                             1: 0.9106382978723404,\n",
              "                             2: 0.999290780141844,\n",
              "                             3: 0.425531914893617}],\n",
              "                           'train_recall_all': [{0: 0.5501671732522793,\n",
              "                             1: 0.3113475177304964,\n",
              "                             2: 0.8722364751088155,\n",
              "                             3: 0.02482269503546099},\n",
              "                            {0: 0.958796014859845,\n",
              "                             1: 0.8915602836879432,\n",
              "                             2: 0.9831405237788217,\n",
              "                             3: 0.26382978723404255},\n",
              "                            {0: 0.9890543735224586,\n",
              "                             1: 0.9063829787234042,\n",
              "                             2: 0.9990647650222118,\n",
              "                             3: 0.40425531914893614},\n",
              "                            {0: 0.999468085106383,\n",
              "                             1: 0.9106382978723404,\n",
              "                             2: 1.0,\n",
              "                             3: 0.425531914893617}],\n",
              "                           'train_f1_all': [{0: 0.5357721540914343,\n",
              "                             1: 0.30404930766632887,\n",
              "                             2: 0.7425550833542177,\n",
              "                             3: 0.027659574468085105},\n",
              "                            {0: 0.9532468145560171,\n",
              "                             1: 0.8801722391084094,\n",
              "                             2: 0.9771031665692782,\n",
              "                             3: 0.2683687943262411},\n",
              "                            {0: 0.9907102944336987,\n",
              "                             1: 0.9049645390070923,\n",
              "                             2: 0.9969829886425632,\n",
              "                             3: 0.40425531914893614},\n",
              "                            {0: 0.9997163120567376,\n",
              "                             1: 0.9106382978723404,\n",
              "                             2: 0.9996131528046421,\n",
              "                             3: 0.425531914893617}],\n",
              "                           'val_acc_all': [0.7932692307692307,\n",
              "                            0.8509615384615384,\n",
              "                            0.8293269230769231,\n",
              "                            0.8629807692307693],\n",
              "                           'val_precision_all': [{0: 0.9054111486803795,\n",
              "                             1: 0.0,\n",
              "                             2: 0.28095238095238095,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8855751620174697,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.37307692307692314,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8350803043110735,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3525641025641026,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8760989010989012,\n",
              "                             1: 0.0,\n",
              "                             2: 0.4423076923076923,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.8625196918466147,\n",
              "                             1: 0.0,\n",
              "                             2: 0.5128205128205129,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9482514280591202,\n",
              "                             1: 0.009615384615384616,\n",
              "                             2: 0.3403846153846154,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.946813442967289,\n",
              "                             1: 0.0,\n",
              "                             2: 0.20833333333333331,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.974376584953508,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3205128205128205,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.8780238854376783,\n",
              "                             1: 0.0,\n",
              "                             2: 0.34072039072039073,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9124443046127676,\n",
              "                             1: 0.015384615384615385,\n",
              "                             2: 0.32115384615384623,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8852281418893896,\n",
              "                             1: 0.0,\n",
              "                             2: 0.24615384615384617,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9206455353114033,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3423076923076923,\n",
              "                             3: 0.0}]}),\n",
              "              10: defaultdict(None,\n",
              "                          {'train_loss_values': [0.6684293354600668,\n",
              "                            0.6684293354600668,\n",
              "                            0.060510322496294976,\n",
              "                            0.060510322496294976,\n",
              "                            0.010087735056877135,\n",
              "                            0.010087735056877135,\n",
              "                            0.0059439202565699815,\n",
              "                            0.0059439202565699815],\n",
              "                           'train_acc_all': [0.73475, 0.9825, 0.99825, 0.999],\n",
              "                           'train_precision_all': [{0: 0.6576222222222222,\n",
              "                             1: 0.3756666666666667,\n",
              "                             2: 0.7792498223998223,\n",
              "                             3: 0.008},\n",
              "                            {0: 0.9858412698412699,\n",
              "                             1: 0.8730666666666668,\n",
              "                             2: 0.9869362193362193,\n",
              "                             3: 0.362},\n",
              "                            {0: 0.9952000000000001,\n",
              "                             1: 0.862,\n",
              "                             2: 0.9974319902319904,\n",
              "                             3: 0.432},\n",
              "                            {0: 0.996,\n",
              "                             1: 0.908,\n",
              "                             2: 0.9980285714285715,\n",
              "                             3: 0.4}],\n",
              "                           'train_recall_all': [{0: 0.681130158730159,\n",
              "                             1: 0.3445999999999999,\n",
              "                             2: 0.9096301587301584,\n",
              "                             3: 0.008},\n",
              "                            {0: 0.9758174603174605,\n",
              "                             1: 0.8913333333333333,\n",
              "                             2: 0.9952396825396824,\n",
              "                             3: 0.354},\n",
              "                            {0: 0.9917079365079365,\n",
              "                             1: 0.864,\n",
              "                             2: 1.0,\n",
              "                             3: 0.432},\n",
              "                            {0: 0.9931841269841271, 1: 0.908, 2: 1.0, 3: 0.4}],\n",
              "                           'train_f1_all': [{0: 0.6406253547278314,\n",
              "                             1: 0.3412251082251082,\n",
              "                             2: 0.8223984359794992,\n",
              "                             3: 0.008},\n",
              "                            {0: 0.9786326272626583,\n",
              "                             1: 0.8788825396825398,\n",
              "                             2: 0.9904605587111173,\n",
              "                             3: 0.35600000000000004},\n",
              "                            {0: 0.9931014580191052,\n",
              "                             1: 0.8626666666666666,\n",
              "                             2: 0.9986172750125691,\n",
              "                             3: 0.432},\n",
              "                            {0: 0.9944411405587876,\n",
              "                             1: 0.908,\n",
              "                             2: 0.9989484480431849,\n",
              "                             3: 0.4}],\n",
              "                           'val_acc_all': [0.8245192307692307,\n",
              "                            0.8509615384615384,\n",
              "                            0.8485576923076923,\n",
              "                            0.8509615384615384],\n",
              "                           'val_precision_all': [{0: 0.8905246996593152,\n",
              "                             1: 0.15384615384615385,\n",
              "                             2: 0.29358974358974355,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8838951112989577,\n",
              "                             1: 0.019230769230769232,\n",
              "                             2: 0.3692307692307692,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8797143561566639,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.3653846153846153,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8797337278106508,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.3474358974358974,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.9149646827531444,\n",
              "                             1: 0.10897435897435898,\n",
              "                             2: 0.26474358974358975,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9547530994646378,\n",
              "                             1: 0.019230769230769232,\n",
              "                             2: 0.27243589743589747,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9500328197443582,\n",
              "                             1: 0.019230769230769232,\n",
              "                             2: 0.33653846153846156,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9533953226260921,\n",
              "                             1: 0.01282051282051282,\n",
              "                             2: 0.2756410256410256,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.8991532613873677,\n",
              "                             1: 0.12179487179487179,\n",
              "                             2: 0.25641025641025644,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9143124155253018,\n",
              "                             1: 0.019230769230769232,\n",
              "                             2: 0.2967948717948718,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9115328240587075,\n",
              "                             1: 0.02564102564102564,\n",
              "                             2: 0.3117216117216117,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9124376148816162,\n",
              "                             1: 0.019230769230769232,\n",
              "                             2: 0.288034188034188,\n",
              "                             3: 0.0}]}),\n",
              "              11: defaultdict(None,\n",
              "                          {'train_loss_values': [0.6368158468379165,\n",
              "                            0.6368158468379165,\n",
              "                            0.049085959770611295,\n",
              "                            0.049085959770611295,\n",
              "                            0.004080091983756437,\n",
              "                            0.004080091983756437,\n",
              "                            0.0027461738446463812,\n",
              "                            0.0027461738446463812],\n",
              "                           'train_acc_all': [0.7537735849056604,\n",
              "                            0.9860849056603773,\n",
              "                            0.9992924528301886,\n",
              "                            0.9995283018867924],\n",
              "                           'train_precision_all': [{0: 0.6418903318903315,\n",
              "                             1: 0.3660377358490566,\n",
              "                             2: 0.822336458091175,\n",
              "                             3: 0.03018867924528302},\n",
              "                            {0: 0.9783182226578455,\n",
              "                             1: 0.8501886792452831,\n",
              "                             2: 0.9893808707016253,\n",
              "                             3: 0.4037735849056604},\n",
              "                            {0: 1.0,\n",
              "                             1: 0.9047169811320754,\n",
              "                             2: 0.9989892183288411,\n",
              "                             3: 0.4339622641509434},\n",
              "                            {0: 1.0,\n",
              "                             1: 0.8754716981132076,\n",
              "                             2: 0.9991852487135505,\n",
              "                             3: 0.4377358490566038}],\n",
              "                           'train_recall_all': [{0: 0.732613057801737,\n",
              "                             1: 0.3020664869721474,\n",
              "                             2: 0.9096501402161783,\n",
              "                             3: 0.03018867924528302},\n",
              "                            {0: 0.974498216668028,\n",
              "                             1: 0.8501886792452831,\n",
              "                             2: 0.9959104522312068,\n",
              "                             3: 0.4025157232704402},\n",
              "                            {0: 0.9979874213836477,\n",
              "                             1: 0.9056603773584906,\n",
              "                             2: 1.0,\n",
              "                             3: 0.4339622641509434},\n",
              "                            {0: 0.9988993710691826,\n",
              "                             1: 0.8754716981132076,\n",
              "                             2: 1.0,\n",
              "                             3: 0.4377358490566038}],\n",
              "                           'train_f1_all': [{0: 0.6586050690487283,\n",
              "                             1: 0.31703504043126685,\n",
              "                             2: 0.8504963331768207,\n",
              "                             3: 0.03018867924528302},\n",
              "                            {0: 0.9738197831661234,\n",
              "                             1: 0.8459359089547768,\n",
              "                             2: 0.9920704575544228,\n",
              "                             3: 0.4030188679245283},\n",
              "                            {0: 0.9988946064417761,\n",
              "                             1: 0.9051212938005391,\n",
              "                             2: 0.9994581519109821,\n",
              "                             3: 0.4339622641509434},\n",
              "                            {0: 0.9994053744997142,\n",
              "                             1: 0.8754716981132076,\n",
              "                             2: 0.9995687331536389,\n",
              "                             3: 0.4377358490566038}],\n",
              "                           'val_acc_all': [0.8533653846153846,\n",
              "                            0.8557692307692307,\n",
              "                            0.8485576923076923,\n",
              "                            0.8557692307692307],\n",
              "                           'val_precision_all': [{0: 0.8452380952380953,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.3557692307692308,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8859802056917443,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.34615384615384615,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8888859537898,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.36538461538461536,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8870174697097776,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.41025641025641024,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.9257396449704142,\n",
              "                             1: 0.05128205128205128,\n",
              "                             2: 0.24999999999999997,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9634932375316989,\n",
              "                             1: 0.05128205128205128,\n",
              "                             2: 0.25,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9494804874612567,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.3269230769230769,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9591479033786727,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.33333333333333337,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.8818664348432466,\n",
              "                             1: 0.057692307692307696,\n",
              "                             2: 0.2743589743589744,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9213159155128867,\n",
              "                             1: 0.057692307692307696,\n",
              "                             2: 0.2804029304029304,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9153838372187824,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.317948717948718,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9186521422510128,\n",
              "                             1: 0.05128205128205128,\n",
              "                             2: 0.35256410256410253,\n",
              "                             3: 0.0}]}),\n",
              "              12: defaultdict(None,\n",
              "                          {'train_loss_values': [0.6201338562715266,\n",
              "                            0.6201338562715266,\n",
              "                            0.037427565941470675,\n",
              "                            0.037427565941470675,\n",
              "                            0.0036890543948434893,\n",
              "                            0.0036890543948434893,\n",
              "                            0.0030027742331315364,\n",
              "                            0.0030027742331315364],\n",
              "                           'train_acc_all': [0.7560267857142857,\n",
              "                            0.9912946428571429,\n",
              "                            0.9986607142857142,\n",
              "                            0.9995535714285714],\n",
              "                           'train_precision_all': [{0: 0.6760254675879676,\n",
              "                             1: 0.48053571428571423,\n",
              "                             2: 0.8048340697001414,\n",
              "                             3: 0.0757142857142857},\n",
              "                            {0: 0.9933545918367348,\n",
              "                             1: 0.891420068027211,\n",
              "                             2: 0.9902335462156893,\n",
              "                             3: 0.45238095238095233},\n",
              "                            {0: 0.9992857142857143,\n",
              "                             1: 0.9357142857142857,\n",
              "                             2: 0.9979421768707482,\n",
              "                             3: 0.42857142857142855},\n",
              "                            {0: 1.0,\n",
              "                             1: 0.9214285714285714,\n",
              "                             2: 0.9991964285714285,\n",
              "                             3: 0.43214285714285716}],\n",
              "                           'train_recall_all': [{0: 0.6619486961451247,\n",
              "                             1: 0.4648554421768708,\n",
              "                             2: 0.9142184006469722,\n",
              "                             3: 0.06607142857142857},\n",
              "                            {0: 0.9746797052154197,\n",
              "                             1: 0.8970238095238094,\n",
              "                             2: 0.9991567460317461,\n",
              "                             3: 0.4517857142857143},\n",
              "                            {0: 0.9958928571428572,\n",
              "                             1: 0.9357142857142857,\n",
              "                             2: 0.9996753246753246,\n",
              "                             3: 0.42857142857142855},\n",
              "                            {0: 0.9987755102040818,\n",
              "                             1: 0.9214285714285714,\n",
              "                             2: 1.0,\n",
              "                             3: 0.43214285714285716}],\n",
              "                           'train_f1_all': [{0: 0.6319321163013111,\n",
              "                             1: 0.4544825809111523,\n",
              "                             2: 0.8392369487519841,\n",
              "                             3: 0.06773809523809524},\n",
              "                            {0: 0.982197425958483,\n",
              "                             1: 0.892953514739229,\n",
              "                             2: 0.9942693072497651,\n",
              "                             3: 0.45166666666666666},\n",
              "                            {0: 0.9972603586889303,\n",
              "                             1: 0.9357142857142857,\n",
              "                             2: 0.9987357667939558,\n",
              "                             3: 0.42857142857142855},\n",
              "                            {0: 0.9993284493284493,\n",
              "                             1: 0.9214285714285714,\n",
              "                             2: 0.9995739348370929,\n",
              "                             3: 0.43214285714285716}],\n",
              "                           'val_acc_all': [0.8269230769230769,\n",
              "                            0.8653846153846154,\n",
              "                            0.8605769230769231,\n",
              "                            0.8245192307692307],\n",
              "                           'val_precision_all': [{0: 0.8900077486615948,\n",
              "                             1: 0.057692307692307696,\n",
              "                             2: 0.33012820512820507,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8831272893772895,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.4230769230769231,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8770269794308257,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3141025641025641,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8497604959143421,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.4423076923076923,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.9259175119752043,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.2794871794871795,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9810210622710621,\n",
              "                             1: 0.009615384615384616,\n",
              "                             2: 0.2403846153846154,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9732671174978869,\n",
              "                             1: 0.0,\n",
              "                             2: 0.25769230769230766,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9309928853198083,\n",
              "                             1: 0.019230769230769232,\n",
              "                             2: 0.342948717948718,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.9025111580343892,\n",
              "                             1: 0.0641025641025641,\n",
              "                             2: 0.2681318681318681,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.926066655362454,\n",
              "                             1: 0.015384615384615385,\n",
              "                             2: 0.2846153846153846,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9206114659609999,\n",
              "                             1: 0.0,\n",
              "                             2: 0.2538461538461539,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8859480293877487,\n",
              "                             1: 0.02564102564102564,\n",
              "                             2: 0.33974358974358976,\n",
              "                             3: 0.0}]}),\n",
              "              13: defaultdict(None,\n",
              "                          {'train_loss_values': [0.6535070680460687,\n",
              "                            0.6535070680460687,\n",
              "                            0.037166637253663426,\n",
              "                            0.037166637253663426,\n",
              "                            0.01017105666727175,\n",
              "                            0.01017105666727175,\n",
              "                            0.0037672032753076658,\n",
              "                            0.0037672032753076658],\n",
              "                           'train_acc_all': [0.7366525423728814,\n",
              "                            0.9904661016949152,\n",
              "                            0.9987288135593221,\n",
              "                            0.999364406779661],\n",
              "                           'train_precision_all': [{0: 0.5738918896546016,\n",
              "                             1: 0.5596771589991929,\n",
              "                             2: 0.75704166360946,\n",
              "                             3: 0.1152542372881356},\n",
              "                            {0: 0.9787933817594834,\n",
              "                             1: 0.8878531073446326,\n",
              "                             2: 0.9882587374960256,\n",
              "                             3: 0.43050847457627117},\n",
              "                            {0: 0.9932203389830508,\n",
              "                             1: 0.9347457627118644,\n",
              "                             2: 0.9977615134394796,\n",
              "                             3: 0.43728813559322033},\n",
              "                            {0: 1.0,\n",
              "                             1: 0.9186440677966101,\n",
              "                             2: 0.9986440677966103,\n",
              "                             3: 0.4271186440677966}],\n",
              "                           'train_recall_all': [{0: 0.5265657788539144,\n",
              "                             1: 0.54909604519774,\n",
              "                             2: 0.9127760375218005,\n",
              "                             3: 0.10621468926553672},\n",
              "                            {0: 0.9642574656981437,\n",
              "                             1: 0.8875706214689267,\n",
              "                             2: 0.9965738498789346,\n",
              "                             3: 0.4288135593220339},\n",
              "                            {0: 0.9891202582728006,\n",
              "                             1: 0.9355932203389831,\n",
              "                             2: 1.0,\n",
              "                             3: 0.43728813559322033},\n",
              "                            {0: 0.9972558514931397,\n",
              "                             1: 0.9186440677966101,\n",
              "                             2: 1.0,\n",
              "                             3: 0.4271186440677966}],\n",
              "                           'train_f1_all': [{0: 0.5210381646071942,\n",
              "                             1: 0.5398796683542446,\n",
              "                             2: 0.8054202038259731,\n",
              "                             3: 0.10892655367231638},\n",
              "                            {0: 0.9692818045271211,\n",
              "                             1: 0.8868266197079755,\n",
              "                             2: 0.9918049137606257,\n",
              "                             3: 0.4293785310734463},\n",
              "                            {0: 0.9909295977092588,\n",
              "                             1: 0.9351089588377723,\n",
              "                             2: 0.9987968561846927,\n",
              "                             3: 0.43728813559322033},\n",
              "                            {0: 0.9983011338943542,\n",
              "                             1: 0.9186440677966101,\n",
              "                             2: 0.999266527901675,\n",
              "                             3: 0.4271186440677966}],\n",
              "                           'val_acc_all': [0.75,\n",
              "                            0.8293269230769231,\n",
              "                            0.8605769230769231,\n",
              "                            0.8629807692307693],\n",
              "                           'val_precision_all': [{0: 0.8948929275852352,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.2330586080586081,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8878013012628398,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.30128205128205127,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8800366300366301,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.3333333333333333,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8844639335023952,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.375,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.8139328620097852,\n",
              "                             1: 0.019230769230769232,\n",
              "                             2: 0.49038461538461536,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9228287737903123,\n",
              "                             1: 0.057692307692307696,\n",
              "                             2: 0.3141025641025641,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9748925753733446,\n",
              "                             1: 0.019230769230769232,\n",
              "                             2: 0.28525641025641024,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.967469709777402,\n",
              "                             1: 0.019230769230769232,\n",
              "                             2: 0.31858974358974357,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.8477682337865708,\n",
              "                             1: 0.02564102564102564,\n",
              "                             2: 0.2913614163614163,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9022664848659543,\n",
              "                             1: 0.0641025641025641,\n",
              "                             2: 0.28727106227106225,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9221268266480895,\n",
              "                             1: 0.02564102564102564,\n",
              "                             2: 0.27692307692307694,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9216179271335319,\n",
              "                             1: 0.02564102564102564,\n",
              "                             2: 0.31996336996337,\n",
              "                             3: 0.0}]})},\n",
              "             '16_2e-05': {0: defaultdict(None,\n",
              "                          {'train_loss_values': [0.5765580122172832,\n",
              "                            0.5765580122172832,\n",
              "                            0.4728256331384182,\n",
              "                            0.4728256331384182,\n",
              "                            0.36995511304587125,\n",
              "                            0.36995511304587125,\n",
              "                            0.29279260013252495,\n",
              "                            0.29279260013252495],\n",
              "                           'train_acc_all': [0.84, 0.851875, 0.89, 0.91875],\n",
              "                           'train_precision_all': [{0: 0.8525,\n",
              "                             1: 0.0,\n",
              "                             2: 0.0,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8524999999999998, 1: 0.0, 2: 0.05, 3: 0.0},\n",
              "                            {0: 0.8976607559107558,\n",
              "                             1: 0.0,\n",
              "                             2: 0.45016666666666666,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9304400599400598,\n",
              "                             1: 0.0,\n",
              "                             2: 0.6738333333333333,\n",
              "                             3: 0.0}],\n",
              "                           'train_recall_all': [{0: 0.9881025641025641,\n",
              "                             1: 0.0,\n",
              "                             2: 0.0,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9986666666666667, 1: 0.0, 2: 0.0225, 3: 0.0},\n",
              "                            {0: 0.9916165917415918,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3420000000000001,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9930329670329673,\n",
              "                             1: 0.0,\n",
              "                             2: 0.5974999999999998,\n",
              "                             3: 0.0}],\n",
              "                           'train_f1_all': [{0: 0.9078031784060709,\n",
              "                             1: 0.0,\n",
              "                             2: 0.0,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9173361388745153,\n",
              "                             1: 0.0,\n",
              "                             2: 0.028999999999999998,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9405278354524376,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3711428571428572,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.959607256980793,\n",
              "                             1: 0.0,\n",
              "                             2: 0.6061139971139968,\n",
              "                             3: 0.0}],\n",
              "                           'val_acc_all': [0.8485576923076923,\n",
              "                            0.8533653846153846,\n",
              "                            0.8485576923076923,\n",
              "                            0.8533653846153846],\n",
              "                           'val_precision_all': [{0: 0.8485576923076923,\n",
              "                             1: 0.0,\n",
              "                             2: 0.0,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8562042124542125,\n",
              "                             1: 0.0,\n",
              "                             2: 0.11538461538461539,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8979342772612005,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3846153846153847,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8879737249929559,\n",
              "                             1: 0.0,\n",
              "                             2: 0.35256410256410253,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 1.0, 1: 0.0, 2: 0.0, 3: 0.0},\n",
              "                            {0: 0.9944773175542406,\n",
              "                             1: 0.0,\n",
              "                             2: 0.057692307692307696,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9466091600706985,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3557692307692308,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9558731332769794,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3647435897435898,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.915709574929221,\n",
              "                             1: 0.0,\n",
              "                             2: 0.0,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9183175814389986,\n",
              "                             1: 0.0,\n",
              "                             2: 0.07564102564102564,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9188294216265469,\n",
              "                             1: 0.0,\n",
              "                             2: 0.33333333333333337,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9171203240988509,\n",
              "                             1: 0.0,\n",
              "                             2: 0.33351648351648355,\n",
              "                             3: 0.0}]}),\n",
              "              1: defaultdict(None,\n",
              "                          {'train_loss_values': [0.7259688792021378,\n",
              "                            0.7259688792021378,\n",
              "                            0.5085014927646389,\n",
              "                            0.5085014927646389,\n",
              "                            0.3109568555717883,\n",
              "                            0.3109568555717883,\n",
              "                            0.19913759576561657,\n",
              "                            0.19913759576561657],\n",
              "                           'train_acc_all': [0.7380434782608696,\n",
              "                            0.8239130434782609,\n",
              "                            0.9005434782608696,\n",
              "                            0.9326086956521739],\n",
              "                           'train_precision_all': [{0: 0.7556735776300996,\n",
              "                             1: 0.0,\n",
              "                             2: 0.15663191880583183,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.865223954789172,\n",
              "                             1: 0.0,\n",
              "                             2: 0.6519047619047619,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9429034371425673,\n",
              "                             1: 0.034782608695652174,\n",
              "                             2: 0.7097722567287787,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9723068718720893,\n",
              "                             1: 0.0782608695652174,\n",
              "                             2: 0.7673395445134573,\n",
              "                             3: 0.0}],\n",
              "                           'train_recall_all': [{0: 0.9583128465737161,\n",
              "                             1: 0.0,\n",
              "                             2: 0.12412008281573499,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9460152166673907,\n",
              "                             1: 0.0,\n",
              "                             2: 0.6191304347826087,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9806441384702254,\n",
              "                             1: 0.024637681159420288,\n",
              "                             2: 0.84040027605245,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9942798747146573,\n",
              "                             1: 0.06521739130434782,\n",
              "                             2: 0.9192753623188405,\n",
              "                             3: 0.0}],\n",
              "                           'train_f1_all': [{0: 0.8342697645284659,\n",
              "                             1: 0.0,\n",
              "                             2: 0.11635570170097025,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.898966703211884,\n",
              "                             1: 0.0,\n",
              "                             2: 0.5896384292036461,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9592366687988093,\n",
              "                             1: 0.02753623188405797,\n",
              "                             2: 0.745073968373201,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9824709238802504,\n",
              "                             1: 0.06956521739130435,\n",
              "                             2: 0.8210975497932015,\n",
              "                             3: 0.0}],\n",
              "                           'val_acc_all': [0.7524038461538461,\n",
              "                            0.8341346153846154,\n",
              "                            0.8245192307692307,\n",
              "                            0.8365384615384616],\n",
              "                           'val_precision_all': [{0: 0.9163116797732181,\n",
              "                             1: 0.0,\n",
              "                             2: 0.2923992673992674,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8877220535874384,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3006410256410257,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9012160916007068,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3358974358974359,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8870350803043112,\n",
              "                             1: 0.0,\n",
              "                             2: 0.36538461538461536,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.8123925753733446,\n",
              "                             1: 0.0,\n",
              "                             2: 0.5474358974358974,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9349679166986861,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3153846153846154,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9050571223648145,\n",
              "                             1: 0.0,\n",
              "                             2: 0.517948717948718,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9305338358222977,\n",
              "                             1: 0.0,\n",
              "                             2: 0.38461538461538464,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.8567336096162068,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3406898656898657,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9084802517965714,\n",
              "                             1: 0.0,\n",
              "                             2: 0.27673992673992676,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9003091532096259,\n",
              "                             1: 0.0,\n",
              "                             2: 0.39299034299034297,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.90543542675313,\n",
              "                             1: 0.0,\n",
              "                             2: 0.347954822954823,\n",
              "                             3: 0.0}]}),\n",
              "              2: defaultdict(None,\n",
              "                          {'train_loss_values': [0.8624383830107175,\n",
              "                            0.8624383830107175,\n",
              "                            0.6251340684982446,\n",
              "                            0.6251340684982446,\n",
              "                            0.36527836030492417,\n",
              "                            0.36527836030492417,\n",
              "                            0.21694921164845044,\n",
              "                            0.21694921164845044],\n",
              "                           'train_acc_all': [0.6600961538461538,\n",
              "                            0.7783653846153846,\n",
              "                            0.8658653846153846,\n",
              "                            0.9317307692307693],\n",
              "                           'train_precision_all': [{0: 0.6677566023719869,\n",
              "                             1: 0.001282051282051282,\n",
              "                             2: 0.17448717948717948,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8059432020970482,\n",
              "                             1: 0.007692307692307693,\n",
              "                             2: 0.6715842490842489,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9046073797996869,\n",
              "                             1: 0.12307692307692308,\n",
              "                             2: 0.7800305250305247,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9559623282700204,\n",
              "                             1: 0.4128205128205128,\n",
              "                             2: 0.8682692307692307,\n",
              "                             3: 0.0}],\n",
              "                           'train_recall_all': [{0: 0.9800035434650818,\n",
              "                             1: 0.002564102564102564,\n",
              "                             2: 0.08557997557997556,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9405099387791693,\n",
              "                             1: 0.0038461538461538464,\n",
              "                             2: 0.6169352869352868,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9619382753998138,\n",
              "                             1: 0.08397435897435897,\n",
              "                             2: 0.8751221001220998,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9904944201098046,\n",
              "                             1: 0.3192307692307692,\n",
              "                             2: 0.9683669108669107,\n",
              "                             3: 0.0}],\n",
              "                           'train_f1_all': [{0: 0.7866385930322793,\n",
              "                             1: 0.0017094017094017094,\n",
              "                             2: 0.10227161727161731,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8603308137552368,\n",
              "                             1: 0.005128205128205128,\n",
              "                             2: 0.6002273794581487,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9281436662091571,\n",
              "                             1: 0.09384615384615386,\n",
              "                             2: 0.807074500411604,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9715208040944956,\n",
              "                             1: 0.3471794871794871,\n",
              "                             2: 0.9030468325038455,\n",
              "                             3: 0.0}],\n",
              "                           'val_acc_all': [0.8100961538461539,\n",
              "                            0.8076923076923077,\n",
              "                            0.8629807692307693,\n",
              "                            0.8605769230769231],\n",
              "                           'val_precision_all': [{0: 0.8795593829247677,\n",
              "                             1: 0.0,\n",
              "                             2: 0.2692307692307692,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8706777730816193,\n",
              "                             1: 0.0,\n",
              "                             2: 0.32967032967032966,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8869329388560158, 1: 0.0, 2: 0.375, 3: 0.0},\n",
              "                            {0: 0.8990965765004227,\n",
              "                             1: 0.0,\n",
              "                             2: 0.46153846153846156,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.9150697059350907,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3243589743589744,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8397664835164836,\n",
              "                             1: 0.0,\n",
              "                             2: 0.5653846153846153,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9630846717385178,\n",
              "                             1: 0.0,\n",
              "                             2: 0.33974358974358976,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9486960155229386,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3942307692307692,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.8935034553729053,\n",
              "                             1: 0.0,\n",
              "                             2: 0.2612942612942613,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8522564310509522,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3798652202498356,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9210496081667506,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3326923076923076,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.920645348709679,\n",
              "                             1: 0.0,\n",
              "                             2: 0.38333333333333336,\n",
              "                             3: 0.0}]}),\n",
              "              3: defaultdict(None,\n",
              "                          {'train_loss_values': [0.8937746508368131,\n",
              "                            0.8937746508368131,\n",
              "                            0.5689857302040889,\n",
              "                            0.5689857302040889,\n",
              "                            0.2869614817715924,\n",
              "                            0.2869614817715924,\n",
              "                            0.14405472738475636,\n",
              "                            0.14405472738475636],\n",
              "                           'train_acc_all': [0.628448275862069,\n",
              "                            0.7922413793103448,\n",
              "                            0.9099137931034482,\n",
              "                            0.9646551724137931],\n",
              "                           'train_precision_all': [{0: 0.6714834016558152,\n",
              "                             1: 0.004300871542250852,\n",
              "                             2: 0.41219885478506163,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8369299091712885,\n",
              "                             1: 0.1103448275862069,\n",
              "                             2: 0.7206503458227593,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9248722733205488,\n",
              "                             1: 0.5331034482758621,\n",
              "                             2: 0.8912967109518831,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9604281924971579,\n",
              "                             1: 0.6770114942528735,\n",
              "                             2: 0.9731116584564861,\n",
              "                             3: 0.020689655172413793}],\n",
              "                           'train_recall_all': [{0: 0.8714010319182732,\n",
              "                             1: 0.020689655172413793,\n",
              "                             2: 0.3617487684729064,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9263271211547073,\n",
              "                             1: 0.0706896551724138,\n",
              "                             2: 0.7917077175697863,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9692567202912028,\n",
              "                             1: 0.4586206896551725,\n",
              "                             2: 0.9345618749067026,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9878240533412946,\n",
              "                             1: 0.664712643678161,\n",
              "                             2: 0.9977586206896553,\n",
              "                             3: 0.01264367816091954}],\n",
              "                           'train_f1_all': [{0: 0.7296311153445744,\n",
              "                             1: 0.007068965517241379,\n",
              "                             2: 0.346192412145225,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8695433194818314,\n",
              "                             1: 0.0832183908045977,\n",
              "                             2: 0.7241151264782092,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9433489054013976,\n",
              "                             1: 0.4772632731253421,\n",
              "                             2: 0.90270593391283,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9723157731991703,\n",
              "                             1: 0.6676737821565408,\n",
              "                             2: 0.9837040737040734,\n",
              "                             3: 0.014942528735632184}],\n",
              "                           'val_acc_all': [0.84375,\n",
              "                            0.8125,\n",
              "                            0.8125,\n",
              "                            0.8341346153846154],\n",
              "                           'val_precision_all': [{0: 0.896529912395297,\n",
              "                             1: 0.0,\n",
              "                             2: 0.37307692307692314,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.906809376520915,\n",
              "                             1: 0.0,\n",
              "                             2: 0.30000000000000004,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9156041074310306,\n",
              "                             1: 0.03205128205128205,\n",
              "                             2: 0.3358974358974359,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9027719075795999,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.40961538461538455,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.9375907746100054,\n",
              "                             1: 0.0,\n",
              "                             2: 0.41025641025641024,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8861185289069904,\n",
              "                             1: 0.0,\n",
              "                             2: 0.4141025641025641,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8772315825200442,\n",
              "                             1: 0.057692307692307696,\n",
              "                             2: 0.46794871794871795,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9183361510284587,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.4493589743589743,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.9137354348999769,\n",
              "                             1: 0.0,\n",
              "                             2: 0.35732600732600744,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8926279585857492,\n",
              "                             1: 0.0,\n",
              "                             2: 0.33137973137973137,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8924733345487342,\n",
              "                             1: 0.041025641025641026,\n",
              "                             2: 0.3673160173160173,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9043344961780906,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.37728937728937734,\n",
              "                             3: 0.0}]}),\n",
              "              4: defaultdict(None,\n",
              "                          {'train_loss_values': [0.9589870687574148,\n",
              "                            0.9589870687574148,\n",
              "                            0.5834763702936471,\n",
              "                            0.5834763702936471,\n",
              "                            0.22787587493658065,\n",
              "                            0.22787587493658065,\n",
              "                            0.06914466893067583,\n",
              "                            0.06914466893067583],\n",
              "                           'train_acc_all': [0.594921875,\n",
              "                            0.794140625,\n",
              "                            0.92578125,\n",
              "                            0.987890625],\n",
              "                           'train_precision_all': [{0: 0.5962622533716284,\n",
              "                             1: 0.0,\n",
              "                             2: 0.4607106782106782,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.800553656413031,\n",
              "                             1: 0.0125,\n",
              "                             2: 0.8082598304473301,\n",
              "                             3: 0.05625},\n",
              "                            {0: 0.9233049068986571,\n",
              "                             1: 0.5098958333333333,\n",
              "                             2: 0.9492336309523809,\n",
              "                             3: 0.20625},\n",
              "                            {0: 0.9865208749583749,\n",
              "                             1: 0.7677083333333333,\n",
              "                             2: 0.9956175595238095,\n",
              "                             3: 0.30625}],\n",
              "                           'train_recall_all': [{0: 0.8836346466033961,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3487723214285714,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9224038808413809,\n",
              "                             1: 0.009375,\n",
              "                             2: 0.8508655753968253,\n",
              "                             3: 0.04583333333333333},\n",
              "                            {0: 0.9846327110389611,\n",
              "                             1: 0.4403125,\n",
              "                             2: 0.9602777777777778,\n",
              "                             3: 0.2},\n",
              "                            {0: 0.9942311507936509,\n",
              "                             1: 0.7497916666666667,\n",
              "                             2: 1.0,\n",
              "                             3: 0.303125}],\n",
              "                           'train_f1_all': [{0: 0.6955412364557897,\n",
              "                             1: 0.0,\n",
              "                             2: 0.360488826779945,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.846850602365358,\n",
              "                             1: 0.010416666666666666,\n",
              "                             2: 0.805934012023408,\n",
              "                             3: 0.04895833333333333},\n",
              "                            {0: 0.9493616373867078,\n",
              "                             1: 0.45508928571428564,\n",
              "                             2: 0.9504624493798255,\n",
              "                             3: 0.20208333333333334},\n",
              "                            {0: 0.9893652460650879,\n",
              "                             1: 0.753561507936508,\n",
              "                             2: 0.997523616734143,\n",
              "                             3: 0.3041666666666667}],\n",
              "                           'val_acc_all': [0.8389423076923077,\n",
              "                            0.8557692307692307,\n",
              "                            0.8221153846153846,\n",
              "                            0.8365384615384616],\n",
              "                           'val_precision_all': [{0: 0.8649725274725275,\n",
              "                             1: 0.0,\n",
              "                             2: 0.25,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8799292054099747,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.3269230769230769,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8997289569404955,\n",
              "                             1: 0.1282051282051282,\n",
              "                             2: 0.40384615384615385,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9018095686364916,\n",
              "                             1: 0.09615384615384616,\n",
              "                             2: 0.3557692307692308,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.9628733446041138,\n",
              "                             1: 0.0,\n",
              "                             2: 0.17307692307692307,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9620554125361817,\n",
              "                             1: 0.019230769230769232,\n",
              "                             2: 0.3019230769230769,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9070741758241762,\n",
              "                             1: 0.12820512820512822,\n",
              "                             2: 0.34615384615384615,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9246240938548631,\n",
              "                             1: 0.08974358974358973,\n",
              "                             2: 0.33012820512820507,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.9093181223069133,\n",
              "                             1: 0.0,\n",
              "                             2: 0.18846153846153849,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9173449532607424,\n",
              "                             1: 0.02564102564102564,\n",
              "                             2: 0.30448717948717946,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9004091678812014,\n",
              "                             1: 0.11538461538461539,\n",
              "                             2: 0.3525641025641026,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.908728323449809,\n",
              "                             1: 0.08717948717948718,\n",
              "                             2: 0.3115384615384616,\n",
              "                             3: 0.0}]}),\n",
              "              5: defaultdict(None,\n",
              "                          {'train_loss_values': [0.9364669321264539,\n",
              "                            0.9364669321264539,\n",
              "                            0.4434453672170639,\n",
              "                            0.4434453672170639,\n",
              "                            0.13035391686218126,\n",
              "                            0.13035391686218126,\n",
              "                            0.04268081501392382,\n",
              "                            0.04268081501392382],\n",
              "                           'train_acc_all': [0.6057142857142858,\n",
              "                            0.8553571428571428,\n",
              "                            0.9625,\n",
              "                            0.9871428571428571],\n",
              "                           'train_precision_all': [{0: 0.633224799010513,\n",
              "                             1: 0.0,\n",
              "                             2: 0.5895920111634397,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8466351109208248,\n",
              "                             1: 0.30076190476190473,\n",
              "                             2: 0.8661381317095604,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9504674056102628,\n",
              "                             1: 0.774761904761905,\n",
              "                             2: 0.9886097711811997,\n",
              "                             3: 0.03428571428571429},\n",
              "                            {0: 0.9815963084534511,\n",
              "                             1: 0.8157142857142857,\n",
              "                             2: 0.995875283446712,\n",
              "                             3: 0.2057142857142857}],\n",
              "                           'train_recall_all': [{0: 0.7984700061842919,\n",
              "                             1: 0.0,\n",
              "                             2: 0.5680626674912388,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9379193504907792,\n",
              "                             1: 0.23609523809523808,\n",
              "                             2: 0.9512719027004739,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9859113584827872,\n",
              "                             1: 0.7861904761904761,\n",
              "                             2: 0.9942698412698413,\n",
              "                             3: 0.03142857142857143},\n",
              "                            {0: 0.9942630385487529,\n",
              "                             1: 0.8228571428571428,\n",
              "                             2: 1.0,\n",
              "                             3: 0.19904761904761906}],\n",
              "                           'train_f1_all': [{0: 0.6802094609371386,\n",
              "                             1: 0.0,\n",
              "                             2: 0.5345858063996054,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8821531409126355,\n",
              "                             1: 0.25052607709750563,\n",
              "                             2: 0.8979828540186399,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9657209551934045,\n",
              "                             1: 0.7743673469387755,\n",
              "                             2: 0.9906037727568023,\n",
              "                             3: 0.03238095238095238},\n",
              "                            {0: 0.9870920172913595,\n",
              "                             1: 0.8182312925170068,\n",
              "                             2: 0.9977688716512245,\n",
              "                             3: 0.20095238095238097}],\n",
              "                           'val_acc_all': [0.8221153846153846,\n",
              "                            0.8365384615384616,\n",
              "                            0.8413461538461539,\n",
              "                            0.8413461538461539],\n",
              "                           'val_precision_all': [{0: 0.8947397154127926,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3461538461538461,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9003663003663005,\n",
              "                             1: 0.11538461538461539,\n",
              "                             2: 0.44551282051282054,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.902997483285945,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.38846153846153847,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9022797715105408,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.37820512820512814,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.9108931132969595,\n",
              "                             1: 0.0,\n",
              "                             2: 0.4224358974358975,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9213704564666103,\n",
              "                             1: 0.08974358974358973,\n",
              "                             2: 0.46474358974358976,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9235933937857015,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.35833333333333334,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9322672519787905,\n",
              "                             1: 0.057692307692307696,\n",
              "                             2: 0.36538461538461536,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.8984362149010903,\n",
              "                             1: 0.0,\n",
              "                             2: 0.33818681318681326,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9087166133512502,\n",
              "                             1: 0.09615384615384616,\n",
              "                             2: 0.408974358974359,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9113287284238658,\n",
              "                             1: 0.0705128205128205,\n",
              "                             2: 0.3416361416361416,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9155278972931995,\n",
              "                             1: 0.0641025641025641,\n",
              "                             2: 0.3641025641025641,\n",
              "                             3: 0.0}]}),\n",
              "              6: defaultdict(None,\n",
              "                          {'train_loss_values': [0.8778875551725689,\n",
              "                            0.8778875551725689,\n",
              "                            0.2587127476538483,\n",
              "                            0.2587127476538483,\n",
              "                            0.04046441751140121,\n",
              "                            0.04046441751140121,\n",
              "                            0.012657683068812873,\n",
              "                            0.012657683068812873],\n",
              "                           'train_acc_all': [0.6207236842105263,\n",
              "                            0.9134868421052632,\n",
              "                            0.9875,\n",
              "                            0.9986842105263158],\n",
              "                           'train_precision_all': [{0: 0.5991783654941547,\n",
              "                             1: 0.013157894736842105,\n",
              "                             2: 0.6446520073493757,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8981170729854943,\n",
              "                             1: 0.6827192982456141,\n",
              "                             2: 0.9386485882538513,\n",
              "                             3: 0.10263157894736842},\n",
              "                            {0: 0.9885252904989748,\n",
              "                             1: 0.800438596491228,\n",
              "                             2: 0.9887949039264828,\n",
              "                             3: 0.32105263157894737},\n",
              "                            {0: 0.9947368421052631,\n",
              "                             1: 0.8105263157894737,\n",
              "                             2: 0.9980054302422724,\n",
              "                             3: 0.3631578947368421}],\n",
              "                           'train_recall_all': [{0: 0.7000379445116284,\n",
              "                             1: 0.015789473684210527,\n",
              "                             2: 0.7242543421490787,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9512231335915549,\n",
              "                             1: 0.6097368421052631,\n",
              "                             2: 0.9616395154553049,\n",
              "                             3: 0.09122807017543859},\n",
              "                            {0: 0.9873410799726591,\n",
              "                             1: 0.8017543859649122,\n",
              "                             2: 0.9982894736842106,\n",
              "                             3: 0.3157894736842105},\n",
              "                            {0: 0.9924415204678363,\n",
              "                             1: 0.8105263157894737,\n",
              "                             2: 1.0,\n",
              "                             3: 0.3631578947368421}],\n",
              "                           'train_f1_all': [{0: 0.6166629837224447,\n",
              "                             1: 0.014035087719298244,\n",
              "                             2: 0.6425312787096479,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9162955442683357,\n",
              "                             1: 0.6278089162299688,\n",
              "                             2: 0.9455780539685537,\n",
              "                             3: 0.09385964912280702},\n",
              "                            {0: 0.9869765114926857,\n",
              "                             1: 0.7987969924812031,\n",
              "                             2: 0.9929114750330327,\n",
              "                             3: 0.3175438596491228},\n",
              "                            {0: 0.9934915720674234,\n",
              "                             1: 0.8105263157894737,\n",
              "                             2: 0.9989346669842025,\n",
              "                             3: 0.3631578947368421}],\n",
              "                           'val_acc_all': [0.8173076923076923,\n",
              "                            0.8365384615384616,\n",
              "                            0.8293269230769231,\n",
              "                            0.8413461538461539],\n",
              "                           'val_precision_all': [{0: 0.8824953892261586,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3391025641025641,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8831519442096365,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.36538461538461536,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8937192615077231,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.3397435897435897,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8887961397576782,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.34615384615384615,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.915680473372781,\n",
              "                             1: 0.0,\n",
              "                             2: 0.42435897435897435,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9399365058018904,\n",
              "                             1: 0.019230769230769232,\n",
              "                             2: 0.24294871794871792,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9254175311867621,\n",
              "                             1: 0.01282051282051282,\n",
              "                             2: 0.3589743589743589,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9447416365685596,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.20769230769230768,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.893902534531461,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3473137973137973,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.906176546153704,\n",
              "                             1: 0.02564102564102564,\n",
              "                             2: 0.26318681318681325,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9067875022759122,\n",
              "                             1: 0.019230769230769232,\n",
              "                             2: 0.31153846153846154,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9135620447713408,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.2500610500610501,\n",
              "                             3: 0.0}]}),\n",
              "              7: defaultdict(None,\n",
              "                          {'train_loss_values': [0.8601746131007264,\n",
              "                            0.8601746131007264,\n",
              "                            0.21651931585880316,\n",
              "                            0.21651931585880316,\n",
              "                            0.03806749875316533,\n",
              "                            0.03806749875316533,\n",
              "                            0.008808928741732749,\n",
              "                            0.008808928741732749],\n",
              "                           'train_acc_all': [0.6347560975609756,\n",
              "                            0.9295731707317073,\n",
              "                            0.9908536585365854,\n",
              "                            0.9984756097560976],\n",
              "                           'train_precision_all': [{0: 0.6085349745105841,\n",
              "                             1: 0.05365853658536585,\n",
              "                             2: 0.6650008663423297,\n",
              "                             3: 0.004878048780487805},\n",
              "                            {0: 0.9155125091710458,\n",
              "                             1: 0.7821951219512193,\n",
              "                             2: 0.939889676718945,\n",
              "                             3: 0.05365853658536585},\n",
              "                            {0: 0.9927332559039878,\n",
              "                             1: 0.8565040650406504,\n",
              "                             2: 0.9904861669495815,\n",
              "                             3: 0.28780487804878047},\n",
              "                            {0: 0.998780487804878,\n",
              "                             1: 0.8463414634146341,\n",
              "                             2: 0.9989024390243902,\n",
              "                             3: 0.3902439024390244}],\n",
              "                           'train_recall_all': [{0: 0.71454316686024,\n",
              "                             1: 0.029268292682926824,\n",
              "                             2: 0.7583799669165523,\n",
              "                             3: 0.004878048780487805},\n",
              "                            {0: 0.9494427523695818,\n",
              "                             1: 0.7508943089430894,\n",
              "                             2: 0.9818176538908246,\n",
              "                             3: 0.04227642276422765},\n",
              "                            {0: 0.9930621546475206,\n",
              "                             1: 0.8658536585365854,\n",
              "                             2: 0.99869918699187,\n",
              "                             3: 0.2686991869918699},\n",
              "                            {0: 0.9969918699186991,\n",
              "                             1: 0.848780487804878,\n",
              "                             2: 1.0,\n",
              "                             3: 0.3902439024390244}],\n",
              "                           'train_f1_all': [{0: 0.632346717366075,\n",
              "                             1: 0.03626016260162602,\n",
              "                             2: 0.6828184954984772,\n",
              "                             3: 0.004878048780487805},\n",
              "                            {0: 0.9249737134722839,\n",
              "                             1: 0.7521641502129309,\n",
              "                             2: 0.9572729159804595,\n",
              "                             3: 0.04617886178861789},\n",
              "                            {0: 0.9920681810072433,\n",
              "                             1: 0.8591405342624856,\n",
              "                             2: 0.9940544320974737,\n",
              "                             3: 0.2754006968641115},\n",
              "                            {0: 0.9976672649843382,\n",
              "                             1: 0.8471544715447153,\n",
              "                             2: 0.9994180573384681,\n",
              "                             3: 0.3902439024390244}],\n",
              "                           'val_acc_all': [0.8197115384615384,\n",
              "                            0.8677884615384616,\n",
              "                            0.8605769230769231,\n",
              "                            0.8509615384615384],\n",
              "                           'val_precision_all': [{0: 0.8828061361715208,\n",
              "                             1: 0.0,\n",
              "                             2: 0.2705128205128205,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8417353479853482,\n",
              "                             1: 0.0,\n",
              "                             2: 0.4166666666666667,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8863394618202312,\n",
              "                             1: 0.0,\n",
              "                             2: 0.391025641025641,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8856254322600476,\n",
              "                             1: 0.0,\n",
              "                             2: 0.4102564102564102,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.9157931811777966,\n",
              "                             1: 0.0,\n",
              "                             2: 0.28846153846153844,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9454212454212455,\n",
              "                             1: 0.0,\n",
              "                             2: 0.31858974358974357,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9693857424626656,\n",
              "                             1: 0.0,\n",
              "                             2: 0.2980769230769231,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9539017072670919,\n",
              "                             1: 0.0,\n",
              "                             2: 0.30128205128205127,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.897211147241802,\n",
              "                             1: 0.0,\n",
              "                             2: 0.25851648351648354,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8873230882899747,\n",
              "                             1: 0.0,\n",
              "                             2: 0.3282051282051282,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9236460156533747,\n",
              "                             1: 0.0,\n",
              "                             2: 0.31923076923076926,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9156712940109022,\n",
              "                             1: 0.0,\n",
              "                             2: 0.33095238095238094,\n",
              "                             3: 0.0}]}),\n",
              "              8: defaultdict(None,\n",
              "                          {'train_loss_values': [0.8415083402937109,\n",
              "                            0.8415083402937109,\n",
              "                            0.19459700620394538,\n",
              "                            0.19459700620394538,\n",
              "                            0.02927654645172879,\n",
              "                            0.02927654645172879,\n",
              "                            0.010348613124171442,\n",
              "                            0.010348613124171442],\n",
              "                           'train_acc_all': [0.6446022727272728,\n",
              "                            0.9457386363636363,\n",
              "                            0.9931818181818182,\n",
              "                            0.9994318181818181],\n",
              "                           'train_precision_all': [{0: 0.6187689835417106,\n",
              "                             1: 0.20643939393939392,\n",
              "                             2: 0.6606569062250877,\n",
              "                             3: 0.00909090909090909},\n",
              "                            {0: 0.9263938082119904,\n",
              "                             1: 0.7631060606060606,\n",
              "                             2: 0.9592510645919737,\n",
              "                             3: 0.18181818181818182},\n",
              "                            {0: 0.9960046897546898,\n",
              "                             1: 0.8733333333333333,\n",
              "                             2: 0.9950757575757576,\n",
              "                             3: 0.38181818181818183},\n",
              "                            {0: 1.0,\n",
              "                             1: 0.8863636363636364,\n",
              "                             2: 0.9988636363636364,\n",
              "                             3: 0.37272727272727274}],\n",
              "                           'train_recall_all': [{0: 0.6463355962219594,\n",
              "                             1: 0.1306060606060606,\n",
              "                             2: 0.8085865144956055,\n",
              "                             3: 0.00909090909090909},\n",
              "                            {0: 0.9512624622851897,\n",
              "                             1: 0.7533333333333334,\n",
              "                             2: 0.9814510363374,\n",
              "                             3: 0.17272727272727273},\n",
              "                            {0: 0.9924729437229438,\n",
              "                             1: 0.8886363636363637,\n",
              "                             2: 0.9978860028860029,\n",
              "                             3: 0.37613636363636366},\n",
              "                            {0: 0.9987824675324676,\n",
              "                             1: 0.8863636363636364,\n",
              "                             2: 1.0,\n",
              "                             3: 0.37272727272727274}],\n",
              "                           'train_f1_all': [{0: 0.5986368428378703,\n",
              "                             1: 0.15063852813852815,\n",
              "                             2: 0.7064699975788057,\n",
              "                             3: 0.00909090909090909},\n",
              "                            {0: 0.9329264335751813,\n",
              "                             1: 0.7475245966155057,\n",
              "                             2: 0.968101637243352,\n",
              "                             3: 0.17575757575757575},\n",
              "                            {0: 0.9936336687673588,\n",
              "                             1: 0.877979797979798,\n",
              "                             2: 0.9962236957843854,\n",
              "                             3: 0.3781385281385282},\n",
              "                            {0: 0.9993473193473192,\n",
              "                             1: 0.8863636363636364,\n",
              "                             2: 0.9993939393939394,\n",
              "                             3: 0.37272727272727274}],\n",
              "                           'val_acc_all': [0.7403846153846154,\n",
              "                            0.8485576923076923,\n",
              "                            0.8269230769230769,\n",
              "                            0.84375],\n",
              "                           'val_precision_all': [{0: 0.9110852288736904,\n",
              "                             1: 0.0,\n",
              "                             2: 0.21904761904761905,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8714056776556778,\n",
              "                             1: 0.0,\n",
              "                             2: 0.34615384615384615,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8859643561566638,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.3173076923076923,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8910062693716542,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.3974358974358974,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.7939796314796316,\n",
              "                             1: 0.0,\n",
              "                             2: 0.43974358974358974,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9686601859678784,\n",
              "                             1: 0.0,\n",
              "                             2: 0.20833333333333334,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.914793059504598,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.32051282051282054,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9454511834319527,\n",
              "                             1: 0.01282051282051282,\n",
              "                             2: 0.33589743589743587,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.8429282395607337,\n",
              "                             1: 0.0,\n",
              "                             2: 0.2796176046176046,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9157671396988588,\n",
              "                             1: 0.0,\n",
              "                             2: 0.24230769230769234,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8981347716652457,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.30109890109890114,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9130783467099925,\n",
              "                             1: 0.019230769230769232,\n",
              "                             2: 0.3322344322344322,\n",
              "                             3: 0.0}]}),\n",
              "              9: defaultdict(None,\n",
              "                          {'train_loss_values': [0.8769977608259688,\n",
              "                            0.8769977608259688,\n",
              "                            0.17373846109679086,\n",
              "                            0.17373846109679086,\n",
              "                            0.020117474153162316,\n",
              "                            0.020117474153162316,\n",
              "                            0.006488493516387299,\n",
              "                            0.006488493516387299],\n",
              "                           'train_acc_all': [0.6127659574468085,\n",
              "                            0.9452127659574469,\n",
              "                            0.9957446808510638,\n",
              "                            0.999468085106383],\n",
              "                           'train_precision_all': [{0: 0.5332631493801705,\n",
              "                             1: 0.2630668385987535,\n",
              "                             2: 0.6452277804937379,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9153622854686685,\n",
              "                             1: 0.8384397163120568,\n",
              "                             2: 0.9622883853734917,\n",
              "                             3: 0.15319148936170213},\n",
              "                            {0: 0.9986828774062817,\n",
              "                             1: 0.8840425531914894,\n",
              "                             2: 0.9925444413742287,\n",
              "                             3: 0.39432624113475173},\n",
              "                            {0: 0.999290780141844,\n",
              "                             1: 0.8808510638297873,\n",
              "                             2: 0.9996131528046421,\n",
              "                             3: 0.425531914893617}],\n",
              "                           'train_recall_all': [{0: 0.5280854134045623,\n",
              "                             1: 0.2177304964539007,\n",
              "                             2: 0.8148945380860274,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9432286389733201,\n",
              "                             1: 0.8422695035460993,\n",
              "                             2: 0.9779931534186854,\n",
              "                             3: 0.13758865248226948},\n",
              "                            {0: 0.9895253446317277,\n",
              "                             1: 0.8851063829787233,\n",
              "                             2: 0.9993920972644377,\n",
              "                             3: 0.39574468085106385},\n",
              "                            {0: 0.9989361702127659,\n",
              "                             1: 0.8808510638297873,\n",
              "                             2: 0.999468085106383,\n",
              "                             3: 0.425531914893617}],\n",
              "                           'train_f1_all': [{0: 0.49442136306045154,\n",
              "                             1: 0.22282233133296955,\n",
              "                             2: 0.6934928011652203,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9225761673278304,\n",
              "                             1: 0.836453593687636,\n",
              "                             2: 0.9676425209143735,\n",
              "                             3: 0.1425531914893617},\n",
              "                            {0: 0.9932774483858076,\n",
              "                             1: 0.8844984802431611,\n",
              "                             2: 0.9956245666143908,\n",
              "                             3: 0.39489361702127657},\n",
              "                            {0: 0.9990052500690798,\n",
              "                             1: 0.8808510638297873,\n",
              "                             2: 0.9995136778115501,\n",
              "                             3: 0.425531914893617}],\n",
              "                           'val_acc_all': [0.6466346153846154,\n",
              "                            0.8293269230769231,\n",
              "                            0.8701923076923077,\n",
              "                            0.8677884615384616],\n",
              "                           'val_precision_all': [{0: 0.8949278285816749,\n",
              "                             1: 0.0,\n",
              "                             2: 0.1772283272283272,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.89668312456774,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.3653846153846153,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8865578331924487,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.45512820512820507,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8938953674530599,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.3878205128205128,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.6829508632393247,\n",
              "                             1: 0.0,\n",
              "                             2: 0.5064102564102564,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9156452521837137,\n",
              "                             1: 0.019230769230769232,\n",
              "                             2: 0.3814102564102564,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.971407438715131,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.35256410256410253,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9640356438433362,\n",
              "                             1: 0.057692307692307696,\n",
              "                             2: 0.3108974358974359,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.7690095684075616,\n",
              "                             1: 0.0,\n",
              "                             2: 0.24758019758019756,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9034160594392329,\n",
              "                             1: 0.02564102564102564,\n",
              "                             2: 0.3437728937728938,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9244793408898827,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.37692307692307697,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9250230609766846,\n",
              "                             1: 0.0641025641025641,\n",
              "                             2: 0.3174908424908425,\n",
              "                             3: 0.0}]}),\n",
              "              10: defaultdict(None,\n",
              "                          {'train_loss_values': [0.817722700715065,\n",
              "                            0.817722700715065,\n",
              "                            0.15943115341477096,\n",
              "                            0.15943115341477096,\n",
              "                            0.014007316500414162,\n",
              "                            0.014007316500414162,\n",
              "                            0.006051703524310142,\n",
              "                            0.006051703524310142],\n",
              "                           'train_acc_all': [0.68025,\n",
              "                            0.95325,\n",
              "                            0.99775,\n",
              "                            0.99925],\n",
              "                           'train_precision_all': [{0: 0.632952092352092,\n",
              "                             1: 0.152,\n",
              "                             2: 0.704033127983128,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.935980230880231,\n",
              "                             1: 0.8292,\n",
              "                             2: 0.9630613275613276,\n",
              "                             3: 0.184},\n",
              "                            {0: 0.9921285714285715,\n",
              "                             1: 0.872,\n",
              "                             2: 0.9985145299145299,\n",
              "                             3: 0.408},\n",
              "                            {0: 1.0,\n",
              "                             1: 0.872,\n",
              "                             2: 0.9986285714285715,\n",
              "                             3: 0.456}],\n",
              "                           'train_recall_all': [{0: 0.6501936507936507,\n",
              "                             1: 0.09066666666666667,\n",
              "                             2: 0.8967128094128092,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9558714285714289,\n",
              "                             1: 0.8152,\n",
              "                             2: 0.9945764346764349,\n",
              "                             3: 0.182},\n",
              "                            {0: 0.9928666666666667,\n",
              "                             1: 0.872,\n",
              "                             2: 0.9978030303030303,\n",
              "                             3: 0.408},\n",
              "                            {0: 0.9985, 1: 0.872, 2: 1.0, 3: 0.456}],\n",
              "                           'train_f1_all': [{0: 0.604428677136417,\n",
              "                             1: 0.1082698412698413,\n",
              "                             2: 0.770964146270664,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9377822675088927,\n",
              "                             1: 0.8149079365079364,\n",
              "                             2: 0.9766307969059403,\n",
              "                             3: 0.18266666666666664},\n",
              "                            {0: 0.9920224664224664,\n",
              "                             1: 0.872,\n",
              "                             2: 0.9980572413130012,\n",
              "                             3: 0.408},\n",
              "                            {0: 0.9992000000000001,\n",
              "                             1: 0.872,\n",
              "                             2: 0.9992478632478633,\n",
              "                             3: 0.456}],\n",
              "                           'val_acc_all': [0.7788461538461539,\n",
              "                            0.8245192307692307,\n",
              "                            0.8533653846153846,\n",
              "                            0.8653846153846154],\n",
              "                           'val_precision_all': [{0: 0.8558937857014779,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.3256410256410257,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.84912123133277,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.4455128205128205,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9040680473372782,\n",
              "                             1: 0.11538461538461539,\n",
              "                             2: 0.423076923076923,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9028793322062554,\n",
              "                             1: 0.11538461538461539,\n",
              "                             2: 0.4012820512820513,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.8593459425190196,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.3243589743589744,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9252888137503523,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.3685897435897436,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.934725530879377,\n",
              "                             1: 0.09615384615384616,\n",
              "                             2: 0.5121794871794871,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9472836458413382,\n",
              "                             1: 0.10256410256410256,\n",
              "                             2: 0.4198717948717948,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.8542781887656534,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.29056776556776565,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8835986407551246,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.39065934065934066,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9163424979990396,\n",
              "                             1: 0.10256410256410256,\n",
              "                             2: 0.4067765567765568,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9215107286672125,\n",
              "                             1: 0.10769230769230768,\n",
              "                             2: 0.3828754578754578,\n",
              "                             3: 0.0}]}),\n",
              "              11: defaultdict(None,\n",
              "                          {'train_loss_values': [0.814566632261816,\n",
              "                            0.814566632261816,\n",
              "                            0.13583559820709645,\n",
              "                            0.13583559820709645,\n",
              "                            0.024555010073554685,\n",
              "                            0.024555010073554685,\n",
              "                            0.00769108457376583,\n",
              "                            0.00769108457376583],\n",
              "                           'train_acc_all': [0.6702830188679245,\n",
              "                            0.9636792452830188,\n",
              "                            0.994811320754717,\n",
              "                            0.9985849056603774],\n",
              "                           'train_precision_all': [{0: 0.5942955262766585,\n",
              "                             1: 0.16981132075471697,\n",
              "                             2: 0.7049549192945419,\n",
              "                             3: 0.0037735849056603774},\n",
              "                            {0: 0.9348317405864575,\n",
              "                             1: 0.8628930817610062,\n",
              "                             2: 0.977064633479728,\n",
              "                             3: 0.3018867924528302},\n",
              "                            {0: 0.998993710691824,\n",
              "                             1: 0.8780503144654087,\n",
              "                             2: 0.9947318195431404,\n",
              "                             3: 0.42452830188679247},\n",
              "                            {0: 0.9962264150943396,\n",
              "                             1: 0.8930817610062893,\n",
              "                             2: 0.9981370306842006,\n",
              "                             3: 0.4037735849056604}],\n",
              "                           'train_recall_all': [{0: 0.5814884696016771,\n",
              "                             1: 0.12465408805031446,\n",
              "                             2: 0.9153052607769592,\n",
              "                             3: 0.0037735849056603774},\n",
              "                            {0: 0.9473808162487407,\n",
              "                             1: 0.8596855345911949,\n",
              "                             2: 0.9917878243349942,\n",
              "                             3: 0.29358490566037737},\n",
              "                            {0: 0.9843261455525607,\n",
              "                             1: 0.8867924528301887,\n",
              "                             2: 0.999245283018868,\n",
              "                             3: 0.42641509433962266},\n",
              "                            {0: 0.9917460317460317,\n",
              "                             1: 0.8943396226415095,\n",
              "                             2: 1.0,\n",
              "                             3: 0.4037735849056604}],\n",
              "                           'train_f1_all': [{0: 0.5460526325684669,\n",
              "                             1: 0.1366157532195268,\n",
              "                             2: 0.777225354802436,\n",
              "                             3: 0.0037735849056603774},\n",
              "                            {0: 0.9343105714310225,\n",
              "                             1: 0.8561558986087288,\n",
              "                             2: 0.9834291468673533,\n",
              "                             3: 0.29643605870020967},\n",
              "                            {0: 0.9904267397613975,\n",
              "                             1: 0.8813896376160528,\n",
              "                             2: 0.9967572734064072,\n",
              "                             3: 0.42515723270440253},\n",
              "                            {0: 0.9937015851333276,\n",
              "                             1: 0.8935849056603774,\n",
              "                             2: 0.9990037043977112,\n",
              "                             3: 0.4037735849056604}],\n",
              "                           'val_acc_all': [0.7235576923076923,\n",
              "                            0.84375,\n",
              "                            0.8629807692307693,\n",
              "                            0.8533653846153846],\n",
              "                           'val_precision_all': [{0: 0.9211104066873298,\n",
              "                             1: 0.15384615384615385,\n",
              "                             2: 0.2233516483516484,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8938961679346297,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.358974358974359,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8521713863060019,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.34615384615384615,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8957383962191655,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.3743589743589744,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.7626194318502013,\n",
              "                             1: 0.1346153846153846,\n",
              "                             2: 0.5147435897435898,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9377729642152719,\n",
              "                             1: 0.019230769230769232,\n",
              "                             2: 0.3794871794871795,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9275650631419862,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.30705128205128207,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9490278951817414,\n",
              "                             1: 0.02564102564102564,\n",
              "                             2: 0.38461538461538464,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.8274184665197162,\n",
              "                             1: 0.14102564102564102,\n",
              "                             2: 0.288003663003663,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9126630838999285,\n",
              "                             1: 0.02564102564102564,\n",
              "                             2: 0.33205128205128204,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.886149902738848,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.3014652014652015,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9186806375039491,\n",
              "                             1: 0.03076923076923077,\n",
              "                             2: 0.3641025641025642,\n",
              "                             3: 0.0}]}),\n",
              "              12: defaultdict(None,\n",
              "                          {'train_loss_values': [0.6432129977004869,\n",
              "                            0.6432129977004869,\n",
              "                            0.06597109772680726,\n",
              "                            0.06597109772680726,\n",
              "                            0.006915276845601121,\n",
              "                            0.006915276845601121,\n",
              "                            0.0022134618047857657,\n",
              "                            0.0022134618047857657],\n",
              "                           'train_acc_all': [0.7537946428571428,\n",
              "                            0.9859375,\n",
              "                            0.9995535714285714,\n",
              "                            0.9993303571428571],\n",
              "                           'train_precision_all': [{0: 0.6439588486909914,\n",
              "                             1: 0.5298129251700681,\n",
              "                             2: 0.7809428220588936,\n",
              "                             3: 0.03214285714285714},\n",
              "                            {0: 0.972080498866213,\n",
              "                             1: 0.8854166666666667,\n",
              "                             2: 0.9866427124462839,\n",
              "                             3: 0.3964285714285714},\n",
              "                            {0: 0.9964285714285714,\n",
              "                             1: 0.9107142857142857,\n",
              "                             2: 0.9992063492063494,\n",
              "                             3: 0.4392857142857143},\n",
              "                            {0: 0.9992857142857143,\n",
              "                             1: 0.9178571428571428,\n",
              "                             2: 0.9990800865800866,\n",
              "                             3: 0.39285714285714285}],\n",
              "                           'train_recall_all': [{0: 0.6332695578231293,\n",
              "                             1: 0.45708333333333334,\n",
              "                             2: 0.9326019813519815,\n",
              "                             3: 0.030357142857142857},\n",
              "                            {0: 0.959234693877551,\n",
              "                             1: 0.8885714285714286,\n",
              "                             2: 0.9952875695732839,\n",
              "                             3: 0.38630952380952377},\n",
              "                            {0: 0.9950255102040816,\n",
              "                             1: 0.9107142857142857,\n",
              "                             2: 1.0,\n",
              "                             3: 0.4392857142857143},\n",
              "                            {0: 0.9988392857142857,\n",
              "                             1: 0.9178571428571428,\n",
              "                             2: 0.9996753246753246,\n",
              "                             3: 0.39285714285714285}],\n",
              "                           'train_f1_all': [{0: 0.6071446029031169,\n",
              "                             1: 0.47506868131868135,\n",
              "                             2: 0.8350160564718406,\n",
              "                             3: 0.030952380952380957},\n",
              "                            {0: 0.9623942992115261,\n",
              "                             1: 0.8864739229024944,\n",
              "                             2: 0.9902797892457209,\n",
              "                             3: 0.38976190476190475},\n",
              "                            {0: 0.9956436420722136,\n",
              "                             1: 0.9107142857142857,\n",
              "                             2: 0.9995798319327731,\n",
              "                             3: 0.4392857142857143},\n",
              "                            {0: 0.998968253968254,\n",
              "                             1: 0.9178571428571428,\n",
              "                             2: 0.9993351886209029,\n",
              "                             3: 0.39285714285714285}],\n",
              "                           'val_acc_all': [0.8509615384615384,\n",
              "                            0.8533653846153846,\n",
              "                            0.8581730769230769,\n",
              "                            0.8605769230769231],\n",
              "                           'val_precision_all': [{0: 0.8837295717103409,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.3333333333333333,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.893505212735982,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.3878205128205128,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8906663848971541,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.37179487179487175,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8847421808960273,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.4294871794871795,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.9590845052383514,\n",
              "                             1: 0.019230769230769232,\n",
              "                             2: 0.3076923076923077,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9492481877097263,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.37820512820512814,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9543339673147364,\n",
              "                             1: 0.01282051282051282,\n",
              "                             2: 0.37179487179487175,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9652315633084864,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.3076923076923077,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.9167822926370885,\n",
              "                             1: 0.02564102564102564,\n",
              "                             2: 0.29633699633699634,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9181571645136329,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.3597069597069597,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9180557064351021,\n",
              "                             1: 0.019230769230769232,\n",
              "                             2: 0.3358974358974359,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9213650017748589,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.33974358974358976,\n",
              "                             3: 0.0}]}),\n",
              "              13: defaultdict(None,\n",
              "                          {'train_loss_values': [0.6494782879948616,\n",
              "                            0.6494782879948616,\n",
              "                            0.07000249868290404,\n",
              "                            0.07000249868290404,\n",
              "                            0.012575789848816092,\n",
              "                            0.012575789848816092,\n",
              "                            0.004213755545048516,\n",
              "                            0.004213755545048516],\n",
              "                           'train_acc_all': [0.7502118644067797,\n",
              "                            0.9815677966101695,\n",
              "                            0.9976694915254237,\n",
              "                            0.9991525423728813],\n",
              "                           'train_precision_all': [{0: 0.6233861618607379,\n",
              "                             1: 0.5359578839239857,\n",
              "                             2: 0.7681887368751779,\n",
              "                             3: 0.1016949152542373},\n",
              "                            {0: 0.9682028517621737,\n",
              "                             1: 0.8866101694915253,\n",
              "                             2: 0.9808749583749587,\n",
              "                             3: 0.3983050847457627},\n",
              "                            {0: 0.992090395480226,\n",
              "                             1: 0.9186440677966101,\n",
              "                             2: 0.9973152459593139,\n",
              "                             3: 0.4542372881355932},\n",
              "                            {0: 0.9932203389830508,\n",
              "                             1: 0.9110169491525424,\n",
              "                             2: 0.99924670433145,\n",
              "                             3: 0.46440677966101696}],\n",
              "                           'train_recall_all': [{0: 0.5636992198009146,\n",
              "                             1: 0.481864406779661,\n",
              "                             2: 0.9434702961821607,\n",
              "                             3: 0.0903954802259887},\n",
              "                            {0: 0.9378221684153887,\n",
              "                             1: 0.8956497175141244,\n",
              "                             2: 0.9947202044659673,\n",
              "                             3: 0.3949152542372881},\n",
              "                            {0: 0.9856698950766746,\n",
              "                             1: 0.9169491525423729,\n",
              "                             2: 0.9996610169491524,\n",
              "                             3: 0.4542372881355932},\n",
              "                            {0: 0.9894350282485875,\n",
              "                             1: 0.911864406779661,\n",
              "                             2: 1.0,\n",
              "                             3: 0.46440677966101696}],\n",
              "                           'train_f1_all': [{0: 0.5627934575846106,\n",
              "                             1: 0.4917284222368968,\n",
              "                             2: 0.831446313473527,\n",
              "                             3: 0.09423728813559323},\n",
              "                            {0: 0.9487382236684334,\n",
              "                             1: 0.8893516276567124,\n",
              "                             2: 0.9870054224082757,\n",
              "                             3: 0.39548022598870053},\n",
              "                            {0: 0.9880508944915727,\n",
              "                             1: 0.9175141242937852,\n",
              "                             2: 0.9983924723884069,\n",
              "                             3: 0.4542372881355932},\n",
              "                            {0: 0.9909213197348791,\n",
              "                             1: 0.9113801452784505,\n",
              "                             2: 0.9996011964107677,\n",
              "                             3: 0.46440677966101696}],\n",
              "                           'val_acc_all': [0.8245192307692307,\n",
              "                            0.8557692307692307,\n",
              "                            0.8509615384615384,\n",
              "                            0.8485576923076923],\n",
              "                           'val_precision_all': [{0: 0.8994559927252236,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.26153846153846155,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8876954775993239,\n",
              "                             1: 0.019230769230769232,\n",
              "                             2: 0.3173076923076923,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.857157105714798,\n",
              "                             1: 0.11538461538461539,\n",
              "                             2: 0.37820512820512814,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8854730205691745,\n",
              "                             1: 0.07692307692307693,\n",
              "                             2: 0.2948717948717948,\n",
              "                             3: 0.0}],\n",
              "                           'val_recall_all': [{0: 0.9153221778221778,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.3416666666666667,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9594560887830119,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.29807692307692313,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9056963869463869,\n",
              "                             1: 0.08653846153846154,\n",
              "                             2: 0.3346153846153846,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9477704987320372,\n",
              "                             1: 0.03205128205128205,\n",
              "                             2: 0.25064102564102564,\n",
              "                             3: 0.0}],\n",
              "                           'val_f1_all': [{0: 0.9039705910624919,\n",
              "                             1: 0.038461538461538464,\n",
              "                             2: 0.28589743589743594,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9198210832109889,\n",
              "                             1: 0.02564102564102564,\n",
              "                             2: 0.29423076923076924,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.8782008425658377,\n",
              "                             1: 0.0923076923076923,\n",
              "                             2: 0.336996336996337,\n",
              "                             3: 0.0},\n",
              "                            {0: 0.9134000355171781,\n",
              "                             1: 0.044871794871794865,\n",
              "                             2: 0.248992673992674,\n",
              "                             3: 0.0}]})}})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ajg8bfSTDuQy"
      },
      "source": [
        "## Incremental rectified training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9Xd9NVkQDuQ0",
        "scrolled": true,
        "colab": {},
        "outputId": "d2dd7d1d-5e86-4960-f52c-d56db7347d7a"
      },
      "source": [
        "import json\n",
        "batch_size = 32\n",
        "lr = 5e-5\n",
        "Bert = Bertnn(train_inputs,train_labels,train_masks, validation_inputs,validation_labels,validation_masks,batch_size=batch_size,lr=lr)\n",
        "all_metrics_one = Bert.searchUpsample(150)\n",
        "\n",
        "\n",
        "del Bert\n",
        "torch.cuda.empty_cache() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: TITAN RTX\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0831 04:52:58.890795 139633676007232 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0831 04:52:58.891639 139633676007232 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0831 04:52:58.991590 139633676007232 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0831 04:53:01.566365 139633676007232 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0831 04:53:01.567780 139633676007232 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current increase 0 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1351 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 53 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 182 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 14 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.844375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.844375\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "53\n",
            "0.033125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "53\n",
            "0.033125\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "182\n",
            "0.11375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "182\n",
            "0.11375\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "14\n",
            "0.00875\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "14\n",
            "0.00875\n",
            "\n",
            "(1600, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0831 04:53:02.249113 139633676007232 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0831 04:53:02.249874 139633676007232 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0831 04:53:02.281864 139633676007232 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0831 04:53:04.872717 139633676007232 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0831 04:53:04.874089 139633676007232 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of     50.    Elapsed: 0:00:15.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.97\n",
            "  Accuracy: 0.83\n",
            "Category: 0\n",
            "  Precision: 0.85\n",
            "  Recall: 0.98\n",
            "  F1: 0.90\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.02\n",
            "  F1: 0.00\n",
            "Category: 2\n",
            "  Precision: 0.00\n",
            "  Recall: 0.01\n",
            "  F1: 0.01\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.2133\n",
            "The average recall is: 0.2541\n",
            "The average f1 is: 0.2274\n",
            "  Training epcoh took: 0:00:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.8355\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9092\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.2089\n",
            "The average recall is: 0.2500\n",
            "The average f1 is: 0.2273\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of     50.    Elapsed: 0:00:15.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 1.19\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.87\n",
            "  Recall: 0.99\n",
            "  F1: 0.92\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "Category: 2\n",
            "  Precision: 0.31\n",
            "  Recall: 0.21\n",
            "  F1: 0.22\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.2959\n",
            "The average recall is: 0.3001\n",
            "The average f1 is: 0.2871\n",
            "  Training epcoh took: 0:00:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8578\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9230\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.5385\n",
            "  Recall: 0.1583\n",
            "  F1: 0.2380\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3491\n",
            "The average recall is: 0.2896\n",
            "The average f1 is: 0.2903\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of     50.    Elapsed: 0:00:15.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 1.04\n",
            "  Accuracy: 0.89\n",
            "Category: 0\n",
            "  Precision: 0.91\n",
            "  Recall: 0.98\n",
            "  F1: 0.94\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "Category: 2\n",
            "  Precision: 0.62\n",
            "  Recall: 0.53\n",
            "  F1: 0.54\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.3819\n",
            "The average recall is: 0.3777\n",
            "The average f1 is: 0.3695\n",
            "  Training epcoh took: 0:00:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8868\n",
            "  Recall: 0.9549\n",
            "  F1: 0.9187\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.5256\n",
            "  Recall: 0.4667\n",
            "  F1: 0.4519\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3531\n",
            "The average recall is: 0.3554\n",
            "The average f1 is: 0.3426\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of     50.    Elapsed: 0:00:15.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.95\n",
            "  Accuracy: 0.90\n",
            "Category: 0\n",
            "  Precision: 0.93\n",
            "  Recall: 0.98\n",
            "  F1: 0.95\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "Category: 2\n",
            "  Precision: 0.68\n",
            "  Recall: 0.66\n",
            "  F1: 0.63\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.4025\n",
            "The average recall is: 0.4086\n",
            "The average f1 is: 0.3949\n",
            "  Training epcoh took: 0:00:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.79\n",
            "Category: 0\n",
            "  Precision: 0.9007\n",
            "  Recall: 0.8517\n",
            "  F1: 0.8749\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3583\n",
            "  Recall: 0.6013\n",
            "  F1: 0.4403\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3147\n",
            "The average recall is: 0.3632\n",
            "The average f1 is: 0.3288\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Current increase 5 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1351 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 53 sampled in this category.\n",
            "After up-sample, there are 1865 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 1865 samples\n",
            "There are 182 sampled in this category.\n",
            "After up-sample, there are 2775 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 2775 samples\n",
            "There are 14 sampled in this category.\n",
            "After up-sample, there are 2845 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.844375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.4748681898066784\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "53\n",
            "0.033125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "318\n",
            "0.11177504393673111\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "182\n",
            "0.11375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1092\n",
            "0.3838312829525483\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "14\n",
            "0.00875\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "84\n",
            "0.02952548330404218\n",
            "\n",
            "(2845, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0831 04:54:25.041595 139633676007232 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0831 04:54:25.042676 139633676007232 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0831 04:54:25.095485 139633676007232 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0831 04:54:27.654156 139633676007232 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0831 04:54:27.655450 139633676007232 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of     89.    Elapsed: 0:00:18.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of     89.    Elapsed: 0:00:35.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 1.95\n",
            "  Accuracy: 0.61\n",
            "Category: 0\n",
            "  Precision: 0.61\n",
            "  Recall: 0.81\n",
            "  F1: 0.68\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "Category: 2\n",
            "  Precision: 0.62\n",
            "  Recall: 0.57\n",
            "  F1: 0.55\n",
            "Category: 3\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.3071\n",
            "The average recall is: 0.3447\n",
            "The average f1 is: 0.3073\n",
            "  Training epcoh took: 0:00:40\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.9003\n",
            "  Recall: 0.9210\n",
            "  F1: 0.9082\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.4623\n",
            "  Recall: 0.5022\n",
            "  F1: 0.4425\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3406\n",
            "The average recall is: 0.3558\n",
            "The average f1 is: 0.3377\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of     89.    Elapsed: 0:00:18.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of     89.    Elapsed: 0:00:36.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 1.25\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.79\n",
            "  Recall: 0.94\n",
            "  F1: 0.86\n",
            "Category: 1\n",
            "  Precision: 0.32\n",
            "  Recall: 0.18\n",
            "  F1: 0.20\n",
            "Category: 2\n",
            "  Precision: 0.92\n",
            "  Recall: 0.95\n",
            "  F1: 0.93\n",
            "Category: 3\n",
            "  Precision: 0.18\n",
            "  Recall: 0.15\n",
            "  F1: 0.16\n",
            "The average precision is: 0.5537\n",
            "The average recall is: 0.5552\n",
            "The average f1 is: 0.5372\n",
            "  Training epcoh took: 0:00:40\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8919\n",
            "  Recall: 0.9556\n",
            "  F1: 0.9220\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.4038\n",
            "  Recall: 0.3000\n",
            "  F1: 0.3344\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3239\n",
            "The average recall is: 0.3139\n",
            "The average f1 is: 0.3141\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of     89.    Elapsed: 0:00:18.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of     89.    Elapsed: 0:00:36.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.24\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.95\n",
            "  Recall: 0.97\n",
            "  F1: 0.96\n",
            "Category: 1\n",
            "  Precision: 0.85\n",
            "  Recall: 0.82\n",
            "  F1: 0.81\n",
            "Category: 2\n",
            "  Precision: 0.98\n",
            "  Recall: 0.99\n",
            "  F1: 0.98\n",
            "Category: 3\n",
            "  Precision: 0.57\n",
            "  Recall: 0.54\n",
            "  F1: 0.55\n",
            "The average precision is: 0.8385\n",
            "The average recall is: 0.8290\n",
            "The average f1 is: 0.8255\n",
            "  Training epcoh took: 0:00:40\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.9185\n",
            "  Recall: 0.9098\n",
            "  F1: 0.9122\n",
            "Category: 1\n",
            "  Precision: 0.2308\n",
            "  Recall: 0.2500\n",
            "  F1: 0.2308\n",
            "Category: 2\n",
            "  Precision: 0.5751\n",
            "  Recall: 0.6051\n",
            "  F1: 0.5584\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4311\n",
            "The average recall is: 0.4412\n",
            "The average f1 is: 0.4253\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of     89.    Elapsed: 0:00:18.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of     89.    Elapsed: 0:00:37.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.94\n",
            "  Recall: 0.94\n",
            "  F1: 0.94\n",
            "Category: 2\n",
            "  Precision: 0.99\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.64\n",
            "  Recall: 0.64\n",
            "  F1: 0.64\n",
            "The average precision is: 0.8932\n",
            "The average recall is: 0.8936\n",
            "The average f1 is: 0.8929\n",
            "  Training epcoh took: 0:00:41\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.8924\n",
            "  Recall: 0.9400\n",
            "  F1: 0.9136\n",
            "Category: 1\n",
            "  Precision: 0.1154\n",
            "  Recall: 0.1026\n",
            "  F1: 0.0897\n",
            "Category: 2\n",
            "  Precision: 0.5165\n",
            "  Recall: 0.4391\n",
            "  F1: 0.4242\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3811\n",
            "The average recall is: 0.3704\n",
            "The average f1 is: 0.3569\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Current increase 10 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1351 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 53 sampled in this category.\n",
            "After up-sample, there are 2130 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 2130 samples\n",
            "There are 182 sampled in this category.\n",
            "After up-sample, there are 3950 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 3950 samples\n",
            "There are 14 sampled in this category.\n",
            "After up-sample, there are 4090 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.844375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.33031784841075795\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "53\n",
            "0.033125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "583\n",
            "0.14254278728606357\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "182\n",
            "0.11375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "2002\n",
            "0.48948655256723717\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "14\n",
            "0.00875\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "154\n",
            "0.03765281173594132\n",
            "\n",
            "(4090, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0831 04:57:12.821429 139633676007232 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0831 04:57:12.822288 139633676007232 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0831 04:57:12.862828 139633676007232 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0831 04:57:15.349667 139633676007232 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0831 04:57:15.350378 139633676007232 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    128.    Elapsed: 0:00:18.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    128.    Elapsed: 0:00:37.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    128.    Elapsed: 0:00:57.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 1.23\n",
            "  Accuracy: 0.69\n",
            "Category: 0\n",
            "  Precision: 0.61\n",
            "  Recall: 0.58\n",
            "  F1: 0.57\n",
            "Category: 1\n",
            "  Precision: 0.58\n",
            "  Recall: 0.44\n",
            "  F1: 0.46\n",
            "Category: 2\n",
            "  Precision: 0.73\n",
            "  Recall: 0.89\n",
            "  F1: 0.78\n",
            "Category: 3\n",
            "  Precision: 0.22\n",
            "  Recall: 0.20\n",
            "  F1: 0.21\n",
            "The average precision is: 0.5351\n",
            "The average recall is: 0.5264\n",
            "The average f1 is: 0.5045\n",
            "  Training epcoh took: 0:01:01\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "Category: 0\n",
            "  Precision: 0.8988\n",
            "  Recall: 0.8780\n",
            "  F1: 0.8868\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.4097\n",
            "  Recall: 0.5534\n",
            "  F1: 0.4576\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3271\n",
            "The average recall is: 0.3578\n",
            "The average f1 is: 0.3361\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    128.    Elapsed: 0:00:19.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    128.    Elapsed: 0:00:39.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    128.    Elapsed: 0:00:58.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.03\n",
            "  Accuracy: 0.98\n",
            "Category: 0\n",
            "  Precision: 0.98\n",
            "  Recall: 0.95\n",
            "  F1: 0.97\n",
            "Category: 1\n",
            "  Precision: 0.96\n",
            "  Recall: 0.97\n",
            "  F1: 0.97\n",
            "Category: 2\n",
            "  Precision: 0.97\n",
            "  Recall: 0.99\n",
            "  F1: 0.98\n",
            "Category: 3\n",
            "  Precision: 0.67\n",
            "  Recall: 0.67\n",
            "  F1: 0.67\n",
            "The average precision is: 0.8985\n",
            "The average recall is: 0.8974\n",
            "The average f1 is: 0.8961\n",
            "  Training epcoh took: 0:01:02\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8928\n",
            "  Recall: 0.9664\n",
            "  F1: 0.9272\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.6167\n",
            "  Recall: 0.4103\n",
            "  F1: 0.4751\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3774\n",
            "The average recall is: 0.3442\n",
            "The average f1 is: 0.3506\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    128.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    128.    Elapsed: 0:00:39.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    128.    Elapsed: 0:00:59.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 0.99\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.68\n",
            "  Recall: 0.68\n",
            "  F1: 0.68\n",
            "The average precision is: 0.9177\n",
            "The average recall is: 0.9165\n",
            "The average f1 is: 0.9170\n",
            "  Training epcoh took: 0:01:02\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8887\n",
            "  Recall: 0.9652\n",
            "  F1: 0.9249\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.6590\n",
            "  Recall: 0.3888\n",
            "  F1: 0.4796\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3869\n",
            "The average recall is: 0.3385\n",
            "The average f1 is: 0.3511\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    128.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    128.    Elapsed: 0:00:40.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    128.    Elapsed: 0:00:59.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.70\n",
            "  Recall: 0.70\n",
            "  F1: 0.70\n",
            "The average precision is: 0.9253\n",
            "The average recall is: 0.9251\n",
            "The average f1 is: 0.9252\n",
            "  Training epcoh took: 0:01:03\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8816\n",
            "  Recall: 0.9692\n",
            "  F1: 0.9222\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.6359\n",
            "  Recall: 0.3529\n",
            "  F1: 0.4102\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3794\n",
            "The average recall is: 0.3305\n",
            "The average f1 is: 0.3331\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Current increase 15 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1351 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 53 sampled in this category.\n",
            "After up-sample, there are 2395 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 2395 samples\n",
            "There are 182 sampled in this category.\n",
            "After up-sample, there are 5125 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 5125 samples\n",
            "There are 14 sampled in this category.\n",
            "After up-sample, there are 5335 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.844375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.25323336457357076\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "53\n",
            "0.033125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "848\n",
            "0.15895032802249298\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "182\n",
            "0.11375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "2912\n",
            "0.5458294283036551\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "14\n",
            "0.00875\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "224\n",
            "0.04198687910028116\n",
            "\n",
            "(5335, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0831 05:01:29.766365 139633676007232 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0831 05:01:29.767261 139633676007232 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0831 05:01:29.856600 139633676007232 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0831 05:01:32.441539 139633676007232 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0831 05:01:32.443420 139633676007232 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    167.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    167.    Elapsed: 0:00:40.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    167.    Elapsed: 0:01:00.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    167.    Elapsed: 0:01:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.72\n",
            "  Accuracy: 0.79\n",
            "Category: 0\n",
            "  Precision: 0.66\n",
            "  Recall: 0.63\n",
            "  F1: 0.62\n",
            "Category: 1\n",
            "  Precision: 0.64\n",
            "  Recall: 0.54\n",
            "  F1: 0.56\n",
            "Category: 2\n",
            "  Precision: 0.82\n",
            "  Recall: 0.95\n",
            "  F1: 0.87\n",
            "Category: 3\n",
            "  Precision: 0.51\n",
            "  Recall: 0.48\n",
            "  F1: 0.48\n",
            "The average precision is: 0.6587\n",
            "The average recall is: 0.6492\n",
            "The average f1 is: 0.6325\n",
            "  Training epcoh took: 0:01:24\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8927\n",
            "  Recall: 0.9624\n",
            "  F1: 0.9254\n",
            "Category: 1\n",
            "  Precision: 0.1154\n",
            "  Recall: 0.1538\n",
            "  F1: 0.1282\n",
            "Category: 2\n",
            "  Precision: 0.6747\n",
            "  Recall: 0.3920\n",
            "  F1: 0.4440\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4207\n",
            "The average recall is: 0.3771\n",
            "The average f1 is: 0.3744\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    167.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    167.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    167.    Elapsed: 0:01:01.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    167.    Elapsed: 0:01:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.97\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 2\n",
            "  Precision: 0.99\n",
            "  Recall: 1.00\n",
            "  F1: 0.99\n",
            "Category: 3\n",
            "  Precision: 0.76\n",
            "  Recall: 0.76\n",
            "  F1: 0.76\n",
            "The average precision is: 0.9308\n",
            "The average recall is: 0.9280\n",
            "The average f1 is: 0.9282\n",
            "  Training epcoh took: 0:01:24\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.8896\n",
            "  Recall: 0.9256\n",
            "  F1: 0.9061\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.4731\n",
            "  Recall: 0.4663\n",
            "  F1: 0.4435\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3599\n",
            "The average recall is: 0.3672\n",
            "The average f1 is: 0.3566\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    167.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    167.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    167.    Elapsed: 0:01:01.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    167.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.79\n",
            "  Recall: 0.79\n",
            "  F1: 0.79\n",
            "The average precision is: 0.9452\n",
            "The average recall is: 0.9448\n",
            "The average f1 is: 0.9449\n",
            "  Training epcoh took: 0:01:25\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8775\n",
            "  Recall: 0.9704\n",
            "  F1: 0.9201\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.6447\n",
            "  Recall: 0.3201\n",
            "  F1: 0.4151\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3998\n",
            "The average recall is: 0.3418\n",
            "The average f1 is: 0.3530\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    167.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    167.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    167.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    167.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.78\n",
            "  Recall: 0.78\n",
            "  F1: 0.78\n",
            "The average precision is: 0.9458\n",
            "The average recall is: 0.9451\n",
            "The average f1 is: 0.9454\n",
            "  Training epcoh took: 0:01:25\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8821\n",
            "  Recall: 0.9783\n",
            "  F1: 0.9264\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.6000\n",
            "  Recall: 0.3865\n",
            "  F1: 0.4211\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3897\n",
            "The average recall is: 0.3604\n",
            "The average f1 is: 0.3561\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Current increase 20 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1351 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 53 sampled in this category.\n",
            "After up-sample, there are 2660 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 2660 samples\n",
            "There are 182 sampled in this category.\n",
            "After up-sample, there are 6300 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 6300 samples\n",
            "There are 14 sampled in this category.\n",
            "After up-sample, there are 6580 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.844375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.2053191489361702\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "53\n",
            "0.033125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1113\n",
            "0.16914893617021276\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "182\n",
            "0.11375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "3822\n",
            "0.5808510638297872\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "14\n",
            "0.00875\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "294\n",
            "0.04468085106382979\n",
            "\n",
            "(6580, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0831 05:07:17.077628 139633676007232 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0831 05:07:17.078501 139633676007232 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0831 05:07:17.134709 139633676007232 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0831 05:07:19.685963 139633676007232 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0831 05:07:19.687307 139633676007232 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    206.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    206.    Elapsed: 0:00:40.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    206.    Elapsed: 0:01:00.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    206.    Elapsed: 0:01:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    206.    Elapsed: 0:01:39.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.77\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.70\n",
            "  Recall: 0.64\n",
            "  F1: 0.65\n",
            "Category: 1\n",
            "  Precision: 0.75\n",
            "  Recall: 0.71\n",
            "  F1: 0.71\n",
            "Category: 2\n",
            "  Precision: 0.85\n",
            "  Recall: 0.96\n",
            "  F1: 0.90\n",
            "Category: 3\n",
            "  Precision: 0.43\n",
            "  Recall: 0.40\n",
            "  F1: 0.41\n",
            "The average precision is: 0.6828\n",
            "The average recall is: 0.6789\n",
            "The average f1 is: 0.6670\n",
            "  Training epcoh took: 0:01:42\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8957\n",
            "  Recall: 0.9438\n",
            "  F1: 0.9174\n",
            "Category: 1\n",
            "  Precision: 0.1538\n",
            "  Recall: 0.1154\n",
            "  F1: 0.1282\n",
            "Category: 2\n",
            "  Precision: 0.4667\n",
            "  Recall: 0.3756\n",
            "  F1: 0.3924\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3791\n",
            "The average recall is: 0.3587\n",
            "The average f1 is: 0.3595\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    206.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    206.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    206.    Elapsed: 0:01:01.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    206.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    206.    Elapsed: 0:01:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.97\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 0.99\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 0.99\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.78\n",
            "  Recall: 0.78\n",
            "  F1: 0.78\n",
            "The average precision is: 0.9390\n",
            "The average recall is: 0.9374\n",
            "The average f1 is: 0.9373\n",
            "  Training epcoh took: 0:01:44\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8847\n",
            "  Recall: 0.9666\n",
            "  F1: 0.9232\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.6410\n",
            "  Recall: 0.4403\n",
            "  F1: 0.4995\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3814\n",
            "The average recall is: 0.3517\n",
            "The average f1 is: 0.3557\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    206.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    206.    Elapsed: 0:00:39.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    206.    Elapsed: 0:01:00.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    206.    Elapsed: 0:01:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    206.    Elapsed: 0:01:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 0.99\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.77\n",
            "  Recall: 0.77\n",
            "  F1: 0.77\n",
            "The average precision is: 0.9382\n",
            "The average recall is: 0.9375\n",
            "The average f1 is: 0.9377\n",
            "  Training epcoh took: 0:01:44\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8862\n",
            "  Recall: 0.9464\n",
            "  F1: 0.9146\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.5115\n",
            "  Recall: 0.3936\n",
            "  F1: 0.4227\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3494\n",
            "The average recall is: 0.3350\n",
            "The average f1 is: 0.3343\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    206.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    206.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    206.    Elapsed: 0:01:01.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    206.    Elapsed: 0:01:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    206.    Elapsed: 0:01:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.74\n",
            "  Recall: 0.74\n",
            "  F1: 0.74\n",
            "The average precision is: 0.9341\n",
            "The average recall is: 0.9337\n",
            "The average f1 is: 0.9339\n",
            "  Training epcoh took: 0:01:44\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8809\n",
            "  Recall: 0.9617\n",
            "  F1: 0.9174\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.6526\n",
            "  Recall: 0.4016\n",
            "  F1: 0.4582\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3834\n",
            "The average recall is: 0.3408\n",
            "The average f1 is: 0.3439\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Current increase 25 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1351 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 53 sampled in this category.\n",
            "After up-sample, there are 2925 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 2925 samples\n",
            "There are 182 sampled in this category.\n",
            "After up-sample, there are 7475 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 7475 samples\n",
            "There are 14 sampled in this category.\n",
            "After up-sample, there are 7825 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.844375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.1726517571884984\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "53\n",
            "0.033125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1378\n",
            "0.17610223642172523\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "182\n",
            "0.11375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "4732\n",
            "0.6047284345047923\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "14\n",
            "0.00875\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "364\n",
            "0.046517571884984024\n",
            "\n",
            "(7825, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0831 05:14:20.365848 139633676007232 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0831 05:14:20.366731 139633676007232 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0831 05:14:20.484482 139633676007232 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0831 05:14:23.068502 139633676007232 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0831 05:14:23.070452 139633676007232 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    245.    Elapsed: 0:00:19.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    245.    Elapsed: 0:00:40.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    245.    Elapsed: 0:01:01.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    245.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    245.    Elapsed: 0:01:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    245.    Elapsed: 0:02:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.52\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.69\n",
            "  Recall: 0.60\n",
            "  F1: 0.62\n",
            "Category: 1\n",
            "  Precision: 0.80\n",
            "  Recall: 0.78\n",
            "  F1: 0.78\n",
            "Category: 2\n",
            "  Precision: 0.87\n",
            "  Recall: 0.98\n",
            "  F1: 0.91\n",
            "Category: 3\n",
            "  Precision: 0.59\n",
            "  Recall: 0.59\n",
            "  F1: 0.59\n",
            "The average precision is: 0.7389\n",
            "The average recall is: 0.7376\n",
            "The average f1 is: 0.7260\n",
            "  Training epcoh took: 0:02:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "Category: 0\n",
            "  Precision: 0.8853\n",
            "  Recall: 0.9168\n",
            "  F1: 0.9000\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0513\n",
            "Category: 2\n",
            "  Precision: 0.4513\n",
            "  Recall: 0.3551\n",
            "  F1: 0.3632\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3438\n",
            "The average recall is: 0.3372\n",
            "The average f1 is: 0.3286\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    245.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    245.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    245.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    245.    Elapsed: 0:01:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    245.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    245.    Elapsed: 0:02:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.98\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 0.99\n",
            "  Recall: 1.00\n",
            "  F1: 0.99\n",
            "Category: 2\n",
            "  Precision: 0.99\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.78\n",
            "  Recall: 0.78\n",
            "  F1: 0.78\n",
            "The average precision is: 0.9381\n",
            "The average recall is: 0.9360\n",
            "The average f1 is: 0.9364\n",
            "  Training epcoh took: 0:02:07\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8824\n",
            "  Recall: 0.9755\n",
            "  F1: 0.9251\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.7308\n",
            "  Recall: 0.4590\n",
            "  F1: 0.5048\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4033\n",
            "The average recall is: 0.3586\n",
            "The average f1 is: 0.3575\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    245.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    245.    Elapsed: 0:00:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    245.    Elapsed: 0:01:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    245.    Elapsed: 0:01:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    245.    Elapsed: 0:01:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    245.    Elapsed: 0:02:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.82\n",
            "  Recall: 0.82\n",
            "  F1: 0.82\n",
            "The average precision is: 0.9544\n",
            "The average recall is: 0.9538\n",
            "The average f1 is: 0.9540\n",
            "  Training epcoh took: 0:02:08\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8776\n",
            "  Recall: 0.9886\n",
            "  F1: 0.9284\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.5449\n",
            "  Recall: 0.2679\n",
            "  F1: 0.3361\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3556\n",
            "The average recall is: 0.3141\n",
            "The average f1 is: 0.3161\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    245.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    245.    Elapsed: 0:00:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    245.    Elapsed: 0:01:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    245.    Elapsed: 0:01:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    245.    Elapsed: 0:01:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    245.    Elapsed: 0:02:06.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.81\n",
            "  Recall: 0.81\n",
            "  F1: 0.81\n",
            "The average precision is: 0.9507\n",
            "The average recall is: 0.9506\n",
            "The average f1 is: 0.9506\n",
            "  Training epcoh took: 0:02:07\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "Category: 0\n",
            "  Precision: 0.8826\n",
            "  Recall: 0.9827\n",
            "  F1: 0.9289\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.6128\n",
            "  Recall: 0.3745\n",
            "  F1: 0.4359\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3739\n",
            "The average recall is: 0.3393\n",
            "The average f1 is: 0.3412\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Current increase 30 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1351 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 53 sampled in this category.\n",
            "After up-sample, there are 3190 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 3190 samples\n",
            "There are 182 sampled in this category.\n",
            "After up-sample, there are 8650 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 8650 samples\n",
            "There are 14 sampled in this category.\n",
            "After up-sample, there are 9070 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.844375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.14895259095920618\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "53\n",
            "0.033125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1643\n",
            "0.18114663726571115\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "182\n",
            "0.11375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "5642\n",
            "0.622050716648291\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "14\n",
            "0.00875\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "434\n",
            "0.04785005512679162\n",
            "\n",
            "(9070, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0831 05:22:57.274172 139633676007232 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0831 05:22:57.275185 139633676007232 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0831 05:22:58.576489 139633676007232 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0831 05:23:01.103360 139633676007232 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0831 05:23:01.105216 139633676007232 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    284.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    284.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    284.    Elapsed: 0:01:01.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    284.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    284.    Elapsed: 0:01:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    284.    Elapsed: 0:02:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    284.    Elapsed: 0:02:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.56\n",
            "  Accuracy: 0.89\n",
            "Category: 0\n",
            "  Precision: 0.73\n",
            "  Recall: 0.63\n",
            "  F1: 0.66\n",
            "Category: 1\n",
            "  Precision: 0.80\n",
            "  Recall: 0.79\n",
            "  F1: 0.78\n",
            "Category: 2\n",
            "  Precision: 0.90\n",
            "  Recall: 0.99\n",
            "  F1: 0.93\n",
            "Category: 3\n",
            "  Precision: 0.56\n",
            "  Recall: 0.58\n",
            "  F1: 0.56\n",
            "The average precision is: 0.7459\n",
            "The average recall is: 0.7459\n",
            "The average f1 is: 0.7344\n",
            "  Training epcoh took: 0:02:25\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.80\n",
            "Category: 0\n",
            "  Precision: 0.8875\n",
            "  Recall: 0.8661\n",
            "  F1: 0.8754\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3404\n",
            "  Recall: 0.4973\n",
            "  F1: 0.3860\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3070\n",
            "The average recall is: 0.3408\n",
            "The average f1 is: 0.3154\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    284.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    284.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    284.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    284.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    284.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    284.    Elapsed: 0:02:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    284.    Elapsed: 0:02:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.98\n",
            "  Recall: 0.96\n",
            "  F1: 0.97\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 0.99\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.79\n",
            "  Recall: 0.80\n",
            "  F1: 0.79\n",
            "The average precision is: 0.9406\n",
            "The average recall is: 0.9383\n",
            "The average f1 is: 0.9384\n",
            "  Training epcoh took: 0:02:25\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8870\n",
            "  Recall: 0.9600\n",
            "  F1: 0.9205\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.6833\n",
            "  Recall: 0.4038\n",
            "  F1: 0.4732\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4118\n",
            "The average recall is: 0.3602\n",
            "The average f1 is: 0.3677\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    284.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    284.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    284.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    284.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    284.    Elapsed: 0:01:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    284.    Elapsed: 0:02:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    284.    Elapsed: 0:02:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.98\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.80\n",
            "  Recall: 0.80\n",
            "  F1: 0.80\n",
            "The average precision is: 0.9453\n",
            "The average recall is: 0.9445\n",
            "The average f1 is: 0.9447\n",
            "  Training epcoh took: 0:02:25\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8766\n",
            "  Recall: 0.9879\n",
            "  F1: 0.9282\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.5462\n",
            "  Recall: 0.3051\n",
            "  F1: 0.3784\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3557\n",
            "The average recall is: 0.3233\n",
            "The average f1 is: 0.3266\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    284.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    284.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    284.    Elapsed: 0:01:01.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    284.    Elapsed: 0:01:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    284.    Elapsed: 0:01:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    284.    Elapsed: 0:02:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    284.    Elapsed: 0:02:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.77\n",
            "  Recall: 0.77\n",
            "  F1: 0.77\n",
            "The average precision is: 0.9408\n",
            "The average recall is: 0.9409\n",
            "The average f1 is: 0.9408\n",
            "  Training epcoh took: 0:02:24\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8688\n",
            "  Recall: 0.9854\n",
            "  F1: 0.9227\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.5513\n",
            "  Recall: 0.2656\n",
            "  F1: 0.3483\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3550\n",
            "The average recall is: 0.3127\n",
            "The average f1 is: 0.3178\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Current increase 35 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1351 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 53 sampled in this category.\n",
            "After up-sample, there are 3455 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 3455 samples\n",
            "There are 182 sampled in this category.\n",
            "After up-sample, there are 9825 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 9825 samples\n",
            "There are 14 sampled in this category.\n",
            "After up-sample, there are 10315 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.844375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.13097430925836162\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "53\n",
            "0.033125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1908\n",
            "0.18497333979641298\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "182\n",
            "0.11375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "6552\n",
            "0.6351914687348521\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "14\n",
            "0.00875\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "504\n",
            "0.04886088221037324\n",
            "\n",
            "(10315, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0831 05:32:46.237800 139633676007232 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0831 05:32:46.238847 139633676007232 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0831 05:32:47.141576 139633676007232 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0831 05:32:49.601983 139633676007232 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0831 05:32:49.603583 139633676007232 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    323.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    323.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    323.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    323.    Elapsed: 0:01:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    323.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    323.    Elapsed: 0:02:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    323.    Elapsed: 0:02:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    323.    Elapsed: 0:02:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.41\n",
            "  Accuracy: 0.91\n",
            "Category: 0\n",
            "  Precision: 0.74\n",
            "  Recall: 0.64\n",
            "  F1: 0.66\n",
            "Category: 1\n",
            "  Precision: 0.84\n",
            "  Recall: 0.84\n",
            "  F1: 0.83\n",
            "Category: 2\n",
            "  Precision: 0.92\n",
            "  Recall: 0.98\n",
            "  F1: 0.94\n",
            "Category: 3\n",
            "  Precision: 0.68\n",
            "  Recall: 0.68\n",
            "  F1: 0.68\n",
            "The average precision is: 0.7928\n",
            "The average recall is: 0.7848\n",
            "The average f1 is: 0.7776\n",
            "  Training epcoh took: 0:02:47\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.9043\n",
            "  Recall: 0.9368\n",
            "  F1: 0.9188\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.6026\n",
            "  Recall: 0.5679\n",
            "  F1: 0.5330\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3767\n",
            "The average recall is: 0.3762\n",
            "The average f1 is: 0.3630\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    323.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    323.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    323.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    323.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    323.    Elapsed: 0:01:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    323.    Elapsed: 0:02:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    323.    Elapsed: 0:02:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    323.    Elapsed: 0:02:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.97\n",
            "  Recall: 0.96\n",
            "  F1: 0.96\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.79\n",
            "  Recall: 0.79\n",
            "  F1: 0.79\n",
            "The average precision is: 0.9384\n",
            "The average recall is: 0.9355\n",
            "The average f1 is: 0.9360\n",
            "  Training epcoh took: 0:02:45\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8877\n",
            "  Recall: 0.9748\n",
            "  F1: 0.9278\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.6769\n",
            "  Recall: 0.4015\n",
            "  F1: 0.4735\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3911\n",
            "The average recall is: 0.3441\n",
            "The average f1 is: 0.3503\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    323.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    323.    Elapsed: 0:00:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    323.    Elapsed: 0:01:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    323.    Elapsed: 0:01:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    323.    Elapsed: 0:01:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    323.    Elapsed: 0:02:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    323.    Elapsed: 0:02:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    323.    Elapsed: 0:02:44.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.98\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.79\n",
            "  Recall: 0.79\n",
            "  F1: 0.79\n",
            "The average precision is: 0.9433\n",
            "The average recall is: 0.9425\n",
            "The average f1 is: 0.9428\n",
            "  Training epcoh took: 0:02:45\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8822\n",
            "  Recall: 0.9545\n",
            "  F1: 0.9155\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.5593\n",
            "  Recall: 0.3427\n",
            "  F1: 0.3961\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3604\n",
            "The average recall is: 0.3243\n",
            "The average f1 is: 0.3279\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    323.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    323.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    323.    Elapsed: 0:01:01.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    323.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    323.    Elapsed: 0:01:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    323.    Elapsed: 0:02:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    323.    Elapsed: 0:02:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    323.    Elapsed: 0:02:44.\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.97\n",
            "  Recall: 0.97\n",
            "  F1: 0.97\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.80\n",
            "  Recall: 0.80\n",
            "  F1: 0.80\n",
            "The average precision is: 0.9427\n",
            "The average recall is: 0.9421\n",
            "The average f1 is: 0.9422\n",
            "  Training epcoh took: 0:02:45\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8762\n",
            "  Recall: 0.9806\n",
            "  F1: 0.9242\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.4780\n",
            "  Recall: 0.2633\n",
            "  F1: 0.3268\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3386\n",
            "The average recall is: 0.3110\n",
            "The average f1 is: 0.3127\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Current increase 40 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1351 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 53 sampled in this category.\n",
            "After up-sample, there are 3720 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 3720 samples\n",
            "There are 182 sampled in this category.\n",
            "After up-sample, there are 11000 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 11000 samples\n",
            "There are 14 sampled in this category.\n",
            "After up-sample, there are 11560 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.844375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.11686851211072664\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "53\n",
            "0.033125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "2173\n",
            "0.1879757785467128\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "182\n",
            "0.11375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "7462\n",
            "0.6455017301038062\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "14\n",
            "0.00875\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "574\n",
            "0.04965397923875432\n",
            "\n",
            "(11560, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0831 05:43:56.922193 139633676007232 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0831 05:43:56.923073 139633676007232 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0831 05:43:56.976497 139633676007232 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0831 05:43:59.436704 139633676007232 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0831 05:43:59.438054 139633676007232 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    362.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    362.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    362.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    362.    Elapsed: 0:01:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    362.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    362.    Elapsed: 0:02:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    362.    Elapsed: 0:02:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    362.    Elapsed: 0:02:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    362.    Elapsed: 0:03:05.\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.37\n",
            "  Accuracy: 0.91\n",
            "Category: 0\n",
            "  Precision: 0.69\n",
            "  Recall: 0.59\n",
            "  F1: 0.62\n",
            "Category: 1\n",
            "  Precision: 0.83\n",
            "  Recall: 0.85\n",
            "  F1: 0.83\n",
            "Category: 2\n",
            "  Precision: 0.92\n",
            "  Recall: 0.99\n",
            "  F1: 0.94\n",
            "Category: 3\n",
            "  Precision: 0.65\n",
            "  Recall: 0.65\n",
            "  F1: 0.65\n",
            "The average precision is: 0.7703\n",
            "The average recall is: 0.7683\n",
            "The average f1 is: 0.7589\n",
            "  Training epcoh took: 0:03:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.8883\n",
            "  Recall: 0.9241\n",
            "  F1: 0.9042\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.5577\n",
            "  Recall: 0.5126\n",
            "  F1: 0.4896\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3807\n",
            "The average recall is: 0.3784\n",
            "The average f1 is: 0.3677\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    362.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    362.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    362.    Elapsed: 0:01:01.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    362.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    362.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    362.    Elapsed: 0:02:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    362.    Elapsed: 0:02:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    362.    Elapsed: 0:02:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    362.    Elapsed: 0:03:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.97\n",
            "  Recall: 0.96\n",
            "  F1: 0.97\n",
            "Category: 1\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.82\n",
            "  Recall: 0.82\n",
            "  F1: 0.82\n",
            "The average precision is: 0.9451\n",
            "The average recall is: 0.9436\n",
            "The average f1 is: 0.9436\n",
            "  Training epcoh took: 0:03:07\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "Category: 0\n",
            "  Precision: 0.8840\n",
            "  Recall: 0.9918\n",
            "  F1: 0.9341\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.7436\n",
            "  Recall: 0.4374\n",
            "  F1: 0.5192\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4261\n",
            "The average recall is: 0.3765\n",
            "The average f1 is: 0.3826\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    362.    Elapsed: 0:00:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    362.    Elapsed: 0:00:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    362.    Elapsed: 0:01:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    362.    Elapsed: 0:01:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    362.    Elapsed: 0:01:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    362.    Elapsed: 0:02:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    362.    Elapsed: 0:02:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    362.    Elapsed: 0:02:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    362.    Elapsed: 0:03:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.98\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.82\n",
            "  Recall: 0.83\n",
            "  F1: 0.83\n",
            "The average precision is: 0.9519\n",
            "The average recall is: 0.9516\n",
            "The average f1 is: 0.9515\n",
            "  Training epcoh took: 0:03:08\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8789\n",
            "  Recall: 0.9493\n",
            "  F1: 0.9120\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.5269\n",
            "  Recall: 0.3958\n",
            "  F1: 0.4447\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3707\n",
            "The average recall is: 0.3555\n",
            "The average f1 is: 0.3584\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    362.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    362.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    362.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    362.    Elapsed: 0:01:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    362.    Elapsed: 0:01:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    362.    Elapsed: 0:02:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    362.    Elapsed: 0:02:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    362.    Elapsed: 0:02:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    362.    Elapsed: 0:03:07.\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.98\n",
            "  Recall: 0.98\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.83\n",
            "  Recall: 0.83\n",
            "  F1: 0.83\n",
            "The average precision is: 0.9509\n",
            "The average recall is: 0.9511\n",
            "The average f1 is: 0.9509\n",
            "  Training epcoh took: 0:03:08\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8861\n",
            "  Recall: 0.9667\n",
            "  F1: 0.9232\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.6423\n",
            "  Recall: 0.4350\n",
            "  F1: 0.5068\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4013\n",
            "The average recall is: 0.3697\n",
            "The average f1 is: 0.3767\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Current increase 45 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1351 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 53 sampled in this category.\n",
            "After up-sample, there are 3985 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 3985 samples\n",
            "There are 182 sampled in this category.\n",
            "After up-sample, there are 12175 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 12175 samples\n",
            "There are 14 sampled in this category.\n",
            "After up-sample, there are 12805 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.844375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.10550566185083951\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "53\n",
            "0.033125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "2438\n",
            "0.19039437719640764\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "182\n",
            "0.11375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "8372\n",
            "0.6538071065989848\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "14\n",
            "0.00875\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "644\n",
            "0.05029285435376806\n",
            "\n",
            "(12805, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0831 05:56:34.082223 139633676007232 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0831 05:56:34.083173 139633676007232 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0831 05:56:35.816161 139633676007232 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0831 05:56:38.294109 139633676007232 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0831 05:56:38.294917 139633676007232 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    401.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    401.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    401.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    401.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    401.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    401.    Elapsed: 0:02:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    401.    Elapsed: 0:02:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    401.    Elapsed: 0:02:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    401.    Elapsed: 0:03:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    401.    Elapsed: 0:03:27.\n",
            "\n",
            "  Average training loss: 0.41\n",
            "  Accuracy: 0.91\n",
            "Category: 0\n",
            "  Precision: 0.66\n",
            "  Recall: 0.57\n",
            "  F1: 0.60\n",
            "Category: 1\n",
            "  Precision: 0.84\n",
            "  Recall: 0.83\n",
            "  F1: 0.82\n",
            "Category: 2\n",
            "  Precision: 0.91\n",
            "  Recall: 0.99\n",
            "  F1: 0.94\n",
            "Category: 3\n",
            "  Precision: 0.66\n",
            "  Recall: 0.66\n",
            "  F1: 0.66\n",
            "The average precision is: 0.7682\n",
            "The average recall is: 0.7616\n",
            "The average f1 is: 0.7542\n",
            "  Training epcoh took: 0:03:27\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "Category: 0\n",
            "  Precision: 0.8963\n",
            "  Recall: 0.8808\n",
            "  F1: 0.8868\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.3707\n",
            "  Recall: 0.5040\n",
            "  F1: 0.4146\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3360\n",
            "The average recall is: 0.3654\n",
            "The average f1 is: 0.3446\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    401.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    401.    Elapsed: 0:00:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    401.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    401.    Elapsed: 0:01:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    401.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    401.    Elapsed: 0:02:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    401.    Elapsed: 0:02:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    401.    Elapsed: 0:02:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    401.    Elapsed: 0:03:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    401.    Elapsed: 0:03:25.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.95\n",
            "  Recall: 0.94\n",
            "  F1: 0.94\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.79\n",
            "  Recall: 0.79\n",
            "  F1: 0.79\n",
            "The average precision is: 0.9340\n",
            "The average recall is: 0.9311\n",
            "The average f1 is: 0.9317\n",
            "  Training epcoh took: 0:03:25\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8873\n",
            "  Recall: 0.9731\n",
            "  F1: 0.9274\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.5449\n",
            "  Recall: 0.3452\n",
            "  F1: 0.4045\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3773\n",
            "The average recall is: 0.3488\n",
            "The average f1 is: 0.3522\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    401.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    401.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    401.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    401.    Elapsed: 0:01:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    401.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    401.    Elapsed: 0:02:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    401.    Elapsed: 0:02:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    401.    Elapsed: 0:02:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    401.    Elapsed: 0:03:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    401.    Elapsed: 0:03:26.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.96\n",
            "  Recall: 0.95\n",
            "  F1: 0.96\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.80\n",
            "  Recall: 0.80\n",
            "  F1: 0.80\n",
            "The average precision is: 0.9386\n",
            "The average recall is: 0.9378\n",
            "The average f1 is: 0.9379\n",
            "  Training epcoh took: 0:03:26\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8774\n",
            "  Recall: 0.9541\n",
            "  F1: 0.9128\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.5333\n",
            "  Recall: 0.4156\n",
            "  F1: 0.4268\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3527\n",
            "The average recall is: 0.3424\n",
            "The average f1 is: 0.3349\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    401.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    401.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    401.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    401.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    401.    Elapsed: 0:01:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    401.    Elapsed: 0:02:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    401.    Elapsed: 0:02:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    401.    Elapsed: 0:02:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    401.    Elapsed: 0:03:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    401.    Elapsed: 0:03:26.\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.97\n",
            "  Recall: 0.97\n",
            "  F1: 0.97\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.81\n",
            "  Recall: 0.81\n",
            "  F1: 0.81\n",
            "The average precision is: 0.9450\n",
            "The average recall is: 0.9444\n",
            "The average f1 is: 0.9446\n",
            "  Training epcoh took: 0:03:26\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8828\n",
            "  Recall: 0.9778\n",
            "  F1: 0.9258\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.6346\n",
            "  Recall: 0.3923\n",
            "  F1: 0.4436\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3986\n",
            "The average recall is: 0.3618\n",
            "The average f1 is: 0.3616\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Current increase 50 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1351 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 53 sampled in this category.\n",
            "After up-sample, there are 4250 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 4250 samples\n",
            "There are 182 sampled in this category.\n",
            "After up-sample, there are 13350 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 13350 samples\n",
            "There are 14 sampled in this category.\n",
            "After up-sample, there are 14050 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.844375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.09615658362989324\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "53\n",
            "0.033125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "2703\n",
            "0.19238434163701068\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "182\n",
            "0.11375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "9282\n",
            "0.6606405693950178\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "14\n",
            "0.00875\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "714\n",
            "0.050818505338078294\n",
            "\n",
            "(14050, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0831 06:10:27.879025 139633676007232 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0831 06:10:27.879961 139633676007232 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0831 06:10:27.957941 139633676007232 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0831 06:10:30.398571 139633676007232 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0831 06:10:30.399917 139633676007232 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    440.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    440.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    440.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    440.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    440.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    440.    Elapsed: 0:02:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    440.    Elapsed: 0:02:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    440.    Elapsed: 0:02:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    440.    Elapsed: 0:03:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    440.    Elapsed: 0:03:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.35\n",
            "  Accuracy: 0.93\n",
            "Category: 0\n",
            "  Precision: 0.66\n",
            "  Recall: 0.61\n",
            "  F1: 0.62\n",
            "Category: 1\n",
            "  Precision: 0.87\n",
            "  Recall: 0.86\n",
            "  F1: 0.85\n",
            "Category: 2\n",
            "  Precision: 0.93\n",
            "  Recall: 0.99\n",
            "  F1: 0.96\n",
            "Category: 3\n",
            "  Precision: 0.65\n",
            "  Recall: 0.67\n",
            "  F1: 0.66\n",
            "The average precision is: 0.7800\n",
            "The average recall is: 0.7818\n",
            "The average f1 is: 0.7724\n",
            "  Training epcoh took: 0:03:44\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.77\n",
            "Category: 0\n",
            "  Precision: 0.9004\n",
            "  Recall: 0.8163\n",
            "  F1: 0.8541\n",
            "Category: 1\n",
            "  Precision: 0.0192\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0256\n",
            "Category: 2\n",
            "  Precision: 0.3610\n",
            "  Recall: 0.6372\n",
            "  F1: 0.4244\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3202\n",
            "The average recall is: 0.3730\n",
            "The average f1 is: 0.3260\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    440.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    440.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    440.    Elapsed: 0:01:01.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    440.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    440.    Elapsed: 0:01:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    440.    Elapsed: 0:02:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    440.    Elapsed: 0:02:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    440.    Elapsed: 0:02:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    440.    Elapsed: 0:03:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    440.    Elapsed: 0:03:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.95\n",
            "  Recall: 0.93\n",
            "  F1: 0.94\n",
            "Category: 1\n",
            "  Precision: 0.99\n",
            "  Recall: 1.00\n",
            "  F1: 0.99\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.82\n",
            "  Recall: 0.82\n",
            "  F1: 0.82\n",
            "The average precision is: 0.9391\n",
            "The average recall is: 0.9364\n",
            "The average f1 is: 0.9364\n",
            "  Training epcoh took: 0:03:45\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8867\n",
            "  Recall: 0.9719\n",
            "  F1: 0.9267\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.6423\n",
            "  Recall: 0.3833\n",
            "  F1: 0.4601\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4015\n",
            "The average recall is: 0.3580\n",
            "The average f1 is: 0.3659\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    440.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    440.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    440.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    440.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    440.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    440.    Elapsed: 0:02:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    440.    Elapsed: 0:02:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    440.    Elapsed: 0:02:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    440.    Elapsed: 0:03:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    440.    Elapsed: 0:03:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.96\n",
            "  Recall: 0.95\n",
            "  F1: 0.96\n",
            "Category: 1\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.82\n",
            "  Recall: 0.82\n",
            "  F1: 0.82\n",
            "The average precision is: 0.9435\n",
            "The average recall is: 0.9419\n",
            "The average f1 is: 0.9424\n",
            "  Training epcoh took: 0:03:45\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "Category: 0\n",
            "  Precision: 0.8852\n",
            "  Recall: 0.9945\n",
            "  F1: 0.9356\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0513\n",
            "Category: 2\n",
            "  Precision: 0.6769\n",
            "  Recall: 0.3463\n",
            "  F1: 0.4266\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4098\n",
            "The average recall is: 0.3448\n",
            "The average f1 is: 0.3534\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    440.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    440.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    440.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    440.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    440.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    440.    Elapsed: 0:02:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    440.    Elapsed: 0:02:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    440.    Elapsed: 0:02:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    440.    Elapsed: 0:03:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    440.    Elapsed: 0:03:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.96\n",
            "  Recall: 0.96\n",
            "  F1: 0.96\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.80\n",
            "  Recall: 0.80\n",
            "  F1: 0.80\n",
            "The average precision is: 0.9394\n",
            "The average recall is: 0.9384\n",
            "The average f1 is: 0.9387\n",
            "  Training epcoh took: 0:03:46\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8831\n",
            "  Recall: 0.9560\n",
            "  F1: 0.9168\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0513\n",
            "Category: 2\n",
            "  Precision: 0.6846\n",
            "  Recall: 0.4205\n",
            "  F1: 0.4878\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4111\n",
            "The average recall is: 0.3537\n",
            "The average f1 is: 0.3640\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Current increase 55 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1351 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 53 sampled in this category.\n",
            "After up-sample, there are 4515 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 4515 samples\n",
            "There are 182 sampled in this category.\n",
            "After up-sample, there are 14525 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 14525 samples\n",
            "There are 14 sampled in this category.\n",
            "After up-sample, there are 15295 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.844375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.08832951945080092\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "53\n",
            "0.033125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "2968\n",
            "0.1940503432494279\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "182\n",
            "0.11375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "10192\n",
            "0.6663615560640732\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "14\n",
            "0.00875\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "784\n",
            "0.05125858123569794\n",
            "\n",
            "(15295, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0831 06:25:36.067112 139633676007232 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0831 06:25:36.067982 139633676007232 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0831 06:25:36.171506 139633676007232 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0831 06:25:38.620705 139633676007232 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0831 06:25:38.621975 139633676007232 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    478.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    478.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    478.    Elapsed: 0:01:01.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    478.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    478.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    478.    Elapsed: 0:02:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    478.    Elapsed: 0:02:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    478.    Elapsed: 0:02:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    478.    Elapsed: 0:03:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    478.    Elapsed: 0:03:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    478.    Elapsed: 0:03:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.26\n",
            "  Accuracy: 0.93\n",
            "Category: 0\n",
            "  Precision: 0.68\n",
            "  Recall: 0.62\n",
            "  F1: 0.63\n",
            "Category: 1\n",
            "  Precision: 0.89\n",
            "  Recall: 0.87\n",
            "  F1: 0.87\n",
            "Category: 2\n",
            "  Precision: 0.94\n",
            "  Recall: 0.99\n",
            "  F1: 0.96\n",
            "Category: 3\n",
            "  Precision: 0.73\n",
            "  Recall: 0.72\n",
            "  F1: 0.72\n",
            "The average precision is: 0.8109\n",
            "The average recall is: 0.7997\n",
            "The average f1 is: 0.7953\n",
            "  Training epcoh took: 0:04:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8766\n",
            "  Recall: 0.9716\n",
            "  F1: 0.9211\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.6346\n",
            "  Recall: 0.3962\n",
            "  F1: 0.4619\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3778\n",
            "The average recall is: 0.3419\n",
            "The average f1 is: 0.3458\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    478.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    478.    Elapsed: 0:00:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    478.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    478.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    478.    Elapsed: 0:01:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    478.    Elapsed: 0:02:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    478.    Elapsed: 0:02:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    478.    Elapsed: 0:02:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    478.    Elapsed: 0:03:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    478.    Elapsed: 0:03:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    478.    Elapsed: 0:03:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.95\n",
            "  Recall: 0.93\n",
            "  F1: 0.94\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.82\n",
            "  Recall: 0.82\n",
            "  F1: 0.82\n",
            "The average precision is: 0.9404\n",
            "The average recall is: 0.9377\n",
            "The average f1 is: 0.9385\n",
            "  Training epcoh took: 0:04:05\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8900\n",
            "  Recall: 0.9663\n",
            "  F1: 0.9256\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.6795\n",
            "  Recall: 0.4951\n",
            "  F1: 0.5222\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3924\n",
            "The average recall is: 0.3653\n",
            "The average f1 is: 0.3620\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    478.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    478.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    478.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    478.    Elapsed: 0:01:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    478.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    478.    Elapsed: 0:02:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    478.    Elapsed: 0:02:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    478.    Elapsed: 0:02:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    478.    Elapsed: 0:03:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    478.    Elapsed: 0:03:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    478.    Elapsed: 0:03:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.96\n",
            "  Recall: 0.95\n",
            "  F1: 0.96\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.79\n",
            "  Recall: 0.79\n",
            "  F1: 0.79\n",
            "The average precision is: 0.9379\n",
            "The average recall is: 0.9375\n",
            "The average f1 is: 0.9376\n",
            "  Training epcoh took: 0:04:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "Category: 0\n",
            "  Precision: 0.8837\n",
            "  Recall: 0.9798\n",
            "  F1: 0.9285\n",
            "Category: 1\n",
            "  Precision: 0.1538\n",
            "  Recall: 0.1154\n",
            "  F1: 0.1282\n",
            "Category: 2\n",
            "  Precision: 0.7436\n",
            "  Recall: 0.3647\n",
            "  F1: 0.4698\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4453\n",
            "The average recall is: 0.3650\n",
            "The average f1 is: 0.3816\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    478.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    478.    Elapsed: 0:00:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    478.    Elapsed: 0:01:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    478.    Elapsed: 0:01:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    478.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    478.    Elapsed: 0:02:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    478.    Elapsed: 0:02:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    478.    Elapsed: 0:02:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    478.    Elapsed: 0:03:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    478.    Elapsed: 0:03:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    478.    Elapsed: 0:03:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.92\n",
            "  Recall: 0.92\n",
            "  F1: 0.92\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.81\n",
            "  Recall: 0.81\n",
            "  F1: 0.81\n",
            "The average precision is: 0.9308\n",
            "The average recall is: 0.9303\n",
            "The average f1 is: 0.9305\n",
            "  Training epcoh took: 0:04:05\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8725\n",
            "  Recall: 0.9825\n",
            "  F1: 0.9227\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.6846\n",
            "  Recall: 0.3457\n",
            "  F1: 0.4383\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3893\n",
            "The average recall is: 0.3321\n",
            "The average f1 is: 0.3403\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Current increase 60 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1351 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 53 sampled in this category.\n",
            "After up-sample, there are 4780 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 4780 samples\n",
            "There are 182 sampled in this category.\n",
            "After up-sample, there are 15700 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 15700 samples\n",
            "There are 14 sampled in this category.\n",
            "After up-sample, there are 16540 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.844375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.0816807738814994\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "53\n",
            "0.033125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "3233\n",
            "0.19546553808948006\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "182\n",
            "0.11375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "11102\n",
            "0.6712212817412334\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "14\n",
            "0.00875\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "854\n",
            "0.05163240628778718\n",
            "\n",
            "(16540, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0831 06:42:05.435698 139633676007232 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0831 06:42:05.436663 139633676007232 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0831 06:42:05.537903 139633676007232 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0831 06:42:08.004853 139633676007232 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0831 06:42:08.005578 139633676007232 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    517.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    517.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    517.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    517.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    517.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    517.    Elapsed: 0:02:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    517.    Elapsed: 0:02:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    517.    Elapsed: 0:02:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    517.    Elapsed: 0:03:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    517.    Elapsed: 0:03:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    517.    Elapsed: 0:03:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    517.    Elapsed: 0:04:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.24\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.74\n",
            "  Recall: 0.67\n",
            "  F1: 0.69\n",
            "Category: 1\n",
            "  Precision: 0.93\n",
            "  Recall: 0.92\n",
            "  F1: 0.92\n",
            "Category: 2\n",
            "  Precision: 0.96\n",
            "  Recall: 0.99\n",
            "  F1: 0.97\n",
            "Category: 3\n",
            "  Precision: 0.76\n",
            "  Recall: 0.75\n",
            "  F1: 0.75\n",
            "The average precision is: 0.8449\n",
            "The average recall is: 0.8357\n",
            "The average f1 is: 0.8325\n",
            "  Training epcoh took: 0:04:25\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8925\n",
            "  Recall: 0.9436\n",
            "  F1: 0.9150\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.5756\n",
            "  Recall: 0.4518\n",
            "  F1: 0.4862\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3863\n",
            "The average recall is: 0.3681\n",
            "The average f1 is: 0.3695\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    517.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    517.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    517.    Elapsed: 0:01:01.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    517.    Elapsed: 0:01:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    517.    Elapsed: 0:01:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    517.    Elapsed: 0:02:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    517.    Elapsed: 0:02:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    517.    Elapsed: 0:02:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    517.    Elapsed: 0:03:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    517.    Elapsed: 0:03:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    517.    Elapsed: 0:03:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    517.    Elapsed: 0:04:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.92\n",
            "  Recall: 0.90\n",
            "  F1: 0.91\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.79\n",
            "  Recall: 0.79\n",
            "  F1: 0.79\n",
            "The average precision is: 0.9251\n",
            "The average recall is: 0.9227\n",
            "The average f1 is: 0.9231\n",
            "  Training epcoh took: 0:04:22\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8860\n",
            "  Recall: 0.9791\n",
            "  F1: 0.9297\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0513\n",
            "Category: 2\n",
            "  Precision: 0.8205\n",
            "  Recall: 0.3932\n",
            "  F1: 0.5033\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4362\n",
            "The average recall is: 0.3623\n",
            "The average f1 is: 0.3711\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    517.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    517.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    517.    Elapsed: 0:01:01.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    517.    Elapsed: 0:01:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    517.    Elapsed: 0:01:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    517.    Elapsed: 0:02:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    517.    Elapsed: 0:02:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    517.    Elapsed: 0:02:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    517.    Elapsed: 0:03:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    517.    Elapsed: 0:03:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    517.    Elapsed: 0:03:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    517.    Elapsed: 0:04:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.92\n",
            "  Recall: 0.91\n",
            "  F1: 0.92\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.81\n",
            "  Recall: 0.81\n",
            "  F1: 0.81\n",
            "The average precision is: 0.9305\n",
            "The average recall is: 0.9301\n",
            "The average f1 is: 0.9301\n",
            "  Training epcoh took: 0:04:22\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8891\n",
            "  Recall: 0.9676\n",
            "  F1: 0.9255\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.7244\n",
            "  Recall: 0.4744\n",
            "  F1: 0.5482\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4226\n",
            "The average recall is: 0.3797\n",
            "The average f1 is: 0.3876\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    517.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    517.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    517.    Elapsed: 0:01:01.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    517.    Elapsed: 0:01:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    517.    Elapsed: 0:01:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    517.    Elapsed: 0:02:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    517.    Elapsed: 0:02:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    517.    Elapsed: 0:02:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    517.    Elapsed: 0:03:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    517.    Elapsed: 0:03:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    517.    Elapsed: 0:03:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    517.    Elapsed: 0:04:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.93\n",
            "  Recall: 0.93\n",
            "  F1: 0.93\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.82\n",
            "  Recall: 0.82\n",
            "  F1: 0.82\n",
            "The average precision is: 0.9384\n",
            "The average recall is: 0.9379\n",
            "The average f1 is: 0.9381\n",
            "  Training epcoh took: 0:04:24\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8888\n",
            "  Recall: 0.9741\n",
            "  F1: 0.9289\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.6154\n",
            "  Recall: 0.4051\n",
            "  F1: 0.4601\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3953\n",
            "The average recall is: 0.3640\n",
            "The average f1 is: 0.3665\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Current increase 65 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1351 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 53 sampled in this category.\n",
            "After up-sample, there are 5045 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 5045 samples\n",
            "There are 182 sampled in this category.\n",
            "After up-sample, there are 16875 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 16875 samples\n",
            "There are 14 sampled in this category.\n",
            "After up-sample, there are 17785 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.844375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.07596289007590666\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "53\n",
            "0.033125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "3498\n",
            "0.19668259769468655\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "182\n",
            "0.11375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "12012\n",
            "0.6754006184987349\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "14\n",
            "0.00875\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "924\n",
            "0.05195389373067191\n",
            "\n",
            "(17785, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0831 06:59:47.240459 139633676007232 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0831 06:59:47.241494 139633676007232 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0831 06:59:47.322036 139633676007232 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0831 06:59:49.818464 139633676007232 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0831 06:59:49.819164 139633676007232 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    556.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    556.    Elapsed: 0:00:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    556.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    556.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    556.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    556.    Elapsed: 0:02:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    556.    Elapsed: 0:02:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    556.    Elapsed: 0:02:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    556.    Elapsed: 0:03:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    556.    Elapsed: 0:03:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    556.    Elapsed: 0:03:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    556.    Elapsed: 0:04:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    556.    Elapsed: 0:04:28.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.21\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.71\n",
            "  Recall: 0.65\n",
            "  F1: 0.66\n",
            "Category: 1\n",
            "  Precision: 0.93\n",
            "  Recall: 0.94\n",
            "  F1: 0.93\n",
            "Category: 2\n",
            "  Precision: 0.96\n",
            "  Recall: 0.99\n",
            "  F1: 0.97\n",
            "Category: 3\n",
            "  Precision: 0.73\n",
            "  Recall: 0.73\n",
            "  F1: 0.73\n",
            "The average precision is: 0.8296\n",
            "The average recall is: 0.8264\n",
            "The average f1 is: 0.8216\n",
            "  Training epcoh took: 0:04:46\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8777\n",
            "  Recall: 0.9681\n",
            "  F1: 0.9197\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.5769\n",
            "  Recall: 0.3393\n",
            "  F1: 0.4105\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3829\n",
            "The average recall is: 0.3461\n",
            "The average f1 is: 0.3518\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    556.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    556.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    556.    Elapsed: 0:01:01.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    556.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    556.    Elapsed: 0:01:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    556.    Elapsed: 0:02:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    556.    Elapsed: 0:02:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    556.    Elapsed: 0:02:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    556.    Elapsed: 0:03:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    556.    Elapsed: 0:03:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    556.    Elapsed: 0:03:48.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    556.    Elapsed: 0:04:08.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    556.    Elapsed: 0:04:28.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.92\n",
            "  Recall: 0.91\n",
            "  F1: 0.91\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.83\n",
            "  Recall: 0.84\n",
            "  F1: 0.83\n",
            "The average precision is: 0.9362\n",
            "The average recall is: 0.9347\n",
            "The average f1 is: 0.9347\n",
            "  Training epcoh took: 0:04:46\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8831\n",
            "  Recall: 0.9725\n",
            "  F1: 0.9244\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.6026\n",
            "  Recall: 0.3281\n",
            "  F1: 0.4078\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3906\n",
            "The average recall is: 0.3444\n",
            "The average f1 is: 0.3523\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    556.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    556.    Elapsed: 0:00:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    556.    Elapsed: 0:01:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    556.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    556.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    556.    Elapsed: 0:02:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    556.    Elapsed: 0:02:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    556.    Elapsed: 0:02:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    556.    Elapsed: 0:03:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    556.    Elapsed: 0:03:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    556.    Elapsed: 0:03:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    556.    Elapsed: 0:04:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    556.    Elapsed: 0:04:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.92\n",
            "  Recall: 0.91\n",
            "  F1: 0.92\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.81\n",
            "  Recall: 0.81\n",
            "  F1: 0.81\n",
            "The average precision is: 0.9320\n",
            "The average recall is: 0.9314\n",
            "The average f1 is: 0.9315\n",
            "  Training epcoh took: 0:04:44\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8897\n",
            "  Recall: 0.9392\n",
            "  F1: 0.9119\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0192\n",
            "  F1: 0.0308\n",
            "Category: 2\n",
            "  Precision: 0.5744\n",
            "  Recall: 0.4832\n",
            "  F1: 0.4751\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3853\n",
            "The average recall is: 0.3604\n",
            "The average f1 is: 0.3544\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    556.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    556.    Elapsed: 0:00:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    556.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    556.    Elapsed: 0:01:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    556.    Elapsed: 0:01:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    556.    Elapsed: 0:02:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    556.    Elapsed: 0:02:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    556.    Elapsed: 0:02:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    556.    Elapsed: 0:03:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    556.    Elapsed: 0:03:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    556.    Elapsed: 0:03:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    556.    Elapsed: 0:04:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    556.    Elapsed: 0:04:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.91\n",
            "  Recall: 0.91\n",
            "  F1: 0.91\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.82\n",
            "  Recall: 0.82\n",
            "  F1: 0.82\n",
            "The average precision is: 0.9337\n",
            "The average recall is: 0.9336\n",
            "The average f1 is: 0.9336\n",
            "  Training epcoh took: 0:04:45\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8755\n",
            "  Recall: 0.9744\n",
            "  F1: 0.9205\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0513\n",
            "Category: 2\n",
            "  Precision: 0.5397\n",
            "  Recall: 0.3378\n",
            "  F1: 0.4018\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3730\n",
            "The average recall is: 0.3377\n",
            "The average f1 is: 0.3434\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Current increase 70 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1351 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 53 sampled in this category.\n",
            "After up-sample, there are 5310 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 5310 samples\n",
            "There are 182 sampled in this category.\n",
            "After up-sample, there are 18050 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 18050 samples\n",
            "There are 14 sampled in this category.\n",
            "After up-sample, there are 19030 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.844375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.07099316868102995\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "53\n",
            "0.033125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "3763\n",
            "0.1977404098791382\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "182\n",
            "0.11375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "12922\n",
            "0.679033105622701\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "14\n",
            "0.00875\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "994\n",
            "0.052233315817130845\n",
            "\n",
            "(19030, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0831 07:18:57.542839 139633676007232 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0831 07:18:57.543836 139633676007232 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0831 07:18:57.621711 139633676007232 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0831 07:19:00.129259 139633676007232 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0831 07:19:00.130602 139633676007232 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    595.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    595.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    595.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    595.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    595.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    595.    Elapsed: 0:02:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    595.    Elapsed: 0:02:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    595.    Elapsed: 0:02:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    595.    Elapsed: 0:03:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    595.    Elapsed: 0:03:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    595.    Elapsed: 0:03:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    595.    Elapsed: 0:04:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    595.    Elapsed: 0:04:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    595.    Elapsed: 0:04:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.24\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.69\n",
            "  Recall: 0.62\n",
            "  F1: 0.64\n",
            "Category: 1\n",
            "  Precision: 0.92\n",
            "  Recall: 0.92\n",
            "  F1: 0.92\n",
            "Category: 2\n",
            "  Precision: 0.96\n",
            "  Recall: 0.99\n",
            "  F1: 0.97\n",
            "Category: 3\n",
            "  Precision: 0.71\n",
            "  Recall: 0.72\n",
            "  F1: 0.71\n",
            "The average precision is: 0.8171\n",
            "The average recall is: 0.8136\n",
            "The average f1 is: 0.8090\n",
            "  Training epcoh took: 0:05:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.75\n",
            "Category: 0\n",
            "  Precision: 0.9047\n",
            "  Recall: 0.8032\n",
            "  F1: 0.8489\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3079\n",
            "  Recall: 0.5874\n",
            "  F1: 0.3878\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3031\n",
            "The average recall is: 0.3476\n",
            "The average f1 is: 0.3092\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    595.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    595.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    595.    Elapsed: 0:01:01.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    595.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    595.    Elapsed: 0:01:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    595.    Elapsed: 0:02:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    595.    Elapsed: 0:02:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    595.    Elapsed: 0:02:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    595.    Elapsed: 0:03:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    595.    Elapsed: 0:03:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    595.    Elapsed: 0:03:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    595.    Elapsed: 0:04:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    595.    Elapsed: 0:04:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    595.    Elapsed: 0:04:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.91\n",
            "  Recall: 0.90\n",
            "  F1: 0.90\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.80\n",
            "  Recall: 0.80\n",
            "  F1: 0.80\n",
            "The average precision is: 0.9263\n",
            "The average recall is: 0.9236\n",
            "The average f1 is: 0.9244\n",
            "  Training epcoh took: 0:05:03\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8790\n",
            "  Recall: 0.9718\n",
            "  F1: 0.9217\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.7500\n",
            "  Recall: 0.4161\n",
            "  F1: 0.4871\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4073\n",
            "The average recall is: 0.3470\n",
            "The average f1 is: 0.3522\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    595.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    595.    Elapsed: 0:00:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    595.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    595.    Elapsed: 0:01:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    595.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    595.    Elapsed: 0:02:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    595.    Elapsed: 0:02:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    595.    Elapsed: 0:02:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    595.    Elapsed: 0:03:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    595.    Elapsed: 0:03:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    595.    Elapsed: 0:03:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    595.    Elapsed: 0:04:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    595.    Elapsed: 0:04:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    595.    Elapsed: 0:04:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.90\n",
            "  Recall: 0.90\n",
            "  F1: 0.90\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.82\n",
            "  Recall: 0.82\n",
            "  F1: 0.82\n",
            "The average precision is: 0.9302\n",
            "The average recall is: 0.9296\n",
            "The average f1 is: 0.9297\n",
            "  Training epcoh took: 0:05:05\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8813\n",
            "  Recall: 0.9632\n",
            "  F1: 0.9194\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.6641\n",
            "  Recall: 0.3927\n",
            "  F1: 0.4745\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3864\n",
            "The average recall is: 0.3390\n",
            "The average f1 is: 0.3485\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    595.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    595.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    595.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    595.    Elapsed: 0:01:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    595.    Elapsed: 0:01:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    595.    Elapsed: 0:02:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    595.    Elapsed: 0:02:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    595.    Elapsed: 0:02:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    595.    Elapsed: 0:03:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    595.    Elapsed: 0:03:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    595.    Elapsed: 0:03:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    595.    Elapsed: 0:04:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    595.    Elapsed: 0:04:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    595.    Elapsed: 0:04:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.90\n",
            "  Recall: 0.90\n",
            "  F1: 0.90\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.80\n",
            "  Recall: 0.80\n",
            "  F1: 0.80\n",
            "The average precision is: 0.9256\n",
            "The average recall is: 0.9254\n",
            "The average f1 is: 0.9255\n",
            "  Training epcoh took: 0:05:05\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8791\n",
            "  Recall: 0.9769\n",
            "  F1: 0.9249\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.6987\n",
            "  Recall: 0.3214\n",
            "  F1: 0.4112\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3945\n",
            "The average recall is: 0.3246\n",
            "The average f1 is: 0.3340\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Current increase 75 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1351 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 53 sampled in this category.\n",
            "After up-sample, there are 5575 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 5575 samples\n",
            "There are 182 sampled in this category.\n",
            "After up-sample, there are 19225 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 19225 samples\n",
            "There are 14 sampled in this category.\n",
            "After up-sample, there are 20275 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.844375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.06663378545006166\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "53\n",
            "0.033125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "4028\n",
            "0.1986683107274969\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "182\n",
            "0.11375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "13832\n",
            "0.6822194821208385\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "14\n",
            "0.00875\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1064\n",
            "0.05247842170160296\n",
            "\n",
            "(20275, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0831 07:39:22.976768 139633676007232 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0831 07:39:22.977707 139633676007232 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0831 07:39:23.960417 139633676007232 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0831 07:39:26.530534 139633676007232 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0831 07:39:26.531788 139633676007232 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    634.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    634.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    634.    Elapsed: 0:01:01.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    634.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    634.    Elapsed: 0:01:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    634.    Elapsed: 0:02:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    634.    Elapsed: 0:02:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    634.    Elapsed: 0:02:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    634.    Elapsed: 0:03:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    634.    Elapsed: 0:03:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    634.    Elapsed: 0:03:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    634.    Elapsed: 0:04:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    634.    Elapsed: 0:04:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    634.    Elapsed: 0:04:48.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    634.    Elapsed: 0:05:09.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.19\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.68\n",
            "  Recall: 0.62\n",
            "  F1: 0.64\n",
            "Category: 1\n",
            "  Precision: 0.93\n",
            "  Recall: 0.93\n",
            "  F1: 0.92\n",
            "Category: 2\n",
            "  Precision: 0.96\n",
            "  Recall: 0.99\n",
            "  F1: 0.98\n",
            "Category: 3\n",
            "  Precision: 0.76\n",
            "  Recall: 0.75\n",
            "  F1: 0.75\n",
            "The average precision is: 0.8336\n",
            "The average recall is: 0.8257\n",
            "The average f1 is: 0.8228\n",
            "  Training epcoh took: 0:05:26\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8907\n",
            "  Recall: 0.9394\n",
            "  F1: 0.9130\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.5141\n",
            "  Recall: 0.5316\n",
            "  F1: 0.4972\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3512\n",
            "The average recall is: 0.3678\n",
            "The average f1 is: 0.3525\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    634.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    634.    Elapsed: 0:00:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    634.    Elapsed: 0:01:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    634.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    634.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    634.    Elapsed: 0:02:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    634.    Elapsed: 0:02:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    634.    Elapsed: 0:02:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    634.    Elapsed: 0:03:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    634.    Elapsed: 0:03:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    634.    Elapsed: 0:03:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    634.    Elapsed: 0:04:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    634.    Elapsed: 0:04:28.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    634.    Elapsed: 0:04:48.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    634.    Elapsed: 0:05:09.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.88\n",
            "  Recall: 0.88\n",
            "  F1: 0.87\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.84\n",
            "  Recall: 0.84\n",
            "  F1: 0.84\n",
            "The average precision is: 0.9284\n",
            "The average recall is: 0.9278\n",
            "The average f1 is: 0.9271\n",
            "  Training epcoh took: 0:05:26\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8861\n",
            "  Recall: 0.9738\n",
            "  F1: 0.9275\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.5654\n",
            "  Recall: 0.3747\n",
            "  F1: 0.4273\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3629\n",
            "The average recall is: 0.3371\n",
            "The average f1 is: 0.3387\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    634.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    634.    Elapsed: 0:00:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    634.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    634.    Elapsed: 0:01:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    634.    Elapsed: 0:01:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    634.    Elapsed: 0:02:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    634.    Elapsed: 0:02:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    634.    Elapsed: 0:02:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    634.    Elapsed: 0:03:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    634.    Elapsed: 0:03:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    634.    Elapsed: 0:03:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    634.    Elapsed: 0:04:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    634.    Elapsed: 0:04:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    634.    Elapsed: 0:04:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    634.    Elapsed: 0:05:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.89\n",
            "  Recall: 0.89\n",
            "  F1: 0.89\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.82\n",
            "  Recall: 0.82\n",
            "  F1: 0.82\n",
            "The average precision is: 0.9290\n",
            "The average recall is: 0.9289\n",
            "The average f1 is: 0.9288\n",
            "  Training epcoh took: 0:05:24\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "Category: 0\n",
            "  Precision: 0.8827\n",
            "  Recall: 0.9852\n",
            "  F1: 0.9300\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.6538\n",
            "  Recall: 0.4297\n",
            "  F1: 0.4891\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3841\n",
            "The average recall is: 0.3537\n",
            "The average f1 is: 0.3548\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    634.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    634.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    634.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    634.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    634.    Elapsed: 0:01:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    634.    Elapsed: 0:02:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    634.    Elapsed: 0:02:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    634.    Elapsed: 0:02:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    634.    Elapsed: 0:03:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    634.    Elapsed: 0:03:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    634.    Elapsed: 0:03:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    634.    Elapsed: 0:04:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    634.    Elapsed: 0:04:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    634.    Elapsed: 0:04:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    634.    Elapsed: 0:05:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.90\n",
            "  Recall: 0.90\n",
            "  F1: 0.90\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.82\n",
            "  Recall: 0.82\n",
            "  F1: 0.82\n",
            "The average precision is: 0.9301\n",
            "The average recall is: 0.9304\n",
            "The average f1 is: 0.9301\n",
            "  Training epcoh took: 0:05:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8836\n",
            "  Recall: 0.9773\n",
            "  F1: 0.9273\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.7115\n",
            "  Recall: 0.4330\n",
            "  F1: 0.5153\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3988\n",
            "The average recall is: 0.3526\n",
            "The average f1 is: 0.3607\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Current increase 80 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1351 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 53 sampled in this category.\n",
            "After up-sample, there are 5840 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 5840 samples\n",
            "There are 182 sampled in this category.\n",
            "After up-sample, there are 20400 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 20400 samples\n",
            "There are 14 sampled in this category.\n",
            "After up-sample, there are 21520 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.844375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.06277881040892193\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "53\n",
            "0.033125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "4293\n",
            "0.19948884758364313\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "182\n",
            "0.11375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "14742\n",
            "0.6850371747211896\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "14\n",
            "0.00875\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1134\n",
            "0.052695167286245355\n",
            "\n",
            "(21520, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0831 08:01:10.808579 139633676007232 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0831 08:01:10.809543 139633676007232 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0831 08:01:14.123894 139633676007232 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0831 08:01:16.627855 139633676007232 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0831 08:01:16.628709 139633676007232 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    673.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    673.    Elapsed: 0:00:40.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    673.    Elapsed: 0:01:00.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    673.    Elapsed: 0:01:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    673.    Elapsed: 0:01:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    673.    Elapsed: 0:02:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    673.    Elapsed: 0:02:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    673.    Elapsed: 0:02:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    673.    Elapsed: 0:03:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    673.    Elapsed: 0:03:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    673.    Elapsed: 0:03:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    673.    Elapsed: 0:04:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    673.    Elapsed: 0:04:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    673.    Elapsed: 0:04:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    673.    Elapsed: 0:05:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    673.    Elapsed: 0:05:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.23\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.67\n",
            "  Recall: 0.60\n",
            "  F1: 0.62\n",
            "Category: 1\n",
            "  Precision: 0.91\n",
            "  Recall: 0.93\n",
            "  F1: 0.92\n",
            "Category: 2\n",
            "  Precision: 0.96\n",
            "  Recall: 0.99\n",
            "  F1: 0.97\n",
            "Category: 3\n",
            "  Precision: 0.75\n",
            "  Recall: 0.74\n",
            "  F1: 0.74\n",
            "The average precision is: 0.8220\n",
            "The average recall is: 0.8162\n",
            "The average f1 is: 0.8120\n",
            "  Training epcoh took: 0:05:44\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8944\n",
            "  Recall: 0.9555\n",
            "  F1: 0.9219\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.6513\n",
            "  Recall: 0.5020\n",
            "  F1: 0.5351\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3864\n",
            "The average recall is: 0.3644\n",
            "The average f1 is: 0.3643\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    673.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    673.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    673.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    673.    Elapsed: 0:01:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    673.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    673.    Elapsed: 0:02:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    673.    Elapsed: 0:02:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    673.    Elapsed: 0:02:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    673.    Elapsed: 0:03:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    673.    Elapsed: 0:03:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    673.    Elapsed: 0:03:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    673.    Elapsed: 0:04:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    673.    Elapsed: 0:04:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    673.    Elapsed: 0:04:48.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    673.    Elapsed: 0:05:08.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    673.    Elapsed: 0:05:30.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.86\n",
            "  Recall: 0.85\n",
            "  F1: 0.86\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.82\n",
            "  Recall: 0.82\n",
            "  F1: 0.82\n",
            "The average precision is: 0.9205\n",
            "The average recall is: 0.9184\n",
            "The average f1 is: 0.9187\n",
            "  Training epcoh took: 0:05:46\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8806\n",
            "  Recall: 0.9546\n",
            "  F1: 0.9151\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.5231\n",
            "  Recall: 0.2936\n",
            "  F1: 0.3660\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3509\n",
            "The average recall is: 0.3120\n",
            "The average f1 is: 0.3203\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    673.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    673.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    673.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    673.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    673.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    673.    Elapsed: 0:02:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    673.    Elapsed: 0:02:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    673.    Elapsed: 0:02:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    673.    Elapsed: 0:03:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    673.    Elapsed: 0:03:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    673.    Elapsed: 0:03:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    673.    Elapsed: 0:04:08.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    673.    Elapsed: 0:04:30.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    673.    Elapsed: 0:04:51.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    673.    Elapsed: 0:05:11.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    673.    Elapsed: 0:05:32.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.87\n",
            "  Recall: 0.87\n",
            "  F1: 0.87\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.83\n",
            "  Recall: 0.83\n",
            "  F1: 0.83\n",
            "The average precision is: 0.9246\n",
            "The average recall is: 0.9239\n",
            "The average f1 is: 0.9240\n",
            "  Training epcoh took: 0:05:49\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8774\n",
            "  Recall: 0.9721\n",
            "  F1: 0.9214\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0513\n",
            "Category: 2\n",
            "  Precision: 0.6575\n",
            "  Recall: 0.3801\n",
            "  F1: 0.4547\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4029\n",
            "The average recall is: 0.3477\n",
            "The average f1 is: 0.3569\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    673.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    673.    Elapsed: 0:00:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    673.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    673.    Elapsed: 0:01:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    673.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    673.    Elapsed: 0:02:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    673.    Elapsed: 0:02:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    673.    Elapsed: 0:02:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    673.    Elapsed: 0:03:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    673.    Elapsed: 0:03:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    673.    Elapsed: 0:03:49.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    673.    Elapsed: 0:04:09.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    673.    Elapsed: 0:04:30.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    673.    Elapsed: 0:04:50.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    673.    Elapsed: 0:05:12.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    673.    Elapsed: 0:05:32.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.87\n",
            "  Recall: 0.87\n",
            "  F1: 0.87\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.82\n",
            "  Recall: 0.82\n",
            "  F1: 0.82\n",
            "The average precision is: 0.9216\n",
            "The average recall is: 0.9214\n",
            "The average f1 is: 0.9215\n",
            "  Training epcoh took: 0:05:49\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8864\n",
            "  Recall: 0.9660\n",
            "  F1: 0.9234\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.6859\n",
            "  Recall: 0.4449\n",
            "  F1: 0.4839\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4123\n",
            "The average recall is: 0.3719\n",
            "The average f1 is: 0.3711\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Current increase 85 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1351 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 53 sampled in this category.\n",
            "After up-sample, there are 6105 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 6105 samples\n",
            "There are 182 sampled in this category.\n",
            "After up-sample, there are 21575 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 21575 samples\n",
            "There are 14 sampled in this category.\n",
            "After up-sample, there are 22765 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.844375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.05934548649242258\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "53\n",
            "0.033125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "4558\n",
            "0.20021963540522733\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "182\n",
            "0.11375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "15652\n",
            "0.6875466725236108\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "14\n",
            "0.00875\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1204\n",
            "0.05288820557873929\n",
            "\n",
            "(22765, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0831 08:24:29.851399 139633676007232 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0831 08:24:29.852332 139633676007232 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0831 08:24:30.752966 139633676007232 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0831 08:24:33.249241 139633676007232 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0831 08:24:33.249924 139633676007232 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    712.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    712.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    712.    Elapsed: 0:01:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    712.    Elapsed: 0:01:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    712.    Elapsed: 0:01:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    712.    Elapsed: 0:02:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    712.    Elapsed: 0:02:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    712.    Elapsed: 0:02:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    712.    Elapsed: 0:03:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    712.    Elapsed: 0:03:28.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    712.    Elapsed: 0:03:49.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    712.    Elapsed: 0:04:10.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    712.    Elapsed: 0:04:31.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    712.    Elapsed: 0:04:51.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    712.    Elapsed: 0:05:12.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    712.    Elapsed: 0:05:33.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of    712.    Elapsed: 0:05:53.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.19\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.65\n",
            "  Recall: 0.61\n",
            "  F1: 0.62\n",
            "Category: 1\n",
            "  Precision: 0.92\n",
            "  Recall: 0.93\n",
            "  F1: 0.93\n",
            "Category: 2\n",
            "  Precision: 0.96\n",
            "  Recall: 0.99\n",
            "  F1: 0.98\n",
            "Category: 3\n",
            "  Precision: 0.74\n",
            "  Recall: 0.74\n",
            "  F1: 0.74\n",
            "The average precision is: 0.8207\n",
            "The average recall is: 0.8193\n",
            "The average f1 is: 0.8151\n",
            "  Training epcoh took: 0:06:10\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8865\n",
            "  Recall: 0.9523\n",
            "  F1: 0.9164\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0513\n",
            "Category: 2\n",
            "  Precision: 0.6641\n",
            "  Recall: 0.4273\n",
            "  F1: 0.4788\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4069\n",
            "The average recall is: 0.3545\n",
            "The average f1 is: 0.3616\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    712.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    712.    Elapsed: 0:00:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    712.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    712.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    712.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    712.    Elapsed: 0:02:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    712.    Elapsed: 0:02:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    712.    Elapsed: 0:02:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    712.    Elapsed: 0:03:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    712.    Elapsed: 0:03:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    712.    Elapsed: 0:03:48.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    712.    Elapsed: 0:04:08.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    712.    Elapsed: 0:04:29.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    712.    Elapsed: 0:04:50.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    712.    Elapsed: 0:05:11.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    712.    Elapsed: 0:05:32.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of    712.    Elapsed: 0:05:52.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.85\n",
            "  Recall: 0.85\n",
            "  F1: 0.85\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.81\n",
            "  Recall: 0.81\n",
            "  F1: 0.81\n",
            "The average precision is: 0.9155\n",
            "The average recall is: 0.9152\n",
            "The average f1 is: 0.9149\n",
            "  Training epcoh took: 0:06:08\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8830\n",
            "  Recall: 0.9627\n",
            "  F1: 0.9200\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.6410\n",
            "  Recall: 0.4505\n",
            "  F1: 0.5106\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4002\n",
            "The average recall is: 0.3725\n",
            "The average f1 is: 0.3769\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    712.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    712.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    712.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    712.    Elapsed: 0:01:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    712.    Elapsed: 0:01:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    712.    Elapsed: 0:02:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    712.    Elapsed: 0:02:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    712.    Elapsed: 0:02:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    712.    Elapsed: 0:03:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    712.    Elapsed: 0:03:28.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    712.    Elapsed: 0:03:49.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    712.    Elapsed: 0:04:10.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    712.    Elapsed: 0:04:31.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    712.    Elapsed: 0:04:52.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    712.    Elapsed: 0:05:13.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    712.    Elapsed: 0:05:33.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of    712.    Elapsed: 0:05:55.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.87\n",
            "  Recall: 0.86\n",
            "  F1: 0.87\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.83\n",
            "  Recall: 0.83\n",
            "  F1: 0.83\n",
            "The average precision is: 0.9240\n",
            "The average recall is: 0.9236\n",
            "The average f1 is: 0.9236\n",
            "  Training epcoh took: 0:06:12\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8843\n",
            "  Recall: 0.9780\n",
            "  F1: 0.9274\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.6154\n",
            "  Recall: 0.3990\n",
            "  F1: 0.4655\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3749\n",
            "The average recall is: 0.3443\n",
            "The average f1 is: 0.3482\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    712.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    712.    Elapsed: 0:00:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    712.    Elapsed: 0:01:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    712.    Elapsed: 0:01:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    712.    Elapsed: 0:01:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    712.    Elapsed: 0:02:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    712.    Elapsed: 0:02:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    712.    Elapsed: 0:02:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    712.    Elapsed: 0:03:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    712.    Elapsed: 0:03:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    712.    Elapsed: 0:03:48.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    712.    Elapsed: 0:04:08.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    712.    Elapsed: 0:04:29.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    712.    Elapsed: 0:04:50.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    712.    Elapsed: 0:05:11.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    712.    Elapsed: 0:05:31.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of    712.    Elapsed: 0:05:52.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.88\n",
            "  Recall: 0.87\n",
            "  F1: 0.87\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.81\n",
            "  Recall: 0.81\n",
            "  F1: 0.81\n",
            "The average precision is: 0.9202\n",
            "The average recall is: 0.9199\n",
            "The average f1 is: 0.9200\n",
            "  Training epcoh took: 0:06:09\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8888\n",
            "  Recall: 0.9634\n",
            "  F1: 0.9233\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.6897\n",
            "  Recall: 0.3866\n",
            "  F1: 0.4606\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3946\n",
            "The average recall is: 0.3375\n",
            "The average f1 is: 0.3460\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Current increase 90 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1351 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 53 sampled in this category.\n",
            "After up-sample, there are 6370 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 6370 samples\n",
            "There are 182 sampled in this category.\n",
            "After up-sample, there are 22750 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 22750 samples\n",
            "There are 14 sampled in this category.\n",
            "After up-sample, there are 24010 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.844375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.056268221574344024\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "53\n",
            "0.033125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "4823\n",
            "0.20087463556851312\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "182\n",
            "0.11375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "16562\n",
            "0.689795918367347\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "14\n",
            "0.00875\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1274\n",
            "0.053061224489795916\n",
            "\n",
            "(24010, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0831 08:49:18.073496 139633676007232 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0831 08:49:18.074585 139633676007232 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0831 08:49:23.146519 139633676007232 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0831 08:49:25.608039 139633676007232 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0831 08:49:25.609424 139633676007232 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    751.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    751.    Elapsed: 0:00:40.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    751.    Elapsed: 0:01:00.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    751.    Elapsed: 0:01:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    751.    Elapsed: 0:01:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    751.    Elapsed: 0:02:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    751.    Elapsed: 0:02:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    751.    Elapsed: 0:02:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    751.    Elapsed: 0:03:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    751.    Elapsed: 0:03:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    751.    Elapsed: 0:03:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    751.    Elapsed: 0:04:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    751.    Elapsed: 0:04:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    751.    Elapsed: 0:04:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    751.    Elapsed: 0:05:08.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    751.    Elapsed: 0:05:29.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of    751.    Elapsed: 0:05:50.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of    751.    Elapsed: 0:06:10.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.17\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.63\n",
            "  Recall: 0.59\n",
            "  F1: 0.60\n",
            "Category: 1\n",
            "  Precision: 0.94\n",
            "  Recall: 0.94\n",
            "  F1: 0.93\n",
            "Category: 2\n",
            "  Precision: 0.97\n",
            "  Recall: 0.99\n",
            "  F1: 0.98\n",
            "Category: 3\n",
            "  Precision: 0.75\n",
            "  Recall: 0.75\n",
            "  F1: 0.75\n",
            "The average precision is: 0.8204\n",
            "The average recall is: 0.8187\n",
            "The average f1 is: 0.8138\n",
            "  Training epcoh took: 0:06:26\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8932\n",
            "  Recall: 0.9363\n",
            "  F1: 0.9136\n",
            "Category: 1\n",
            "  Precision: 0.1538\n",
            "  Recall: 0.0577\n",
            "  F1: 0.0821\n",
            "Category: 2\n",
            "  Precision: 0.6676\n",
            "  Recall: 0.5179\n",
            "  F1: 0.5518\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4287\n",
            "The average recall is: 0.3780\n",
            "The average f1 is: 0.3869\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    751.    Elapsed: 0:00:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    751.    Elapsed: 0:00:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    751.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    751.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    751.    Elapsed: 0:01:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    751.    Elapsed: 0:02:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    751.    Elapsed: 0:02:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    751.    Elapsed: 0:02:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    751.    Elapsed: 0:03:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    751.    Elapsed: 0:03:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    751.    Elapsed: 0:03:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    751.    Elapsed: 0:04:08.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    751.    Elapsed: 0:04:29.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    751.    Elapsed: 0:04:49.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    751.    Elapsed: 0:05:09.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    751.    Elapsed: 0:05:30.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of    751.    Elapsed: 0:05:51.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of    751.    Elapsed: 0:06:11.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.80\n",
            "  Recall: 0.79\n",
            "  F1: 0.79\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.82\n",
            "  Recall: 0.82\n",
            "  F1: 0.82\n",
            "The average precision is: 0.9031\n",
            "The average recall is: 0.9012\n",
            "The average f1 is: 0.9012\n",
            "  Training epcoh took: 0:06:27\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8790\n",
            "  Recall: 0.9542\n",
            "  F1: 0.9133\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.5667\n",
            "  Recall: 0.3713\n",
            "  F1: 0.3993\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3806\n",
            "The average recall is: 0.3506\n",
            "The average f1 is: 0.3474\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    751.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    751.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    751.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    751.    Elapsed: 0:01:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    751.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    751.    Elapsed: 0:02:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    751.    Elapsed: 0:02:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    751.    Elapsed: 0:02:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    751.    Elapsed: 0:03:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    751.    Elapsed: 0:03:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    751.    Elapsed: 0:03:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    751.    Elapsed: 0:04:08.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    751.    Elapsed: 0:04:28.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    751.    Elapsed: 0:04:49.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    751.    Elapsed: 0:05:10.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    751.    Elapsed: 0:05:31.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of    751.    Elapsed: 0:05:52.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of    751.    Elapsed: 0:06:12.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.85\n",
            "  Recall: 0.84\n",
            "  F1: 0.84\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.83\n",
            "  Recall: 0.83\n",
            "  F1: 0.83\n",
            "The average precision is: 0.9190\n",
            "The average recall is: 0.9186\n",
            "The average f1 is: 0.9186\n",
            "  Training epcoh took: 0:06:27\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8806\n",
            "  Recall: 0.9472\n",
            "  F1: 0.9104\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.6000\n",
            "  Recall: 0.4337\n",
            "  F1: 0.4704\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3701\n",
            "The average recall is: 0.3452\n",
            "The average f1 is: 0.3452\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    751.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    751.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    751.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    751.    Elapsed: 0:01:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    751.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    751.    Elapsed: 0:02:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    751.    Elapsed: 0:02:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    751.    Elapsed: 0:02:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    751.    Elapsed: 0:03:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    751.    Elapsed: 0:03:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    751.    Elapsed: 0:03:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    751.    Elapsed: 0:04:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    751.    Elapsed: 0:04:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    751.    Elapsed: 0:04:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    751.    Elapsed: 0:05:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    751.    Elapsed: 0:05:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of    751.    Elapsed: 0:05:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of    751.    Elapsed: 0:06:08.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.84\n",
            "  Recall: 0.84\n",
            "  F1: 0.84\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.82\n",
            "  Recall: 0.82\n",
            "  F1: 0.82\n",
            "The average precision is: 0.9138\n",
            "The average recall is: 0.9136\n",
            "The average f1 is: 0.9137\n",
            "  Training epcoh took: 0:06:24\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8787\n",
            "  Recall: 0.9713\n",
            "  F1: 0.9220\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.6795\n",
            "  Recall: 0.4324\n",
            "  F1: 0.5011\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3895\n",
            "The average recall is: 0.3509\n",
            "The average f1 is: 0.3558\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Current increase 95 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1351 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 53 sampled in this category.\n",
            "After up-sample, there are 6635 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 6635 samples\n",
            "There are 182 sampled in this category.\n",
            "After up-sample, there are 23925 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 23925 samples\n",
            "There are 14 sampled in this category.\n",
            "After up-sample, there are 25255 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.844375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.05349435755295981\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "53\n",
            "0.033125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "5088\n",
            "0.2014650564244704\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "182\n",
            "0.11375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "17472\n",
            "0.691823401306672\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "14\n",
            "0.00875\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1344\n",
            "0.05321718471589784\n",
            "\n",
            "(25255, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0831 09:15:15.651803 139633676007232 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0831 09:15:15.652798 139633676007232 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0831 09:15:15.753480 139633676007232 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0831 09:15:18.185045 139633676007232 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0831 09:15:18.186336 139633676007232 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    790.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    790.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    790.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    790.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    790.    Elapsed: 0:01:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    790.    Elapsed: 0:02:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    790.    Elapsed: 0:02:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    790.    Elapsed: 0:02:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    790.    Elapsed: 0:03:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    790.    Elapsed: 0:03:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    790.    Elapsed: 0:03:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    790.    Elapsed: 0:04:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    790.    Elapsed: 0:04:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    790.    Elapsed: 0:04:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    790.    Elapsed: 0:05:09.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    790.    Elapsed: 0:05:29.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of    790.    Elapsed: 0:05:50.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of    790.    Elapsed: 0:06:10.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of    790.    Elapsed: 0:06:31.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.18\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.64\n",
            "  Recall: 0.59\n",
            "  F1: 0.61\n",
            "Category: 1\n",
            "  Precision: 0.95\n",
            "  Recall: 0.95\n",
            "  F1: 0.94\n",
            "Category: 2\n",
            "  Precision: 0.97\n",
            "  Recall: 0.99\n",
            "  F1: 0.98\n",
            "Category: 3\n",
            "  Precision: 0.73\n",
            "  Recall: 0.74\n",
            "  F1: 0.73\n",
            "The average precision is: 0.8232\n",
            "The average recall is: 0.8188\n",
            "The average f1 is: 0.8155\n",
            "  Training epcoh took: 0:06:46\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8808\n",
            "  Recall: 0.9741\n",
            "  F1: 0.9245\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.6538\n",
            "  Recall: 0.3201\n",
            "  F1: 0.4187\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3837\n",
            "The average recall is: 0.3236\n",
            "The average f1 is: 0.3358\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    790.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    790.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    790.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    790.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    790.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    790.    Elapsed: 0:02:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    790.    Elapsed: 0:02:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    790.    Elapsed: 0:02:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    790.    Elapsed: 0:03:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    790.    Elapsed: 0:03:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    790.    Elapsed: 0:03:49.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    790.    Elapsed: 0:04:09.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    790.    Elapsed: 0:04:30.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    790.    Elapsed: 0:04:50.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    790.    Elapsed: 0:05:11.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    790.    Elapsed: 0:05:32.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of    790.    Elapsed: 0:05:53.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of    790.    Elapsed: 0:06:13.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of    790.    Elapsed: 0:06:34.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.82\n",
            "  Recall: 0.81\n",
            "  F1: 0.81\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.84\n",
            "  Recall: 0.84\n",
            "  F1: 0.84\n",
            "The average precision is: 0.9125\n",
            "The average recall is: 0.9116\n",
            "The average f1 is: 0.9114\n",
            "  Training epcoh took: 0:06:49\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8860\n",
            "  Recall: 0.9749\n",
            "  F1: 0.9268\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.6731\n",
            "  Recall: 0.3951\n",
            "  F1: 0.4714\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3898\n",
            "The average recall is: 0.3425\n",
            "The average f1 is: 0.3496\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    790.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    790.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    790.    Elapsed: 0:01:01.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    790.    Elapsed: 0:01:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    790.    Elapsed: 0:01:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    790.    Elapsed: 0:02:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    790.    Elapsed: 0:02:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    790.    Elapsed: 0:02:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    790.    Elapsed: 0:03:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    790.    Elapsed: 0:03:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    790.    Elapsed: 0:03:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    790.    Elapsed: 0:04:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    790.    Elapsed: 0:04:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    790.    Elapsed: 0:04:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    790.    Elapsed: 0:05:08.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    790.    Elapsed: 0:05:28.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of    790.    Elapsed: 0:05:49.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of    790.    Elapsed: 0:06:10.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of    790.    Elapsed: 0:06:30.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.82\n",
            "  Recall: 0.82\n",
            "  F1: 0.82\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.82\n",
            "  Recall: 0.82\n",
            "  F1: 0.82\n",
            "The average precision is: 0.9103\n",
            "The average recall is: 0.9098\n",
            "The average f1 is: 0.9097\n",
            "  Training epcoh took: 0:06:46\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8845\n",
            "  Recall: 0.9684\n",
            "  F1: 0.9235\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.6744\n",
            "  Recall: 0.3910\n",
            "  F1: 0.4788\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3897\n",
            "The average recall is: 0.3398\n",
            "The average f1 is: 0.3506\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    790.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    790.    Elapsed: 0:00:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    790.    Elapsed: 0:01:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    790.    Elapsed: 0:01:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    790.    Elapsed: 0:01:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    790.    Elapsed: 0:02:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    790.    Elapsed: 0:02:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    790.    Elapsed: 0:02:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    790.    Elapsed: 0:03:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    790.    Elapsed: 0:03:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    790.    Elapsed: 0:03:48.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    790.    Elapsed: 0:04:09.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    790.    Elapsed: 0:04:30.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    790.    Elapsed: 0:04:51.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    790.    Elapsed: 0:05:11.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    790.    Elapsed: 0:05:32.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of    790.    Elapsed: 0:05:52.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of    790.    Elapsed: 0:06:14.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of    790.    Elapsed: 0:06:34.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.82\n",
            "  Recall: 0.82\n",
            "  F1: 0.82\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.85\n",
            "  Recall: 0.85\n",
            "  F1: 0.85\n",
            "The average precision is: 0.9169\n",
            "The average recall is: 0.9170\n",
            "The average f1 is: 0.9169\n",
            "  Training epcoh took: 0:06:49\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8800\n",
            "  Recall: 0.9800\n",
            "  F1: 0.9259\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.6538\n",
            "  Recall: 0.3603\n",
            "  F1: 0.4454\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3835\n",
            "The average recall is: 0.3351\n",
            "The average f1 is: 0.3428\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Current increase 100 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1351 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 53 sampled in this category.\n",
            "After up-sample, there are 6900 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 6900 samples\n",
            "There are 182 sampled in this category.\n",
            "After up-sample, there are 25100 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 25100 samples\n",
            "There are 14 sampled in this category.\n",
            "After up-sample, there are 26500 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.844375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.0509811320754717\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "53\n",
            "0.033125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "5353\n",
            "0.202\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "182\n",
            "0.11375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "18382\n",
            "0.6936603773584906\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "14\n",
            "0.00875\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1414\n",
            "0.05335849056603774\n",
            "\n",
            "(26500, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0831 09:42:33.971452 139633676007232 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0831 09:42:33.972424 139633676007232 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0831 09:42:34.058718 139633676007232 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0831 09:42:36.509026 139633676007232 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0831 09:42:36.510925 139633676007232 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    829.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    829.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    829.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    829.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    829.    Elapsed: 0:01:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    829.    Elapsed: 0:02:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    829.    Elapsed: 0:02:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    829.    Elapsed: 0:02:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    829.    Elapsed: 0:03:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    829.    Elapsed: 0:03:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    829.    Elapsed: 0:03:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    829.    Elapsed: 0:04:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    829.    Elapsed: 0:04:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    829.    Elapsed: 0:04:48.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    829.    Elapsed: 0:05:08.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    829.    Elapsed: 0:05:28.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of    829.    Elapsed: 0:05:49.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of    829.    Elapsed: 0:06:09.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of    829.    Elapsed: 0:06:29.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of    829.    Elapsed: 0:06:50.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.15\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.61\n",
            "  Recall: 0.57\n",
            "  F1: 0.58\n",
            "Category: 1\n",
            "  Precision: 0.94\n",
            "  Recall: 0.94\n",
            "  F1: 0.93\n",
            "Category: 2\n",
            "  Precision: 0.97\n",
            "  Recall: 0.99\n",
            "  F1: 0.98\n",
            "Category: 3\n",
            "  Precision: 0.76\n",
            "  Recall: 0.76\n",
            "  F1: 0.76\n",
            "The average precision is: 0.8178\n",
            "The average recall is: 0.8149\n",
            "The average f1 is: 0.8118\n",
            "  Training epcoh took: 0:07:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.80\n",
            "Category: 0\n",
            "  Precision: 0.9026\n",
            "  Recall: 0.8662\n",
            "  F1: 0.8829\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.3979\n",
            "  Recall: 0.6487\n",
            "  F1: 0.4664\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3251\n",
            "The average recall is: 0.3787\n",
            "The average f1 is: 0.3373\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    829.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    829.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    829.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    829.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    829.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    829.    Elapsed: 0:02:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    829.    Elapsed: 0:02:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    829.    Elapsed: 0:02:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    829.    Elapsed: 0:03:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    829.    Elapsed: 0:03:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    829.    Elapsed: 0:03:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    829.    Elapsed: 0:04:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    829.    Elapsed: 0:04:28.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    829.    Elapsed: 0:04:49.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    829.    Elapsed: 0:05:09.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    829.    Elapsed: 0:05:30.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of    829.    Elapsed: 0:05:51.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of    829.    Elapsed: 0:06:11.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of    829.    Elapsed: 0:06:32.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of    829.    Elapsed: 0:06:52.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.81\n",
            "  Recall: 0.80\n",
            "  F1: 0.80\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.83\n",
            "  Recall: 0.83\n",
            "  F1: 0.83\n",
            "The average precision is: 0.9103\n",
            "The average recall is: 0.9088\n",
            "The average f1 is: 0.9090\n",
            "  Training epcoh took: 0:07:08\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "Category: 0\n",
            "  Precision: 0.8763\n",
            "  Recall: 0.9405\n",
            "  F1: 0.9063\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.5321\n",
            "  Recall: 0.3013\n",
            "  F1: 0.3591\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3713\n",
            "The average recall is: 0.3297\n",
            "The average f1 is: 0.3356\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    829.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    829.    Elapsed: 0:00:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    829.    Elapsed: 0:01:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    829.    Elapsed: 0:01:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    829.    Elapsed: 0:01:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    829.    Elapsed: 0:02:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    829.    Elapsed: 0:02:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    829.    Elapsed: 0:02:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    829.    Elapsed: 0:03:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    829.    Elapsed: 0:03:28.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    829.    Elapsed: 0:03:48.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    829.    Elapsed: 0:04:08.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    829.    Elapsed: 0:04:29.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    829.    Elapsed: 0:04:49.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    829.    Elapsed: 0:05:09.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    829.    Elapsed: 0:05:29.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of    829.    Elapsed: 0:05:49.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of    829.    Elapsed: 0:06:11.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of    829.    Elapsed: 0:06:32.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of    829.    Elapsed: 0:06:52.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.81\n",
            "  Recall: 0.80\n",
            "  F1: 0.80\n",
            "Category: 1\n",
            "  Precision: 0.99\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.82\n",
            "  Recall: 0.82\n",
            "  F1: 0.82\n",
            "The average precision is: 0.9058\n",
            "The average recall is: 0.9048\n",
            "The average f1 is: 0.9050\n",
            "  Training epcoh took: 0:07:07\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8786\n",
            "  Recall: 0.9659\n",
            "  F1: 0.9192\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.5641\n",
            "  Recall: 0.3544\n",
            "  F1: 0.4098\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3799\n",
            "The average recall is: 0.3493\n",
            "The average f1 is: 0.3515\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    829.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    829.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    829.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    829.    Elapsed: 0:01:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    829.    Elapsed: 0:01:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    829.    Elapsed: 0:02:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    829.    Elapsed: 0:02:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    829.    Elapsed: 0:02:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    829.    Elapsed: 0:03:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    829.    Elapsed: 0:03:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    829.    Elapsed: 0:03:48.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    829.    Elapsed: 0:04:09.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    829.    Elapsed: 0:04:29.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    829.    Elapsed: 0:04:50.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    829.    Elapsed: 0:05:10.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    829.    Elapsed: 0:05:30.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of    829.    Elapsed: 0:05:51.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of    829.    Elapsed: 0:06:11.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of    829.    Elapsed: 0:06:32.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of    829.    Elapsed: 0:06:52.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.83\n",
            "  Recall: 0.83\n",
            "  F1: 0.83\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.83\n",
            "  Recall: 0.83\n",
            "  F1: 0.83\n",
            "The average precision is: 0.9145\n",
            "The average recall is: 0.9142\n",
            "The average f1 is: 0.9143\n",
            "  Training epcoh took: 0:07:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8839\n",
            "  Recall: 0.9686\n",
            "  F1: 0.9232\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0513\n",
            "Category: 2\n",
            "  Precision: 0.5872\n",
            "  Recall: 0.3897\n",
            "  F1: 0.4469\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3870\n",
            "The average recall is: 0.3492\n",
            "The average f1 is: 0.3553\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Current increase 105 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1351 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 53 sampled in this category.\n",
            "After up-sample, there are 7165 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 7165 samples\n",
            "There are 182 sampled in this category.\n",
            "After up-sample, there are 26275 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 26275 samples\n",
            "There are 14 sampled in this category.\n",
            "After up-sample, there are 27745 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.844375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.04869345828077131\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "53\n",
            "0.033125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "5618\n",
            "0.20248693458280773\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "182\n",
            "0.11375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "19292\n",
            "0.6953324923409623\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "14\n",
            "0.00875\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1484\n",
            "0.05348711479545864\n",
            "\n",
            "(27745, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0831 10:11:07.766123 139633676007232 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0831 10:11:07.767119 139633676007232 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0831 10:11:09.447188 139633676007232 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0831 10:11:11.883980 139633676007232 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0831 10:11:11.885265 139633676007232 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    868.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    868.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    868.    Elapsed: 0:01:01.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    868.    Elapsed: 0:01:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    868.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    868.    Elapsed: 0:02:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    868.    Elapsed: 0:02:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    868.    Elapsed: 0:02:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    868.    Elapsed: 0:03:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    868.    Elapsed: 0:03:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    868.    Elapsed: 0:03:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    868.    Elapsed: 0:04:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    868.    Elapsed: 0:04:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    868.    Elapsed: 0:04:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    868.    Elapsed: 0:05:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    868.    Elapsed: 0:05:28.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of    868.    Elapsed: 0:05:48.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of    868.    Elapsed: 0:06:09.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of    868.    Elapsed: 0:06:29.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of    868.    Elapsed: 0:06:49.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   840  of    868.    Elapsed: 0:07:09.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.21\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.57\n",
            "  Recall: 0.54\n",
            "  F1: 0.54\n",
            "Category: 1\n",
            "  Precision: 0.92\n",
            "  Recall: 0.92\n",
            "  F1: 0.92\n",
            "Category: 2\n",
            "  Precision: 0.96\n",
            "  Recall: 0.99\n",
            "  F1: 0.98\n",
            "Category: 3\n",
            "  Precision: 0.74\n",
            "  Recall: 0.74\n",
            "  F1: 0.74\n",
            "The average precision is: 0.7978\n",
            "The average recall is: 0.7979\n",
            "The average f1 is: 0.7930\n",
            "  Training epcoh took: 0:07:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.8783\n",
            "  Recall: 0.9415\n",
            "  F1: 0.9069\n",
            "Category: 1\n",
            "  Precision: 0.0577\n",
            "  Recall: 0.0513\n",
            "  F1: 0.0527\n",
            "Category: 2\n",
            "  Precision: 0.6923\n",
            "  Recall: 0.3603\n",
            "  F1: 0.4590\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4071\n",
            "The average recall is: 0.3383\n",
            "The average f1 is: 0.3547\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    868.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    868.    Elapsed: 0:00:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    868.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    868.    Elapsed: 0:01:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    868.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    868.    Elapsed: 0:02:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    868.    Elapsed: 0:02:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    868.    Elapsed: 0:02:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    868.    Elapsed: 0:03:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    868.    Elapsed: 0:03:28.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    868.    Elapsed: 0:03:49.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    868.    Elapsed: 0:04:10.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    868.    Elapsed: 0:04:31.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    868.    Elapsed: 0:04:51.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    868.    Elapsed: 0:05:11.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    868.    Elapsed: 0:05:32.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of    868.    Elapsed: 0:05:53.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of    868.    Elapsed: 0:06:13.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of    868.    Elapsed: 0:06:34.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of    868.    Elapsed: 0:06:54.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   840  of    868.    Elapsed: 0:07:15.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.77\n",
            "  Recall: 0.75\n",
            "  F1: 0.76\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.83\n",
            "  Recall: 0.83\n",
            "  F1: 0.83\n",
            "The average precision is: 0.8980\n",
            "The average recall is: 0.8958\n",
            "The average f1 is: 0.8962\n",
            "  Training epcoh took: 0:07:29\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8803\n",
            "  Recall: 0.9535\n",
            "  F1: 0.9136\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.5872\n",
            "  Recall: 0.3595\n",
            "  F1: 0.4117\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3669\n",
            "The average recall is: 0.3283\n",
            "The average f1 is: 0.3313\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    868.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    868.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    868.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    868.    Elapsed: 0:01:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    868.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    868.    Elapsed: 0:02:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    868.    Elapsed: 0:02:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    868.    Elapsed: 0:02:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    868.    Elapsed: 0:03:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    868.    Elapsed: 0:03:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    868.    Elapsed: 0:03:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    868.    Elapsed: 0:04:08.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    868.    Elapsed: 0:04:29.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    868.    Elapsed: 0:04:50.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    868.    Elapsed: 0:05:11.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    868.    Elapsed: 0:05:32.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of    868.    Elapsed: 0:05:52.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of    868.    Elapsed: 0:06:13.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of    868.    Elapsed: 0:06:33.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of    868.    Elapsed: 0:06:53.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   840  of    868.    Elapsed: 0:07:14.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.80\n",
            "  Recall: 0.80\n",
            "  F1: 0.80\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.83\n",
            "  Recall: 0.83\n",
            "  F1: 0.83\n",
            "The average precision is: 0.9064\n",
            "The average recall is: 0.9057\n",
            "The average f1 is: 0.9059\n",
            "  Training epcoh took: 0:07:28\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8724\n",
            "  Recall: 0.9884\n",
            "  F1: 0.9241\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.7051\n",
            "  Recall: 0.3855\n",
            "  F1: 0.4506\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3944\n",
            "The average recall is: 0.3435\n",
            "The average f1 is: 0.3437\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    868.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    868.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    868.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    868.    Elapsed: 0:01:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    868.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    868.    Elapsed: 0:02:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    868.    Elapsed: 0:02:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    868.    Elapsed: 0:02:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    868.    Elapsed: 0:03:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    868.    Elapsed: 0:03:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    868.    Elapsed: 0:03:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    868.    Elapsed: 0:04:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    868.    Elapsed: 0:04:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    868.    Elapsed: 0:04:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    868.    Elapsed: 0:05:08.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    868.    Elapsed: 0:05:28.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of    868.    Elapsed: 0:05:49.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of    868.    Elapsed: 0:06:09.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of    868.    Elapsed: 0:06:30.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of    868.    Elapsed: 0:06:51.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   840  of    868.    Elapsed: 0:07:11.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.81\n",
            "  Recall: 0.81\n",
            "  F1: 0.81\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.82\n",
            "  Recall: 0.82\n",
            "  F1: 0.82\n",
            "The average precision is: 0.9086\n",
            "The average recall is: 0.9086\n",
            "The average f1 is: 0.9086\n",
            "  Training epcoh took: 0:07:25\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8782\n",
            "  Recall: 0.9855\n",
            "  F1: 0.9283\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.7051\n",
            "  Recall: 0.3692\n",
            "  F1: 0.4670\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3958\n",
            "The average recall is: 0.3387\n",
            "The average f1 is: 0.3488\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Current increase 110 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1351 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 53 sampled in this category.\n",
            "After up-sample, there are 7430 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 7430 samples\n",
            "There are 182 sampled in this category.\n",
            "After up-sample, there are 27450 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 27450 samples\n",
            "There are 14 sampled in this category.\n",
            "After up-sample, there are 28990 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.844375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.046602276647119696\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "53\n",
            "0.033125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "5883\n",
            "0.2029320455329424\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "182\n",
            "0.11375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "20202\n",
            "0.6968609865470852\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "14\n",
            "0.00875\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1554\n",
            "0.05360469127285271\n",
            "\n",
            "(28990, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0831 10:41:03.832752 139633676007232 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0831 10:41:03.833770 139633676007232 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0831 10:41:03.925225 139633676007232 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0831 10:41:06.499464 139633676007232 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0831 10:41:06.501148 139633676007232 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    906.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    906.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    906.    Elapsed: 0:01:01.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    906.    Elapsed: 0:01:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    906.    Elapsed: 0:01:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    906.    Elapsed: 0:02:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    906.    Elapsed: 0:02:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    906.    Elapsed: 0:02:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    906.    Elapsed: 0:03:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    906.    Elapsed: 0:03:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    906.    Elapsed: 0:03:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    906.    Elapsed: 0:04:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    906.    Elapsed: 0:04:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    906.    Elapsed: 0:04:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    906.    Elapsed: 0:05:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    906.    Elapsed: 0:05:28.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of    906.    Elapsed: 0:05:48.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of    906.    Elapsed: 0:06:08.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of    906.    Elapsed: 0:06:28.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of    906.    Elapsed: 0:06:49.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   840  of    906.    Elapsed: 0:07:09.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   880  of    906.    Elapsed: 0:07:30.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.09\n",
            "  Accuracy: 0.97\n",
            "Category: 0\n",
            "  Precision: 0.61\n",
            "  Recall: 0.56\n",
            "  F1: 0.57\n",
            "Category: 1\n",
            "  Precision: 0.94\n",
            "  Recall: 0.94\n",
            "  F1: 0.94\n",
            "Category: 2\n",
            "  Precision: 0.97\n",
            "  Recall: 1.00\n",
            "  F1: 0.98\n",
            "Category: 3\n",
            "  Precision: 0.80\n",
            "  Recall: 0.81\n",
            "  F1: 0.80\n",
            "The average precision is: 0.8302\n",
            "The average recall is: 0.8268\n",
            "The average f1 is: 0.8245\n",
            "  Training epcoh took: 0:07:44\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "Category: 0\n",
            "  Precision: 0.9048\n",
            "  Recall: 0.9032\n",
            "  F1: 0.9024\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0513\n",
            "Category: 2\n",
            "  Precision: 0.4936\n",
            "  Recall: 0.5723\n",
            "  F1: 0.5032\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3592\n",
            "The average recall is: 0.3881\n",
            "The average f1 is: 0.3642\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    906.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    906.    Elapsed: 0:00:40.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    906.    Elapsed: 0:01:01.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    906.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    906.    Elapsed: 0:01:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    906.    Elapsed: 0:02:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    906.    Elapsed: 0:02:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    906.    Elapsed: 0:02:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    906.    Elapsed: 0:03:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    906.    Elapsed: 0:03:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    906.    Elapsed: 0:03:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    906.    Elapsed: 0:04:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    906.    Elapsed: 0:04:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    906.    Elapsed: 0:04:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    906.    Elapsed: 0:05:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    906.    Elapsed: 0:05:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of    906.    Elapsed: 0:05:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of    906.    Elapsed: 0:06:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of    906.    Elapsed: 0:06:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of    906.    Elapsed: 0:06:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   840  of    906.    Elapsed: 0:07:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   880  of    906.    Elapsed: 0:07:28.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.76\n",
            "  Recall: 0.76\n",
            "  F1: 0.76\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.81\n",
            "  Recall: 0.81\n",
            "  F1: 0.81\n",
            "The average precision is: 0.8937\n",
            "The average recall is: 0.8925\n",
            "The average f1 is: 0.8922\n",
            "  Training epcoh took: 0:07:41\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8678\n",
            "  Recall: 0.9912\n",
            "  F1: 0.9243\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.6731\n",
            "  Recall: 0.2330\n",
            "  F1: 0.3359\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3852\n",
            "The average recall is: 0.3060\n",
            "The average f1 is: 0.3151\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    906.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    906.    Elapsed: 0:00:40.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    906.    Elapsed: 0:01:01.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    906.    Elapsed: 0:01:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    906.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    906.    Elapsed: 0:02:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    906.    Elapsed: 0:02:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    906.    Elapsed: 0:02:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    906.    Elapsed: 0:03:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    906.    Elapsed: 0:03:28.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    906.    Elapsed: 0:03:48.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    906.    Elapsed: 0:04:09.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    906.    Elapsed: 0:04:30.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    906.    Elapsed: 0:04:50.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    906.    Elapsed: 0:05:11.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    906.    Elapsed: 0:05:31.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of    906.    Elapsed: 0:05:52.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of    906.    Elapsed: 0:06:12.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of    906.    Elapsed: 0:06:32.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of    906.    Elapsed: 0:06:53.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   840  of    906.    Elapsed: 0:07:14.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   880  of    906.    Elapsed: 0:07:34.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.79\n",
            "  Recall: 0.79\n",
            "  F1: 0.79\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.85\n",
            "  Recall: 0.85\n",
            "  F1: 0.85\n",
            "The average precision is: 0.9084\n",
            "The average recall is: 0.9081\n",
            "The average f1 is: 0.9081\n",
            "  Training epcoh took: 0:07:47\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "Category: 0\n",
            "  Precision: 0.8839\n",
            "  Recall: 0.9892\n",
            "  F1: 0.9322\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0513\n",
            "Category: 2\n",
            "  Precision: 0.6795\n",
            "  Recall: 0.4038\n",
            "  F1: 0.4619\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4101\n",
            "The average recall is: 0.3579\n",
            "The average f1 is: 0.3613\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    906.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    906.    Elapsed: 0:00:40.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    906.    Elapsed: 0:01:01.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    906.    Elapsed: 0:01:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    906.    Elapsed: 0:01:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    906.    Elapsed: 0:02:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    906.    Elapsed: 0:02:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    906.    Elapsed: 0:02:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    906.    Elapsed: 0:03:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    906.    Elapsed: 0:03:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    906.    Elapsed: 0:03:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    906.    Elapsed: 0:04:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    906.    Elapsed: 0:04:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    906.    Elapsed: 0:04:48.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    906.    Elapsed: 0:05:09.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    906.    Elapsed: 0:05:30.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of    906.    Elapsed: 0:05:50.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of    906.    Elapsed: 0:06:11.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of    906.    Elapsed: 0:06:31.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of    906.    Elapsed: 0:06:52.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   840  of    906.    Elapsed: 0:07:13.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   880  of    906.    Elapsed: 0:07:34.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.77\n",
            "  Recall: 0.77\n",
            "  F1: 0.77\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.82\n",
            "  Recall: 0.82\n",
            "  F1: 0.82\n",
            "The average precision is: 0.8987\n",
            "The average recall is: 0.8985\n",
            "The average f1 is: 0.8985\n",
            "  Training epcoh took: 0:07:47\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8790\n",
            "  Recall: 0.9884\n",
            "  F1: 0.9299\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.6795\n",
            "  Recall: 0.3077\n",
            "  F1: 0.4092\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4089\n",
            "The average recall is: 0.3432\n",
            "The average f1 is: 0.3540\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Current increase 115 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1351 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 53 sampled in this category.\n",
            "After up-sample, there are 7695 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 7695 samples\n",
            "There are 182 sampled in this category.\n",
            "After up-sample, there are 28625 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 28625 samples\n",
            "There are 14 sampled in this category.\n",
            "After up-sample, there are 30235 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.844375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.04468331404001984\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "53\n",
            "0.033125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "6148\n",
            "0.20334049942120058\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "182\n",
            "0.11375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "21112\n",
            "0.6982636017860095\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "14\n",
            "0.00875\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1624\n",
            "0.053712584752769965\n",
            "\n",
            "(30235, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0831 11:12:11.388628 139633676007232 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0831 11:12:11.389682 139633676007232 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0831 11:12:11.478726 139633676007232 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0831 11:12:13.993428 139633676007232 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0831 11:12:13.994198 139633676007232 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    945.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    945.    Elapsed: 0:00:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    945.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    945.    Elapsed: 0:01:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    945.    Elapsed: 0:01:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    945.    Elapsed: 0:02:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    945.    Elapsed: 0:02:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    945.    Elapsed: 0:02:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    945.    Elapsed: 0:03:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    945.    Elapsed: 0:03:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    945.    Elapsed: 0:03:48.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    945.    Elapsed: 0:04:08.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    945.    Elapsed: 0:04:29.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    945.    Elapsed: 0:04:49.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    945.    Elapsed: 0:05:10.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    945.    Elapsed: 0:05:30.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of    945.    Elapsed: 0:05:51.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of    945.    Elapsed: 0:06:11.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of    945.    Elapsed: 0:06:32.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of    945.    Elapsed: 0:06:51.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   840  of    945.    Elapsed: 0:07:12.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   880  of    945.    Elapsed: 0:07:33.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   920  of    945.    Elapsed: 0:07:53.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.16\n",
            "  Accuracy: 0.97\n",
            "Category: 0\n",
            "  Precision: 0.56\n",
            "  Recall: 0.53\n",
            "  F1: 0.53\n",
            "Category: 1\n",
            "  Precision: 0.96\n",
            "  Recall: 0.95\n",
            "  F1: 0.95\n",
            "Category: 2\n",
            "  Precision: 0.97\n",
            "  Recall: 0.99\n",
            "  F1: 0.98\n",
            "Category: 3\n",
            "  Precision: 0.77\n",
            "  Recall: 0.77\n",
            "  F1: 0.77\n",
            "The average precision is: 0.8153\n",
            "The average recall is: 0.8097\n",
            "The average f1 is: 0.8077\n",
            "  Training epcoh took: 0:08:05\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.8910\n",
            "  Recall: 0.9290\n",
            "  F1: 0.9079\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.6013\n",
            "  Recall: 0.5282\n",
            "  F1: 0.5011\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3923\n",
            "The average recall is: 0.3835\n",
            "The average f1 is: 0.3715\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    945.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    945.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    945.    Elapsed: 0:01:01.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    945.    Elapsed: 0:01:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    945.    Elapsed: 0:01:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    945.    Elapsed: 0:02:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    945.    Elapsed: 0:02:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    945.    Elapsed: 0:02:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    945.    Elapsed: 0:03:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    945.    Elapsed: 0:03:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    945.    Elapsed: 0:03:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    945.    Elapsed: 0:04:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    945.    Elapsed: 0:04:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    945.    Elapsed: 0:04:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    945.    Elapsed: 0:05:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    945.    Elapsed: 0:05:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of    945.    Elapsed: 0:05:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of    945.    Elapsed: 0:06:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of    945.    Elapsed: 0:06:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of    945.    Elapsed: 0:06:48.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   840  of    945.    Elapsed: 0:07:08.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   880  of    945.    Elapsed: 0:07:28.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   920  of    945.    Elapsed: 0:07:49.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.75\n",
            "  Recall: 0.74\n",
            "  F1: 0.75\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.82\n",
            "  Recall: 0.82\n",
            "  F1: 0.82\n",
            "The average precision is: 0.8920\n",
            "The average recall is: 0.8897\n",
            "The average f1 is: 0.8900\n",
            "  Training epcoh took: 0:08:02\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8855\n",
            "  Recall: 0.9466\n",
            "  F1: 0.9140\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.5385\n",
            "  Recall: 0.4548\n",
            "  F1: 0.4721\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3560\n",
            "The average recall is: 0.3503\n",
            "The average f1 is: 0.3465\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    945.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    945.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    945.    Elapsed: 0:01:01.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    945.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    945.    Elapsed: 0:01:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    945.    Elapsed: 0:02:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    945.    Elapsed: 0:02:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    945.    Elapsed: 0:02:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    945.    Elapsed: 0:03:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    945.    Elapsed: 0:03:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    945.    Elapsed: 0:03:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    945.    Elapsed: 0:04:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    945.    Elapsed: 0:04:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    945.    Elapsed: 0:04:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    945.    Elapsed: 0:05:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    945.    Elapsed: 0:05:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of    945.    Elapsed: 0:05:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of    945.    Elapsed: 0:06:08.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of    945.    Elapsed: 0:06:28.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of    945.    Elapsed: 0:06:48.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   840  of    945.    Elapsed: 0:07:09.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   880  of    945.    Elapsed: 0:07:30.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   920  of    945.    Elapsed: 0:07:50.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.77\n",
            "  Recall: 0.77\n",
            "  F1: 0.77\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.81\n",
            "  Recall: 0.81\n",
            "  F1: 0.81\n",
            "The average precision is: 0.8944\n",
            "The average recall is: 0.8942\n",
            "The average f1 is: 0.8941\n",
            "  Training epcoh took: 0:08:03\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.8745\n",
            "  Recall: 0.9548\n",
            "  F1: 0.9116\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.5885\n",
            "  Recall: 0.4115\n",
            "  F1: 0.4358\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3657\n",
            "The average recall is: 0.3416\n",
            "The average f1 is: 0.3369\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    945.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    945.    Elapsed: 0:00:40.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    945.    Elapsed: 0:01:00.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    945.    Elapsed: 0:01:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    945.    Elapsed: 0:01:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    945.    Elapsed: 0:02:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    945.    Elapsed: 0:02:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    945.    Elapsed: 0:02:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    945.    Elapsed: 0:03:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    945.    Elapsed: 0:03:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    945.    Elapsed: 0:03:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    945.    Elapsed: 0:04:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    945.    Elapsed: 0:04:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    945.    Elapsed: 0:04:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    945.    Elapsed: 0:05:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    945.    Elapsed: 0:05:28.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of    945.    Elapsed: 0:05:49.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of    945.    Elapsed: 0:06:09.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of    945.    Elapsed: 0:06:30.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of    945.    Elapsed: 0:06:50.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   840  of    945.    Elapsed: 0:07:10.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   880  of    945.    Elapsed: 0:07:31.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   920  of    945.    Elapsed: 0:07:51.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.77\n",
            "  Recall: 0.77\n",
            "  F1: 0.77\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.83\n",
            "  Recall: 0.83\n",
            "  F1: 0.83\n",
            "The average precision is: 0.8985\n",
            "The average recall is: 0.8984\n",
            "The average f1 is: 0.8984\n",
            "  Training epcoh took: 0:08:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8728\n",
            "  Recall: 0.9672\n",
            "  F1: 0.9161\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.4936\n",
            "  Recall: 0.3492\n",
            "  F1: 0.3914\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3416\n",
            "The average recall is: 0.3291\n",
            "The average f1 is: 0.3269\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Current increase 120 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1351 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 53 sampled in this category.\n",
            "After up-sample, there are 7960 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 7960 samples\n",
            "There are 182 sampled in this category.\n",
            "After up-sample, there are 29800 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 29800 samples\n",
            "There are 14 sampled in this category.\n",
            "After up-sample, there are 31480 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.844375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.04291613722998729\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "53\n",
            "0.033125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "6413\n",
            "0.2037166454891995\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "182\n",
            "0.11375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "22022\n",
            "0.6995552731893265\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "14\n",
            "0.00875\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1694\n",
            "0.05381194409148666\n",
            "\n",
            "(31480, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0831 11:44:33.888108 139633676007232 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0831 11:44:33.889139 139633676007232 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0831 11:44:38.099762 139633676007232 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0831 11:44:40.602655 139633676007232 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0831 11:44:40.603974 139633676007232 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    984.    Elapsed: 0:00:19.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    984.    Elapsed: 0:00:40.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    984.    Elapsed: 0:01:00.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    984.    Elapsed: 0:01:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    984.    Elapsed: 0:01:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    984.    Elapsed: 0:02:00.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    984.    Elapsed: 0:02:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    984.    Elapsed: 0:02:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    984.    Elapsed: 0:03:01.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    984.    Elapsed: 0:03:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    984.    Elapsed: 0:03:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    984.    Elapsed: 0:04:01.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    984.    Elapsed: 0:04:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    984.    Elapsed: 0:04:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    984.    Elapsed: 0:05:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    984.    Elapsed: 0:05:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of    984.    Elapsed: 0:05:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of    984.    Elapsed: 0:06:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of    984.    Elapsed: 0:06:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of    984.    Elapsed: 0:06:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   840  of    984.    Elapsed: 0:07:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   880  of    984.    Elapsed: 0:07:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   920  of    984.    Elapsed: 0:07:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   960  of    984.    Elapsed: 0:08:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.12\n",
            "  Accuracy: 0.97\n",
            "Category: 0\n",
            "  Precision: 0.60\n",
            "  Recall: 0.57\n",
            "  F1: 0.58\n",
            "Category: 1\n",
            "  Precision: 0.96\n",
            "  Recall: 0.96\n",
            "  F1: 0.95\n",
            "Category: 2\n",
            "  Precision: 0.98\n",
            "  Recall: 1.00\n",
            "  F1: 0.99\n",
            "Category: 3\n",
            "  Precision: 0.77\n",
            "  Recall: 0.77\n",
            "  F1: 0.77\n",
            "The average precision is: 0.8265\n",
            "The average recall is: 0.8222\n",
            "The average f1 is: 0.8207\n",
            "  Training epcoh took: 0:08:18\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8935\n",
            "  Recall: 0.9552\n",
            "  F1: 0.9213\n",
            "Category: 1\n",
            "  Precision: 0.0385\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0513\n",
            "Category: 2\n",
            "  Precision: 0.5718\n",
            "  Recall: 0.4051\n",
            "  F1: 0.4520\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3759\n",
            "The average recall is: 0.3593\n",
            "The average f1 is: 0.3562\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    984.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    984.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    984.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    984.    Elapsed: 0:01:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    984.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    984.    Elapsed: 0:02:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    984.    Elapsed: 0:02:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    984.    Elapsed: 0:02:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    984.    Elapsed: 0:03:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    984.    Elapsed: 0:03:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    984.    Elapsed: 0:03:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    984.    Elapsed: 0:04:08.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    984.    Elapsed: 0:04:29.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    984.    Elapsed: 0:04:49.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    984.    Elapsed: 0:05:10.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    984.    Elapsed: 0:05:31.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of    984.    Elapsed: 0:05:51.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of    984.    Elapsed: 0:06:12.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of    984.    Elapsed: 0:06:32.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of    984.    Elapsed: 0:06:53.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   840  of    984.    Elapsed: 0:07:13.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   880  of    984.    Elapsed: 0:07:33.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   920  of    984.    Elapsed: 0:07:54.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   960  of    984.    Elapsed: 0:08:14.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.75\n",
            "  Recall: 0.75\n",
            "  F1: 0.75\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.83\n",
            "  Recall: 0.83\n",
            "  F1: 0.83\n",
            "The average precision is: 0.8955\n",
            "The average recall is: 0.8937\n",
            "The average f1 is: 0.8941\n",
            "  Training epcoh took: 0:08:27\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8868\n",
            "  Recall: 0.9595\n",
            "  F1: 0.9207\n",
            "Category: 1\n",
            "  Precision: 0.1538\n",
            "  Recall: 0.1538\n",
            "  F1: 0.1538\n",
            "Category: 2\n",
            "  Precision: 0.5167\n",
            "  Recall: 0.2960\n",
            "  F1: 0.3527\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3893\n",
            "The average recall is: 0.3523\n",
            "The average f1 is: 0.3568\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    984.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    984.    Elapsed: 0:00:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    984.    Elapsed: 0:01:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    984.    Elapsed: 0:01:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    984.    Elapsed: 0:01:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    984.    Elapsed: 0:02:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    984.    Elapsed: 0:02:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    984.    Elapsed: 0:02:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    984.    Elapsed: 0:03:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    984.    Elapsed: 0:03:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    984.    Elapsed: 0:03:48.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    984.    Elapsed: 0:04:09.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    984.    Elapsed: 0:04:29.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    984.    Elapsed: 0:04:49.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    984.    Elapsed: 0:05:10.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    984.    Elapsed: 0:05:31.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of    984.    Elapsed: 0:05:51.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of    984.    Elapsed: 0:06:12.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of    984.    Elapsed: 0:06:32.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of    984.    Elapsed: 0:06:52.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   840  of    984.    Elapsed: 0:07:14.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   880  of    984.    Elapsed: 0:07:34.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   920  of    984.    Elapsed: 0:07:54.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   960  of    984.    Elapsed: 0:08:15.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.74\n",
            "  Recall: 0.74\n",
            "  F1: 0.74\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.84\n",
            "  Recall: 0.84\n",
            "  F1: 0.84\n",
            "The average precision is: 0.8959\n",
            "The average recall is: 0.8955\n",
            "The average f1 is: 0.8954\n",
            "  Training epcoh took: 0:08:28\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8763\n",
            "  Recall: 0.9733\n",
            "  F1: 0.9212\n",
            "Category: 1\n",
            "  Precision: 0.1538\n",
            "  Recall: 0.1154\n",
            "  F1: 0.1282\n",
            "Category: 2\n",
            "  Precision: 0.5055\n",
            "  Recall: 0.2738\n",
            "  F1: 0.3461\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3839\n",
            "The average recall is: 0.3406\n",
            "The average f1 is: 0.3489\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of    984.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of    984.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of    984.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of    984.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of    984.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of    984.    Elapsed: 0:02:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of    984.    Elapsed: 0:02:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of    984.    Elapsed: 0:02:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of    984.    Elapsed: 0:03:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of    984.    Elapsed: 0:03:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of    984.    Elapsed: 0:03:48.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of    984.    Elapsed: 0:04:08.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of    984.    Elapsed: 0:04:28.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of    984.    Elapsed: 0:04:48.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of    984.    Elapsed: 0:05:09.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of    984.    Elapsed: 0:05:29.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of    984.    Elapsed: 0:05:50.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of    984.    Elapsed: 0:06:10.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of    984.    Elapsed: 0:06:31.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of    984.    Elapsed: 0:06:51.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   840  of    984.    Elapsed: 0:07:12.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   880  of    984.    Elapsed: 0:07:32.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   920  of    984.    Elapsed: 0:07:53.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   960  of    984.    Elapsed: 0:08:13.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.75\n",
            "  Recall: 0.75\n",
            "  F1: 0.75\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.82\n",
            "  Recall: 0.82\n",
            "  F1: 0.82\n",
            "The average precision is: 0.8925\n",
            "The average recall is: 0.8921\n",
            "The average f1 is: 0.8922\n",
            "  Training epcoh took: 0:08:25\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8788\n",
            "  Recall: 0.9770\n",
            "  F1: 0.9237\n",
            "Category: 1\n",
            "  Precision: 0.1538\n",
            "  Recall: 0.0641\n",
            "  F1: 0.0897\n",
            "Category: 2\n",
            "  Precision: 0.5936\n",
            "  Recall: 0.3863\n",
            "  F1: 0.4222\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4066\n",
            "The average recall is: 0.3569\n",
            "The average f1 is: 0.3589\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Current increase 125 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1351 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 53 sampled in this category.\n",
            "After up-sample, there are 8225 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 8225 samples\n",
            "There are 182 sampled in this category.\n",
            "After up-sample, there are 30975 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 30975 samples\n",
            "There are 14 sampled in this category.\n",
            "After up-sample, there are 32725 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.844375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.04128342245989305\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "53\n",
            "0.033125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "6678\n",
            "0.20406417112299466\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "182\n",
            "0.11375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "22932\n",
            "0.7007486631016043\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "14\n",
            "0.00875\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1764\n",
            "0.05390374331550802\n",
            "\n",
            "(32725, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0831 12:18:24.333403 139633676007232 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0831 12:18:24.334351 139633676007232 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0831 12:18:24.446898 139633676007232 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0831 12:18:27.034681 139633676007232 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0831 12:18:27.036047 139633676007232 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of  1,023.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of  1,023.    Elapsed: 0:00:40.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of  1,023.    Elapsed: 0:01:01.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of  1,023.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of  1,023.    Elapsed: 0:01:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of  1,023.    Elapsed: 0:02:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of  1,023.    Elapsed: 0:02:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of  1,023.    Elapsed: 0:02:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of  1,023.    Elapsed: 0:03:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of  1,023.    Elapsed: 0:03:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of  1,023.    Elapsed: 0:03:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of  1,023.    Elapsed: 0:04:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of  1,023.    Elapsed: 0:04:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of  1,023.    Elapsed: 0:04:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of  1,023.    Elapsed: 0:05:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of  1,023.    Elapsed: 0:05:28.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of  1,023.    Elapsed: 0:05:48.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of  1,023.    Elapsed: 0:06:08.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of  1,023.    Elapsed: 0:06:29.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of  1,023.    Elapsed: 0:06:49.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   840  of  1,023.    Elapsed: 0:07:10.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   880  of  1,023.    Elapsed: 0:07:30.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   920  of  1,023.    Elapsed: 0:07:51.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   960  of  1,023.    Elapsed: 0:08:11.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,000  of  1,023.    Elapsed: 0:08:31.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.11\n",
            "  Accuracy: 0.97\n",
            "Category: 0\n",
            "  Precision: 0.57\n",
            "  Recall: 0.55\n",
            "  F1: 0.55\n",
            "Category: 1\n",
            "  Precision: 0.97\n",
            "  Recall: 0.97\n",
            "  F1: 0.96\n",
            "Category: 2\n",
            "  Precision: 0.98\n",
            "  Recall: 1.00\n",
            "  F1: 0.98\n",
            "Category: 3\n",
            "  Precision: 0.79\n",
            "  Recall: 0.79\n",
            "  F1: 0.79\n",
            "The average precision is: 0.8269\n",
            "The average recall is: 0.8247\n",
            "The average f1 is: 0.8221\n",
            "  Training epcoh took: 0:08:43\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.78\n",
            "Category: 0\n",
            "  Precision: 0.8859\n",
            "  Recall: 0.8591\n",
            "  F1: 0.8688\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0513\n",
            "Category: 2\n",
            "  Precision: 0.3463\n",
            "  Recall: 0.4399\n",
            "  F1: 0.3522\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3273\n",
            "The average recall is: 0.3344\n",
            "The average f1 is: 0.3181\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of  1,023.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of  1,023.    Elapsed: 0:00:40.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of  1,023.    Elapsed: 0:01:01.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of  1,023.    Elapsed: 0:01:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of  1,023.    Elapsed: 0:01:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of  1,023.    Elapsed: 0:02:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of  1,023.    Elapsed: 0:02:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of  1,023.    Elapsed: 0:02:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of  1,023.    Elapsed: 0:03:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of  1,023.    Elapsed: 0:03:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of  1,023.    Elapsed: 0:03:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of  1,023.    Elapsed: 0:04:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of  1,023.    Elapsed: 0:04:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of  1,023.    Elapsed: 0:04:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of  1,023.    Elapsed: 0:05:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of  1,023.    Elapsed: 0:05:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of  1,023.    Elapsed: 0:05:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of  1,023.    Elapsed: 0:06:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of  1,023.    Elapsed: 0:06:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of  1,023.    Elapsed: 0:06:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   840  of  1,023.    Elapsed: 0:07:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   880  of  1,023.    Elapsed: 0:07:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   920  of  1,023.    Elapsed: 0:07:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   960  of  1,023.    Elapsed: 0:08:08.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,000  of  1,023.    Elapsed: 0:08:28.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.72\n",
            "  Recall: 0.72\n",
            "  F1: 0.72\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.83\n",
            "  Recall: 0.83\n",
            "  F1: 0.83\n",
            "The average precision is: 0.8868\n",
            "The average recall is: 0.8857\n",
            "The average f1 is: 0.8856\n",
            "  Training epcoh took: 0:08:39\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "Category: 0\n",
            "  Precision: 0.8885\n",
            "  Recall: 0.9741\n",
            "  F1: 0.9270\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0513\n",
            "Category: 2\n",
            "  Precision: 0.6667\n",
            "  Recall: 0.3974\n",
            "  F1: 0.4717\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4080\n",
            "The average recall is: 0.3525\n",
            "The average f1 is: 0.3625\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of  1,023.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of  1,023.    Elapsed: 0:00:40.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of  1,023.    Elapsed: 0:01:01.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of  1,023.    Elapsed: 0:01:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of  1,023.    Elapsed: 0:01:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of  1,023.    Elapsed: 0:02:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of  1,023.    Elapsed: 0:02:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of  1,023.    Elapsed: 0:02:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of  1,023.    Elapsed: 0:03:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of  1,023.    Elapsed: 0:03:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of  1,023.    Elapsed: 0:03:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of  1,023.    Elapsed: 0:04:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of  1,023.    Elapsed: 0:04:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of  1,023.    Elapsed: 0:04:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of  1,023.    Elapsed: 0:05:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of  1,023.    Elapsed: 0:05:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of  1,023.    Elapsed: 0:05:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of  1,023.    Elapsed: 0:06:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of  1,023.    Elapsed: 0:06:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of  1,023.    Elapsed: 0:06:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   840  of  1,023.    Elapsed: 0:07:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   880  of  1,023.    Elapsed: 0:07:28.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   920  of  1,023.    Elapsed: 0:07:48.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   960  of  1,023.    Elapsed: 0:08:08.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,000  of  1,023.    Elapsed: 0:08:28.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.75\n",
            "  Recall: 0.75\n",
            "  F1: 0.75\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.82\n",
            "  Recall: 0.82\n",
            "  F1: 0.82\n",
            "The average precision is: 0.8914\n",
            "The average recall is: 0.8912\n",
            "The average f1 is: 0.8911\n",
            "  Training epcoh took: 0:08:41\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "Category: 0\n",
            "  Precision: 0.8783\n",
            "  Recall: 0.9943\n",
            "  F1: 0.9319\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0513\n",
            "Category: 2\n",
            "  Precision: 0.8205\n",
            "  Recall: 0.3612\n",
            "  F1: 0.4923\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4439\n",
            "The average recall is: 0.3485\n",
            "The average f1 is: 0.3689\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of  1,023.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of  1,023.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of  1,023.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of  1,023.    Elapsed: 0:01:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of  1,023.    Elapsed: 0:01:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of  1,023.    Elapsed: 0:02:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of  1,023.    Elapsed: 0:02:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of  1,023.    Elapsed: 0:02:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of  1,023.    Elapsed: 0:03:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of  1,023.    Elapsed: 0:03:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of  1,023.    Elapsed: 0:03:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of  1,023.    Elapsed: 0:04:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of  1,023.    Elapsed: 0:04:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of  1,023.    Elapsed: 0:04:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of  1,023.    Elapsed: 0:05:08.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of  1,023.    Elapsed: 0:05:28.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of  1,023.    Elapsed: 0:05:48.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of  1,023.    Elapsed: 0:06:09.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of  1,023.    Elapsed: 0:06:30.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of  1,023.    Elapsed: 0:06:50.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   840  of  1,023.    Elapsed: 0:07:11.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   880  of  1,023.    Elapsed: 0:07:32.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   920  of  1,023.    Elapsed: 0:07:52.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   960  of  1,023.    Elapsed: 0:08:13.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,000  of  1,023.    Elapsed: 0:08:33.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.75\n",
            "  Recall: 0.75\n",
            "  F1: 0.75\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.83\n",
            "  Recall: 0.83\n",
            "  F1: 0.83\n",
            "The average precision is: 0.8947\n",
            "The average recall is: 0.8947\n",
            "The average f1 is: 0.8947\n",
            "  Training epcoh took: 0:08:45\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "Category: 0\n",
            "  Precision: 0.8811\n",
            "  Recall: 0.9917\n",
            "  F1: 0.9328\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.7692\n",
            "  Recall: 0.3837\n",
            "  F1: 0.4867\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4318\n",
            "The average recall is: 0.3631\n",
            "The average f1 is: 0.3741\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Current increase 130 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1351 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 53 sampled in this category.\n",
            "After up-sample, there are 8490 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 8490 samples\n",
            "There are 182 sampled in this category.\n",
            "After up-sample, there are 32150 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 32150 samples\n",
            "There are 14 sampled in this category.\n",
            "After up-sample, there are 33970 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.844375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.03977038563438328\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "53\n",
            "0.033125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "6943\n",
            "0.20438622313806298\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "182\n",
            "0.11375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "23842\n",
            "0.7018545775684427\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "14\n",
            "0.00875\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1834\n",
            "0.05398881365911098\n",
            "\n",
            "(33970, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0831 12:53:20.942054 139633676007232 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0831 12:53:20.942986 139633676007232 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0831 12:53:20.976657 139633676007232 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0831 12:53:23.517924 139633676007232 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0831 12:53:23.518668 139633676007232 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of  1,062.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of  1,062.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of  1,062.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of  1,062.    Elapsed: 0:01:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of  1,062.    Elapsed: 0:01:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of  1,062.    Elapsed: 0:02:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of  1,062.    Elapsed: 0:02:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of  1,062.    Elapsed: 0:02:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of  1,062.    Elapsed: 0:03:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of  1,062.    Elapsed: 0:03:28.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of  1,062.    Elapsed: 0:03:48.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of  1,062.    Elapsed: 0:04:09.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of  1,062.    Elapsed: 0:04:29.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of  1,062.    Elapsed: 0:04:50.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of  1,062.    Elapsed: 0:05:10.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of  1,062.    Elapsed: 0:05:31.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of  1,062.    Elapsed: 0:05:51.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of  1,062.    Elapsed: 0:06:12.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of  1,062.    Elapsed: 0:06:32.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of  1,062.    Elapsed: 0:06:53.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   840  of  1,062.    Elapsed: 0:07:14.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   880  of  1,062.    Elapsed: 0:07:34.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   920  of  1,062.    Elapsed: 0:07:55.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   960  of  1,062.    Elapsed: 0:08:15.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,000  of  1,062.    Elapsed: 0:08:36.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,040  of  1,062.    Elapsed: 0:08:56.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.09\n",
            "  Accuracy: 0.97\n",
            "Category: 0\n",
            "  Precision: 0.51\n",
            "  Recall: 0.49\n",
            "  F1: 0.49\n",
            "Category: 1\n",
            "  Precision: 0.94\n",
            "  Recall: 0.94\n",
            "  F1: 0.94\n",
            "Category: 2\n",
            "  Precision: 0.97\n",
            "  Recall: 1.00\n",
            "  F1: 0.98\n",
            "Category: 3\n",
            "  Precision: 0.81\n",
            "  Recall: 0.80\n",
            "  F1: 0.80\n",
            "The average precision is: 0.8075\n",
            "The average recall is: 0.8086\n",
            "The average f1 is: 0.8046\n",
            "  Training epcoh took: 0:09:08\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8806\n",
            "  Recall: 0.9500\n",
            "  F1: 0.9133\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0256\n",
            "  F1: 0.0385\n",
            "Category: 2\n",
            "  Precision: 0.4372\n",
            "  Recall: 0.3310\n",
            "  F1: 0.3712\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3487\n",
            "The average recall is: 0.3267\n",
            "The average f1 is: 0.3308\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of  1,062.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of  1,062.    Elapsed: 0:00:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of  1,062.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of  1,062.    Elapsed: 0:01:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of  1,062.    Elapsed: 0:01:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of  1,062.    Elapsed: 0:02:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of  1,062.    Elapsed: 0:02:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of  1,062.    Elapsed: 0:02:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of  1,062.    Elapsed: 0:03:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of  1,062.    Elapsed: 0:03:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of  1,062.    Elapsed: 0:03:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of  1,062.    Elapsed: 0:04:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of  1,062.    Elapsed: 0:04:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of  1,062.    Elapsed: 0:04:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of  1,062.    Elapsed: 0:05:08.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of  1,062.    Elapsed: 0:05:28.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of  1,062.    Elapsed: 0:05:48.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of  1,062.    Elapsed: 0:06:08.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of  1,062.    Elapsed: 0:06:29.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of  1,062.    Elapsed: 0:06:49.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   840  of  1,062.    Elapsed: 0:07:10.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   880  of  1,062.    Elapsed: 0:07:31.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   920  of  1,062.    Elapsed: 0:07:52.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   960  of  1,062.    Elapsed: 0:08:12.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,000  of  1,062.    Elapsed: 0:08:32.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,040  of  1,062.    Elapsed: 0:08:53.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.70\n",
            "  Recall: 0.69\n",
            "  F1: 0.69\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.82\n",
            "  Recall: 0.82\n",
            "  F1: 0.82\n",
            "The average precision is: 0.8786\n",
            "The average recall is: 0.8775\n",
            "The average f1 is: 0.8774\n",
            "  Training epcoh took: 0:09:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.8816\n",
            "  Recall: 0.9440\n",
            "  F1: 0.9104\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0513\n",
            "Category: 2\n",
            "  Precision: 0.4936\n",
            "  Recall: 0.3795\n",
            "  F1: 0.4142\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3630\n",
            "The average recall is: 0.3405\n",
            "The average f1 is: 0.3440\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of  1,062.    Elapsed: 0:00:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of  1,062.    Elapsed: 0:00:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of  1,062.    Elapsed: 0:01:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of  1,062.    Elapsed: 0:01:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of  1,062.    Elapsed: 0:01:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of  1,062.    Elapsed: 0:02:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of  1,062.    Elapsed: 0:02:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of  1,062.    Elapsed: 0:02:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of  1,062.    Elapsed: 0:03:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of  1,062.    Elapsed: 0:03:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of  1,062.    Elapsed: 0:03:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of  1,062.    Elapsed: 0:04:08.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of  1,062.    Elapsed: 0:04:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of  1,062.    Elapsed: 0:04:48.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of  1,062.    Elapsed: 0:05:08.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of  1,062.    Elapsed: 0:05:29.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of  1,062.    Elapsed: 0:05:50.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of  1,062.    Elapsed: 0:06:10.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of  1,062.    Elapsed: 0:06:30.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of  1,062.    Elapsed: 0:06:51.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   840  of  1,062.    Elapsed: 0:07:11.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   880  of  1,062.    Elapsed: 0:07:32.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   920  of  1,062.    Elapsed: 0:07:52.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   960  of  1,062.    Elapsed: 0:08:12.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,000  of  1,062.    Elapsed: 0:08:33.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,040  of  1,062.    Elapsed: 0:08:53.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.72\n",
            "  Recall: 0.72\n",
            "  F1: 0.72\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.84\n",
            "  Recall: 0.84\n",
            "  F1: 0.84\n",
            "The average precision is: 0.8903\n",
            "The average recall is: 0.8900\n",
            "The average f1 is: 0.8900\n",
            "  Training epcoh took: 0:09:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8822\n",
            "  Recall: 0.9595\n",
            "  F1: 0.9180\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.5885\n",
            "  Recall: 0.3808\n",
            "  F1: 0.4467\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3677\n",
            "The average recall is: 0.3351\n",
            "The average f1 is: 0.3412\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of  1,062.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of  1,062.    Elapsed: 0:00:40.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of  1,062.    Elapsed: 0:01:01.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of  1,062.    Elapsed: 0:01:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of  1,062.    Elapsed: 0:01:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of  1,062.    Elapsed: 0:02:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of  1,062.    Elapsed: 0:02:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of  1,062.    Elapsed: 0:02:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of  1,062.    Elapsed: 0:03:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of  1,062.    Elapsed: 0:03:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of  1,062.    Elapsed: 0:03:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of  1,062.    Elapsed: 0:04:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of  1,062.    Elapsed: 0:04:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of  1,062.    Elapsed: 0:04:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of  1,062.    Elapsed: 0:05:08.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of  1,062.    Elapsed: 0:05:29.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of  1,062.    Elapsed: 0:05:48.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of  1,062.    Elapsed: 0:06:08.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of  1,062.    Elapsed: 0:06:29.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of  1,062.    Elapsed: 0:06:50.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   840  of  1,062.    Elapsed: 0:07:10.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   880  of  1,062.    Elapsed: 0:07:31.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   920  of  1,062.    Elapsed: 0:07:51.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   960  of  1,062.    Elapsed: 0:08:12.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,000  of  1,062.    Elapsed: 0:08:32.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,040  of  1,062.    Elapsed: 0:08:53.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.74\n",
            "  Recall: 0.74\n",
            "  F1: 0.74\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.83\n",
            "  Recall: 0.83\n",
            "  F1: 0.83\n",
            "The average precision is: 0.8912\n",
            "The average recall is: 0.8911\n",
            "The average f1 is: 0.8911\n",
            "  Training epcoh took: 0:09:03\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8744\n",
            "  Recall: 0.9709\n",
            "  F1: 0.9187\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.5256\n",
            "  Recall: 0.2417\n",
            "  F1: 0.3172\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3500\n",
            "The average recall is: 0.3032\n",
            "The average f1 is: 0.3090\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Current increase 135 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1351 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 53 sampled in this category.\n",
            "After up-sample, there are 8755 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 8755 samples\n",
            "There are 182 sampled in this category.\n",
            "After up-sample, there are 33325 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 33325 samples\n",
            "There are 14 sampled in this category.\n",
            "After up-sample, there are 35215 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.844375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.03836433338066165\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "53\n",
            "0.033125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "7208\n",
            "0.2046855033366463\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "182\n",
            "0.11375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "24752\n",
            "0.7028822944767854\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "14\n",
            "0.00875\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1904\n",
            "0.054067868805906576\n",
            "\n",
            "(35215, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0831 13:29:48.256402 139633676007232 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0831 13:29:48.257469 139633676007232 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0831 13:29:48.312572 139633676007232 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0831 13:29:50.939835 139633676007232 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0831 13:29:50.942012 139633676007232 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of  1,101.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of  1,101.    Elapsed: 0:00:40.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of  1,101.    Elapsed: 0:01:00.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of  1,101.    Elapsed: 0:01:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of  1,101.    Elapsed: 0:01:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of  1,101.    Elapsed: 0:02:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of  1,101.    Elapsed: 0:02:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of  1,101.    Elapsed: 0:02:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of  1,101.    Elapsed: 0:03:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of  1,101.    Elapsed: 0:03:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of  1,101.    Elapsed: 0:03:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of  1,101.    Elapsed: 0:04:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of  1,101.    Elapsed: 0:04:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of  1,101.    Elapsed: 0:04:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of  1,101.    Elapsed: 0:05:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of  1,101.    Elapsed: 0:05:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of  1,101.    Elapsed: 0:05:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of  1,101.    Elapsed: 0:06:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of  1,101.    Elapsed: 0:06:28.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of  1,101.    Elapsed: 0:06:49.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   840  of  1,101.    Elapsed: 0:07:09.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   880  of  1,101.    Elapsed: 0:07:30.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   920  of  1,101.    Elapsed: 0:07:51.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   960  of  1,101.    Elapsed: 0:08:11.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,000  of  1,101.    Elapsed: 0:08:33.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,040  of  1,101.    Elapsed: 0:08:55.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,080  of  1,101.    Elapsed: 0:09:16.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.15\n",
            "  Accuracy: 0.98\n",
            "Category: 0\n",
            "  Precision: 0.56\n",
            "  Recall: 0.54\n",
            "  F1: 0.54\n",
            "Category: 1\n",
            "  Precision: 0.96\n",
            "  Recall: 0.96\n",
            "  F1: 0.96\n",
            "Category: 2\n",
            "  Precision: 0.98\n",
            "  Recall: 1.00\n",
            "  F1: 0.99\n",
            "Category: 3\n",
            "  Precision: 0.78\n",
            "  Recall: 0.78\n",
            "  F1: 0.78\n",
            "The average precision is: 0.8202\n",
            "The average recall is: 0.8182\n",
            "The average f1 is: 0.8161\n",
            "  Training epcoh took: 0:09:27\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "Category: 0\n",
            "  Precision: 0.8868\n",
            "  Recall: 0.9191\n",
            "  F1: 0.9000\n",
            "Category: 1\n",
            "  Precision: 0.1154\n",
            "  Recall: 0.1538\n",
            "  F1: 0.1282\n",
            "Category: 2\n",
            "  Precision: 0.4974\n",
            "  Recall: 0.3683\n",
            "  F1: 0.4157\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3749\n",
            "The average recall is: 0.3603\n",
            "The average f1 is: 0.3610\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of  1,101.    Elapsed: 0:00:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of  1,101.    Elapsed: 0:00:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of  1,101.    Elapsed: 0:01:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of  1,101.    Elapsed: 0:01:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of  1,101.    Elapsed: 0:01:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of  1,101.    Elapsed: 0:02:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of  1,101.    Elapsed: 0:02:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of  1,101.    Elapsed: 0:02:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of  1,101.    Elapsed: 0:03:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of  1,101.    Elapsed: 0:03:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of  1,101.    Elapsed: 0:03:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of  1,101.    Elapsed: 0:03:59.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of  1,101.    Elapsed: 0:04:19.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of  1,101.    Elapsed: 0:04:37.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of  1,101.    Elapsed: 0:04:56.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of  1,101.    Elapsed: 0:05:16.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of  1,101.    Elapsed: 0:05:34.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of  1,101.    Elapsed: 0:05:53.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of  1,101.    Elapsed: 0:06:12.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of  1,101.    Elapsed: 0:06:31.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   840  of  1,101.    Elapsed: 0:06:50.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   880  of  1,101.    Elapsed: 0:07:09.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   920  of  1,101.    Elapsed: 0:07:29.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   960  of  1,101.    Elapsed: 0:07:48.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,000  of  1,101.    Elapsed: 0:08:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,040  of  1,101.    Elapsed: 0:08:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,080  of  1,101.    Elapsed: 0:08:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.70\n",
            "  Recall: 0.70\n",
            "  F1: 0.70\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.84\n",
            "  Recall: 0.84\n",
            "  F1: 0.84\n",
            "The average precision is: 0.8837\n",
            "The average recall is: 0.8827\n",
            "The average f1 is: 0.8823\n",
            "  Training epcoh took: 0:08:55\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8870\n",
            "  Recall: 0.9500\n",
            "  F1: 0.9154\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.5962\n",
            "  Recall: 0.4513\n",
            "  F1: 0.4902\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3708\n",
            "The average recall is: 0.3503\n",
            "The average f1 is: 0.3514\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of  1,101.    Elapsed: 0:00:19.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of  1,101.    Elapsed: 0:00:38.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of  1,101.    Elapsed: 0:00:58.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of  1,101.    Elapsed: 0:01:17.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of  1,101.    Elapsed: 0:01:36.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of  1,101.    Elapsed: 0:01:55.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of  1,101.    Elapsed: 0:02:14.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of  1,101.    Elapsed: 0:02:33.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of  1,101.    Elapsed: 0:02:53.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of  1,101.    Elapsed: 0:03:12.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of  1,101.    Elapsed: 0:03:31.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of  1,101.    Elapsed: 0:03:51.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of  1,101.    Elapsed: 0:04:10.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of  1,101.    Elapsed: 0:04:29.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of  1,101.    Elapsed: 0:04:48.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of  1,101.    Elapsed: 0:05:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of  1,101.    Elapsed: 0:05:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of  1,101.    Elapsed: 0:05:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of  1,101.    Elapsed: 0:06:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of  1,101.    Elapsed: 0:06:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   840  of  1,101.    Elapsed: 0:06:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   880  of  1,101.    Elapsed: 0:07:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   920  of  1,101.    Elapsed: 0:07:22.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   960  of  1,101.    Elapsed: 0:07:41.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,000  of  1,101.    Elapsed: 0:08:00.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,040  of  1,101.    Elapsed: 0:08:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,080  of  1,101.    Elapsed: 0:08:39.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.71\n",
            "  Recall: 0.71\n",
            "  F1: 0.71\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.84\n",
            "  Recall: 0.84\n",
            "  F1: 0.84\n",
            "The average precision is: 0.8866\n",
            "The average recall is: 0.8861\n",
            "The average f1 is: 0.8862\n",
            "  Training epcoh took: 0:08:49\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8797\n",
            "  Recall: 0.9662\n",
            "  F1: 0.9197\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.5603\n",
            "  Recall: 0.3397\n",
            "  F1: 0.4057\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3792\n",
            "The average recall is: 0.3457\n",
            "The average f1 is: 0.3506\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of  1,101.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of  1,101.    Elapsed: 0:00:39.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of  1,101.    Elapsed: 0:00:59.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of  1,101.    Elapsed: 0:01:18.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of  1,101.    Elapsed: 0:01:38.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of  1,101.    Elapsed: 0:01:57.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of  1,101.    Elapsed: 0:02:16.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of  1,101.    Elapsed: 0:02:35.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of  1,101.    Elapsed: 0:02:55.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of  1,101.    Elapsed: 0:03:14.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of  1,101.    Elapsed: 0:03:33.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of  1,101.    Elapsed: 0:03:53.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of  1,101.    Elapsed: 0:04:12.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of  1,101.    Elapsed: 0:04:31.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of  1,101.    Elapsed: 0:04:50.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of  1,101.    Elapsed: 0:05:09.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of  1,101.    Elapsed: 0:05:28.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of  1,101.    Elapsed: 0:05:48.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of  1,101.    Elapsed: 0:06:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of  1,101.    Elapsed: 0:06:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   840  of  1,101.    Elapsed: 0:06:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   880  of  1,101.    Elapsed: 0:07:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   920  of  1,101.    Elapsed: 0:07:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   960  of  1,101.    Elapsed: 0:07:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,000  of  1,101.    Elapsed: 0:08:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,040  of  1,101.    Elapsed: 0:08:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,080  of  1,101.    Elapsed: 0:08:39.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.71\n",
            "  Recall: 0.71\n",
            "  F1: 0.71\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.83\n",
            "  Recall: 0.83\n",
            "  F1: 0.83\n",
            "The average precision is: 0.8864\n",
            "The average recall is: 0.8862\n",
            "The average f1 is: 0.8863\n",
            "  Training epcoh took: 0:08:49\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8793\n",
            "  Recall: 0.9716\n",
            "  F1: 0.9224\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0769\n",
            "  F1: 0.0769\n",
            "Category: 2\n",
            "  Precision: 0.5590\n",
            "  Recall: 0.3244\n",
            "  F1: 0.3877\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3788\n",
            "The average recall is: 0.3432\n",
            "The average f1 is: 0.3468\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Current increase 140 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1351 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 53 sampled in this category.\n",
            "After up-sample, there are 9020 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 9020 samples\n",
            "There are 182 sampled in this category.\n",
            "After up-sample, there are 34500 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 34500 samples\n",
            "There are 14 sampled in this category.\n",
            "After up-sample, there are 36460 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.844375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.03705430608886451\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "53\n",
            "0.033125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "7473\n",
            "0.20496434448710915\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "182\n",
            "0.11375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "25662\n",
            "0.7038398244651674\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "14\n",
            "0.00875\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1974\n",
            "0.05414152495885902\n",
            "\n",
            "(36460, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0831 14:05:56.373484 139633676007232 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0831 14:05:56.374389 139633676007232 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0831 14:05:57.299029 139633676007232 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0831 14:05:59.724575 139633676007232 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0831 14:05:59.725860 139633676007232 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of  1,140.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of  1,140.    Elapsed: 0:00:39.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of  1,140.    Elapsed: 0:00:58.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of  1,140.    Elapsed: 0:01:18.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of  1,140.    Elapsed: 0:01:37.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of  1,140.    Elapsed: 0:01:56.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of  1,140.    Elapsed: 0:02:16.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of  1,140.    Elapsed: 0:02:35.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of  1,140.    Elapsed: 0:02:55.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of  1,140.    Elapsed: 0:03:14.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of  1,140.    Elapsed: 0:03:34.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of  1,140.    Elapsed: 0:03:54.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of  1,140.    Elapsed: 0:04:13.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of  1,140.    Elapsed: 0:04:32.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of  1,140.    Elapsed: 0:04:52.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of  1,140.    Elapsed: 0:05:11.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of  1,140.    Elapsed: 0:05:30.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of  1,140.    Elapsed: 0:05:50.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of  1,140.    Elapsed: 0:06:10.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of  1,140.    Elapsed: 0:06:29.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   840  of  1,140.    Elapsed: 0:06:48.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   880  of  1,140.    Elapsed: 0:07:08.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   920  of  1,140.    Elapsed: 0:07:28.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   960  of  1,140.    Elapsed: 0:07:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,000  of  1,140.    Elapsed: 0:08:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,040  of  1,140.    Elapsed: 0:08:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,080  of  1,140.    Elapsed: 0:08:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,120  of  1,140.    Elapsed: 0:09:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.12\n",
            "  Accuracy: 0.97\n",
            "Category: 0\n",
            "  Precision: 0.53\n",
            "  Recall: 0.50\n",
            "  F1: 0.51\n",
            "Category: 1\n",
            "  Precision: 0.96\n",
            "  Recall: 0.96\n",
            "  F1: 0.95\n",
            "Category: 2\n",
            "  Precision: 0.98\n",
            "  Recall: 1.00\n",
            "  F1: 0.99\n",
            "Category: 3\n",
            "  Precision: 0.79\n",
            "  Recall: 0.79\n",
            "  F1: 0.79\n",
            "The average precision is: 0.8146\n",
            "The average recall is: 0.8110\n",
            "The average f1 is: 0.8092\n",
            "  Training epcoh took: 0:09:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.78\n",
            "Category: 0\n",
            "  Precision: 0.8988\n",
            "  Recall: 0.8522\n",
            "  F1: 0.8732\n",
            "Category: 1\n",
            "  Precision: 0.1564\n",
            "  Recall: 0.2308\n",
            "  F1: 0.1810\n",
            "Category: 2\n",
            "  Precision: 0.4949\n",
            "  Recall: 0.4317\n",
            "  F1: 0.4505\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3875\n",
            "The average recall is: 0.3787\n",
            "The average f1 is: 0.3762\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of  1,140.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of  1,140.    Elapsed: 0:00:39.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of  1,140.    Elapsed: 0:00:59.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of  1,140.    Elapsed: 0:01:17.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of  1,140.    Elapsed: 0:01:37.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of  1,140.    Elapsed: 0:01:56.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of  1,140.    Elapsed: 0:02:16.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of  1,140.    Elapsed: 0:02:35.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of  1,140.    Elapsed: 0:02:53.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of  1,140.    Elapsed: 0:03:13.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of  1,140.    Elapsed: 0:03:32.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of  1,140.    Elapsed: 0:03:51.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of  1,140.    Elapsed: 0:04:10.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of  1,140.    Elapsed: 0:04:30.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of  1,140.    Elapsed: 0:04:49.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of  1,140.    Elapsed: 0:05:09.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of  1,140.    Elapsed: 0:05:28.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of  1,140.    Elapsed: 0:05:48.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of  1,140.    Elapsed: 0:06:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of  1,140.    Elapsed: 0:06:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   840  of  1,140.    Elapsed: 0:06:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   880  of  1,140.    Elapsed: 0:07:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   920  of  1,140.    Elapsed: 0:07:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   960  of  1,140.    Elapsed: 0:07:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,000  of  1,140.    Elapsed: 0:08:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,040  of  1,140.    Elapsed: 0:08:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,080  of  1,140.    Elapsed: 0:08:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,120  of  1,140.    Elapsed: 0:09:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.68\n",
            "  Recall: 0.67\n",
            "  F1: 0.67\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.82\n",
            "  Recall: 0.82\n",
            "  F1: 0.82\n",
            "The average precision is: 0.8738\n",
            "The average recall is: 0.8725\n",
            "The average f1 is: 0.8725\n",
            "  Training epcoh took: 0:09:11\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8850\n",
            "  Recall: 0.9560\n",
            "  F1: 0.9174\n",
            "Category: 1\n",
            "  Precision: 0.0769\n",
            "  Recall: 0.0385\n",
            "  F1: 0.0513\n",
            "Category: 2\n",
            "  Precision: 0.5962\n",
            "  Recall: 0.3555\n",
            "  F1: 0.4209\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3895\n",
            "The average recall is: 0.3375\n",
            "The average f1 is: 0.3474\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of  1,140.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of  1,140.    Elapsed: 0:00:40.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of  1,140.    Elapsed: 0:00:59.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of  1,140.    Elapsed: 0:01:18.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of  1,140.    Elapsed: 0:01:37.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of  1,140.    Elapsed: 0:01:57.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of  1,140.    Elapsed: 0:02:16.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of  1,140.    Elapsed: 0:02:36.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of  1,140.    Elapsed: 0:02:55.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of  1,140.    Elapsed: 0:03:14.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of  1,140.    Elapsed: 0:03:34.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of  1,140.    Elapsed: 0:03:53.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of  1,140.    Elapsed: 0:04:12.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of  1,140.    Elapsed: 0:04:31.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of  1,140.    Elapsed: 0:04:51.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of  1,140.    Elapsed: 0:05:10.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of  1,140.    Elapsed: 0:05:29.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of  1,140.    Elapsed: 0:05:48.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of  1,140.    Elapsed: 0:06:07.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of  1,140.    Elapsed: 0:06:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   840  of  1,140.    Elapsed: 0:06:46.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   880  of  1,140.    Elapsed: 0:07:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   920  of  1,140.    Elapsed: 0:07:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   960  of  1,140.    Elapsed: 0:07:44.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,000  of  1,140.    Elapsed: 0:08:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,040  of  1,140.    Elapsed: 0:08:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,080  of  1,140.    Elapsed: 0:08:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,120  of  1,140.    Elapsed: 0:09:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.70\n",
            "  Recall: 0.70\n",
            "  F1: 0.70\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.83\n",
            "  Recall: 0.83\n",
            "  F1: 0.83\n",
            "The average precision is: 0.8820\n",
            "The average recall is: 0.8817\n",
            "The average f1 is: 0.8817\n",
            "  Training epcoh took: 0:09:11\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8686\n",
            "  Recall: 0.9780\n",
            "  F1: 0.9195\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.5000\n",
            "  Recall: 0.2484\n",
            "  F1: 0.3233\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3421\n",
            "The average recall is: 0.3066\n",
            "The average f1 is: 0.3107\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of  1,140.    Elapsed: 0:00:19.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of  1,140.    Elapsed: 0:00:38.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of  1,140.    Elapsed: 0:00:58.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of  1,140.    Elapsed: 0:01:17.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of  1,140.    Elapsed: 0:01:37.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of  1,140.    Elapsed: 0:01:56.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of  1,140.    Elapsed: 0:02:16.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of  1,140.    Elapsed: 0:02:35.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of  1,140.    Elapsed: 0:02:55.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of  1,140.    Elapsed: 0:03:14.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of  1,140.    Elapsed: 0:03:34.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of  1,140.    Elapsed: 0:03:53.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of  1,140.    Elapsed: 0:04:12.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of  1,140.    Elapsed: 0:04:31.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of  1,140.    Elapsed: 0:04:50.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of  1,140.    Elapsed: 0:05:10.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of  1,140.    Elapsed: 0:05:29.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of  1,140.    Elapsed: 0:05:49.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of  1,140.    Elapsed: 0:06:08.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of  1,140.    Elapsed: 0:06:28.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   840  of  1,140.    Elapsed: 0:06:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   880  of  1,140.    Elapsed: 0:07:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   920  of  1,140.    Elapsed: 0:07:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   960  of  1,140.    Elapsed: 0:07:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,000  of  1,140.    Elapsed: 0:08:05.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,040  of  1,140.    Elapsed: 0:08:24.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,080  of  1,140.    Elapsed: 0:08:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,120  of  1,140.    Elapsed: 0:09:03.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.68\n",
            "  Recall: 0.68\n",
            "  F1: 0.68\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.84\n",
            "  Recall: 0.84\n",
            "  F1: 0.84\n",
            "The average precision is: 0.8797\n",
            "The average recall is: 0.8800\n",
            "The average f1 is: 0.8798\n",
            "  Training epcoh took: 0:09:12\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8657\n",
            "  Recall: 0.9911\n",
            "  F1: 0.9233\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.6282\n",
            "  Recall: 0.2769\n",
            "  F1: 0.3652\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3735\n",
            "The average recall is: 0.3170\n",
            "The average f1 is: 0.3221\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Current increase 145 times\n",
            "Current is processing category 0\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 1351 sampled in this category.\n",
            "After up-sample, there are 1600 samples\n",
            "\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1600 samples\n",
            "There are 53 sampled in this category.\n",
            "After up-sample, there are 9285 samples\n",
            "\n",
            "Current is processing category 2\n",
            "Before up-sample, there are 9285 samples\n",
            "There are 182 sampled in this category.\n",
            "After up-sample, there are 35675 samples\n",
            "\n",
            "Current is processing category 3\n",
            "Before up-sample, there are 35675 samples\n",
            "There are 14 sampled in this category.\n",
            "After up-sample, there are 37705 samples\n",
            "\n",
            "Currrent is processing on categorie Low\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.844375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1351\n",
            "0.03583079167219202\n",
            "\n",
            "Currrent is processing on categorie Medium\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "53\n",
            "0.033125\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "7738\n",
            "0.2052247712504973\n",
            "\n",
            "Currrent is processing on categorie High\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "182\n",
            "0.11375\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "26572\n",
            "0.7047341201432171\n",
            "\n",
            "Currrent is processing on categorie Critical\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "14\n",
            "0.00875\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "2044\n",
            "0.05421031693409362\n",
            "\n",
            "(37705, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0831 14:42:54.602991 139633676007232 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0831 14:42:54.603943 139633676007232 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0831 14:42:59.608022 139633676007232 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0831 14:43:02.163489 139633676007232 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0831 14:43:02.164764 139633676007232 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of  1,179.    Elapsed: 0:00:19.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of  1,179.    Elapsed: 0:00:38.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of  1,179.    Elapsed: 0:00:57.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of  1,179.    Elapsed: 0:01:17.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of  1,179.    Elapsed: 0:01:37.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of  1,179.    Elapsed: 0:01:56.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of  1,179.    Elapsed: 0:02:16.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of  1,179.    Elapsed: 0:02:35.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of  1,179.    Elapsed: 0:02:54.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of  1,179.    Elapsed: 0:03:13.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of  1,179.    Elapsed: 0:03:33.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of  1,179.    Elapsed: 0:03:52.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of  1,179.    Elapsed: 0:04:11.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of  1,179.    Elapsed: 0:04:30.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of  1,179.    Elapsed: 0:04:49.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of  1,179.    Elapsed: 0:05:09.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of  1,179.    Elapsed: 0:05:28.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of  1,179.    Elapsed: 0:05:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of  1,179.    Elapsed: 0:06:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of  1,179.    Elapsed: 0:06:25.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   840  of  1,179.    Elapsed: 0:06:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   880  of  1,179.    Elapsed: 0:07:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   920  of  1,179.    Elapsed: 0:07:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   960  of  1,179.    Elapsed: 0:07:43.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,000  of  1,179.    Elapsed: 0:08:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,040  of  1,179.    Elapsed: 0:08:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,080  of  1,179.    Elapsed: 0:08:40.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,120  of  1,179.    Elapsed: 0:09:00.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,160  of  1,179.    Elapsed: 0:09:19.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.13\n",
            "  Accuracy: 0.98\n",
            "Category: 0\n",
            "  Precision: 0.51\n",
            "  Recall: 0.48\n",
            "  F1: 0.49\n",
            "Category: 1\n",
            "  Precision: 0.95\n",
            "  Recall: 0.96\n",
            "  F1: 0.96\n",
            "Category: 2\n",
            "  Precision: 0.98\n",
            "  Recall: 1.00\n",
            "  F1: 0.99\n",
            "Category: 3\n",
            "  Precision: 0.77\n",
            "  Recall: 0.77\n",
            "  F1: 0.77\n",
            "The average precision is: 0.8036\n",
            "The average recall is: 0.8039\n",
            "The average f1 is: 0.8008\n",
            "  Training epcoh took: 0:09:28\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8896\n",
            "  Recall: 0.9402\n",
            "  F1: 0.9136\n",
            "Category: 1\n",
            "  Precision: 0.1154\n",
            "  Recall: 0.1538\n",
            "  F1: 0.1282\n",
            "Category: 2\n",
            "  Precision: 0.5244\n",
            "  Recall: 0.4038\n",
            "  F1: 0.4392\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3823\n",
            "The average recall is: 0.3745\n",
            "The average f1 is: 0.3702\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of  1,179.    Elapsed: 0:00:20.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of  1,179.    Elapsed: 0:00:38.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of  1,179.    Elapsed: 0:00:57.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of  1,179.    Elapsed: 0:01:16.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of  1,179.    Elapsed: 0:01:36.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of  1,179.    Elapsed: 0:01:56.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of  1,179.    Elapsed: 0:02:15.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of  1,179.    Elapsed: 0:02:34.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of  1,179.    Elapsed: 0:02:54.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of  1,179.    Elapsed: 0:03:13.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of  1,179.    Elapsed: 0:03:33.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of  1,179.    Elapsed: 0:03:52.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of  1,179.    Elapsed: 0:04:11.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of  1,179.    Elapsed: 0:04:30.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of  1,179.    Elapsed: 0:04:50.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of  1,179.    Elapsed: 0:05:09.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of  1,179.    Elapsed: 0:05:28.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of  1,179.    Elapsed: 0:05:48.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   760  of  1,179.    Elapsed: 0:06:08.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   800  of  1,179.    Elapsed: 0:06:27.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   840  of  1,179.    Elapsed: 0:06:47.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   880  of  1,179.    Elapsed: 0:07:06.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   920  of  1,179.    Elapsed: 0:07:26.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   960  of  1,179.    Elapsed: 0:07:45.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,000  of  1,179.    Elapsed: 0:08:04.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,040  of  1,179.    Elapsed: 0:08:23.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,080  of  1,179.    Elapsed: 0:08:42.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,120  of  1,179.    Elapsed: 0:09:02.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch 1,160  of  1,179.    Elapsed: 0:09:21.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.66\n",
            "  Recall: 0.65\n",
            "  F1: 0.65\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 2\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 3\n",
            "  Precision: 0.84\n",
            "  Recall: 0.84\n",
            "  F1: 0.84\n",
            "The average precision is: 0.8738\n",
            "The average recall is: 0.8730\n",
            "The average f1 is: 0.8728\n",
            "  Training epcoh took: 0:09:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8812\n",
            "  Recall: 0.9638\n",
            "  F1: 0.9185\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "Category: 2\n",
            "  Precision: 0.5321\n",
            "  Recall: 0.3350\n",
            "  F1: 0.4020\n",
            "Category: 3\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.3533\n",
            "The average recall is: 0.3247\n",
            "The average f1 is: 0.3301\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    40  of  1,179.    Elapsed: 0:00:19.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch    80  of  1,179.    Elapsed: 0:00:38.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   120  of  1,179.    Elapsed: 0:00:58.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   160  of  1,179.    Elapsed: 0:01:17.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   200  of  1,179.    Elapsed: 0:01:36.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   240  of  1,179.    Elapsed: 0:01:56.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   280  of  1,179.    Elapsed: 0:02:16.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   320  of  1,179.    Elapsed: 0:02:35.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   360  of  1,179.    Elapsed: 0:02:54.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   400  of  1,179.    Elapsed: 0:03:13.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   440  of  1,179.    Elapsed: 0:03:32.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   480  of  1,179.    Elapsed: 0:03:51.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   520  of  1,179.    Elapsed: 0:04:11.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   560  of  1,179.    Elapsed: 0:04:31.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   600  of  1,179.    Elapsed: 0:04:50.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   640  of  1,179.    Elapsed: 0:05:09.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   680  of  1,179.    Elapsed: 0:05:29.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "  Batch   720  of  1,179.    Elapsed: 0:05:48.\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n",
            "Invoke 3\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}