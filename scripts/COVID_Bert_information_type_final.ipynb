{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COVID_Bert_information_type_final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "_Rh3iwCqWcSk",
        "iqxvbG3XWc4M",
        "egQ4fqBGWdd8",
        "bXtcQIcrWeDc",
        "wGbqnJyhWejl"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "B8yb2kzS-JW9"
      },
      "source": [
        "# Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5bqvajMe0Ql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Acknowlegement: Some codes used to initialise BERT are from BERT tutorial(https://colab.research.google.com/drive/1Y4o3jh3ZH70tl6mCd76vz_IxX23biCPP)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2v2kcLX81EH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import necessary libraries\n",
        "import re\n",
        "import string\n",
        "import os \n",
        "from collections import defaultdict\n",
        "from collections import Counter\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import datetime\n",
        "import copy\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from covid_tools import *\n",
        "from BERTs import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1PeHWGXE94uq",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "# load orginal data(COVID-19 TREC-IS 2020 task) from json file.\n",
        "cv19_dc = pd.read_json('./Pythonbooks/Data/COVID/cv19_dc_test.json',lines=True,orient='records')\n",
        "cv19_ws = pd.read_json('./Pythonbooks/Data/COVID/cv19_washington_state_test.json',lines=True,orient='records')\n",
        "cv19_ny = pd.read_json('./Pythonbooks/Data/COVID/cv19_nyc_test.json',lines=True,orient='records')\n",
        "\n",
        "# Read lablled tweets from json file which contains all labels based on union of labels from all human assessors.\n",
        "all_labels  = read_union_labels_from_file()\n",
        "\n",
        "# Merge original dataset with lablled dataset based on id of tweets\n",
        "cv19_dc_labeled = pd.merge(cv19_dc,all_labels,on=['id'])\n",
        "cv19_ws_labeled = pd.merge(cv19_ws,all_labels,on=['id'])\n",
        "cv19_ny_labeled = pd.merge(cv19_ny,all_labels,on=['id'])\n",
        "\n",
        "# As for priorization task, we use majority vote of labels instead of union.\n",
        "'''More specifically, if one tweet is assessed by more than two assessors,\n",
        " we use the most common label as the priority label. And if one tweet is assessed by less than two assessors, \n",
        " we randomly choose one label as the true label. \n",
        " '''\n",
        "cv19_dc_labeled = extract_majority_vote_label(cv19_dc_labeled)\n",
        "cv19_ny_labeled = extract_majority_vote_label(cv19_ny_labeled)\n",
        "cv19_ws_labeled = extract_majority_vote_label(cv19_ws_labeled)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YaUZV6Io9_p5",
        "colab": {}
      },
      "source": [
        "def build_trainingset(trainSet):\n",
        "  # Extract training set from dataFrame\n",
        "  # Extract features from dataFrame by using feature names\n",
        "  featureList = ['full_text','entities','favorite_count'] #,'favorited'\n",
        "  trainF = extract_features(trainSet,featureList)\n",
        "  # Select column named \"priority\" as labels\n",
        "  labelList = ['priority']\n",
        "  trainL_temp = extract_features(trainSet,labelList)['priority']\n",
        "  # Extract hashtags from dataFrame for each samples\n",
        "  trainF = extract_hashtags(trainF)\n",
        "  \n",
        "  # Transfer text labels to numerical labels\n",
        "  trainL = []\n",
        "  for label in trainL_temp:\n",
        "    if label == 'Low':\n",
        "      trainL.append(0)\n",
        "    elif label == 'Medium':\n",
        "      trainL.append(1)\n",
        "    elif label == 'High':\n",
        "      trainL.append(2)\n",
        "    elif label == 'Critical':\n",
        "      trainL.append(3)\n",
        "  return trainF, trainL\n",
        "\n",
        "def store_csv(df,location,val_ratio=0.2):\n",
        "  # Store training, valdation, text set into csv file\n",
        "  trainF, trainL = build_trainingset(df)\n",
        "    \n",
        "  idx = np.arange(df.shape[0])\n",
        "  np.random.shuffle(idx)\n",
        "    \n",
        "  val_size = int(len(idx) * val_ratio)\n",
        "  if not os.path.exists('priority/'+location):\n",
        "      os.makedirs('priority/'+location)\n",
        "    \n",
        "  print(len(trainL))\n",
        "  df = pd.DataFrame(trainF)\n",
        "  df['target'] = trainL\n",
        "  # Rename labels to target\n",
        "  df[['full_text','hashtags','favorite_count', 'target']].to_csv('priority/'+location+'/dataset_all.csv',\n",
        "                   index=False)\n",
        "    \n",
        "  df.iloc[idx[val_size:], :][['full_text','hashtags','favorite_count','target']].to_csv('priority/'+location+'/dataset_test.csv',\n",
        "                   index=False)                 \n",
        "  df.iloc[idx[val_size:], :][['full_text','hashtags','favorite_count','target']].to_csv(\n",
        "        'priority/'+location+'/dataset_train.csv',index=False)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k8AQChIR-CXZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "d8c41c66-c5ed-4d08-c034-a1464e77f4ea"
      },
      "source": [
        "# Store training,  test set into csv file\n",
        "if not os.path.exists('/priority/'):\n",
        "  store_csv(cv19_ws_labeled,location='WS') \n",
        "  store_csv(cv19_dc_labeled,location='DC') \n",
        "  store_csv(cv19_ny_labeled,location='NY') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2577\n",
            "2504\n",
            "2502\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rpjyJxpE-HMZ",
        "colab": {}
      },
      "source": [
        "# check GPU situation\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime â†’ \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QSbMI-8I-RC7"
      },
      "source": [
        "# Pre-process the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qUQGA0qe-pVD",
        "colab": {}
      },
      "source": [
        "# Choose one dataset to use in this section\n",
        "Tweets = cv19_ws_labeled"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "__CCHe61-rTI",
        "colab": {}
      },
      "source": [
        "categories = ['GoodsServices','InformationWanted','Volunteer','EmergingThreats','NewSubEvent','ServiceAvailable','Advice',]\n",
        "\n",
        "# Extract training set\n",
        "featureList = ['full_text'] #,'favorited'\n",
        "dataset_inputs = extract_features(Tweets,featureList)\n",
        "\n",
        "# Extract labels\n",
        "labelList = ['categories']\n",
        "labels = extract_features(Tweets,labelList)['categories']\n",
        "\n",
        "# Transfer a list of text labels into a list of number labels, like [0,1,0,0,0,0,0]\n",
        "labels = extractLabels(dataset_inputs,labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q1C9EyXvghvU"
      },
      "source": [
        "#### Build label for each catergory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0_U-AdJoghAm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "0a51a58a-ecdb-4391-8432-aafa7a9b7045"
      },
      "source": [
        "categories = ['GoodsServices','InformationWanted','Volunteer','EmergingThreats','NewSubEvent','ServiceAvailable','Advice']\n",
        "# Sperate labels for each category and store them in one dict\n",
        "# A dict Contains labels for all categories e.g. trainL_single[category]\n",
        "labels_single = {}\n",
        "for i in range(7):\n",
        "  print('Currrent is processing on categorie %s'%(categories[i]))\n",
        "  print()\n",
        "  # if i == 3:\n",
        "  #   continue\n",
        "  labels_one_category = []\n",
        "  for j in range(len(labels)):\n",
        "    labels_one_category.append(labels[j][i])\n",
        "  labels_single[i] = labels_one_category\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Currrent is processing on categorie Volunteer\n",
            "\n",
            "Currrent is processing on categorie EmergingThreats\n",
            "\n",
            "Currrent is processing on categorie NewSubEvent\n",
            "\n",
            "Currrent is processing on categorie ServiceAvailable\n",
            "\n",
            "Currrent is processing on categorie Advice\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zbJTdlRHD1lp"
      },
      "source": [
        "## Tokenization: Bert tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FWYbLDSfD2ug",
        "colab": {}
      },
      "source": [
        "sentences = Tweets.full_text.values\n",
        "labels = labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MWJ5VTWDD-MP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "cd97c99a-41fa-4c24-be46-85331f4bf25d"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n",
            " Original:  I see lots of people panicking about coronavirus around Seattle and King County.\n",
            "\n",
            "There are already hundreds, if not thousands, of undiagnosed cases in the local area. We will all be exposed to it. The spread will not be stopped. \n",
            "\n",
            "Iâ€™m not trying to incite panic, though...\n",
            "Tokenized:  ['i', 'see', 'lots', 'of', 'people', 'panic', '##king', 'about', 'corona', '##virus', 'around', 'seattle', 'and', 'king', 'county', '.', 'there', 'are', 'already', 'hundreds', ',', 'if', 'not', 'thousands', ',', 'of', 'und', '##ia', '##gno', '##sed', 'cases', 'in', 'the', 'local', 'area', '.', 'we', 'will', 'all', 'be', 'exposed', 'to', 'it', '.', 'the', 'spread', 'will', 'not', 'be', 'stopped', '.', 'i', 'â€™', 'm', 'not', 'trying', 'to', 'inc', '##ite', 'panic', ',', 'though', '.', '.', '.']\n",
            "Token IDs:  [1045, 2156, 7167, 1997, 2111, 6634, 6834, 2055, 21887, 23350, 2105, 5862, 1998, 2332, 2221, 1012, 2045, 2024, 2525, 5606, 1010, 2065, 2025, 5190, 1010, 1997, 6151, 2401, 26745, 6924, 3572, 1999, 1996, 2334, 2181, 1012, 2057, 2097, 2035, 2022, 6086, 2000, 2009, 1012, 1996, 3659, 2097, 2025, 2022, 3030, 1012, 1045, 1521, 1049, 2025, 2667, 2000, 4297, 4221, 6634, 1010, 2295, 1012, 1012, 1012]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q2JPyq9iFHSr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "9fecc6d0-9e01-4470-8a0b-1bd53a6808d2"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    # If the length of token is over the bert limitation, cut off the back\n",
        "    if(len(encoded_sent)>144):\n",
        "        diff = int((len(encoded_sent) - 145)/2)\n",
        "        encoded_sent = encoded_sent[diff:144+diff]\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  I see lots of people panicking about coronavirus around Seattle and King County.\n",
            "\n",
            "There are already hundreds, if not thousands, of undiagnosed cases in the local area. We will all be exposed to it. The spread will not be stopped. \n",
            "\n",
            "Iâ€™m not trying to incite panic, though...\n",
            "Token IDs: [101, 1045, 2156, 7167, 1997, 2111, 6634, 6834, 2055, 21887, 23350, 2105, 5862, 1998, 2332, 2221, 1012, 2045, 2024, 2525, 5606, 1010, 2065, 2025, 5190, 1010, 1997, 6151, 2401, 26745, 6924, 3572, 1999, 1996, 2334, 2181, 1012, 2057, 2097, 2035, 2022, 6086, 2000, 2009, 1012, 1996, 3659, 2097, 2025, 2022, 3030, 1012, 1045, 1521, 1049, 2025, 2667, 2000, 4297, 4221, 6634, 1010, 2295, 1012, 1012, 1012, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HApbJUIo3uoT",
        "colab_type": "text"
      },
      "source": [
        "## Padding\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wXkeVbwFFLmg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "f546ad1c-537c-4262-e092-44b2d88b2e75"
      },
      "source": [
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "MAX_LEN = 144\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 144 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSzbtxFP30ZK",
        "colab_type": "text"
      },
      "source": [
        "## Attension mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sys-Jh5vFIEq",
        "colab": {}
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ThdCl_uCsRIW"
      },
      "source": [
        "# Classication one category by on category"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jhBKQGW53XB",
        "colab_type": "text"
      },
      "source": [
        "All training split dataset first. Then use BERT to evaluate and store the result into a file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_Vz_7WthsURS",
        "colab": {}
      },
      "source": [
        "# A dict to store all metrics fro each category, Use name of category as the key to search\n",
        "all_metrics_all_category = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "olHEfcJDhrll"
      },
      "source": [
        "### For 'GoodsServices'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aVgSb3P5FPDa"
      },
      "source": [
        "#### Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FW6SI9RvFOMS",
        "colab": {}
      },
      "source": [
        "# Use train_test_split to split our data into train and validation and test sets for\n",
        "# training\n",
        "section_category = 0\n",
        "labels = labels_single[section_category]\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 80% for training and 20% for validation.\n",
        "temp_inputs, test_inputs,  temp_labels, test_labels = train_test_split(input_ids, labels, random_state=1999, test_size=0.2)\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(temp_inputs, temp_labels,random_state=1999, test_size=0.2)\n",
        "\n",
        "# Do the same for the masks.\n",
        "temp_masks, test_masks, temp_labels, _ = train_test_split(attention_masks, labels,random_state=1999, test_size=0.2)\n",
        "\n",
        "train_masks, validation_masks, _, _ = train_test_split(temp_masks, temp_labels,random_state=1999, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "w7ITcGYRIhSs"
      },
      "source": [
        "#### Normal training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TuTKz5D4gl3s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7156f0ab-6c8e-4ea4-9b68-849e5642e802"
      },
      "source": [
        "import json\n",
        "batch_size = 8\n",
        "lr = 3e-5\n",
        "test_batch = [test_inputs,test_labels,test_masks]\n",
        "Bert = Bertnn_info(train_inputs,train_labels,train_masks, validation_inputs,validation_labels,validation_masks,test_batch,batch_size=batch_size,lr=lr)\n",
        "all_metrics_one, all_tesst_metrics = Bert.searchUpsample(100)\n",
        "all_metrics_one['test'] = all_tesst_metrics\n",
        "all_metrics_all_category[section_category] = all_metrics_one\n",
        "if not os.path.exists('BertSearchResult'):\n",
        "  os.makedirs('BertSearchResult')\n",
        "\n",
        "filename = './BertSearchResult/'+str(batch_size) + '_' + str(lr) + '_'  + str(section_category)\n",
        "with open(filename,'w') as file_obj:\n",
        "  json.dump(all_metrics_one,file_obj)\n",
        "  print('Successfully save file %s'%(filename))\n",
        "\n",
        "del Bert\n",
        "torch.cuda.empty_cache() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: GeForce RTX 2070 SUPER\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current increase 0 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 3 sampled in this category.\n",
            "After up-sample, there are 1648 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1645\n",
            "0.9981796116504854\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "3\n",
            "0.0018203883495145632\n",
            "\n",
            "(1648, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    206.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    206.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    206.    Elapsed: 0:00:27.\n",
            "  Batch   160  of    206.    Elapsed: 0:00:35.\n",
            "  Batch   200  of    206.    Elapsed: 0:00:44.\n",
            "\n",
            "  Average training loss: 0.03\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.4991\n",
            "The average recall is: 0.4982\n",
            "The average f1 is: 0.4981\n",
            "  Training epcoh took: 0:00:46\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    206.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    206.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    206.    Elapsed: 0:00:27.\n",
            "  Batch   160  of    206.    Elapsed: 0:00:36.\n",
            "  Batch   200  of    206.    Elapsed: 0:00:45.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.4991\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4995\n",
            "  Training epcoh took: 0:00:47\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    206.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    206.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    206.    Elapsed: 0:00:27.\n",
            "  Batch   160  of    206.    Elapsed: 0:00:36.\n",
            "  Batch   200  of    206.    Elapsed: 0:00:45.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.4991\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4995\n",
            "  Training epcoh took: 0:00:46\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    206.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    206.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    206.    Elapsed: 0:00:27.\n",
            "  Batch   160  of    206.    Elapsed: 0:00:36.\n",
            "  Batch   200  of    206.    Elapsed: 0:00:45.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.4991\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4995\n",
            "  Training epcoh took: 0:00:46\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n",
            "Testing...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.9981\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9990\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4990\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4995\n",
            "  Testing took: 0:00:03\n",
            "Successfully save file ./BertSearchResult/8_3e-05_0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vw3vfQF4InQr"
      },
      "source": [
        "#### Incremental recitfied training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "g9gPQyuHZipw",
        "colab_type": "code",
        "colab": {},
        "outputId": "be5de905-0b35-492a-8308-710e13783062"
      },
      "source": [
        "import json\n",
        "batch_size = 32\n",
        "lr = 3e-5\n",
        "test_batch = [test_inputs,test_labels,test_masks]\n",
        "Bert = Bertnn_rectified_info(train_inputs,train_labels,train_masks, validation_inputs,validation_labels,validation_masks,test_batch,batch_size=batch_size,lr=lr)\n",
        "all_metrics_one, all_tesst_metrics = Bert.searchUpsample(100)\n",
        "all_metrics_one['test'] = all_tesst_metrics\n",
        "all_metrics_all_category[section_category] = all_metrics_one\n",
        "if not os.path.exists('BertSearchResult'):\n",
        "  os.makedirs('BertSearchResult')\n",
        "\n",
        "filename = './BertSearchResult/'+'rectified'+'_'+str(section_category)+'_'+str(batch_size) + '_' + str(lr) + '_'  + str(section_category)\n",
        "with open(filename,'w') as file_obj:\n",
        "  json.dump(all_metrics_one,file_obj)\n",
        "  print('Successfully save file %s'%(filename))\n",
        "\n",
        "del Bert\n",
        "torch.cuda.empty_cache() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: TITAN RTX\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0904 07:41:22.816618 139984129095488 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0904 07:41:22.817810 139984129095488 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0904 07:41:24.544897 139984129095488 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0904 07:41:27.123279 139984129095488 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0904 07:41:27.124095 139984129095488 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current increase 0 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 3 sampled in this category.\n",
            "After up-sample, there are 1648 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1645\n",
            "0.9981796116504854\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "3\n",
            "0.0018203883495145632\n",
            "\n",
            "(1648, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0904 07:41:27.731730 139984129095488 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0904 07:41:27.732635 139984129095488 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0904 07:41:27.822070 139984129095488 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0904 07:41:30.477641 139984129095488 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0904 07:41:30.478448 139984129095488 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     52.    Elapsed: 0:00:14.\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.38\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 0.99\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.4991\n",
            "The average recall is: 0.4973\n",
            "The average f1 is: 0.4980\n",
            "  Training epcoh took: 0:00:18\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     52.    Elapsed: 0:00:14.\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.36\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.4991\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4995\n",
            "  Training epcoh took: 0:00:18\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     52.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 0.33\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.4991\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4995\n",
            "  Training epcoh took: 0:00:18\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     52.    Elapsed: 0:00:14.\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.34\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.4991\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4995\n",
            "  Training epcoh took: 0:00:18\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.9982\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9991\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4991\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4995\n",
            "  Testing took: 0:00:01\n",
            "Current increase 10 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 3 sampled in this category.\n",
            "After up-sample, there are 1678 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1645\n",
            "0.9803337306317044\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "33\n",
            "0.01966626936829559\n",
            "\n",
            "(1678, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0904 07:42:50.245889 139984129095488 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0904 07:42:50.248139 139984129095488 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0904 07:42:50.565573 139984129095488 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0904 07:42:53.147342 139984129095488 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0904 07:42:53.148796 139984129095488 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     53.    Elapsed: 0:00:17.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.88\n",
            "  Accuracy: 0.97\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.98\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 0.04\n",
            "  Recall: 0.08\n",
            "  F1: 0.05\n",
            "The average precision is: 0.5142\n",
            "The average recall is: 0.5282\n",
            "The average f1 is: 0.5121\n",
            "  Training epcoh took: 0:00:27\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     53.    Elapsed: 0:00:18.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.51\n",
            "  Recall: 0.51\n",
            "  F1: 0.51\n",
            "The average precision is: 0.7547\n",
            "The average recall is: 0.7547\n",
            "The average f1 is: 0.7547\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     53.    Elapsed: 0:00:17.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.47\n",
            "  Recall: 0.47\n",
            "  F1: 0.47\n",
            "The average precision is: 0.7358\n",
            "The average recall is: 0.7358\n",
            "The average f1 is: 0.7358\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     53.    Elapsed: 0:00:18.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.45\n",
            "  Recall: 0.45\n",
            "  F1: 0.45\n",
            "The average precision is: 0.7264\n",
            "The average recall is: 0.7264\n",
            "The average f1 is: 0.7264\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.9982\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9991\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4991\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4995\n",
            "  Testing took: 0:00:01\n",
            "Current increase 20 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 3 sampled in this category.\n",
            "After up-sample, there are 1708 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1645\n",
            "0.9631147540983607\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "63\n",
            "0.036885245901639344\n",
            "\n",
            "(1708, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0904 07:44:36.748656 139984129095488 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0904 07:44:36.749817 139984129095488 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0904 07:44:36.792573 139984129095488 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0904 07:44:39.484605 139984129095488 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0904 07:44:39.485610 139984129095488 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     54.    Elapsed: 0:00:20.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.73\n",
            "  Accuracy: 0.97\n",
            "Category: 0\n",
            "  Precision: 0.98\n",
            "  Recall: 0.99\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 0.37\n",
            "  Recall: 0.38\n",
            "  F1: 0.36\n",
            "The average precision is: 0.6745\n",
            "The average recall is: 0.6841\n",
            "The average f1 is: 0.6736\n",
            "  Training epcoh took: 0:00:27\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     54.    Elapsed: 0:00:21.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.71\n",
            "  Recall: 0.72\n",
            "  F1: 0.71\n",
            "The average precision is: 0.8526\n",
            "The average recall is: 0.8602\n",
            "The average f1 is: 0.8556\n",
            "  Training epcoh took: 0:00:28\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     54.    Elapsed: 0:00:21.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.76\n",
            "  Recall: 0.76\n",
            "  F1: 0.76\n",
            "The average precision is: 0.8796\n",
            "The average recall is: 0.8796\n",
            "The average f1 is: 0.8796\n",
            "  Training epcoh took: 0:00:28\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     54.    Elapsed: 0:00:21.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.67\n",
            "  Recall: 0.67\n",
            "  F1: 0.67\n",
            "The average precision is: 0.8333\n",
            "The average recall is: 0.8333\n",
            "The average f1 is: 0.8333\n",
            "  Training epcoh took: 0:00:28\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.9982\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9991\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4991\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4995\n",
            "  Testing took: 0:00:02\n",
            "Current increase 30 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 3 sampled in this category.\n",
            "After up-sample, there are 1738 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1645\n",
            "0.9464902186421174\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "93\n",
            "0.053509781357882626\n",
            "\n",
            "(1738, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0904 07:46:37.970458 139984129095488 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0904 07:46:37.971758 139984129095488 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0904 07:46:39.647258 139984129095488 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0904 07:46:42.287564 139984129095488 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0904 07:46:42.288311 139984129095488 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     55.    Elapsed: 0:00:21.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.52\n",
            "  Accuracy: 0.98\n",
            "Category: 0\n",
            "  Precision: 0.98\n",
            "  Recall: 1.00\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.57\n",
            "  Recall: 0.55\n",
            "  F1: 0.55\n",
            "The average precision is: 0.7754\n",
            "The average recall is: 0.7745\n",
            "The average f1 is: 0.7709\n",
            "  Training epcoh took: 0:00:29\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     55.    Elapsed: 0:00:21.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.84\n",
            "  Recall: 0.84\n",
            "  F1: 0.84\n",
            "The average precision is: 0.9182\n",
            "The average recall is: 0.9182\n",
            "The average f1 is: 0.9182\n",
            "  Training epcoh took: 0:00:29\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     55.    Elapsed: 0:00:21.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.84\n",
            "  Recall: 0.84\n",
            "  F1: 0.84\n",
            "The average precision is: 0.9182\n",
            "The average recall is: 0.9182\n",
            "The average f1 is: 0.9182\n",
            "  Training epcoh took: 0:00:29\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     55.    Elapsed: 0:00:21.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.84\n",
            "  Recall: 0.84\n",
            "  F1: 0.84\n",
            "The average precision is: 0.9182\n",
            "The average recall is: 0.9182\n",
            "The average f1 is: 0.9182\n",
            "  Training epcoh took: 0:00:28\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.9982\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9991\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4991\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4995\n",
            "  Testing took: 0:00:02\n",
            "Current increase 40 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 3 sampled in this category.\n",
            "After up-sample, there are 1768 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1645\n",
            "0.9304298642533937\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "123\n",
            "0.06957013574660634\n",
            "\n",
            "(1768, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0904 07:48:45.070306 139984129095488 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0904 07:48:45.071531 139984129095488 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0904 07:48:45.112248 139984129095488 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0904 07:48:47.841093 139984129095488 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0904 07:48:47.842653 139984129095488 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     56.    Elapsed: 0:00:21.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.39\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.98\n",
            "  Recall: 0.98\n",
            "  F1: 0.97\n",
            "Category: 1\n",
            "  Precision: 0.58\n",
            "  Recall: 0.60\n",
            "  F1: 0.58\n",
            "The average precision is: 0.7783\n",
            "The average recall is: 0.7901\n",
            "The average f1 is: 0.7750\n",
            "  Training epcoh took: 0:00:29\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     56.    Elapsed: 0:00:21.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.88\n",
            "  Recall: 0.88\n",
            "  F1: 0.88\n",
            "The average precision is: 0.9375\n",
            "The average recall is: 0.9375\n",
            "The average f1 is: 0.9375\n",
            "  Training epcoh took: 0:00:29\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     56.    Elapsed: 0:00:21.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.88\n",
            "  Recall: 0.88\n",
            "  F1: 0.88\n",
            "The average precision is: 0.9375\n",
            "The average recall is: 0.9375\n",
            "The average f1 is: 0.9375\n",
            "  Training epcoh took: 0:00:29\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     56.    Elapsed: 0:00:21.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.86\n",
            "  Recall: 0.86\n",
            "  F1: 0.86\n",
            "The average precision is: 0.9286\n",
            "The average recall is: 0.9286\n",
            "The average f1 is: 0.9286\n",
            "  Training epcoh took: 0:00:29\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.9982\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9991\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4991\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4995\n",
            "  Testing took: 0:00:02\n",
            "Current increase 50 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 3 sampled in this category.\n",
            "After up-sample, there are 1798 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1645\n",
            "0.9149054505005562\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "153\n",
            "0.08509454949944383\n",
            "\n",
            "(1798, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0904 07:50:50.487488 139984129095488 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0904 07:50:50.488777 139984129095488 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0904 07:50:50.555927 139984129095488 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0904 07:50:53.282213 139984129095488 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0904 07:50:53.283914 139984129095488 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     57.    Elapsed: 0:00:21.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.32\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 1.00\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.80\n",
            "  Recall: 0.78\n",
            "  F1: 0.79\n",
            "The average precision is: 0.8937\n",
            "The average recall is: 0.8893\n",
            "The average f1 is: 0.8891\n",
            "  Training epcoh took: 0:00:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     57.    Elapsed: 0:00:21.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.91\n",
            "  Recall: 0.91\n",
            "  F1: 0.91\n",
            "The average precision is: 0.9558\n",
            "The average recall is: 0.9544\n",
            "The average f1 is: 0.9550\n",
            "  Training epcoh took: 0:00:29\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.97\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 0.9712\n",
            "  F1: 0.9851\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.4856\n",
            "The average f1 is: 0.4926\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     57.    Elapsed: 0:00:21.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.89\n",
            "  Recall: 0.89\n",
            "  F1: 0.89\n",
            "The average precision is: 0.9474\n",
            "The average recall is: 0.9471\n",
            "The average f1 is: 0.9472\n",
            "  Training epcoh took: 0:00:29\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     57.    Elapsed: 0:00:21.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.95\n",
            "  Recall: 0.95\n",
            "  F1: 0.95\n",
            "The average precision is: 0.9737\n",
            "The average recall is: 0.9737\n",
            "The average f1 is: 0.9737\n",
            "  Training epcoh took: 0:00:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.9982\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9991\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4991\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4995\n",
            "  Testing took: 0:00:01\n",
            "Current increase 60 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 3 sampled in this category.\n",
            "After up-sample, there are 1828 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1645\n",
            "0.899890590809628\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "183\n",
            "0.10010940919037199\n",
            "\n",
            "(1828, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0904 07:52:58.656882 139984129095488 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0904 07:52:58.658089 139984129095488 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0904 07:52:58.703637 139984129095488 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0904 07:53:01.361294 139984129095488 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0904 07:53:01.362502 139984129095488 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     58.    Elapsed: 0:00:21.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.32\n",
            "  Accuracy: 0.97\n",
            "Category: 0\n",
            "  Precision: 0.97\n",
            "  Recall: 0.99\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 0.84\n",
            "  Recall: 0.73\n",
            "  F1: 0.76\n",
            "The average precision is: 0.9083\n",
            "The average recall is: 0.8610\n",
            "The average f1 is: 0.8710\n",
            "  Training epcoh took: 0:00:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     58.    Elapsed: 0:00:21.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.92\n",
            "  Recall: 0.93\n",
            "  F1: 0.93\n",
            "The average precision is: 0.9616\n",
            "The average recall is: 0.9649\n",
            "The average f1 is: 0.9630\n",
            "  Training epcoh took: 0:00:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     58.    Elapsed: 0:00:21.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.94\n",
            "  Recall: 0.95\n",
            "  F1: 0.94\n",
            "The average precision is: 0.9698\n",
            "The average recall is: 0.9735\n",
            "The average f1 is: 0.9714\n",
            "  Training epcoh took: 0:00:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.9982\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9991\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4991\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4995\n",
            "  Testing took: 0:00:01\n",
            "Current increase 70 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 3 sampled in this category.\n",
            "After up-sample, there are 1858 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1645\n",
            "0.8853606027987083\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "213\n",
            "0.11463939720129171\n",
            "\n",
            "(1858, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0904 07:55:09.542805 139984129095488 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0904 07:55:09.543895 139984129095488 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0904 07:55:09.598317 139984129095488 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0904 07:55:12.212032 139984129095488 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0904 07:55:12.213116 139984129095488 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     59.    Elapsed: 0:00:21.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.28\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.96\n",
            "  Recall: 0.98\n",
            "  F1: 0.97\n",
            "Category: 1\n",
            "  Precision: 0.80\n",
            "  Recall: 0.80\n",
            "  F1: 0.79\n",
            "The average precision is: 0.8801\n",
            "The average recall is: 0.8874\n",
            "The average f1 is: 0.8780\n",
            "  Training epcoh took: 0:00:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     59.    Elapsed: 0:00:21.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.98\n",
            "  Recall: 0.97\n",
            "  F1: 0.97\n",
            "The average precision is: 0.9877\n",
            "The average recall is: 0.9867\n",
            "The average f1 is: 0.9863\n",
            "  Training epcoh took: 0:00:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     59.    Elapsed: 0:00:21.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.94\n",
            "  Recall: 0.95\n",
            "  F1: 0.95\n",
            "The average precision is: 0.9718\n",
            "The average recall is: 0.9743\n",
            "The average f1 is: 0.9727\n",
            "  Training epcoh took: 0:00:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     59.    Elapsed: 0:00:21.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.97\n",
            "  Recall: 0.97\n",
            "  F1: 0.97\n",
            "The average precision is: 0.9831\n",
            "The average recall is: 0.9831\n",
            "The average f1 is: 0.9831\n",
            "  Training epcoh took: 0:00:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.9982\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9991\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4991\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4995\n",
            "  Testing took: 0:00:02\n",
            "Current increase 80 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 3 sampled in this category.\n",
            "After up-sample, there are 1888 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1645\n",
            "0.871292372881356\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "243\n",
            "0.12870762711864406\n",
            "\n",
            "(1888, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0904 07:57:22.757156 139984129095488 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0904 07:57:22.758334 139984129095488 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0904 07:57:22.798760 139984129095488 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0904 07:57:25.572783 139984129095488 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0904 07:57:25.574472 139984129095488 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     59.    Elapsed: 0:00:21.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.27\n",
            "  Accuracy: 0.98\n",
            "Category: 0\n",
            "  Precision: 0.98\n",
            "  Recall: 1.00\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.85\n",
            "  Recall: 0.82\n",
            "  F1: 0.83\n",
            "The average precision is: 0.9135\n",
            "The average recall is: 0.9110\n",
            "The average f1 is: 0.9082\n",
            "  Training epcoh took: 0:00:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     59.    Elapsed: 0:00:21.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.98\n",
            "  Recall: 0.98\n",
            "  F1: 0.98\n",
            "The average precision is: 0.9915\n",
            "The average recall is: 0.9915\n",
            "The average f1 is: 0.9915\n",
            "  Training epcoh took: 0:00:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     59.    Elapsed: 0:00:21.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 1.0000\n",
            "The average recall is: 1.0000\n",
            "The average f1 is: 1.0000\n",
            "  Training epcoh took: 0:00:32\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     59.    Elapsed: 0:00:21.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.97\n",
            "  Recall: 0.97\n",
            "  F1: 0.97\n",
            "The average precision is: 0.9831\n",
            "The average recall is: 0.9831\n",
            "The average f1 is: 0.9831\n",
            "  Training epcoh took: 0:00:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.9982\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9991\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4991\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4995\n",
            "  Testing took: 0:00:01\n",
            "Current increase 90 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 3 sampled in this category.\n",
            "After up-sample, there are 1918 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1645\n",
            "0.8576642335766423\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "273\n",
            "0.14233576642335766\n",
            "\n",
            "(1918, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0904 07:59:37.952741 139984129095488 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0904 07:59:37.953974 139984129095488 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0904 07:59:38.000062 139984129095488 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0904 07:59:40.675218 139984129095488 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0904 07:59:40.676022 139984129095488 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     60.    Elapsed: 0:00:21.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.30\n",
            "  Accuracy: 0.97\n",
            "Category: 0\n",
            "  Precision: 0.97\n",
            "  Recall: 0.99\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 0.91\n",
            "  Recall: 0.80\n",
            "  F1: 0.82\n",
            "The average precision is: 0.9402\n",
            "The average recall is: 0.8956\n",
            "The average f1 is: 0.9008\n",
            "  Training epcoh took: 0:00:32\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     60.    Elapsed: 0:00:22.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 1.0000\n",
            "The average recall is: 1.0000\n",
            "The average f1 is: 1.0000\n",
            "  Training epcoh took: 0:00:32\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     60.    Elapsed: 0:00:21.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.97\n",
            "  Recall: 0.97\n",
            "  F1: 0.97\n",
            "The average precision is: 0.9833\n",
            "The average recall is: 0.9833\n",
            "The average f1 is: 0.9833\n",
            "  Training epcoh took: 0:00:32\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     60.    Elapsed: 0:00:22.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 1.0000\n",
            "The average recall is: 1.0000\n",
            "The average f1 is: 1.0000\n",
            "  Training epcoh took: 0:00:32\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.9982\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9991\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4991\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4995\n",
            "  Testing took: 0:00:01\n",
            "Successfully save file ./BertSearchResult/rectified_0_32_3e-05_0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Dyn2ddG-jkfQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "d1085ac1-8fce-4aa1-ad12-b13ab71cb2bc"
      },
      "source": [
        "all_metrics_one['test']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: [[{0: 0.9980769230769231, 1: 0.0}],\n",
              "  [{0: 1.0, 1: 0.0}],\n",
              "  [{0: 0.998974358974359, 1: 0.0}],\n",
              "  [0.9980769230769231]]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f48pz_B6io7Y"
      },
      "source": [
        "### For 'InformationWanted'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OQuojg0sWbjt"
      },
      "source": [
        "#### Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w32SGs11Wbjv",
        "colab": {}
      },
      "source": [
        "# Use train_test_split to split our data into train and validation and test sets for\n",
        "# training\n",
        "section_category = 0\n",
        "labels = labels_single[section_category]\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 80% for training and 20% for validation.\n",
        "temp_inputs, test_inputs,  temp_labels, test_labels = train_test_split(input_ids, labels, random_state=1999, test_size=0.2)\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(temp_inputs, temp_labels,random_state=1999, test_size=0.2)\n",
        "\n",
        "# Do the same for the masks.\n",
        "temp_masks, test_masks, temp_labels, _ = train_test_split(attention_masks, labels,random_state=1999, test_size=0.2)\n",
        "\n",
        "train_masks, validation_masks, _, _ = train_test_split(temp_masks, temp_labels,random_state=1999, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jEUrbPFwJU1W"
      },
      "source": [
        "#### Normal training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "scrolled": true,
        "id": "Ck8eoWGDZip_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7156f0ab-6c8e-4ea4-9b68-849e5642e802"
      },
      "source": [
        "import json\n",
        "batch_size = 16\n",
        "lr = 2e-5\n",
        "test_batch = [test_inputs,test_labels,test_masks]\n",
        "Bert = Bertnn_info(train_inputs,train_labels,train_masks, validation_inputs,validation_labels,validation_masks,test_batch,batch_size=batch_size,lr=lr)\n",
        "all_metrics_one, all_tesst_metrics = Bert.searchUpsample(100)\n",
        "all_metrics_one['test'] = all_tesst_metrics\n",
        "all_metrics_all_category[section_category] = all_metrics_one\n",
        "if not os.path.exists('BertSearchResult'):\n",
        "  os.makedirs('BertSearchResult')\n",
        "\n",
        "filename = './BertSearchResult/'+str(section_category)+'_'+str(batch_size) + '_' + str(lr) + '_'  + str(section_category)\n",
        "with open(filename,'w') as file_obj:\n",
        "  json.dump(all_metrics_one,file_obj)\n",
        "  print('Successfully save file %s'%(filename))\n",
        "\n",
        "del Bert\n",
        "torch.cuda.empty_cache() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: TITAN RTX\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 01:37:20.923159 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 01:37:20.924405 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 01:37:21.036392 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 01:37:23.646085 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 01:37:23.647834 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current increase 0 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 7 sampled in this category.\n",
            "After up-sample, there are 1648 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1641\n",
            "0.995752427184466\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "7\n",
            "0.00424757281553398\n",
            "\n",
            "(1648, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 01:37:24.331399 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 01:37:24.333372 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 01:37:24.364717 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 01:37:26.965202 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 01:37:26.966169 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:15.\n",
            "\n",
            "  Average training loss: 0.06\n",
            "  Accuracy: 0.98\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.4930\n",
            "The average recall is: 0.4927\n",
            "The average f1 is: 0.4924\n",
            "  Training epcoh took: 0:00:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:15.\n",
            "\n",
            "  Average training loss: 0.03\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.4979\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4989\n",
            "  Training epcoh took: 0:00:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:15.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.4979\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4989\n",
            "  Training epcoh took: 0:00:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9922\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9960\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4961\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4980\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.4979\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4989\n",
            "  Training epcoh took: 0:00:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9905\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9947\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4953\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4973\n",
            "  Testing took: 0:00:01\n",
            "Current increase 10 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 7 sampled in this category.\n",
            "After up-sample, there are 1718 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1641\n",
            "0.9551804423748544\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "77\n",
            "0.044819557625145515\n",
            "\n",
            "(1718, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 01:38:53.495622 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 01:38:53.497077 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 01:38:53.920240 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 01:38:56.505828 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 01:38:56.506610 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    108.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    108.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 0.14\n",
            "  Accuracy: 0.94\n",
            "Category: 0\n",
            "  Precision: 0.95\n",
            "  Recall: 0.98\n",
            "  F1: 0.96\n",
            "Category: 1\n",
            "  Precision: 0.09\n",
            "  Recall: 0.08\n",
            "  F1: 0.08\n",
            "The average precision is: 0.5195\n",
            "The average recall is: 0.5312\n",
            "The average f1 is: 0.5214\n",
            "  Training epcoh took: 0:00:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    108.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    108.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.55\n",
            "  Recall: 0.55\n",
            "  F1: 0.55\n",
            "The average precision is: 0.7731\n",
            "The average recall is: 0.7731\n",
            "The average f1 is: 0.7731\n",
            "  Training epcoh took: 0:00:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    108.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    108.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.55\n",
            "  Recall: 0.55\n",
            "  F1: 0.55\n",
            "The average precision is: 0.7731\n",
            "The average recall is: 0.7731\n",
            "The average f1 is: 0.7731\n",
            "  Training epcoh took: 0:00:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    108.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    108.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.54\n",
            "  Recall: 0.54\n",
            "  F1: 0.54\n",
            "The average precision is: 0.7685\n",
            "The average recall is: 0.7685\n",
            "The average f1 is: 0.7685\n",
            "  Training epcoh took: 0:00:22\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9905\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9947\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4953\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4973\n",
            "  Testing took: 0:00:02\n",
            "Current increase 20 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 7 sampled in this category.\n",
            "After up-sample, there are 1788 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1641\n",
            "0.9177852348993288\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "147\n",
            "0.08221476510067115\n",
            "\n",
            "(1788, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 01:40:29.731939 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 01:40:29.733327 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 01:40:30.136471 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 01:40:32.790187 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 01:40:32.791114 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    112.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    112.    Elapsed: 0:00:17.\n",
            "\n",
            "  Average training loss: 0.14\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.95\n",
            "  Recall: 1.00\n",
            "  F1: 0.97\n",
            "Category: 1\n",
            "  Precision: 0.39\n",
            "  Recall: 0.34\n",
            "  F1: 0.36\n",
            "The average precision is: 0.6723\n",
            "The average recall is: 0.6689\n",
            "The average f1 is: 0.6651\n",
            "  Training epcoh took: 0:00:24\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9962\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    112.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    112.    Elapsed: 0:00:17.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.76\n",
            "  Recall: 0.76\n",
            "  F1: 0.76\n",
            "The average precision is: 0.8791\n",
            "The average recall is: 0.8783\n",
            "The average f1 is: 0.8786\n",
            "  Training epcoh took: 0:00:24\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    112.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    112.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.78\n",
            "  Recall: 0.78\n",
            "  F1: 0.78\n",
            "The average precision is: 0.8884\n",
            "The average recall is: 0.8884\n",
            "The average f1 is: 0.8884\n",
            "  Training epcoh took: 0:00:25\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    112.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    112.    Elapsed: 0:00:17.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.71\n",
            "  Recall: 0.71\n",
            "  F1: 0.71\n",
            "The average precision is: 0.8571\n",
            "The average recall is: 0.8571\n",
            "The average f1 is: 0.8571\n",
            "  Training epcoh took: 0:00:25\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9922\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9960\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4961\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4980\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.9962\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9980\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4981\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4990\n",
            "  Testing took: 0:00:02\n",
            "Current increase 30 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 7 sampled in this category.\n",
            "After up-sample, there are 1858 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1641\n",
            "0.8832077502691066\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "217\n",
            "0.11679224973089343\n",
            "\n",
            "(1858, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 01:42:17.582624 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 01:42:17.584014 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 01:42:17.635803 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 01:42:20.311327 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 01:42:20.313671 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    117.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    117.    Elapsed: 0:00:17.\n",
            "\n",
            "  Average training loss: 0.11\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.96\n",
            "  Recall: 0.99\n",
            "  F1: 0.97\n",
            "Category: 1\n",
            "  Precision: 0.65\n",
            "  Recall: 0.62\n",
            "  F1: 0.62\n",
            "The average precision is: 0.8024\n",
            "The average recall is: 0.8079\n",
            "The average f1 is: 0.7979\n",
            "  Training epcoh took: 0:00:26\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    117.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    117.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.91\n",
            "  Recall: 0.91\n",
            "  F1: 0.91\n",
            "The average precision is: 0.9530\n",
            "The average recall is: 0.9530\n",
            "The average f1 is: 0.9530\n",
            "  Training epcoh took: 0:00:26\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    117.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    117.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.85\n",
            "  Recall: 0.85\n",
            "  F1: 0.85\n",
            "The average precision is: 0.9231\n",
            "The average recall is: 0.9231\n",
            "The average f1 is: 0.9231\n",
            "  Training epcoh took: 0:00:27\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9962\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    117.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    117.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.87\n",
            "  Recall: 0.87\n",
            "  F1: 0.87\n",
            "The average precision is: 0.9359\n",
            "The average recall is: 0.9359\n",
            "The average f1 is: 0.9359\n",
            "  Training epcoh took: 0:00:26\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9922\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9960\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4961\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4980\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.9962\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9980\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4981\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4990\n",
            "  Testing took: 0:00:02\n",
            "Current increase 40 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 7 sampled in this category.\n",
            "After up-sample, there are 1928 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1641\n",
            "0.8511410788381742\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "287\n",
            "0.14885892116182572\n",
            "\n",
            "(1928, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 01:44:13.982671 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 01:44:13.984063 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 01:44:14.094962 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 01:44:16.768467 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 01:44:16.769789 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    121.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    121.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    121.    Elapsed: 0:00:28.\n",
            "\n",
            "  Average training loss: 0.14\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.95\n",
            "  Recall: 0.99\n",
            "  F1: 0.96\n",
            "Category: 1\n",
            "  Precision: 0.71\n",
            "  Recall: 0.64\n",
            "  F1: 0.66\n",
            "The average precision is: 0.8298\n",
            "The average recall is: 0.8121\n",
            "The average f1 is: 0.8093\n",
            "  Training epcoh took: 0:00:28\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    121.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    121.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    121.    Elapsed: 0:00:28.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.91\n",
            "  Recall: 0.91\n",
            "  F1: 0.91\n",
            "The average precision is: 0.9545\n",
            "The average recall is: 0.9545\n",
            "The average f1 is: 0.9545\n",
            "  Training epcoh took: 0:00:28\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    121.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    121.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    121.    Elapsed: 0:00:27.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.91\n",
            "  Recall: 0.91\n",
            "  F1: 0.91\n",
            "The average precision is: 0.9545\n",
            "The average recall is: 0.9545\n",
            "The average f1 is: 0.9545\n",
            "  Training epcoh took: 0:00:28\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    121.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    121.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    121.    Elapsed: 0:00:28.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.94\n",
            "  Recall: 0.94\n",
            "  F1: 0.94\n",
            "The average precision is: 0.9711\n",
            "The average recall is: 0.9711\n",
            "The average f1 is: 0.9711\n",
            "  Training epcoh took: 0:00:28\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.9962\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9980\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4981\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4990\n",
            "  Testing took: 0:00:02\n",
            "Current increase 50 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 7 sampled in this category.\n",
            "After up-sample, there are 1998 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1641\n",
            "0.8213213213213213\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "357\n",
            "0.17867867867867868\n",
            "\n",
            "(1998, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 01:46:16.476400 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 01:46:16.477797 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 01:46:16.534738 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 01:46:19.072107 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 01:46:19.072908 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    125.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    125.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    125.    Elapsed: 0:00:27.\n",
            "\n",
            "  Average training loss: 0.11\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.96\n",
            "  Recall: 1.00\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 0.81\n",
            "  Recall: 0.77\n",
            "  F1: 0.78\n",
            "The average precision is: 0.8867\n",
            "The average recall is: 0.8840\n",
            "The average f1 is: 0.8793\n",
            "  Training epcoh took: 0:00:28\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9922\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9960\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4961\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4980\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    125.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    125.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    125.    Elapsed: 0:00:28.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.97\n",
            "  Recall: 0.98\n",
            "  F1: 0.97\n",
            "The average precision is: 0.9870\n",
            "The average recall is: 0.9877\n",
            "The average f1 is: 0.9873\n",
            "  Training epcoh took: 0:00:29\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9922\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9960\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4961\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4980\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    125.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    125.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    125.    Elapsed: 0:00:28.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.98\n",
            "  Recall: 0.98\n",
            "  F1: 0.98\n",
            "The average precision is: 0.9880\n",
            "The average recall is: 0.9880\n",
            "The average f1 is: 0.9880\n",
            "  Training epcoh took: 0:00:29\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    125.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    125.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    125.    Elapsed: 0:00:29.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.94\n",
            "  Recall: 0.94\n",
            "  F1: 0.94\n",
            "The average precision is: 0.9680\n",
            "The average recall is: 0.9680\n",
            "The average f1 is: 0.9680\n",
            "  Training epcoh took: 0:00:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9962\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.9962\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9980\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4981\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4990\n",
            "  Testing took: 0:00:02\n",
            "Current increase 60 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 7 sampled in this category.\n",
            "After up-sample, there are 2068 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1641\n",
            "0.7935203094777563\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "427\n",
            "0.20647969052224371\n",
            "\n",
            "(2068, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 01:48:24.017533 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 01:48:24.019021 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 01:48:24.432451 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 01:48:26.964277 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 01:48:26.964997 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    130.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    130.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    130.    Elapsed: 0:00:27.\n",
            "\n",
            "  Average training loss: 0.12\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.96\n",
            "  Recall: 0.99\n",
            "  F1: 0.97\n",
            "Category: 1\n",
            "  Precision: 0.81\n",
            "  Recall: 0.80\n",
            "  F1: 0.80\n",
            "The average precision is: 0.8859\n",
            "The average recall is: 0.8948\n",
            "The average f1 is: 0.8863\n",
            "  Training epcoh took: 0:00:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9922\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9960\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4961\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4980\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    130.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    130.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    130.    Elapsed: 0:00:27.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.95\n",
            "  Recall: 0.95\n",
            "  F1: 0.95\n",
            "The average precision is: 0.9769\n",
            "The average recall is: 0.9769\n",
            "The average f1 is: 0.9769\n",
            "  Training epcoh took: 0:00:29\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 0.9976\n",
            "  F1: 0.9950\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.4988\n",
            "The average f1 is: 0.4975\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    130.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    130.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    130.    Elapsed: 0:00:28.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.97\n",
            "  Recall: 0.97\n",
            "  F1: 0.97\n",
            "The average precision is: 0.9846\n",
            "The average recall is: 0.9846\n",
            "The average f1 is: 0.9846\n",
            "  Training epcoh took: 0:00:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9922\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9960\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4961\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4980\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    130.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    130.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    130.    Elapsed: 0:00:28.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.98\n",
            "  Recall: 0.98\n",
            "  F1: 0.98\n",
            "The average precision is: 0.9923\n",
            "The average recall is: 0.9923\n",
            "The average f1 is: 0.9923\n",
            "  Training epcoh took: 0:00:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.9962\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9980\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4981\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4990\n",
            "  Testing took: 0:00:02\n",
            "Current increase 70 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 7 sampled in this category.\n",
            "After up-sample, there are 2138 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1641\n",
            "0.7675397567820393\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "497\n",
            "0.23246024321796072\n",
            "\n",
            "(2138, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 01:50:33.858427 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 01:50:33.859900 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 01:50:34.328859 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 01:50:36.894568 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 01:50:36.895960 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    134.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    134.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    134.    Elapsed: 0:00:27.\n",
            "\n",
            "  Average training loss: 0.09\n",
            "  Accuracy: 0.97\n",
            "Category: 0\n",
            "  Precision: 0.97\n",
            "  Recall: 0.99\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 0.92\n",
            "  Recall: 0.89\n",
            "  F1: 0.90\n",
            "The average precision is: 0.9457\n",
            "The average recall is: 0.9398\n",
            "The average f1 is: 0.9371\n",
            "  Training epcoh took: 0:00:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9922\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9960\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4961\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4980\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    134.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    134.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    134.    Elapsed: 0:00:27.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 1.0000\n",
            "The average recall is: 1.0000\n",
            "The average f1 is: 1.0000\n",
            "  Training epcoh took: 0:00:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    134.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    134.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    134.    Elapsed: 0:00:27.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.97\n",
            "  Recall: 0.97\n",
            "  F1: 0.97\n",
            "The average precision is: 0.9851\n",
            "The average recall is: 0.9851\n",
            "The average f1 is: 0.9851\n",
            "  Training epcoh took: 0:00:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9962\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    134.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    134.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    134.    Elapsed: 0:00:27.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "The average precision is: 0.9963\n",
            "The average recall is: 0.9963\n",
            "The average f1 is: 0.9963\n",
            "  Training epcoh took: 0:00:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.9962\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9980\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4981\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4990\n",
            "  Testing took: 0:00:02\n",
            "Current increase 80 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 7 sampled in this category.\n",
            "After up-sample, there are 2208 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1641\n",
            "0.7432065217391305\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "567\n",
            "0.25679347826086957\n",
            "\n",
            "(2208, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 01:52:46.136069 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 01:52:46.137539 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 01:52:46.232057 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 01:52:48.835115 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 01:52:48.836008 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    138.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    138.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    138.    Elapsed: 0:00:27.\n",
            "\n",
            "  Average training loss: 0.09\n",
            "  Accuracy: 0.97\n",
            "Category: 0\n",
            "  Precision: 0.97\n",
            "  Recall: 1.00\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 0.94\n",
            "  Recall: 0.91\n",
            "  F1: 0.92\n",
            "The average precision is: 0.9566\n",
            "The average recall is: 0.9537\n",
            "The average f1 is: 0.9516\n",
            "  Training epcoh took: 0:00:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    138.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    138.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    138.    Elapsed: 0:00:27.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.98\n",
            "  Recall: 0.98\n",
            "  F1: 0.98\n",
            "The average precision is: 0.9891\n",
            "The average recall is: 0.9891\n",
            "The average f1 is: 0.9891\n",
            "  Training epcoh took: 0:00:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    138.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    138.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    138.    Elapsed: 0:00:27.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "The average precision is: 0.9964\n",
            "The average recall is: 0.9964\n",
            "The average f1 is: 0.9964\n",
            "  Training epcoh took: 0:00:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    138.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    138.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    138.    Elapsed: 0:00:28.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.98\n",
            "  Recall: 0.98\n",
            "  F1: 0.98\n",
            "The average precision is: 0.9891\n",
            "The average recall is: 0.9891\n",
            "The average f1 is: 0.9891\n",
            "  Training epcoh took: 0:00:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9922\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9960\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4961\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4980\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.9962\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9980\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4981\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4990\n",
            "  Testing took: 0:00:02\n",
            "Current increase 90 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 7 sampled in this category.\n",
            "After up-sample, there are 2278 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1641\n",
            "0.7203687445127305\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "637\n",
            "0.2796312554872695\n",
            "\n",
            "(2278, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 01:55:01.120578 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 01:55:01.122064 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 01:55:01.178817 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 01:55:03.769651 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 01:55:03.770630 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    143.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    143.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    143.    Elapsed: 0:00:27.\n",
            "\n",
            "  Average training loss: 0.10\n",
            "  Accuracy: 0.97\n",
            "Category: 0\n",
            "  Precision: 0.96\n",
            "  Recall: 0.99\n",
            "  F1: 0.97\n",
            "Category: 1\n",
            "  Precision: 0.94\n",
            "  Recall: 0.91\n",
            "  F1: 0.91\n",
            "The average precision is: 0.9542\n",
            "The average recall is: 0.9463\n",
            "The average f1 is: 0.9428\n",
            "  Training epcoh took: 0:00:33\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    143.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    143.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    143.    Elapsed: 0:00:27.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "The average precision is: 0.9965\n",
            "The average recall is: 0.9965\n",
            "The average f1 is: 0.9965\n",
            "  Training epcoh took: 0:00:32\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    143.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    143.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    143.    Elapsed: 0:00:27.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 1.0000\n",
            "The average recall is: 1.0000\n",
            "The average f1 is: 1.0000\n",
            "  Training epcoh took: 0:00:32\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    143.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    143.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    143.    Elapsed: 0:00:27.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "The average precision is: 0.9965\n",
            "The average recall is: 0.9965\n",
            "The average f1 is: 0.9965\n",
            "  Training epcoh took: 0:00:32\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.9962\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9980\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4981\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4990\n",
            "  Testing took: 0:00:02\n",
            "Successfully save file ./BertSearchResult/1_16_2e-05_1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w_ddsuV_Wbj2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "outputId": "203b4107-6a44-4a39-d1ce-f5ea357bf42a"
      },
      "source": [
        "all_metrics_one"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: defaultdict(None,\n",
              "             {'train_loss_values': [0.02451061978212838,\n",
              "               0.02451061978212838,\n",
              "               0.014020035567792874,\n",
              "               0.014020035567792874,\n",
              "               0.014816705897016433,\n",
              "               0.014816705897016433,\n",
              "               0.012088468786582205,\n",
              "               0.012088468786582205],\n",
              "              'train_acc_all': [0.9981796116504854,\n",
              "               0.9981796116504854,\n",
              "               0.9981796116504854,\n",
              "               0.9981796116504854],\n",
              "              'train_precision_all': [{0: 0.9981796116504854, 1: 0.0},\n",
              "               {0: 0.9981796116504854, 1: 0.0},\n",
              "               {0: 0.9981796116504854, 1: 0.0},\n",
              "               {0: 0.9981796116504854, 1: 0.0}],\n",
              "              'train_recall_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}],\n",
              "              'train_f1_all': [{0: 0.9990291262135923, 1: 0.0},\n",
              "               {0: 0.9990291262135923, 1: 0.0},\n",
              "               {0: 0.9990291262135923, 1: 0.0},\n",
              "               {0: 0.9990291262135923, 1: 0.0}],\n",
              "              'val_acc_all': [1.0, 1.0, 1.0, 1.0],\n",
              "              'val_precision_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}],\n",
              "              'val_recall_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}],\n",
              "              'val_f1_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}]})}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MfDSm7suJNu_"
      },
      "source": [
        "#### Incremental recitfied training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "5_dsfQffZiqB",
        "colab_type": "code",
        "colab": {},
        "outputId": "60d3c97b-7d53-4e97-e43e-a78001da7d48"
      },
      "source": [
        "import json\n",
        "batch_size = 32\n",
        "lr = 3e-5\n",
        "test_batch = [test_inputs,test_labels,test_masks]\n",
        "Bert = Bertnn_rectified_info(train_inputs,train_labels,train_masks, validation_inputs,validation_labels,validation_masks,test_batch,batch_size=batch_size,lr=lr)\n",
        "all_metrics_one, all_tesst_metrics = Bert.searchUpsample(100)\n",
        "all_metrics_one['test'] = all_tesst_metrics\n",
        "all_metrics_all_category[section_category] = all_metrics_one\n",
        "if not os.path.exists('BertSearchResult'):\n",
        "  os.makedirs('BertSearchResult')\n",
        "\n",
        "filename = './BertSearchResult/'+'rectified'+'_'+str(section_category)+'_'+str(batch_size) + '_' + str(lr) + '_'  + str(section_category)\n",
        "with open(filename,'w') as file_obj:\n",
        "  json.dump(all_metrics_one,file_obj)\n",
        "  print('Successfully save file %s'%(filename))\n",
        "\n",
        "del Bert\n",
        "torch.cuda.empty_cache() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: TITAN RTX\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0904 13:53:40.984838 139984129095488 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0904 13:53:40.985996 139984129095488 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0904 13:53:41.077767 139984129095488 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0904 13:53:43.721373 139984129095488 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0904 13:53:43.722556 139984129095488 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current increase 0 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 7 sampled in this category.\n",
            "After up-sample, there are 1648 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1641\n",
            "0.995752427184466\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "7\n",
            "0.00424757281553398\n",
            "\n",
            "(1648, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0904 13:53:44.402355 139984129095488 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0904 13:53:44.403277 139984129095488 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0904 13:53:44.436729 139984129095488 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0904 13:53:47.096873 139984129095488 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0904 13:53:47.098870 139984129095488 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     52.    Elapsed: 0:00:14.\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.61\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.4979\n",
            "The average recall is: 0.4964\n",
            "The average f1 is: 0.4967\n",
            "  Training epcoh took: 0:00:18\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4982\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     52.    Elapsed: 0:00:14.\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.63\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.4979\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4989\n",
            "  Training epcoh took: 0:00:18\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     54.    Elapsed: 0:00:20.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.80\n",
            "  Recall: 0.80\n",
            "  F1: 0.80\n",
            "The average precision is: 0.8981\n",
            "The average recall is: 0.8981\n",
            "The average f1 is: 0.8981\n",
            "  Training epcoh took: 0:00:26\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4982\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     54.    Elapsed: 0:00:19.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.76\n",
            "  Recall: 0.76\n",
            "  F1: 0.76\n",
            "The average precision is: 0.8796\n",
            "The average recall is: 0.8796\n",
            "The average f1 is: 0.8796\n",
            "  Training epcoh took: 0:00:26\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.9963\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9981\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4982\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4991\n",
            "  Testing took: 0:00:01\n",
            "Current increase 20 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 7 sampled in this category.\n",
            "After up-sample, there are 1788 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1641\n",
            "0.9177852348993288\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "147\n",
            "0.08221476510067115\n",
            "\n",
            "(1788, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0904 13:57:00.805952 139984129095488 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0904 13:57:00.807021 139984129095488 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0904 13:57:00.850739 139984129095488 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0904 13:57:03.465704 139984129095488 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0904 13:57:03.467409 139984129095488 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     56.    Elapsed: 0:00:21.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.49\n",
            "  Accuracy: 0.97\n",
            "Category: 0\n",
            "  Precision: 0.97\n",
            "  Recall: 1.00\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 0.73\n",
            "  Recall: 0.71\n",
            "  F1: 0.71\n",
            "The average precision is: 0.8533\n",
            "The average recall is: 0.8531\n",
            "The average f1 is: 0.8497\n",
            "  Training epcoh took: 0:00:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4982\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     56.    Elapsed: 0:00:22.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.96\n",
            "  Recall: 0.96\n",
            "  F1: 0.96\n",
            "The average precision is: 0.9821\n",
            "The average recall is: 0.9821\n",
            "The average f1 is: 0.9821\n",
            "  Training epcoh took: 0:00:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4982\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     56.    Elapsed: 0:00:21.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.93\n",
            "  Recall: 0.93\n",
            "  F1: 0.93\n",
            "The average precision is: 0.9643\n",
            "The average recall is: 0.9643\n",
            "The average f1 is: 0.9643\n",
            "  Training epcoh took: 0:00:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4982\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     56.    Elapsed: 0:00:23.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.96\n",
            "  Recall: 0.96\n",
            "  F1: 0.96\n",
            "The average precision is: 0.9821\n",
            "The average recall is: 0.9821\n",
            "The average f1 is: 0.9821\n",
            "  Training epcoh took: 0:00:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9925\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9962\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4963\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.9963\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9981\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4982\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4991\n",
            "  Testing took: 0:00:02\n",
            "Current increase 30 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 7 sampled in this category.\n",
            "After up-sample, there are 1858 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1641\n",
            "0.8832077502691066\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "217\n",
            "0.11679224973089343\n",
            "\n",
            "(1858, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0904 13:59:12.552029 139984129095488 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0904 13:59:12.553211 139984129095488 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0904 13:59:12.650757 139984129095488 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0904 13:59:15.270008 139984129095488 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0904 13:59:15.270907 139984129095488 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     59.    Elapsed: 0:00:22.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.53\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.97\n",
            "  Recall: 0.98\n",
            "  F1: 0.96\n",
            "Category: 1\n",
            "  Precision: 0.75\n",
            "  Recall: 0.68\n",
            "  F1: 0.68\n",
            "The average precision is: 0.8560\n",
            "The average recall is: 0.8298\n",
            "The average f1 is: 0.8233\n",
            "  Training epcoh took: 0:00:32\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4982\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     59.    Elapsed: 0:00:22.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.98\n",
            "  Recall: 0.98\n",
            "  F1: 0.98\n",
            "The average precision is: 0.9915\n",
            "The average recall is: 0.9915\n",
            "The average f1 is: 0.9915\n",
            "  Training epcoh took: 0:00:33\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     59.    Elapsed: 0:00:22.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.97\n",
            "  Recall: 0.97\n",
            "  F1: 0.97\n",
            "The average precision is: 0.9831\n",
            "The average recall is: 0.9831\n",
            "The average f1 is: 0.9831\n",
            "  Training epcoh took: 0:00:33\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4982\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     59.    Elapsed: 0:00:23.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.93\n",
            "  Recall: 0.93\n",
            "  F1: 0.93\n",
            "The average precision is: 0.9661\n",
            "The average recall is: 0.9661\n",
            "The average f1 is: 0.9661\n",
            "  Training epcoh took: 0:00:33\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4982\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.9963\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9981\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4982\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4991\n",
            "  Testing took: 0:00:02\n",
            "Current increase 40 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 7 sampled in this category.\n",
            "After up-sample, there are 1928 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1641\n",
            "0.8511410788381742\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "287\n",
            "0.14885892116182572\n",
            "\n",
            "(1928, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0904 14:01:34.024106 139984129095488 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0904 14:01:34.025238 139984129095488 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0904 14:01:34.075600 139984129095488 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0904 14:01:36.757913 139984129095488 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0904 14:01:36.759401 139984129095488 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     61.    Elapsed: 0:00:23.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.28\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.96\n",
            "  Recall: 0.96\n",
            "  F1: 0.96\n",
            "Category: 1\n",
            "  Precision: 0.87\n",
            "  Recall: 0.87\n",
            "  F1: 0.85\n",
            "The average precision is: 0.9117\n",
            "The average recall is: 0.9171\n",
            "The average f1 is: 0.9044\n",
            "  Training epcoh took: 0:00:35\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9925\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9962\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4963\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     61.    Elapsed: 0:00:23.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.98\n",
            "  Recall: 0.98\n",
            "  F1: 0.98\n",
            "The average precision is: 0.9918\n",
            "The average recall is: 0.9918\n",
            "The average f1 is: 0.9918\n",
            "  Training epcoh took: 0:00:35\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9925\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9962\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4963\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     61.    Elapsed: 0:00:22.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.97\n",
            "  Recall: 0.97\n",
            "  F1: 0.97\n",
            "The average precision is: 0.9836\n",
            "The average recall is: 0.9836\n",
            "The average f1 is: 0.9836\n",
            "  Training epcoh took: 0:00:33\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9925\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9962\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4963\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     61.    Elapsed: 0:00:22.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.98\n",
            "  Recall: 0.98\n",
            "  F1: 0.98\n",
            "The average precision is: 0.9918\n",
            "The average recall is: 0.9918\n",
            "The average f1 is: 0.9918\n",
            "  Training epcoh took: 0:00:33\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4982\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.9963\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9981\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4982\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4991\n",
            "  Testing took: 0:00:02\n",
            "Current increase 50 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 7 sampled in this category.\n",
            "After up-sample, there are 1998 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1641\n",
            "0.8213213213213213\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "357\n",
            "0.17867867867867868\n",
            "\n",
            "(1998, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0904 14:03:59.433241 139984129095488 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0904 14:03:59.434335 139984129095488 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0904 14:03:59.490442 139984129095488 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0904 14:04:02.145837 139984129095488 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0904 14:04:02.146637 139984129095488 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     63.    Elapsed: 0:00:22.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.29\n",
            "  Accuracy: 0.97\n",
            "Category: 0\n",
            "  Precision: 0.97\n",
            "  Recall: 1.00\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 0.85\n",
            "  Recall: 0.83\n",
            "  F1: 0.84\n",
            "The average precision is: 0.9114\n",
            "The average recall is: 0.9149\n",
            "The average f1 is: 0.9094\n",
            "  Training epcoh took: 0:00:34\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4982\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     63.    Elapsed: 0:00:21.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.97\n",
            "  Recall: 0.97\n",
            "  F1: 0.97\n",
            "The average precision is: 0.9841\n",
            "The average recall is: 0.9841\n",
            "The average f1 is: 0.9841\n",
            "  Training epcoh took: 0:00:33\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9925\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9962\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4963\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "  Batch    40  of     63.    Elapsed: 0:00:22.\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 1.0000\n",
            "The average recall is: 1.0000\n",
            "The average f1 is: 1.0000\n",
            "  Training epcoh took: 0:00:34\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9928\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9963\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4964\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4981\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n",
            "Invoke 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MKDy60_hZiqC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "outputId": "203b4107-6a44-4a39-d1ce-f5ea357bf42a"
      },
      "source": [
        "all_metrics_one"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: defaultdict(None,\n",
              "             {'train_loss_values': [0.02451061978212838,\n",
              "               0.02451061978212838,\n",
              "               0.014020035567792874,\n",
              "               0.014020035567792874,\n",
              "               0.014816705897016433,\n",
              "               0.014816705897016433,\n",
              "               0.012088468786582205,\n",
              "               0.012088468786582205],\n",
              "              'train_acc_all': [0.9981796116504854,\n",
              "               0.9981796116504854,\n",
              "               0.9981796116504854,\n",
              "               0.9981796116504854],\n",
              "              'train_precision_all': [{0: 0.9981796116504854, 1: 0.0},\n",
              "               {0: 0.9981796116504854, 1: 0.0},\n",
              "               {0: 0.9981796116504854, 1: 0.0},\n",
              "               {0: 0.9981796116504854, 1: 0.0}],\n",
              "              'train_recall_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}],\n",
              "              'train_f1_all': [{0: 0.9990291262135923, 1: 0.0},\n",
              "               {0: 0.9990291262135923, 1: 0.0},\n",
              "               {0: 0.9990291262135923, 1: 0.0},\n",
              "               {0: 0.9990291262135923, 1: 0.0}],\n",
              "              'val_acc_all': [1.0, 1.0, 1.0, 1.0],\n",
              "              'val_precision_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}],\n",
              "              'val_recall_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}],\n",
              "              'val_f1_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}]})}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BJiFSGLhiqKz"
      },
      "source": [
        "### For 'Volunteer'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_Rh3iwCqWcSk"
      },
      "source": [
        "#### Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3CStc_GRWcSl",
        "colab": {}
      },
      "source": [
        "# Use train_test_split to split our data into train and validation and test sets for\n",
        "# training\n",
        "section_category = 0\n",
        "labels = labels_single[section_category]\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 80% for training and 20% for validation.\n",
        "temp_inputs, test_inputs,  temp_labels, test_labels = train_test_split(input_ids, labels, random_state=1999, test_size=0.2)\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(temp_inputs, temp_labels,random_state=1999, test_size=0.2)\n",
        "\n",
        "# Do the same for the masks.\n",
        "temp_masks, test_masks, temp_labels, _ = train_test_split(attention_masks, labels,random_state=1999, test_size=0.2)\n",
        "\n",
        "train_masks, validation_masks, _, _ = train_test_split(temp_masks, temp_labels,random_state=1999, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FqB4vLBYJVim"
      },
      "source": [
        "#### Normal training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "N0VVU00JZiqJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7156f0ab-6c8e-4ea4-9b68-849e5642e802"
      },
      "source": [
        "import json\n",
        "batch_size = 16\n",
        "lr = 2e-5\n",
        "test_batch = [test_inputs,test_labels,test_masks]\n",
        "Bert = Bertnn_info(train_inputs,train_labels,train_masks, validation_inputs,validation_labels,validation_masks,test_batch,batch_size=batch_size,lr=lr)\n",
        "all_metrics_one, all_tesst_metrics = Bert.searchUpsample(100)\n",
        "all_metrics_one['test'] = all_tesst_metrics\n",
        "all_metrics_all_category[section_category] = all_metrics_one\n",
        "if not os.path.exists('BertSearchResult'):\n",
        "  os.makedirs('BertSearchResult')\n",
        "\n",
        "filename = './BertSearchResult/'+str(section_category)+'_'+str(batch_size) + '_' + str(lr) + '_'  + str(section_category)\n",
        "with open(filename,'w') as file_obj:\n",
        "  json.dump(all_metrics_one,file_obj)\n",
        "  print('Successfully save file %s'%(filename))\n",
        "\n",
        "del Bert\n",
        "torch.cuda.empty_cache() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: TITAN RTX\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 05:49:34.023838 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 05:49:34.024934 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 05:49:35.389530 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 05:49:38.046023 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 05:49:38.046883 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current increase 0 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 13 sampled in this category.\n",
            "After up-sample, there are 1648 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1635\n",
            "0.9921116504854369\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "13\n",
            "0.007888349514563107\n",
            "\n",
            "(1648, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 05:49:38.730350 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 05:49:38.731376 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 05:49:39.215317 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 05:49:41.776158 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 05:49:41.777534 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:07.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:15.\n",
            "\n",
            "  Average training loss: 0.09\n",
            "  Accuracy: 0.98\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.4947\n",
            "The average recall is: 0.4946\n",
            "The average f1 is: 0.4937\n",
            "  Training epcoh took: 0:00:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9904\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9950\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4952\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4975\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:15.\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.4961\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4980\n",
            "  Training epcoh took: 0:00:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9904\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9950\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4952\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4975\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:15.\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.4961\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4980\n",
            "  Training epcoh took: 0:00:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9904\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9950\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4952\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4975\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:15.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.01\n",
            "  Recall: 0.01\n",
            "  F1: 0.01\n",
            "The average precision is: 0.5015\n",
            "The average recall is: 0.5049\n",
            "The average f1 is: 0.5031\n",
            "  Training epcoh took: 0:00:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9904\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9950\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4952\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4975\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9943\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9971\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4972\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4985\n",
            "  Testing took: 0:00:01\n",
            "Current increase 10 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 13 sampled in this category.\n",
            "After up-sample, there are 1778 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1635\n",
            "0.9195725534308211\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "143\n",
            "0.08042744656917886\n",
            "\n",
            "(1778, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 05:51:06.468665 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 05:51:06.469830 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 05:51:06.570824 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 05:51:09.092842 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 05:51:09.093712 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    112.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    112.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 0.16\n",
            "  Accuracy: 0.94\n",
            "Category: 0\n",
            "  Precision: 0.94\n",
            "  Recall: 0.98\n",
            "  F1: 0.95\n",
            "Category: 1\n",
            "  Precision: 0.40\n",
            "  Recall: 0.36\n",
            "  F1: 0.36\n",
            "The average precision is: 0.6671\n",
            "The average recall is: 0.6670\n",
            "The average f1 is: 0.6580\n",
            "  Training epcoh took: 0:00:22\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9904\n",
            "  Recall: 0.9976\n",
            "  F1: 0.9938\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4952\n",
            "The average recall is: 0.4988\n",
            "The average f1 is: 0.4969\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    112.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    112.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.74\n",
            "  Recall: 0.73\n",
            "  F1: 0.74\n",
            "The average precision is: 0.8696\n",
            "The average recall is: 0.8668\n",
            "The average f1 is: 0.8677\n",
            "  Training epcoh took: 0:00:22\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9904\n",
            "  Recall: 0.9952\n",
            "  F1: 0.9925\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4952\n",
            "The average recall is: 0.4976\n",
            "The average f1 is: 0.4962\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    112.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    112.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.72\n",
            "  Recall: 0.72\n",
            "  F1: 0.72\n",
            "The average precision is: 0.8616\n",
            "The average recall is: 0.8616\n",
            "The average f1 is: 0.8616\n",
            "  Training epcoh took: 0:00:22\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9904\n",
            "  Recall: 0.9952\n",
            "  F1: 0.9926\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4952\n",
            "The average recall is: 0.4976\n",
            "The average f1 is: 0.4963\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    112.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    112.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.74\n",
            "  Recall: 0.74\n",
            "  F1: 0.74\n",
            "The average precision is: 0.8705\n",
            "The average recall is: 0.8705\n",
            "The average f1 is: 0.8705\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9904\n",
            "  Recall: 0.9952\n",
            "  F1: 0.9926\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4952\n",
            "The average recall is: 0.4976\n",
            "The average f1 is: 0.4963\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9943\n",
            "  Recall: 0.9981\n",
            "  F1: 0.9961\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4972\n",
            "The average recall is: 0.4991\n",
            "The average f1 is: 0.4980\n",
            "  Testing took: 0:00:02\n",
            "Current increase 20 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 13 sampled in this category.\n",
            "After up-sample, there are 1908 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1635\n",
            "0.8569182389937107\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "273\n",
            "0.1430817610062893\n",
            "\n",
            "(1908, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 05:52:44.838659 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 05:52:44.839651 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 05:52:44.888096 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 05:52:47.389297 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 05:52:47.390031 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    120.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    120.    Elapsed: 0:00:17.\n",
            "\n",
            "  Average training loss: 0.13\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.95\n",
            "  Recall: 0.99\n",
            "  F1: 0.97\n",
            "Category: 1\n",
            "  Precision: 0.71\n",
            "  Recall: 0.66\n",
            "  F1: 0.68\n",
            "The average precision is: 0.8344\n",
            "The average recall is: 0.8284\n",
            "The average f1 is: 0.8233\n",
            "  Training epcoh took: 0:00:25\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9904\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9950\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4952\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4975\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    120.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    120.    Elapsed: 0:00:17.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.92\n",
            "  Recall: 0.92\n",
            "  F1: 0.92\n",
            "The average precision is: 0.9583\n",
            "The average recall is: 0.9583\n",
            "The average f1 is: 0.9583\n",
            "  Training epcoh took: 0:00:25\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9904\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9950\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4952\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4975\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    120.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    120.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.93\n",
            "  Recall: 0.93\n",
            "  F1: 0.93\n",
            "The average precision is: 0.9625\n",
            "The average recall is: 0.9625\n",
            "The average f1 is: 0.9625\n",
            "  Training epcoh took: 0:00:26\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9904\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9950\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4952\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4975\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    120.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    120.    Elapsed: 0:00:17.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.89\n",
            "  Recall: 0.89\n",
            "  F1: 0.89\n",
            "The average precision is: 0.9458\n",
            "The average recall is: 0.9458\n",
            "The average f1 is: 0.9458\n",
            "  Training epcoh took: 0:00:26\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9902\n",
            "  Recall: 0.9974\n",
            "  F1: 0.9937\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4951\n",
            "The average recall is: 0.4987\n",
            "The average f1 is: 0.4969\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9943\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9971\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4972\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4985\n",
            "  Testing took: 0:00:02\n",
            "Current increase 30 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 13 sampled in this category.\n",
            "After up-sample, there are 2038 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1635\n",
            "0.8022571148184494\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "403\n",
            "0.19774288518155053\n",
            "\n",
            "(2038, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 05:54:38.413788 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 05:54:38.415004 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 05:54:38.464779 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 05:54:40.968967 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 05:54:40.969734 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    128.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    128.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    128.    Elapsed: 0:00:26.\n",
            "\n",
            "  Average training loss: 0.13\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.96\n",
            "  Recall: 0.99\n",
            "  F1: 0.97\n",
            "Category: 1\n",
            "  Precision: 0.79\n",
            "  Recall: 0.77\n",
            "  F1: 0.77\n",
            "The average precision is: 0.8771\n",
            "The average recall is: 0.8804\n",
            "The average f1 is: 0.8706\n",
            "  Training epcoh took: 0:00:28\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9904\n",
            "  Recall: 0.9976\n",
            "  F1: 0.9938\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4952\n",
            "The average recall is: 0.4988\n",
            "The average f1 is: 0.4969\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    128.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    128.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    128.    Elapsed: 0:00:27.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.95\n",
            "  Recall: 0.95\n",
            "  F1: 0.95\n",
            "The average precision is: 0.9766\n",
            "The average recall is: 0.9766\n",
            "The average f1 is: 0.9766\n",
            "  Training epcoh took: 0:00:29\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9904\n",
            "  Recall: 0.9976\n",
            "  F1: 0.9937\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4952\n",
            "The average recall is: 0.4988\n",
            "The average f1 is: 0.4969\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    128.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    128.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    128.    Elapsed: 0:00:27.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.98\n",
            "  Recall: 0.98\n",
            "  F1: 0.98\n",
            "The average precision is: 0.9922\n",
            "The average recall is: 0.9922\n",
            "The average f1 is: 0.9922\n",
            "  Training epcoh took: 0:00:29\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9904\n",
            "  Recall: 0.9976\n",
            "  F1: 0.9938\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4952\n",
            "The average recall is: 0.4988\n",
            "The average f1 is: 0.4969\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    128.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    128.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    128.    Elapsed: 0:00:27.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.98\n",
            "  Recall: 0.98\n",
            "  F1: 0.98\n",
            "The average precision is: 0.9922\n",
            "The average recall is: 0.9922\n",
            "The average f1 is: 0.9922\n",
            "  Training epcoh took: 0:00:29\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9904\n",
            "  Recall: 0.9976\n",
            "  F1: 0.9938\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4952\n",
            "The average recall is: 0.4988\n",
            "The average f1 is: 0.4969\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9943\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9971\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4972\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4985\n",
            "  Testing took: 0:00:02\n",
            "Current increase 40 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 13 sampled in this category.\n",
            "After up-sample, there are 2168 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1635\n",
            "0.7541512915129152\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "533\n",
            "0.24584870848708487\n",
            "\n",
            "(2168, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 05:56:42.884102 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 05:56:42.885180 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 05:56:42.976402 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 05:56:45.473794 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 05:56:45.474646 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    136.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    136.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    136.    Elapsed: 0:00:27.\n",
            "\n",
            "  Average training loss: 0.11\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.96\n",
            "  Recall: 0.99\n",
            "  F1: 0.97\n",
            "Category: 1\n",
            "  Precision: 0.86\n",
            "  Recall: 0.84\n",
            "  F1: 0.84\n",
            "The average precision is: 0.9104\n",
            "The average recall is: 0.9118\n",
            "The average f1 is: 0.9045\n",
            "  Training epcoh took: 0:00:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9904\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9950\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4952\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4975\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    136.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    136.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    136.    Elapsed: 0:00:27.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "The average precision is: 0.9963\n",
            "The average recall is: 0.9963\n",
            "The average f1 is: 0.9963\n",
            "  Training epcoh took: 0:00:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9904\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9950\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4952\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4975\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    136.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    136.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    136.    Elapsed: 0:00:27.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "The average precision is: 0.9926\n",
            "The average recall is: 0.9926\n",
            "The average f1 is: 0.9926\n",
            "  Training epcoh took: 0:00:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "Category: 0\n",
            "  Precision: 0.9902\n",
            "  Recall: 0.9926\n",
            "  F1: 0.9912\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4951\n",
            "The average recall is: 0.4963\n",
            "The average f1 is: 0.4956\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    136.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    136.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    136.    Elapsed: 0:00:28.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 1.0000\n",
            "The average recall is: 1.0000\n",
            "The average f1 is: 1.0000\n",
            "  Training epcoh took: 0:00:32\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9904\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9950\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4952\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4975\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9943\n",
            "  Recall: 0.9981\n",
            "  F1: 0.9961\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4972\n",
            "The average recall is: 0.4991\n",
            "The average f1 is: 0.4980\n",
            "  Testing took: 0:00:02\n",
            "Current increase 50 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 13 sampled in this category.\n",
            "After up-sample, there are 2298 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1635\n",
            "0.7114882506527415\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "663\n",
            "0.2885117493472585\n",
            "\n",
            "(2298, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 05:58:57.572921 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 05:58:57.574002 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 05:58:58.053131 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 05:59:00.572151 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 05:59:00.572904 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    144.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    144.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    144.    Elapsed: 0:00:28.\n",
            "\n",
            "  Average training loss: 0.12\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.96\n",
            "  Recall: 0.99\n",
            "  F1: 0.97\n",
            "Category: 1\n",
            "  Precision: 0.93\n",
            "  Recall: 0.89\n",
            "  F1: 0.90\n",
            "The average precision is: 0.9458\n",
            "The average recall is: 0.9383\n",
            "The average f1 is: 0.9349\n",
            "  Training epcoh took: 0:00:34\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9904\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9950\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4952\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4975\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    144.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    144.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    144.    Elapsed: 0:00:28.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "The average precision is: 0.9965\n",
            "The average recall is: 0.9965\n",
            "The average f1 is: 0.9965\n",
            "  Training epcoh took: 0:00:33\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9904\n",
            "  Recall: 0.9976\n",
            "  F1: 0.9938\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4952\n",
            "The average recall is: 0.4988\n",
            "The average f1 is: 0.4969\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    144.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    144.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    144.    Elapsed: 0:00:29.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "The average precision is: 0.9931\n",
            "The average recall is: 0.9931\n",
            "The average f1 is: 0.9931\n",
            "  Training epcoh took: 0:00:35\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9896\n",
            "  Recall: 0.9968\n",
            "  F1: 0.9931\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4948\n",
            "The average recall is: 0.4984\n",
            "The average f1 is: 0.4965\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    144.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    144.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    144.    Elapsed: 0:00:29.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 1.0000\n",
            "The average recall is: 1.0000\n",
            "The average f1 is: 1.0000\n",
            "  Training epcoh took: 0:00:34\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9897\n",
            "  Recall: 0.9974\n",
            "  F1: 0.9934\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4948\n",
            "The average recall is: 0.4987\n",
            "The average f1 is: 0.4967\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9943\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9971\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4972\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4985\n",
            "  Testing took: 0:00:02\n",
            "Current increase 60 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 13 sampled in this category.\n",
            "After up-sample, there are 2428 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1635\n",
            "0.6733937397034596\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "793\n",
            "0.3266062602965404\n",
            "\n",
            "(2428, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 06:01:24.802717 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 06:01:24.803773 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 06:01:24.844640 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 06:01:27.345633 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 06:01:27.346443 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    152.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    152.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    152.    Elapsed: 0:00:28.\n",
            "  Batch    40  of    152.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    152.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    152.    Elapsed: 0:00:28.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9993\n",
            "The average recall is: 0.9997\n",
            "The average f1 is: 0.9995\n",
            "  Training epcoh took: 0:00:35\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9898\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9947\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4949\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4974\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    152.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    152.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    152.    Elapsed: 0:00:27.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 1.0000\n",
            "The average recall is: 1.0000\n",
            "The average f1 is: 1.0000\n",
            "  Training epcoh took: 0:00:34\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9904\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9950\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4952\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4975\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    152.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    152.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    152.    Elapsed: 0:00:27.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 1.0000\n",
            "The average recall is: 1.0000\n",
            "The average f1 is: 1.0000\n",
            "  Training epcoh took: 0:00:34\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9904\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9950\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4952\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4975\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9943\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9971\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4972\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4985\n",
            "  Testing took: 0:00:02\n",
            "Current increase 70 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 13 sampled in this category.\n",
            "After up-sample, there are 2558 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1635\n",
            "0.6391712275215011\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "923\n",
            "0.3608287724784988\n",
            "\n",
            "(2558, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 06:03:54.173996 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 06:03:54.175016 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 06:03:54.268332 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 06:03:56.766520 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 06:03:56.767282 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    160.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    160.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    160.    Elapsed: 0:00:27.\n",
            "\n",
            "  Average training loss: 0.10\n",
            "  Accuracy: 0.97\n",
            "Category: 0\n",
            "  Precision: 0.96\n",
            "  Recall: 0.99\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 0.95\n",
            "  Recall: 0.91\n",
            "  F1: 0.92\n",
            "The average precision is: 0.9560\n",
            "The average recall is: 0.9540\n",
            "The average f1 is: 0.9502\n",
            "  Training epcoh took: 0:00:35\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9904\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9950\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4952\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4975\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    160.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    160.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    160.    Elapsed: 0:00:29.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9994\n",
            "The average recall is: 0.9997\n",
            "The average f1 is: 0.9995\n",
            "  Training epcoh took: 0:00:38\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9904\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9950\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4952\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4975\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    160.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    160.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    160.    Elapsed: 0:00:28.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 1.0000\n",
            "The average recall is: 1.0000\n",
            "The average f1 is: 1.0000\n",
            "  Training epcoh took: 0:00:37\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9904\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9950\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4952\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4975\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    160.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    160.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    160.    Elapsed: 0:00:29.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 1.0000\n",
            "The average recall is: 1.0000\n",
            "The average f1 is: 1.0000\n",
            "  Training epcoh took: 0:00:38\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9904\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9950\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4952\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4975\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9943\n",
            "  Recall: 0.9981\n",
            "  F1: 0.9960\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4972\n",
            "The average recall is: 0.4991\n",
            "The average f1 is: 0.4980\n",
            "  Testing took: 0:00:02\n",
            "Current increase 80 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 13 sampled in this category.\n",
            "After up-sample, there are 2688 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1635\n",
            "0.6082589285714286\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1053\n",
            "0.39174107142857145\n",
            "\n",
            "(2688, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 06:06:34.006869 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 06:06:34.007946 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 06:06:34.049268 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 06:06:36.553819 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 06:06:36.554674 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    168.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    168.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    168.    Elapsed: 0:00:28.\n",
            "  Batch   160  of    168.    Elapsed: 0:00:37.\n",
            "\n",
            "  Average training loss: 0.10\n",
            "  Accuracy: 0.97\n",
            "Category: 0\n",
            "  Precision: 0.97\n",
            "  Recall: 0.99\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 0.98\n",
            "  Recall: 0.95\n",
            "  F1: 0.95\n",
            "The average precision is: 0.9731\n",
            "The average recall is: 0.9661\n",
            "The average f1 is: 0.9649\n",
            "  Training epcoh took: 0:00:39\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9904\n",
            "  Recall: 0.9976\n",
            "  F1: 0.9938\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4952\n",
            "The average recall is: 0.4988\n",
            "The average f1 is: 0.4969\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    168.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    168.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    168.    Elapsed: 0:00:28.\n",
            "  Batch   160  of    168.    Elapsed: 0:00:38.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9993\n",
            "The average recall is: 0.9991\n",
            "The average f1 is: 0.9991\n",
            "  Training epcoh took: 0:00:40\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9904\n",
            "  Recall: 0.9952\n",
            "  F1: 0.9926\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4952\n",
            "The average recall is: 0.4976\n",
            "The average f1 is: 0.4963\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    168.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    168.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    168.    Elapsed: 0:00:29.\n",
            "  Batch   160  of    168.    Elapsed: 0:00:39.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 1.0000\n",
            "The average recall is: 1.0000\n",
            "The average f1 is: 1.0000\n",
            "  Training epcoh took: 0:00:41\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9904\n",
            "  Recall: 0.9952\n",
            "  F1: 0.9926\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4952\n",
            "The average recall is: 0.4976\n",
            "The average f1 is: 0.4963\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    168.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    168.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    168.    Elapsed: 0:00:29.\n",
            "  Batch   160  of    168.    Elapsed: 0:00:38.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 1.0000\n",
            "The average recall is: 1.0000\n",
            "The average f1 is: 1.0000\n",
            "  Training epcoh took: 0:00:40\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9904\n",
            "  Recall: 0.9952\n",
            "  F1: 0.9926\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4952\n",
            "The average recall is: 0.4976\n",
            "The average f1 is: 0.4963\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9943\n",
            "  Recall: 0.9981\n",
            "  F1: 0.9961\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4972\n",
            "The average recall is: 0.4991\n",
            "The average f1 is: 0.4980\n",
            "  Testing took: 0:00:02\n",
            "Current increase 90 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 13 sampled in this category.\n",
            "After up-sample, there are 2818 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1635\n",
            "0.5801987224982257\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1183\n",
            "0.4198012775017743\n",
            "\n",
            "(2818, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 06:09:25.052129 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 06:09:25.053167 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 06:09:26.375674 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 06:09:28.889082 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 06:09:28.889801 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    177.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    177.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    177.    Elapsed: 0:00:28.\n",
            "  Batch   160  of    177.    Elapsed: 0:00:38.\n",
            "\n",
            "  Average training loss: 0.09\n",
            "  Accuracy: 0.97\n",
            "Category: 0\n",
            "  Precision: 0.98\n",
            "  Recall: 0.98\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 0.97\n",
            "  Recall: 0.96\n",
            "  F1: 0.96\n",
            "The average precision is: 0.9725\n",
            "The average recall is: 0.9737\n",
            "The average f1 is: 0.9714\n",
            "  Training epcoh took: 0:00:42\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9904\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9950\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4952\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4975\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    177.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    177.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    177.    Elapsed: 0:00:29.\n",
            "  Batch   160  of    177.    Elapsed: 0:00:39.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9997\n",
            "The average recall is: 0.9996\n",
            "The average f1 is: 0.9996\n",
            "  Training epcoh took: 0:00:43\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9904\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9950\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4952\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4975\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    177.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    177.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    177.    Elapsed: 0:00:29.\n",
            "  Batch   160  of    177.    Elapsed: 0:00:39.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9972\n",
            "The average recall is: 0.9972\n",
            "The average f1 is: 0.9972\n",
            "  Training epcoh took: 0:00:43\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9904\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9950\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4952\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4975\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    177.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    177.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    177.    Elapsed: 0:00:29.\n",
            "  Batch   160  of    177.    Elapsed: 0:00:39.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 1.0000\n",
            "The average recall is: 1.0000\n",
            "The average f1 is: 1.0000\n",
            "  Training epcoh took: 0:00:43\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9904\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9950\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4952\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4975\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.9943\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9971\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4972\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4985\n",
            "  Testing took: 0:00:02\n",
            "Successfully save file ./BertSearchResult/2_16_2e-05_2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bSITnL01WcSr",
        "jupyter": {
          "outputs_hidden": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "outputId": "203b4107-6a44-4a39-d1ce-f5ea357bf42a"
      },
      "source": [
        "all_metrics_one"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: defaultdict(None,\n",
              "             {'train_loss_values': [0.02451061978212838,\n",
              "               0.02451061978212838,\n",
              "               0.014020035567792874,\n",
              "               0.014020035567792874,\n",
              "               0.014816705897016433,\n",
              "               0.014816705897016433,\n",
              "               0.012088468786582205,\n",
              "               0.012088468786582205],\n",
              "              'train_acc_all': [0.9981796116504854,\n",
              "               0.9981796116504854,\n",
              "               0.9981796116504854,\n",
              "               0.9981796116504854],\n",
              "              'train_precision_all': [{0: 0.9981796116504854, 1: 0.0},\n",
              "               {0: 0.9981796116504854, 1: 0.0},\n",
              "               {0: 0.9981796116504854, 1: 0.0},\n",
              "               {0: 0.9981796116504854, 1: 0.0}],\n",
              "              'train_recall_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}],\n",
              "              'train_f1_all': [{0: 0.9990291262135923, 1: 0.0},\n",
              "               {0: 0.9990291262135923, 1: 0.0},\n",
              "               {0: 0.9990291262135923, 1: 0.0},\n",
              "               {0: 0.9990291262135923, 1: 0.0}],\n",
              "              'val_acc_all': [1.0, 1.0, 1.0, 1.0],\n",
              "              'val_precision_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}],\n",
              "              'val_recall_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}],\n",
              "              'val_f1_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}]})}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oAk234wpJOuX"
      },
      "source": [
        "#### Incremental recitfied training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "ybkhk_NaZiqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "batch_size = 32\n",
        "lr = 3e-5\n",
        "test_batch = [test_inputs,test_labels,test_masks]\n",
        "Bert = Bertnn_rectified_info(train_inputs,train_labels,train_masks, validation_inputs,validation_labels,validation_masks,test_batch,batch_size=batch_size,lr=lr)\n",
        "all_metrics_one, all_tesst_metrics = Bert.searchUpsample(100)\n",
        "all_metrics_one['test'] = all_tesst_metrics\n",
        "all_metrics_all_category[section_category] = all_metrics_one\n",
        "if not os.path.exists('BertSearchResult'):\n",
        "  os.makedirs('BertSearchResult')\n",
        "\n",
        "filename = './BertSearchResult/'+'rectified'+'_'+str(section_category)+'_'+str(batch_size) + '_' + str(lr) + '_'  + str(section_category)\n",
        "with open(filename,'w') as file_obj:\n",
        "  json.dump(all_metrics_one,file_obj)\n",
        "  print('Successfully save file %s'%(filename))\n",
        "\n",
        "del Bert\n",
        "torch.cuda.empty_cache() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A2nypAMJJOua",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "d1085ac1-8fce-4aa1-ad12-b13ab71cb2bc"
      },
      "source": [
        "all_metrics_one['test']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: [[{0: 0.9980769230769231, 1: 0.0}],\n",
              "  [{0: 1.0, 1: 0.0}],\n",
              "  [{0: 0.998974358974359, 1: 0.0}],\n",
              "  [0.9980769230769231]]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EDYahFJ_irjM"
      },
      "source": [
        "### For 'EmergingThreats'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iqxvbG3XWc4M"
      },
      "source": [
        "#### Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ozpkc196Wc4N",
        "colab": {}
      },
      "source": [
        "# Use train_test_split to split our data into train and validation and test sets for\n",
        "# training\n",
        "section_category = 0\n",
        "labels = labels_single[section_category]\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 80% for training and 20% for validation.\n",
        "temp_inputs, test_inputs,  temp_labels, test_labels = train_test_split(input_ids, labels, random_state=1999, test_size=0.2)\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(temp_inputs, temp_labels,random_state=1999, test_size=0.2)\n",
        "\n",
        "# Do the same for the masks.\n",
        "temp_masks, test_masks, temp_labels, _ = train_test_split(attention_masks, labels,random_state=1999, test_size=0.2)\n",
        "\n",
        "train_masks, validation_masks, _, _ = train_test_split(temp_masks, temp_labels,random_state=1999, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YxpATCNRJWRu"
      },
      "source": [
        "#### Normal training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "AJifNU83Ziqa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7156f0ab-6c8e-4ea4-9b68-849e5642e802"
      },
      "source": [
        "import json\n",
        "batch_size = 16\n",
        "lr = 2e-5\n",
        "test_batch = [test_inputs,test_labels,test_masks]\n",
        "Bert = Bertnn_info(train_inputs,train_labels,train_masks, validation_inputs,validation_labels,validation_masks,test_batch,batch_size=batch_size,lr=lr)\n",
        "all_metrics_one, all_tesst_metrics = Bert.searchUpsample(100)\n",
        "all_metrics_one['test'] = all_tesst_metrics\n",
        "all_metrics_all_category[section_category] = all_metrics_one\n",
        "if not os.path.exists('BertSearchResult'):\n",
        "  os.makedirs('BertSearchResult')\n",
        "\n",
        "filename = './BertSearchResult/'+str(section_category)+'_'+str(batch_size) + '_' + str(lr) + '_'  + str(section_category)\n",
        "with open(filename,'w') as file_obj:\n",
        "  json.dump(all_metrics_one,file_obj)\n",
        "  print('Successfully save file %s'%(filename))\n",
        "\n",
        "del Bert\n",
        "torch.cuda.empty_cache() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: TITAN RTX\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 12:00:24.529457 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 12:00:24.530456 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 12:00:24.646162 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 12:00:27.109945 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 12:00:27.110691 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current increase 0 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 0 sampled in this category.\n",
            "After up-sample, there are 1648 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1648\n",
            "1.0\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "(1648, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 12:00:27.709919 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 12:00:27.710898 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 12:00:27.744937 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 12:00:30.327651 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 12:00:30.329095 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:07.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:15.\n",
            "\n",
            "  Average training loss: 0.03\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Training epcoh took: 0:00:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:07.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:15.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Training epcoh took: 0:00:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:15.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Training epcoh took: 0:00:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:15.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Training epcoh took: 0:00:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Testing took: 0:00:01\n",
            "Current increase 10 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 0 sampled in this category.\n",
            "After up-sample, there are 1648 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1648\n",
            "1.0\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "(1648, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 12:01:54.917705 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 12:01:54.918792 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 12:01:54.961054 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 12:01:57.471032 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 12:01:57.471803 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:15.\n",
            "\n",
            "  Average training loss: 0.03\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Training epcoh took: 0:00:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Training epcoh took: 0:00:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Training epcoh took: 0:00:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Training epcoh took: 0:00:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Testing took: 0:00:02\n",
            "Current increase 20 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 0 sampled in this category.\n",
            "After up-sample, there are 1648 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1648\n",
            "1.0\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "(1648, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 12:03:25.490554 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 12:03:25.491676 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 12:03:26.016855 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 12:03:28.475493 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 12:03:28.476220 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 0.03\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.4942\n",
            "The average f1 is: 0.4950\n",
            "  Training epcoh took: 0:00:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:17.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Training epcoh took: 0:00:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:17.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Training epcoh took: 0:00:22\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:17.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Training epcoh took: 0:00:22\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Testing took: 0:00:02\n",
            "Current increase 30 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 0 sampled in this category.\n",
            "After up-sample, there are 1648 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1648\n",
            "1.0\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "(1648, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 12:05:03.107093 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 12:05:03.108125 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 12:05:03.149988 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 12:05:05.635433 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 12:05:05.637220 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:17.\n",
            "\n",
            "  Average training loss: 0.07\n",
            "  Accuracy: 0.98\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.98\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.4951\n",
            "The average recall is: 0.4912\n",
            "The average f1 is: 0.4923\n",
            "  Training epcoh took: 0:00:22\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:17.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Testing took: 0:00:02\n",
            "Current increase 40 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 0 sampled in this category.\n",
            "After up-sample, there are 1648 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1648\n",
            "1.0\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "(1648, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 12:06:43.229407 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 12:06:43.230636 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 12:06:43.306637 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 12:06:45.771559 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 12:06:45.772369 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.4954\n",
            "The average f1 is: 0.4964\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:17.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Testing took: 0:00:02\n",
            "Current increase 50 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 0 sampled in this category.\n",
            "After up-sample, there are 1648 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1648\n",
            "1.0\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "(1648, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 12:08:25.137054 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 12:08:25.138092 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 12:08:25.623700 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 12:08:28.111937 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 12:08:28.112694 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:17.\n",
            "\n",
            "  Average training loss: 0.03\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:17.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Training epcoh took: 0:00:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:11.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:20.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Training epcoh took: 0:00:25\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Training epcoh took: 0:00:24\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Testing took: 0:00:02\n",
            "Current increase 60 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 0 sampled in this category.\n",
            "After up-sample, there are 1648 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1648\n",
            "1.0\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "(1648, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 12:10:09.320777 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 12:10:09.321880 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 12:10:09.388150 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 12:10:11.908879 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 12:10:11.910388 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 0.07\n",
            "  Accuracy: 0.98\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.98\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.4951\n",
            "The average recall is: 0.4900\n",
            "The average f1 is: 0.4909\n",
            "  Training epcoh took: 0:00:22\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:19.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Training epcoh took: 0:00:24\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Testing took: 0:00:02\n",
            "Current increase 70 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 0 sampled in this category.\n",
            "After up-sample, there are 1648 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1648\n",
            "1.0\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "(1648, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 12:11:52.700798 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 12:11:52.701927 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 12:11:52.761190 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 12:11:55.237318 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 12:11:55.238115 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 0.05\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.4933\n",
            "The average f1 is: 0.4944\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:19.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Training epcoh took: 0:00:24\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Testing took: 0:00:02\n",
            "Current increase 80 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 0 sampled in this category.\n",
            "After up-sample, there are 1648 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1648\n",
            "1.0\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "(1648, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 12:13:35.874093 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 12:13:35.875189 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 12:13:35.923444 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 12:13:38.448125 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 12:13:38.449551 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 0.05\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.4930\n",
            "The average f1 is: 0.4945\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Testing took: 0:00:02\n",
            "Current increase 90 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 0 sampled in this category.\n",
            "After up-sample, there are 1648 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1648\n",
            "1.0\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "(1648, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 12:15:19.170035 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 12:15:19.171057 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 12:15:19.226593 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 12:15:21.699354 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 12:15:21.700084 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.4939\n",
            "The average f1 is: 0.4951\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Training epcoh took: 0:00:24\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Training epcoh took: 0:00:24\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1: 1.0000\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.5000\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.5000\n",
            "  Testing took: 0:00:02\n",
            "Successfully save file ./BertSearchResult/3_16_2e-05_3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "collapsed": true,
        "id": "1fUNAU-lWc4T",
        "jupyter": {
          "outputs_hidden": true
        },
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "outputId": "203b4107-6a44-4a39-d1ce-f5ea357bf42a"
      },
      "source": [
        "all_metrics_one"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: defaultdict(None,\n",
              "             {'train_loss_values': [0.02451061978212838,\n",
              "               0.02451061978212838,\n",
              "               0.014020035567792874,\n",
              "               0.014020035567792874,\n",
              "               0.014816705897016433,\n",
              "               0.014816705897016433,\n",
              "               0.012088468786582205,\n",
              "               0.012088468786582205],\n",
              "              'train_acc_all': [0.9981796116504854,\n",
              "               0.9981796116504854,\n",
              "               0.9981796116504854,\n",
              "               0.9981796116504854],\n",
              "              'train_precision_all': [{0: 0.9981796116504854, 1: 0.0},\n",
              "               {0: 0.9981796116504854, 1: 0.0},\n",
              "               {0: 0.9981796116504854, 1: 0.0},\n",
              "               {0: 0.9981796116504854, 1: 0.0}],\n",
              "              'train_recall_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}],\n",
              "              'train_f1_all': [{0: 0.9990291262135923, 1: 0.0},\n",
              "               {0: 0.9990291262135923, 1: 0.0},\n",
              "               {0: 0.9990291262135923, 1: 0.0},\n",
              "               {0: 0.9990291262135923, 1: 0.0}],\n",
              "              'val_acc_all': [1.0, 1.0, 1.0, 1.0],\n",
              "              'val_precision_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}],\n",
              "              'val_recall_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}],\n",
              "              'val_f1_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}]})}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sjVH5bq4JP4W"
      },
      "source": [
        "#### Incremental recitfied training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "FBVouzTvZiqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "batch_size = 32\n",
        "lr = 3e-5\n",
        "test_batch = [test_inputs,test_labels,test_masks]\n",
        "Bert = Bertnn_rectified_info(train_inputs,train_labels,train_masks, validation_inputs,validation_labels,validation_masks,test_batch,batch_size=batch_size,lr=lr)\n",
        "all_metrics_one, all_tesst_metrics = Bert.searchUpsample(100)\n",
        "all_metrics_one['test'] = all_tesst_metrics\n",
        "all_metrics_all_category[section_category] = all_metrics_one\n",
        "if not os.path.exists('BertSearchResult'):\n",
        "  os.makedirs('BertSearchResult')\n",
        "\n",
        "filename = './BertSearchResult/'+'rectified'+'_'+str(section_category)+'_'+str(batch_size) + '_' + str(lr) + '_'  + str(section_category)\n",
        "with open(filename,'w') as file_obj:\n",
        "  json.dump(all_metrics_one,file_obj)\n",
        "  print('Successfully save file %s'%(filename))\n",
        "\n",
        "del Bert\n",
        "torch.cuda.empty_cache() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9CiHb01IJP4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "d1085ac1-8fce-4aa1-ad12-b13ab71cb2bc"
      },
      "source": [
        "all_metrics_one['test']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: [[{0: 0.9980769230769231, 1: 0.0}],\n",
              "  [{0: 1.0, 1: 0.0}],\n",
              "  [{0: 0.998974358974359, 1: 0.0}],\n",
              "  [0.9980769230769231]]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JxW5G6xTWRWm"
      },
      "source": [
        "### For 'NewSubEvent'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "egQ4fqBGWdd8"
      },
      "source": [
        "#### Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "six78S36Wdd9",
        "colab": {}
      },
      "source": [
        "# Use train_test_split to split our data into train and validation and test sets for\n",
        "# training\n",
        "section_category = 0\n",
        "labels = labels_single[section_category]\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 80% for training and 20% for validation.\n",
        "temp_inputs, test_inputs,  temp_labels, test_labels = train_test_split(input_ids, labels, random_state=1999, test_size=0.2)\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(temp_inputs, temp_labels,random_state=1999, test_size=0.2)\n",
        "\n",
        "# Do the same for the masks.\n",
        "temp_masks, test_masks, temp_labels, _ = train_test_split(attention_masks, labels,random_state=1999, test_size=0.2)\n",
        "\n",
        "train_masks, validation_masks, _, _ = train_test_split(temp_masks, temp_labels,random_state=1999, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ee-0UKtgJXAO"
      },
      "source": [
        "#### Normal training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "zZZMnyiQZiqz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7156f0ab-6c8e-4ea4-9b68-849e5642e802"
      },
      "source": [
        "import json\n",
        "batch_size = 16\n",
        "lr = 2e-5\n",
        "test_batch = [test_inputs,test_labels,test_masks]\n",
        "Bert = Bertnn_info(train_inputs,train_labels,train_masks, validation_inputs,validation_labels,validation_masks,test_batch,batch_size=batch_size,lr=lr)\n",
        "all_metrics_one, all_tesst_metrics = Bert.searchUpsample(100)\n",
        "all_metrics_one['test'] = all_tesst_metrics\n",
        "all_metrics_all_category[section_category] = all_metrics_one\n",
        "if not os.path.exists('BertSearchResult'):\n",
        "  os.makedirs('BertSearchResult')\n",
        "\n",
        "filename = './BertSearchResult/'+str(section_category)+'_'+str(batch_size) + '_' + str(lr) + '_'  + str(section_category)\n",
        "with open(filename,'w') as file_obj:\n",
        "  json.dump(all_metrics_one,file_obj)\n",
        "  print('Successfully save file %s'%(filename))\n",
        "\n",
        "del Bert\n",
        "torch.cuda.empty_cache() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: TITAN RTX\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 08:16:10.895144 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 08:16:10.896262 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 08:16:11.016486 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 08:16:13.501247 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 08:16:13.501969 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current increase 0 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 103 sampled in this category.\n",
            "After up-sample, there are 1648 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1545\n",
            "0.9375\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "103\n",
            "0.0625\n",
            "\n",
            "(1648, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 08:16:14.120489 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 08:16:14.121343 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 08:16:14.585554 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 08:16:17.082231 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 08:16:17.083010 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:15.\n",
            "\n",
            "  Average training loss: 0.26\n",
            "  Accuracy: 0.93\n",
            "Category: 0\n",
            "  Precision: 0.93\n",
            "  Recall: 0.98\n",
            "  F1: 0.95\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.02\n",
            "  F1: 0.01\n",
            "The average precision is: 0.4670\n",
            "The average recall is: 0.5002\n",
            "The average f1 is: 0.4802\n",
            "  Training epcoh took: 0:00:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.94\n",
            "Category: 0\n",
            "  Precision: 0.9412\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9689\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4706\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4845\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:15.\n",
            "\n",
            "  Average training loss: 0.23\n",
            "  Accuracy: 0.94\n",
            "Category: 0\n",
            "  Precision: 0.94\n",
            "  Recall: 1.00\n",
            "  F1: 0.97\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.4688\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4834\n",
            "  Training epcoh took: 0:00:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.94\n",
            "Category: 0\n",
            "  Precision: 0.9418\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9692\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4709\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4846\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:15.\n",
            "\n",
            "  Average training loss: 0.21\n",
            "  Accuracy: 0.94\n",
            "Category: 0\n",
            "  Precision: 0.94\n",
            "  Recall: 1.00\n",
            "  F1: 0.97\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.4688\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4833\n",
            "  Training epcoh took: 0:00:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.94\n",
            "Category: 0\n",
            "  Precision: 0.9423\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9694\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4712\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4847\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:15.\n",
            "\n",
            "  Average training loss: 0.17\n",
            "  Accuracy: 0.94\n",
            "Category: 0\n",
            "  Precision: 0.94\n",
            "  Recall: 1.00\n",
            "  F1: 0.97\n",
            "Category: 1\n",
            "  Precision: 0.03\n",
            "  Recall: 0.02\n",
            "  F1: 0.02\n",
            "The average precision is: 0.4841\n",
            "The average recall is: 0.5104\n",
            "The average f1 is: 0.4948\n",
            "  Training epcoh took: 0:00:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.94\n",
            "Category: 0\n",
            "  Precision: 0.9483\n",
            "  Recall: 0.9950\n",
            "  F1: 0.9707\n",
            "Category: 1\n",
            "  Precision: 0.1154\n",
            "  Recall: 0.0577\n",
            "  F1: 0.0769\n",
            "The average precision is: 0.5319\n",
            "The average recall is: 0.5264\n",
            "The average f1 is: 0.5238\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9486\n",
            "  Recall: 0.9960\n",
            "  F1: 0.9708\n",
            "Category: 1\n",
            "  Precision: 0.1515\n",
            "  Recall: 0.1515\n",
            "  F1: 0.1515\n",
            "The average precision is: 0.5501\n",
            "The average recall is: 0.5737\n",
            "The average f1 is: 0.5611\n",
            "  Testing took: 0:00:01\n",
            "Current increase 10 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 103 sampled in this category.\n",
            "After up-sample, there are 2678 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1545\n",
            "0.5769230769230769\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1133\n",
            "0.4230769230769231\n",
            "\n",
            "(2678, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 08:17:42.528029 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 08:17:42.528997 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 08:17:42.570927 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 08:17:45.054177 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 08:17:45.054885 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    168.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    168.    Elapsed: 0:00:16.\n",
            "  Batch   120  of    168.    Elapsed: 0:00:24.\n",
            "  Batch   160  of    168.    Elapsed: 0:00:31.\n",
            "\n",
            "  Average training loss: 0.36\n",
            "  Accuracy: 0.83\n",
            "Category: 0\n",
            "  Precision: 0.85\n",
            "  Recall: 0.90\n",
            "  F1: 0.86\n",
            "Category: 1\n",
            "  Precision: 0.78\n",
            "  Recall: 0.75\n",
            "  F1: 0.74\n",
            "The average precision is: 0.8150\n",
            "The average recall is: 0.8207\n",
            "The average f1 is: 0.8002\n",
            "  Training epcoh took: 0:00:33\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.92\n",
            "Category: 0\n",
            "  Precision: 0.9717\n",
            "  Recall: 0.9474\n",
            "  F1: 0.9571\n",
            "Category: 1\n",
            "  Precision: 0.3205\n",
            "  Recall: 0.2949\n",
            "  F1: 0.2846\n",
            "The average precision is: 0.6461\n",
            "The average recall is: 0.6211\n",
            "The average f1 is: 0.6209\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    168.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    168.    Elapsed: 0:00:16.\n",
            "  Batch   120  of    168.    Elapsed: 0:00:24.\n",
            "  Batch   160  of    168.    Elapsed: 0:00:32.\n",
            "\n",
            "  Average training loss: 0.05\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.98\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.97\n",
            "  Recall: 0.99\n",
            "  F1: 0.98\n",
            "The average precision is: 0.9843\n",
            "The average recall is: 0.9862\n",
            "The average f1 is: 0.9842\n",
            "  Training epcoh took: 0:00:33\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.93\n",
            "Category: 0\n",
            "  Precision: 0.9715\n",
            "  Recall: 0.9520\n",
            "  F1: 0.9600\n",
            "Category: 1\n",
            "  Precision: 0.2885\n",
            "  Recall: 0.3205\n",
            "  F1: 0.2821\n",
            "The average precision is: 0.6300\n",
            "The average recall is: 0.6363\n",
            "The average f1 is: 0.6210\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    168.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    168.    Elapsed: 0:00:16.\n",
            "  Batch   120  of    168.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    168.    Elapsed: 0:00:33.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 0.99\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.99\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9960\n",
            "The average recall is: 0.9972\n",
            "The average f1 is: 0.9963\n",
            "  Training epcoh took: 0:00:35\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9620\n",
            "  Recall: 0.9897\n",
            "  F1: 0.9748\n",
            "Category: 1\n",
            "  Precision: 0.2500\n",
            "  Recall: 0.2115\n",
            "  F1: 0.2256\n",
            "The average precision is: 0.6060\n",
            "The average recall is: 0.6006\n",
            "The average f1 is: 0.6002\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    168.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    168.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    168.    Elapsed: 0:00:26.\n",
            "  Batch   160  of    168.    Elapsed: 0:00:34.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9996\n",
            "The average recall is: 0.9997\n",
            "The average f1 is: 0.9996\n",
            "  Training epcoh took: 0:00:36\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9574\n",
            "  Recall: 0.9922\n",
            "  F1: 0.9739\n",
            "Category: 1\n",
            "  Precision: 0.2115\n",
            "  Recall: 0.1731\n",
            "  F1: 0.1872\n",
            "The average precision is: 0.5845\n",
            "The average recall is: 0.5827\n",
            "The average f1 is: 0.5805\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.93\n",
            "Category: 0\n",
            "  Precision: 0.9597\n",
            "  Recall: 0.9654\n",
            "  F1: 0.9617\n",
            "Category: 1\n",
            "  Precision: 0.1970\n",
            "  Recall: 0.2071\n",
            "  F1: 0.1889\n",
            "The average precision is: 0.5783\n",
            "The average recall is: 0.5863\n",
            "The average f1 is: 0.5753\n",
            "  Testing took: 0:00:02\n",
            "Current increase 20 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 103 sampled in this category.\n",
            "After up-sample, there are 3708 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1545\n",
            "0.4166666666666667\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "2163\n",
            "0.5833333333333334\n",
            "\n",
            "(3708, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 08:20:08.822949 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 08:20:08.823984 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 08:20:08.866756 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 08:20:11.408542 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 08:20:11.409321 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    232.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    232.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    232.    Elapsed: 0:00:26.\n",
            "  Batch   160  of    232.    Elapsed: 0:00:35.\n",
            "  Batch   200  of    232.    Elapsed: 0:00:44.\n",
            "\n",
            "  Average training loss: 0.24\n",
            "  Accuracy: 0.90\n",
            "Category: 0\n",
            "  Precision: 0.88\n",
            "  Recall: 0.82\n",
            "  F1: 0.83\n",
            "Category: 1\n",
            "  Precision: 0.90\n",
            "  Recall: 0.94\n",
            "  F1: 0.91\n",
            "The average precision is: 0.8893\n",
            "The average recall is: 0.8816\n",
            "The average f1 is: 0.8692\n",
            "  Training epcoh took: 0:00:51\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.94\n",
            "Category: 0\n",
            "  Precision: 0.9706\n",
            "  Recall: 0.9693\n",
            "  F1: 0.9690\n",
            "Category: 1\n",
            "  Precision: 0.4103\n",
            "  Recall: 0.3782\n",
            "  F1: 0.3745\n",
            "The average precision is: 0.6904\n",
            "The average recall is: 0.6738\n",
            "The average f1 is: 0.6718\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    232.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    232.    Elapsed: 0:00:16.\n",
            "  Batch   120  of    232.    Elapsed: 0:00:27.\n",
            "  Batch   160  of    232.    Elapsed: 0:00:37.\n",
            "  Batch   200  of    232.    Elapsed: 0:00:46.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 0.98\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.99\n",
            "  Recall: 1.00\n",
            "  F1: 0.99\n",
            "The average precision is: 0.9931\n",
            "The average recall is: 0.9909\n",
            "The average f1 is: 0.9914\n",
            "  Training epcoh took: 0:00:53\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9577\n",
            "  Recall: 0.9897\n",
            "  F1: 0.9727\n",
            "Category: 1\n",
            "  Precision: 0.2115\n",
            "  Recall: 0.1442\n",
            "  F1: 0.1628\n",
            "The average precision is: 0.5846\n",
            "The average recall is: 0.5670\n",
            "The average f1 is: 0.5678\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    232.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    232.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    232.    Elapsed: 0:00:26.\n",
            "  Batch   160  of    232.    Elapsed: 0:00:35.\n",
            "  Batch   200  of    232.    Elapsed: 0:00:43.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9981\n",
            "The average recall is: 0.9976\n",
            "The average f1 is: 0.9977\n",
            "  Training epcoh took: 0:00:50\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9620\n",
            "  Recall: 0.9901\n",
            "  F1: 0.9751\n",
            "Category: 1\n",
            "  Precision: 0.3077\n",
            "  Recall: 0.2500\n",
            "  F1: 0.2692\n",
            "The average precision is: 0.6349\n",
            "The average recall is: 0.6200\n",
            "The average f1 is: 0.6222\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    232.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    232.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    232.    Elapsed: 0:00:27.\n",
            "  Batch   160  of    232.    Elapsed: 0:00:36.\n",
            "  Batch   200  of    232.    Elapsed: 0:00:44.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9995\n",
            "The average recall is: 0.9995\n",
            "The average f1 is: 0.9995\n",
            "  Training epcoh took: 0:00:50\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9616\n",
            "  Recall: 0.9889\n",
            "  F1: 0.9745\n",
            "Category: 1\n",
            "  Precision: 0.2692\n",
            "  Recall: 0.2083\n",
            "  F1: 0.2295\n",
            "The average precision is: 0.6154\n",
            "The average recall is: 0.5986\n",
            "The average f1 is: 0.6020\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.94\n",
            "Category: 0\n",
            "  Precision: 0.9609\n",
            "  Recall: 0.9726\n",
            "  F1: 0.9651\n",
            "Category: 1\n",
            "  Precision: 0.3030\n",
            "  Recall: 0.2677\n",
            "  F1: 0.2576\n",
            "The average precision is: 0.6319\n",
            "The average recall is: 0.6201\n",
            "The average f1 is: 0.6114\n",
            "  Testing took: 0:00:02\n",
            "Current increase 30 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 103 sampled in this category.\n",
            "After up-sample, there are 4738 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1545\n",
            "0.32608695652173914\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "3193\n",
            "0.6739130434782609\n",
            "\n",
            "(4738, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 08:23:43.945258 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 08:23:43.946365 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 08:23:44.438137 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 08:23:46.953501 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 08:23:46.954337 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    297.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    297.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    297.    Elapsed: 0:00:27.\n",
            "  Batch   160  of    297.    Elapsed: 0:00:35.\n",
            "  Batch   200  of    297.    Elapsed: 0:00:44.\n",
            "  Batch   240  of    297.    Elapsed: 0:00:58.\n",
            "  Batch   280  of    297.    Elapsed: 0:01:08.\n",
            "\n",
            "  Average training loss: 0.20\n",
            "  Accuracy: 0.92\n",
            "Category: 0\n",
            "  Precision: 0.86\n",
            "  Recall: 0.82\n",
            "  F1: 0.82\n",
            "Category: 1\n",
            "  Precision: 0.92\n",
            "  Recall: 0.97\n",
            "  F1: 0.94\n",
            "The average precision is: 0.8934\n",
            "The average recall is: 0.8933\n",
            "The average f1 is: 0.8815\n",
            "  Training epcoh took: 0:01:11\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9646\n",
            "  Recall: 0.9849\n",
            "  F1: 0.9735\n",
            "Category: 1\n",
            "  Precision: 0.2756\n",
            "  Recall: 0.2308\n",
            "  F1: 0.2346\n",
            "The average precision is: 0.6201\n",
            "The average recall is: 0.6078\n",
            "The average f1 is: 0.6041\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    297.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    297.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    297.    Elapsed: 0:00:28.\n",
            "  Batch   160  of    297.    Elapsed: 0:00:37.\n",
            "  Batch   200  of    297.    Elapsed: 0:00:47.\n",
            "  Batch   240  of    297.    Elapsed: 0:00:56.\n",
            "  Batch   280  of    297.    Elapsed: 0:01:05.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9965\n",
            "The average recall is: 0.9952\n",
            "The average f1 is: 0.9957\n",
            "  Training epcoh took: 0:01:09\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9585\n",
            "  Recall: 0.9974\n",
            "  F1: 0.9770\n",
            "Category: 1\n",
            "  Precision: 0.2308\n",
            "  Recall: 0.1859\n",
            "  F1: 0.1987\n",
            "The average precision is: 0.5946\n",
            "The average recall is: 0.5917\n",
            "The average f1 is: 0.5879\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    297.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    297.    Elapsed: 0:00:20.\n",
            "  Batch   120  of    297.    Elapsed: 0:00:29.\n",
            "  Batch   160  of    297.    Elapsed: 0:00:38.\n",
            "  Batch   200  of    297.    Elapsed: 0:00:48.\n",
            "  Batch   240  of    297.    Elapsed: 0:00:57.\n",
            "  Batch   280  of    297.    Elapsed: 0:01:07.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 0.99\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9977\n",
            "The average recall is: 0.9971\n",
            "The average f1 is: 0.9973\n",
            "  Training epcoh took: 0:01:11\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9600\n",
            "  Recall: 0.9945\n",
            "  F1: 0.9766\n",
            "Category: 1\n",
            "  Precision: 0.2308\n",
            "  Recall: 0.1923\n",
            "  F1: 0.2051\n",
            "The average precision is: 0.5954\n",
            "The average recall is: 0.5934\n",
            "The average f1 is: 0.5909\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    297.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    297.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    297.    Elapsed: 0:00:29.\n",
            "  Batch   160  of    297.    Elapsed: 0:00:38.\n",
            "  Batch   200  of    297.    Elapsed: 0:00:48.\n",
            "  Batch   240  of    297.    Elapsed: 0:00:57.\n",
            "  Batch   280  of    297.    Elapsed: 0:01:07.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9948\n",
            "The average recall is: 0.9947\n",
            "The average f1 is: 0.9947\n",
            "  Training epcoh took: 0:01:10\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9606\n",
            "  Recall: 0.9947\n",
            "  F1: 0.9766\n",
            "Category: 1\n",
            "  Precision: 0.1923\n",
            "  Recall: 0.1346\n",
            "  F1: 0.1538\n",
            "The average precision is: 0.5764\n",
            "The average recall is: 0.5647\n",
            "The average f1 is: 0.5652\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9646\n",
            "  Recall: 0.9842\n",
            "  F1: 0.9733\n",
            "Category: 1\n",
            "  Precision: 0.3030\n",
            "  Recall: 0.2601\n",
            "  F1: 0.2646\n",
            "The average precision is: 0.6338\n",
            "The average recall is: 0.6222\n",
            "The average f1 is: 0.6190\n",
            "  Testing took: 0:00:02\n",
            "Current increase 40 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 103 sampled in this category.\n",
            "After up-sample, there are 5768 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1545\n",
            "0.26785714285714285\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "4223\n",
            "0.7321428571428571\n",
            "\n",
            "(5768, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 08:28:37.663468 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 08:28:37.664490 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 08:28:38.157601 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 08:28:40.678821 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 08:28:40.680252 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    361.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    361.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    361.    Elapsed: 0:00:26.\n",
            "  Batch   160  of    361.    Elapsed: 0:00:34.\n",
            "  Batch   200  of    361.    Elapsed: 0:00:50.\n",
            "  Batch   240  of    361.    Elapsed: 0:01:00.\n",
            "  Batch   280  of    361.    Elapsed: 0:01:09.\n",
            "  Batch   320  of    361.    Elapsed: 0:01:18.\n",
            "  Batch   360  of    361.    Elapsed: 0:01:28.\n",
            "\n",
            "  Average training loss: 0.14\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.90\n",
            "  Recall: 0.83\n",
            "  F1: 0.85\n",
            "Category: 1\n",
            "  Precision: 0.95\n",
            "  Recall: 0.99\n",
            "  F1: 0.97\n",
            "The average precision is: 0.9241\n",
            "The average recall is: 0.9130\n",
            "The average f1 is: 0.9110\n",
            "  Training epcoh took: 0:01:28\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.94\n",
            "Category: 0\n",
            "  Precision: 0.9642\n",
            "  Recall: 0.9739\n",
            "  F1: 0.9683\n",
            "Category: 1\n",
            "  Precision: 0.2756\n",
            "  Recall: 0.3077\n",
            "  F1: 0.2782\n",
            "The average precision is: 0.6199\n",
            "The average recall is: 0.6408\n",
            "The average f1 is: 0.6233\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    361.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    361.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    361.    Elapsed: 0:00:28.\n",
            "  Batch   160  of    361.    Elapsed: 0:00:38.\n",
            "  Batch   200  of    361.    Elapsed: 0:00:48.\n",
            "  Batch   240  of    361.    Elapsed: 0:00:57.\n",
            "  Batch   280  of    361.    Elapsed: 0:01:07.\n",
            "  Batch   320  of    361.    Elapsed: 0:01:16.\n",
            "  Batch   360  of    361.    Elapsed: 0:01:26.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.98\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9923\n",
            "The average recall is: 0.9917\n",
            "The average f1 is: 0.9916\n",
            "  Training epcoh took: 0:01:26\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9724\n",
            "  Recall: 0.9743\n",
            "  F1: 0.9727\n",
            "Category: 1\n",
            "  Precision: 0.3526\n",
            "  Recall: 0.3846\n",
            "  F1: 0.3577\n",
            "The average precision is: 0.6625\n",
            "The average recall is: 0.6795\n",
            "The average f1 is: 0.6652\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    361.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    361.    Elapsed: 0:00:20.\n",
            "  Batch   120  of    361.    Elapsed: 0:00:30.\n",
            "  Batch   160  of    361.    Elapsed: 0:00:39.\n",
            "  Batch   200  of    361.    Elapsed: 0:00:49.\n",
            "  Batch   240  of    361.    Elapsed: 0:00:59.\n",
            "  Batch   280  of    361.    Elapsed: 0:01:09.\n",
            "  Batch   320  of    361.    Elapsed: 0:01:18.\n",
            "  Batch   360  of    361.    Elapsed: 0:01:28.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9970\n",
            "The average recall is: 0.9966\n",
            "The average f1 is: 0.9968\n",
            "  Training epcoh took: 0:01:28\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9596\n",
            "  Recall: 0.9924\n",
            "  F1: 0.9750\n",
            "Category: 1\n",
            "  Precision: 0.2885\n",
            "  Recall: 0.1859\n",
            "  F1: 0.2179\n",
            "The average precision is: 0.6240\n",
            "The average recall is: 0.5892\n",
            "The average f1 is: 0.5965\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    361.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    361.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    361.    Elapsed: 0:00:29.\n",
            "  Batch   160  of    361.    Elapsed: 0:00:39.\n",
            "  Batch   200  of    361.    Elapsed: 0:00:48.\n",
            "  Batch   240  of    361.    Elapsed: 0:00:58.\n",
            "  Batch   280  of    361.    Elapsed: 0:01:07.\n",
            "  Batch   320  of    361.    Elapsed: 0:01:17.\n",
            "  Batch   360  of    361.    Elapsed: 0:01:27.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9971\n",
            "The average recall is: 0.9969\n",
            "The average f1 is: 0.9970\n",
            "  Training epcoh took: 0:01:27\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9607\n",
            "  Recall: 0.9950\n",
            "  F1: 0.9770\n",
            "Category: 1\n",
            "  Precision: 0.2885\n",
            "  Recall: 0.2244\n",
            "  F1: 0.2372\n",
            "The average precision is: 0.6246\n",
            "The average recall is: 0.6097\n",
            "The average f1 is: 0.6071\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9662\n",
            "  Recall: 0.9778\n",
            "  F1: 0.9710\n",
            "Category: 1\n",
            "  Precision: 0.2323\n",
            "  Recall: 0.2121\n",
            "  F1: 0.2121\n",
            "The average precision is: 0.5993\n",
            "The average recall is: 0.5950\n",
            "The average f1 is: 0.5916\n",
            "  Testing took: 0:00:02\n",
            "Current increase 50 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 103 sampled in this category.\n",
            "After up-sample, there are 6798 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1545\n",
            "0.22727272727272727\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "5253\n",
            "0.7727272727272727\n",
            "\n",
            "(6798, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 08:34:38.057186 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 08:34:38.058266 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 08:34:38.608827 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 08:34:41.102512 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 08:34:41.103865 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    425.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    425.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    425.    Elapsed: 0:00:28.\n",
            "  Batch   160  of    425.    Elapsed: 0:00:38.\n",
            "  Batch   200  of    425.    Elapsed: 0:00:47.\n",
            "  Batch   240  of    425.    Elapsed: 0:00:57.\n",
            "  Batch   280  of    425.    Elapsed: 0:01:07.\n",
            "  Batch   320  of    425.    Elapsed: 0:01:17.\n",
            "  Batch   360  of    425.    Elapsed: 0:01:26.\n",
            "  Batch   400  of    425.    Elapsed: 0:01:36.\n",
            "\n",
            "  Average training loss: 0.14\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.84\n",
            "  Recall: 0.78\n",
            "  F1: 0.79\n",
            "Category: 1\n",
            "  Precision: 0.95\n",
            "  Recall: 1.00\n",
            "  F1: 0.97\n",
            "The average precision is: 0.8935\n",
            "The average recall is: 0.8865\n",
            "The average f1 is: 0.8813\n",
            "  Training epcoh took: 0:01:42\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9599\n",
            "  Recall: 0.9896\n",
            "  F1: 0.9739\n",
            "Category: 1\n",
            "  Precision: 0.2885\n",
            "  Recall: 0.2179\n",
            "  F1: 0.2372\n",
            "The average precision is: 0.6242\n",
            "The average recall is: 0.6038\n",
            "The average f1 is: 0.6055\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    425.    Elapsed: 0:00:11.\n",
            "  Batch    80  of    425.    Elapsed: 0:00:21.\n",
            "  Batch   120  of    425.    Elapsed: 0:00:30.\n",
            "  Batch   160  of    425.    Elapsed: 0:00:40.\n",
            "  Batch   200  of    425.    Elapsed: 0:00:49.\n",
            "  Batch   240  of    425.    Elapsed: 0:00:58.\n",
            "  Batch   280  of    425.    Elapsed: 0:01:07.\n",
            "  Batch   320  of    425.    Elapsed: 0:01:16.\n",
            "  Batch   360  of    425.    Elapsed: 0:01:25.\n",
            "  Batch   400  of    425.    Elapsed: 0:01:34.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.98\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9912\n",
            "The average recall is: 0.9884\n",
            "The average f1 is: 0.9893\n",
            "  Training epcoh took: 0:01:40\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9621\n",
            "  Recall: 0.9945\n",
            "  F1: 0.9773\n",
            "Category: 1\n",
            "  Precision: 0.2564\n",
            "  Recall: 0.2115\n",
            "  F1: 0.2231\n",
            "The average precision is: 0.6092\n",
            "The average recall is: 0.6030\n",
            "The average f1 is: 0.6002\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    425.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    425.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    425.    Elapsed: 0:00:26.\n",
            "  Batch   160  of    425.    Elapsed: 0:00:35.\n",
            "  Batch   200  of    425.    Elapsed: 0:00:44.\n",
            "  Batch   240  of    425.    Elapsed: 0:00:53.\n",
            "  Batch   280  of    425.    Elapsed: 0:01:02.\n",
            "  Batch   320  of    425.    Elapsed: 0:01:11.\n",
            "  Batch   360  of    425.    Elapsed: 0:01:20.\n",
            "  Batch   400  of    425.    Elapsed: 0:01:30.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.98\n",
            "  Recall: 0.98\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9907\n",
            "The average recall is: 0.9914\n",
            "The average f1 is: 0.9909\n",
            "  Training epcoh took: 0:01:37\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9630\n",
            "  Recall: 0.9949\n",
            "  F1: 0.9781\n",
            "Category: 1\n",
            "  Precision: 0.2885\n",
            "  Recall: 0.2372\n",
            "  F1: 0.2487\n",
            "The average precision is: 0.6257\n",
            "The average recall is: 0.6160\n",
            "The average f1 is: 0.6134\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    425.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    425.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    425.    Elapsed: 0:00:28.\n",
            "  Batch   160  of    425.    Elapsed: 0:00:37.\n",
            "  Batch   200  of    425.    Elapsed: 0:00:47.\n",
            "  Batch   240  of    425.    Elapsed: 0:00:57.\n",
            "  Batch   280  of    425.    Elapsed: 0:01:06.\n",
            "  Batch   320  of    425.    Elapsed: 0:01:15.\n",
            "  Batch   360  of    425.    Elapsed: 0:01:25.\n",
            "  Batch   400  of    425.    Elapsed: 0:01:34.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9925\n",
            "The average recall is: 0.9925\n",
            "The average f1 is: 0.9925\n",
            "  Training epcoh took: 0:01:40\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9595\n",
            "  Recall: 0.9952\n",
            "  F1: 0.9761\n",
            "Category: 1\n",
            "  Precision: 0.3077\n",
            "  Recall: 0.2212\n",
            "  F1: 0.2462\n",
            "The average precision is: 0.6336\n",
            "The average recall is: 0.6082\n",
            "The average f1 is: 0.6111\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.94\n",
            "Category: 0\n",
            "  Precision: 0.9601\n",
            "  Recall: 0.9757\n",
            "  F1: 0.9668\n",
            "Category: 1\n",
            "  Precision: 0.2222\n",
            "  Recall: 0.1667\n",
            "  F1: 0.1838\n",
            "The average precision is: 0.5912\n",
            "The average recall is: 0.5712\n",
            "The average f1 is: 0.5753\n",
            "  Testing took: 0:00:02\n",
            "Current increase 60 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 103 sampled in this category.\n",
            "After up-sample, there are 7828 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1545\n",
            "0.19736842105263158\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "6283\n",
            "0.8026315789473685\n",
            "\n",
            "(7828, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 08:41:27.965163 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 08:41:27.966355 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 08:41:28.463518 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 08:41:30.963410 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 08:41:30.964459 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    490.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    490.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    490.    Elapsed: 0:00:28.\n",
            "  Batch   160  of    490.    Elapsed: 0:00:38.\n",
            "  Batch   200  of    490.    Elapsed: 0:00:48.\n",
            "  Batch   240  of    490.    Elapsed: 0:00:57.\n",
            "  Batch   280  of    490.    Elapsed: 0:01:07.\n",
            "  Batch   320  of    490.    Elapsed: 0:01:16.\n",
            "  Batch   360  of    490.    Elapsed: 0:01:26.\n",
            "  Batch   400  of    490.    Elapsed: 0:01:35.\n",
            "  Batch   440  of    490.    Elapsed: 0:01:45.\n",
            "  Batch   480  of    490.    Elapsed: 0:01:55.\n",
            "\n",
            "  Average training loss: 0.14\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.84\n",
            "  Recall: 0.77\n",
            "  F1: 0.79\n",
            "Category: 1\n",
            "  Precision: 0.95\n",
            "  Recall: 0.99\n",
            "  F1: 0.97\n",
            "The average precision is: 0.8970\n",
            "The average recall is: 0.8790\n",
            "The average f1 is: 0.8785\n",
            "  Training epcoh took: 0:01:57\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.94\n",
            "Category: 0\n",
            "  Precision: 0.9868\n",
            "  Recall: 0.9444\n",
            "  F1: 0.9638\n",
            "Category: 1\n",
            "  Precision: 0.3974\n",
            "  Recall: 0.4936\n",
            "  F1: 0.4163\n",
            "The average precision is: 0.6921\n",
            "The average recall is: 0.7190\n",
            "The average f1 is: 0.6901\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    490.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    490.    Elapsed: 0:00:20.\n",
            "  Batch   120  of    490.    Elapsed: 0:00:30.\n",
            "  Batch   160  of    490.    Elapsed: 0:00:40.\n",
            "  Batch   200  of    490.    Elapsed: 0:00:49.\n",
            "  Batch   240  of    490.    Elapsed: 0:00:59.\n",
            "  Batch   280  of    490.    Elapsed: 0:01:09.\n",
            "  Batch   320  of    490.    Elapsed: 0:01:18.\n",
            "  Batch   360  of    490.    Elapsed: 0:01:28.\n",
            "  Batch   400  of    490.    Elapsed: 0:01:38.\n",
            "  Batch   440  of    490.    Elapsed: 0:01:48.\n",
            "  Batch   480  of    490.    Elapsed: 0:01:57.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.98\n",
            "  Recall: 0.97\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9892\n",
            "The average recall is: 0.9860\n",
            "The average f1 is: 0.9869\n",
            "  Training epcoh took: 0:01:59\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.97\n",
            "Category: 0\n",
            "  Precision: 0.9646\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9814\n",
            "Category: 1\n",
            "  Precision: 0.3462\n",
            "  Recall: 0.2692\n",
            "  F1: 0.2949\n",
            "The average precision is: 0.6554\n",
            "The average recall is: 0.6346\n",
            "The average f1 is: 0.6381\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    490.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    490.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    490.    Elapsed: 0:00:29.\n",
            "  Batch   160  of    490.    Elapsed: 0:00:39.\n",
            "  Batch   200  of    490.    Elapsed: 0:00:49.\n",
            "  Batch   240  of    490.    Elapsed: 0:00:58.\n",
            "  Batch   280  of    490.    Elapsed: 0:01:08.\n",
            "  Batch   320  of    490.    Elapsed: 0:01:18.\n",
            "  Batch   360  of    490.    Elapsed: 0:01:27.\n",
            "  Batch   400  of    490.    Elapsed: 0:01:37.\n",
            "  Batch   440  of    490.    Elapsed: 0:01:46.\n",
            "  Batch   480  of    490.    Elapsed: 0:01:55.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.96\n",
            "  Recall: 0.96\n",
            "  F1: 0.96\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9809\n",
            "The average recall is: 0.9798\n",
            "The average f1 is: 0.9802\n",
            "  Training epcoh took: 0:01:57\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9619\n",
            "  Recall: 0.9950\n",
            "  F1: 0.9777\n",
            "Category: 1\n",
            "  Precision: 0.3077\n",
            "  Recall: 0.1923\n",
            "  F1: 0.2295\n",
            "The average precision is: 0.6348\n",
            "The average recall is: 0.5937\n",
            "The average f1 is: 0.6036\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    490.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    490.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    490.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    490.    Elapsed: 0:00:36.\n",
            "  Batch   200  of    490.    Elapsed: 0:00:45.\n",
            "  Batch   240  of    490.    Elapsed: 0:00:54.\n",
            "  Batch   280  of    490.    Elapsed: 0:01:03.\n",
            "  Batch   320  of    490.    Elapsed: 0:01:11.\n",
            "  Batch   360  of    490.    Elapsed: 0:01:20.\n",
            "  Batch   400  of    490.    Elapsed: 0:01:30.\n",
            "  Batch   440  of    490.    Elapsed: 0:01:39.\n",
            "  Batch   480  of    490.    Elapsed: 0:01:48.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.96\n",
            "  Recall: 0.96\n",
            "  F1: 0.96\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9822\n",
            "The average recall is: 0.9819\n",
            "The average f1 is: 0.9819\n",
            "  Training epcoh took: 0:01:50\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9617\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9799\n",
            "Category: 1\n",
            "  Precision: 0.1923\n",
            "  Recall: 0.1410\n",
            "  F1: 0.1590\n",
            "The average precision is: 0.5770\n",
            "The average recall is: 0.5705\n",
            "The average f1 is: 0.5694\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9589\n",
            "  Recall: 0.9840\n",
            "  F1: 0.9704\n",
            "Category: 1\n",
            "  Precision: 0.2121\n",
            "  Recall: 0.1616\n",
            "  F1: 0.1737\n",
            "The average precision is: 0.5855\n",
            "The average recall is: 0.5728\n",
            "The average f1 is: 0.5721\n",
            "  Testing took: 0:00:02\n",
            "Current increase 70 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 103 sampled in this category.\n",
            "After up-sample, there are 8858 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1545\n",
            "0.1744186046511628\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "7313\n",
            "0.8255813953488372\n",
            "\n",
            "(8858, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 08:49:22.607593 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 08:49:22.608743 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 08:49:23.933348 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 08:49:26.459997 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 08:49:26.460772 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    554.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    554.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    554.    Elapsed: 0:00:27.\n",
            "  Batch   160  of    554.    Elapsed: 0:00:36.\n",
            "  Batch   200  of    554.    Elapsed: 0:00:46.\n",
            "  Batch   240  of    554.    Elapsed: 0:00:55.\n",
            "  Batch   280  of    554.    Elapsed: 0:01:04.\n",
            "  Batch   320  of    554.    Elapsed: 0:01:14.\n",
            "  Batch   360  of    554.    Elapsed: 0:01:23.\n",
            "  Batch   400  of    554.    Elapsed: 0:01:33.\n",
            "  Batch   440  of    554.    Elapsed: 0:01:42.\n",
            "  Batch   480  of    554.    Elapsed: 0:01:52.\n",
            "  Batch   520  of    554.    Elapsed: 0:02:01.\n",
            "\n",
            "  Average training loss: 0.12\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.82\n",
            "  Recall: 0.78\n",
            "  F1: 0.79\n",
            "Category: 1\n",
            "  Precision: 0.96\n",
            "  Recall: 0.99\n",
            "  F1: 0.98\n",
            "The average precision is: 0.8922\n",
            "The average recall is: 0.8851\n",
            "The average f1 is: 0.8827\n",
            "  Training epcoh took: 0:02:09\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.94\n",
            "Category: 0\n",
            "  Precision: 0.9748\n",
            "  Recall: 0.9602\n",
            "  F1: 0.9655\n",
            "Category: 1\n",
            "  Precision: 0.3814\n",
            "  Recall: 0.3846\n",
            "  F1: 0.3526\n",
            "The average precision is: 0.6781\n",
            "The average recall is: 0.6724\n",
            "The average f1 is: 0.6590\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    554.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    554.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    554.    Elapsed: 0:00:28.\n",
            "  Batch   160  of    554.    Elapsed: 0:00:38.\n",
            "  Batch   200  of    554.    Elapsed: 0:00:48.\n",
            "  Batch   240  of    554.    Elapsed: 0:00:57.\n",
            "  Batch   280  of    554.    Elapsed: 0:01:07.\n",
            "  Batch   320  of    554.    Elapsed: 0:01:17.\n",
            "  Batch   360  of    554.    Elapsed: 0:01:27.\n",
            "  Batch   400  of    554.    Elapsed: 0:01:36.\n",
            "  Batch   440  of    554.    Elapsed: 0:01:46.\n",
            "  Batch   480  of    554.    Elapsed: 0:01:56.\n",
            "  Batch   520  of    554.    Elapsed: 0:02:05.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.95\n",
            "  Recall: 0.94\n",
            "  F1: 0.94\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9727\n",
            "The average recall is: 0.9708\n",
            "The average f1 is: 0.9711\n",
            "  Training epcoh took: 0:02:13\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9636\n",
            "  Recall: 0.9952\n",
            "  F1: 0.9782\n",
            "Category: 1\n",
            "  Precision: 0.2692\n",
            "  Recall: 0.2308\n",
            "  F1: 0.2436\n",
            "The average precision is: 0.6164\n",
            "The average recall is: 0.6130\n",
            "The average f1 is: 0.6109\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    554.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    554.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    554.    Elapsed: 0:00:29.\n",
            "  Batch   160  of    554.    Elapsed: 0:00:39.\n",
            "  Batch   200  of    554.    Elapsed: 0:00:48.\n",
            "  Batch   240  of    554.    Elapsed: 0:00:58.\n",
            "  Batch   280  of    554.    Elapsed: 0:01:08.\n",
            "  Batch   320  of    554.    Elapsed: 0:01:17.\n",
            "  Batch   360  of    554.    Elapsed: 0:01:27.\n",
            "  Batch   400  of    554.    Elapsed: 0:01:37.\n",
            "  Batch   440  of    554.    Elapsed: 0:01:46.\n",
            "  Batch   480  of    554.    Elapsed: 0:01:56.\n",
            "  Batch   520  of    554.    Elapsed: 0:02:06.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.95\n",
            "  Recall: 0.95\n",
            "  F1: 0.95\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9768\n",
            "The average recall is: 0.9754\n",
            "The average f1 is: 0.9758\n",
            "  Training epcoh took: 0:02:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9587\n",
            "  Recall: 0.9974\n",
            "  F1: 0.9767\n",
            "Category: 1\n",
            "  Precision: 0.2692\n",
            "  Recall: 0.2308\n",
            "  F1: 0.2436\n",
            "The average precision is: 0.6139\n",
            "The average recall is: 0.6141\n",
            "The average f1 is: 0.6102\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    554.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    554.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    554.    Elapsed: 0:00:29.\n",
            "  Batch   160  of    554.    Elapsed: 0:00:38.\n",
            "  Batch   200  of    554.    Elapsed: 0:00:47.\n",
            "  Batch   240  of    554.    Elapsed: 0:00:57.\n",
            "  Batch   280  of    554.    Elapsed: 0:01:06.\n",
            "  Batch   320  of    554.    Elapsed: 0:01:15.\n",
            "  Batch   360  of    554.    Elapsed: 0:01:25.\n",
            "  Batch   400  of    554.    Elapsed: 0:01:34.\n",
            "  Batch   440  of    554.    Elapsed: 0:01:43.\n",
            "  Batch   480  of    554.    Elapsed: 0:01:52.\n",
            "  Batch   520  of    554.    Elapsed: 0:02:02.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.95\n",
            "  Recall: 0.95\n",
            "  F1: 0.95\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9745\n",
            "The average recall is: 0.9740\n",
            "The average f1 is: 0.9742\n",
            "  Training epcoh took: 0:02:10\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9594\n",
            "  Recall: 0.9944\n",
            "  F1: 0.9761\n",
            "Category: 1\n",
            "  Precision: 0.2179\n",
            "  Recall: 0.1538\n",
            "  F1: 0.1758\n",
            "The average precision is: 0.5887\n",
            "The average recall is: 0.5741\n",
            "The average f1 is: 0.5759\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9664\n",
            "  Recall: 0.9822\n",
            "  F1: 0.9734\n",
            "Category: 1\n",
            "  Precision: 0.3333\n",
            "  Recall: 0.2803\n",
            "  F1: 0.2848\n",
            "The average precision is: 0.6499\n",
            "The average recall is: 0.6313\n",
            "The average f1 is: 0.6291\n",
            "  Testing took: 0:00:02\n",
            "Current increase 80 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 103 sampled in this category.\n",
            "After up-sample, there are 9888 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1545\n",
            "0.15625\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "8343\n",
            "0.84375\n",
            "\n",
            "(9888, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 08:58:21.431536 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 08:58:21.432586 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 08:58:21.548952 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 08:58:24.080668 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 08:58:24.081444 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    618.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    618.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    618.    Elapsed: 0:00:31.\n",
            "  Batch   160  of    618.    Elapsed: 0:00:41.\n",
            "  Batch   200  of    618.    Elapsed: 0:00:51.\n",
            "  Batch   240  of    618.    Elapsed: 0:01:01.\n",
            "  Batch   280  of    618.    Elapsed: 0:01:10.\n",
            "  Batch   320  of    618.    Elapsed: 0:01:20.\n",
            "  Batch   360  of    618.    Elapsed: 0:01:30.\n",
            "  Batch   400  of    618.    Elapsed: 0:01:39.\n",
            "  Batch   440  of    618.    Elapsed: 0:01:49.\n",
            "  Batch   480  of    618.    Elapsed: 0:01:59.\n",
            "  Batch   520  of    618.    Elapsed: 0:02:09.\n",
            "  Batch   560  of    618.    Elapsed: 0:02:19.\n",
            "  Batch   600  of    618.    Elapsed: 0:02:28.\n",
            "\n",
            "  Average training loss: 0.10\n",
            "  Accuracy: 0.97\n",
            "Category: 0\n",
            "  Precision: 0.87\n",
            "  Recall: 0.81\n",
            "  F1: 0.83\n",
            "Category: 1\n",
            "  Precision: 0.97\n",
            "  Recall: 0.99\n",
            "  F1: 0.98\n",
            "The average precision is: 0.9211\n",
            "The average recall is: 0.9044\n",
            "The average f1 is: 0.9052\n",
            "  Training epcoh took: 0:02:33\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.94\n",
            "Category: 0\n",
            "  Precision: 0.9711\n",
            "  Recall: 0.9610\n",
            "  F1: 0.9653\n",
            "Category: 1\n",
            "  Precision: 0.2981\n",
            "  Recall: 0.3558\n",
            "  F1: 0.3045\n",
            "The average precision is: 0.6346\n",
            "The average recall is: 0.6584\n",
            "The average f1 is: 0.6349\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    618.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    618.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    618.    Elapsed: 0:00:29.\n",
            "  Batch   160  of    618.    Elapsed: 0:00:39.\n",
            "  Batch   200  of    618.    Elapsed: 0:00:48.\n",
            "  Batch   240  of    618.    Elapsed: 0:00:58.\n",
            "  Batch   280  of    618.    Elapsed: 0:01:07.\n",
            "  Batch   320  of    618.    Elapsed: 0:01:17.\n",
            "  Batch   360  of    618.    Elapsed: 0:01:26.\n",
            "  Batch   400  of    618.    Elapsed: 0:01:36.\n",
            "  Batch   440  of    618.    Elapsed: 0:01:45.\n",
            "  Batch   480  of    618.    Elapsed: 0:01:54.\n",
            "  Batch   520  of    618.    Elapsed: 0:02:04.\n",
            "  Batch   560  of    618.    Elapsed: 0:02:13.\n",
            "  Batch   600  of    618.    Elapsed: 0:02:23.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.93\n",
            "  Recall: 0.93\n",
            "  F1: 0.93\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9649\n",
            "The average recall is: 0.9636\n",
            "The average f1 is: 0.9640\n",
            "  Training epcoh took: 0:02:27\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9683\n",
            "  Recall: 0.9922\n",
            "  F1: 0.9792\n",
            "Category: 1\n",
            "  Precision: 0.2596\n",
            "  Recall: 0.2244\n",
            "  F1: 0.2317\n",
            "The average precision is: 0.6139\n",
            "The average recall is: 0.6083\n",
            "The average f1 is: 0.6055\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    618.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    618.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    618.    Elapsed: 0:00:29.\n",
            "  Batch   160  of    618.    Elapsed: 0:00:39.\n",
            "  Batch   200  of    618.    Elapsed: 0:00:49.\n",
            "  Batch   240  of    618.    Elapsed: 0:00:59.\n",
            "  Batch   280  of    618.    Elapsed: 0:01:09.\n",
            "  Batch   320  of    618.    Elapsed: 0:01:18.\n",
            "  Batch   360  of    618.    Elapsed: 0:01:28.\n",
            "  Batch   400  of    618.    Elapsed: 0:01:37.\n",
            "  Batch   440  of    618.    Elapsed: 0:01:46.\n",
            "  Batch   480  of    618.    Elapsed: 0:01:55.\n",
            "  Batch   520  of    618.    Elapsed: 0:02:04.\n",
            "  Batch   560  of    618.    Elapsed: 0:02:13.\n",
            "  Batch   600  of    618.    Elapsed: 0:02:21.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.93\n",
            "  Recall: 0.92\n",
            "  F1: 0.93\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9633\n",
            "The average recall is: 0.9625\n",
            "The average f1 is: 0.9628\n",
            "  Training epcoh took: 0:02:25\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9559\n",
            "  Recall: 0.9976\n",
            "  F1: 0.9755\n",
            "Category: 1\n",
            "  Precision: 0.2308\n",
            "  Recall: 0.1346\n",
            "  F1: 0.1667\n",
            "The average precision is: 0.5933\n",
            "The average recall is: 0.5661\n",
            "The average f1 is: 0.5711\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    618.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    618.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    618.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    618.    Elapsed: 0:00:34.\n",
            "  Batch   200  of    618.    Elapsed: 0:00:42.\n",
            "  Batch   240  of    618.    Elapsed: 0:00:51.\n",
            "  Batch   280  of    618.    Elapsed: 0:00:59.\n",
            "  Batch   320  of    618.    Elapsed: 0:01:07.\n",
            "  Batch   360  of    618.    Elapsed: 0:01:16.\n",
            "  Batch   400  of    618.    Elapsed: 0:01:24.\n",
            "  Batch   440  of    618.    Elapsed: 0:01:33.\n",
            "  Batch   480  of    618.    Elapsed: 0:01:41.\n",
            "  Batch   520  of    618.    Elapsed: 0:01:49.\n",
            "  Batch   560  of    618.    Elapsed: 0:01:57.\n",
            "  Batch   600  of    618.    Elapsed: 0:02:06.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.93\n",
            "  Recall: 0.93\n",
            "  F1: 0.93\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9631\n",
            "The average recall is: 0.9633\n",
            "The average f1 is: 0.9631\n",
            "  Training epcoh took: 0:02:09\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.97\n",
            "Category: 0\n",
            "  Precision: 0.9672\n",
            "  Recall: 0.9974\n",
            "  F1: 0.9816\n",
            "Category: 1\n",
            "  Precision: 0.3462\n",
            "  Recall: 0.2756\n",
            "  F1: 0.3000\n",
            "The average precision is: 0.6567\n",
            "The average recall is: 0.6365\n",
            "The average f1 is: 0.6408\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.93\n",
            "Category: 0\n",
            "  Precision: 0.9585\n",
            "  Recall: 0.9719\n",
            "  F1: 0.9641\n",
            "Category: 1\n",
            "  Precision: 0.2172\n",
            "  Recall: 0.2020\n",
            "  F1: 0.1949\n",
            "The average precision is: 0.5879\n",
            "The average recall is: 0.5870\n",
            "The average f1 is: 0.5795\n",
            "  Testing took: 0:00:02\n",
            "Current increase 90 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 103 sampled in this category.\n",
            "After up-sample, there are 10918 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1545\n",
            "0.14150943396226415\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "9373\n",
            "0.8584905660377359\n",
            "\n",
            "(10918, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 09:08:06.620725 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 09:08:06.621844 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 09:08:06.700091 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 09:08:09.285914 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 09:08:09.286655 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    683.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    683.    Elapsed: 0:00:16.\n",
            "  Batch   120  of    683.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    683.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    683.    Elapsed: 0:00:41.\n",
            "  Batch   240  of    683.    Elapsed: 0:00:49.\n",
            "  Batch   280  of    683.    Elapsed: 0:00:57.\n",
            "  Batch   320  of    683.    Elapsed: 0:01:06.\n",
            "  Batch   360  of    683.    Elapsed: 0:01:14.\n",
            "  Batch   400  of    683.    Elapsed: 0:01:22.\n",
            "  Batch   440  of    683.    Elapsed: 0:01:31.\n",
            "  Batch   480  of    683.    Elapsed: 0:01:39.\n",
            "  Batch   520  of    683.    Elapsed: 0:01:47.\n",
            "  Batch   560  of    683.    Elapsed: 0:01:55.\n",
            "  Batch   600  of    683.    Elapsed: 0:02:04.\n",
            "  Batch   640  of    683.    Elapsed: 0:02:12.\n",
            "  Batch   680  of    683.    Elapsed: 0:02:20.\n",
            "\n",
            "  Average training loss: 0.09\n",
            "  Accuracy: 0.97\n",
            "Category: 0\n",
            "  Precision: 0.79\n",
            "  Recall: 0.75\n",
            "  F1: 0.76\n",
            "Category: 1\n",
            "  Precision: 0.97\n",
            "  Recall: 1.00\n",
            "  F1: 0.98\n",
            "The average precision is: 0.8794\n",
            "The average recall is: 0.8729\n",
            "The average f1 is: 0.8713\n",
            "  Training epcoh took: 0:02:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9618\n",
            "  Recall: 0.9915\n",
            "  F1: 0.9760\n",
            "Category: 1\n",
            "  Precision: 0.2372\n",
            "  Recall: 0.1987\n",
            "  F1: 0.2130\n",
            "The average precision is: 0.5995\n",
            "The average recall is: 0.5951\n",
            "The average f1 is: 0.5945\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    683.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    683.    Elapsed: 0:00:16.\n",
            "  Batch   120  of    683.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    683.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    683.    Elapsed: 0:00:41.\n",
            "  Batch   240  of    683.    Elapsed: 0:00:49.\n",
            "  Batch   280  of    683.    Elapsed: 0:00:58.\n",
            "  Batch   320  of    683.    Elapsed: 0:01:06.\n",
            "  Batch   360  of    683.    Elapsed: 0:01:14.\n",
            "  Batch   400  of    683.    Elapsed: 0:01:22.\n",
            "  Batch   440  of    683.    Elapsed: 0:01:30.\n",
            "  Batch   480  of    683.    Elapsed: 0:01:39.\n",
            "  Batch   520  of    683.    Elapsed: 0:01:47.\n",
            "  Batch   560  of    683.    Elapsed: 0:01:55.\n",
            "  Batch   600  of    683.    Elapsed: 0:02:03.\n",
            "  Batch   640  of    683.    Elapsed: 0:02:11.\n",
            "  Batch   680  of    683.    Elapsed: 0:02:20.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.92\n",
            "  Recall: 0.92\n",
            "  F1: 0.92\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9598\n",
            "The average recall is: 0.9589\n",
            "The average f1 is: 0.9591\n",
            "  Training epcoh took: 0:02:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9630\n",
            "  Recall: 0.9947\n",
            "  F1: 0.9781\n",
            "Category: 1\n",
            "  Precision: 0.3269\n",
            "  Recall: 0.2692\n",
            "  F1: 0.2885\n",
            "The average precision is: 0.6449\n",
            "The average recall is: 0.6320\n",
            "The average f1 is: 0.6333\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    683.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    683.    Elapsed: 0:00:16.\n",
            "  Batch   120  of    683.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    683.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    683.    Elapsed: 0:00:41.\n",
            "  Batch   240  of    683.    Elapsed: 0:00:49.\n",
            "  Batch   280  of    683.    Elapsed: 0:00:57.\n",
            "  Batch   320  of    683.    Elapsed: 0:01:06.\n",
            "  Batch   360  of    683.    Elapsed: 0:01:14.\n",
            "  Batch   400  of    683.    Elapsed: 0:01:22.\n",
            "  Batch   440  of    683.    Elapsed: 0:01:30.\n",
            "  Batch   480  of    683.    Elapsed: 0:01:38.\n",
            "  Batch   520  of    683.    Elapsed: 0:01:47.\n",
            "  Batch   560  of    683.    Elapsed: 0:01:55.\n",
            "  Batch   600  of    683.    Elapsed: 0:02:03.\n",
            "  Batch   640  of    683.    Elapsed: 0:02:11.\n",
            "  Batch   680  of    683.    Elapsed: 0:02:19.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.90\n",
            "  Recall: 0.90\n",
            "  F1: 0.90\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9509\n",
            "The average recall is: 0.9506\n",
            "The average f1 is: 0.9507\n",
            "  Training epcoh took: 0:02:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9626\n",
            "  Recall: 0.9897\n",
            "  F1: 0.9751\n",
            "Category: 1\n",
            "  Precision: 0.2692\n",
            "  Recall: 0.2179\n",
            "  F1: 0.2359\n",
            "The average precision is: 0.6159\n",
            "The average recall is: 0.6038\n",
            "The average f1 is: 0.6055\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    683.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    683.    Elapsed: 0:00:16.\n",
            "  Batch   120  of    683.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    683.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    683.    Elapsed: 0:00:41.\n",
            "  Batch   240  of    683.    Elapsed: 0:00:49.\n",
            "  Batch   280  of    683.    Elapsed: 0:00:57.\n",
            "  Batch   320  of    683.    Elapsed: 0:01:06.\n",
            "  Batch   360  of    683.    Elapsed: 0:01:14.\n",
            "  Batch   400  of    683.    Elapsed: 0:01:22.\n",
            "  Batch   440  of    683.    Elapsed: 0:01:30.\n",
            "  Batch   480  of    683.    Elapsed: 0:01:39.\n",
            "  Batch   520  of    683.    Elapsed: 0:01:47.\n",
            "  Batch   560  of    683.    Elapsed: 0:01:55.\n",
            "  Batch   600  of    683.    Elapsed: 0:02:03.\n",
            "  Batch   640  of    683.    Elapsed: 0:02:11.\n",
            "  Batch   680  of    683.    Elapsed: 0:02:20.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.92\n",
            "  Recall: 0.92\n",
            "  F1: 0.92\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9590\n",
            "The average recall is: 0.9588\n",
            "The average f1 is: 0.9588\n",
            "  Training epcoh took: 0:02:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9631\n",
            "  Recall: 0.9923\n",
            "  F1: 0.9769\n",
            "Category: 1\n",
            "  Precision: 0.2885\n",
            "  Recall: 0.2628\n",
            "  F1: 0.2692\n",
            "The average precision is: 0.6258\n",
            "The average recall is: 0.6276\n",
            "The average f1 is: 0.6231\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.94\n",
            "Category: 0\n",
            "  Precision: 0.9610\n",
            "  Recall: 0.9761\n",
            "  F1: 0.9671\n",
            "Category: 1\n",
            "  Precision: 0.2576\n",
            "  Recall: 0.2374\n",
            "  F1: 0.2313\n",
            "The average precision is: 0.6093\n",
            "The average recall is: 0.6067\n",
            "The average f1 is: 0.5992\n",
            "  Testing took: 0:00:02\n",
            "Successfully save file ./BertSearchResult/5_16_2e-05_5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5_K4mVl0WdeC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "outputId": "203b4107-6a44-4a39-d1ce-f5ea357bf42a"
      },
      "source": [
        "all_metrics_one"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: defaultdict(None,\n",
              "             {'train_loss_values': [0.02451061978212838,\n",
              "               0.02451061978212838,\n",
              "               0.014020035567792874,\n",
              "               0.014020035567792874,\n",
              "               0.014816705897016433,\n",
              "               0.014816705897016433,\n",
              "               0.012088468786582205,\n",
              "               0.012088468786582205],\n",
              "              'train_acc_all': [0.9981796116504854,\n",
              "               0.9981796116504854,\n",
              "               0.9981796116504854,\n",
              "               0.9981796116504854],\n",
              "              'train_precision_all': [{0: 0.9981796116504854, 1: 0.0},\n",
              "               {0: 0.9981796116504854, 1: 0.0},\n",
              "               {0: 0.9981796116504854, 1: 0.0},\n",
              "               {0: 0.9981796116504854, 1: 0.0}],\n",
              "              'train_recall_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}],\n",
              "              'train_f1_all': [{0: 0.9990291262135923, 1: 0.0},\n",
              "               {0: 0.9990291262135923, 1: 0.0},\n",
              "               {0: 0.9990291262135923, 1: 0.0},\n",
              "               {0: 0.9990291262135923, 1: 0.0}],\n",
              "              'val_acc_all': [1.0, 1.0, 1.0, 1.0],\n",
              "              'val_precision_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}],\n",
              "              'val_recall_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}],\n",
              "              'val_f1_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}]})}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F_ge-7JOJQrH"
      },
      "source": [
        "#### Incremental recitfied training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "aDc4WdigZiq0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "batch_size = 32\n",
        "lr = 3e-5\n",
        "test_batch = [test_inputs,test_labels,test_masks]\n",
        "Bert = Bertnn_rectified_info(train_inputs,train_labels,train_masks, validation_inputs,validation_labels,validation_masks,test_batch,batch_size=batch_size,lr=lr)\n",
        "all_metrics_one, all_tesst_metrics = Bert.searchUpsample(100)\n",
        "all_metrics_one['test'] = all_tesst_metrics\n",
        "all_metrics_all_category[section_category] = all_metrics_one\n",
        "if not os.path.exists('BertSearchResult'):\n",
        "  os.makedirs('BertSearchResult')\n",
        "\n",
        "filename = './BertSearchResult/'+'rectified'+'_'+str(section_category)+'_'+str(batch_size) + '_' + str(lr) + '_'  + str(section_category)\n",
        "with open(filename,'w') as file_obj:\n",
        "  json.dump(all_metrics_one,file_obj)\n",
        "  print('Successfully save file %s'%(filename))\n",
        "\n",
        "del Bert\n",
        "torch.cuda.empty_cache() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pCR0i2rpJQrK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "d1085ac1-8fce-4aa1-ad12-b13ab71cb2bc"
      },
      "source": [
        "all_metrics_one['test']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: [[{0: 0.9980769230769231, 1: 0.0}],\n",
              "  [{0: 1.0, 1: 0.0}],\n",
              "  [{0: 0.998974358974359, 1: 0.0}],\n",
              "  [0.9980769230769231]]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6kfAWcW0WSQm"
      },
      "source": [
        "### For 'ServiceAvailable'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bXtcQIcrWeDc"
      },
      "source": [
        "#### Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EM42X_VfWeDd",
        "colab": {}
      },
      "source": [
        "# Use train_test_split to split our data into train and validation and test sets for\n",
        "# training\n",
        "section_category = 0\n",
        "labels = labels_single[section_category]\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 80% for training and 20% for validation.\n",
        "temp_inputs, test_inputs,  temp_labels, test_labels = train_test_split(input_ids, labels, random_state=1999, test_size=0.2)\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(temp_inputs, temp_labels,random_state=1999, test_size=0.2)\n",
        "\n",
        "# Do the same for the masks.\n",
        "temp_masks, test_masks, temp_labels, _ = train_test_split(attention_masks, labels,random_state=1999, test_size=0.2)\n",
        "\n",
        "train_masks, validation_masks, _, _ = train_test_split(temp_masks, temp_labels,random_state=1999, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KSWDRnmrJXkm"
      },
      "source": [
        "#### Normal training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "scrolled": true,
        "id": "ZdUHHRoPZirA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7156f0ab-6c8e-4ea4-9b68-849e5642e802"
      },
      "source": [
        "import json\n",
        "batch_size = 16\n",
        "lr = 2e-5\n",
        "test_batch = [test_inputs,test_labels,test_masks]\n",
        "Bert = Bertnn_info(train_inputs,train_labels,train_masks, validation_inputs,validation_labels,validation_masks,test_batch,batch_size=batch_size,lr=lr)\n",
        "all_metrics_one, all_tesst_metrics = Bert.searchUpsample(100)\n",
        "all_metrics_one['test'] = all_tesst_metrics\n",
        "all_metrics_all_category[section_category] = all_metrics_one\n",
        "if not os.path.exists('BertSearchResult'):\n",
        "  os.makedirs('BertSearchResult')\n",
        "\n",
        "filename = './BertSearchResult/'+str(section_category)+'_'+str(batch_size) + '_' + str(lr) + '_'  + str(section_category)\n",
        "with open(filename,'w') as file_obj:\n",
        "  json.dump(all_metrics_one,file_obj)\n",
        "  print('Successfully save file %s'%(filename))\n",
        "\n",
        "del Bert\n",
        "torch.cuda.empty_cache() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: TITAN RTX\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 09:17:37.160173 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 09:17:37.161261 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 09:17:38.442567 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 09:17:41.046041 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 09:17:41.047022 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current increase 0 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 87 sampled in this category.\n",
            "After up-sample, there are 1648 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1561\n",
            "0.9472087378640777\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "87\n",
            "0.05279126213592233\n",
            "\n",
            "(1648, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 09:17:41.651647 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 09:17:41.652540 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 09:17:41.685500 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 09:17:44.239362 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 09:17:44.240711 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 0.24\n",
            "  Accuracy: 0.94\n",
            "Category: 0\n",
            "  Precision: 0.95\n",
            "  Recall: 0.99\n",
            "  F1: 0.96\n",
            "Category: 1\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1: 0.00\n",
            "The average precision is: 0.4735\n",
            "The average recall is: 0.4945\n",
            "The average f1 is: 0.4811\n",
            "  Training epcoh took: 0:00:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9471\n",
            "  Recall: 1.0000\n",
            "  F1: 0.9720\n",
            "Category: 1\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1: 0.0000\n",
            "The average precision is: 0.4736\n",
            "The average recall is: 0.5000\n",
            "The average f1 is: 0.4860\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 0.14\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.96\n",
            "  Recall: 1.00\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 0.14\n",
            "  Recall: 0.09\n",
            "  F1: 0.11\n",
            "The average precision is: 0.5462\n",
            "The average recall is: 0.5469\n",
            "The average f1 is: 0.5420\n",
            "  Training epcoh took: 0:00:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9538\n",
            "  Recall: 0.9976\n",
            "  F1: 0.9748\n",
            "Category: 1\n",
            "  Precision: 0.1154\n",
            "  Recall: 0.0705\n",
            "  F1: 0.0833\n",
            "The average precision is: 0.5346\n",
            "The average recall is: 0.5341\n",
            "The average f1 is: 0.5290\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:17.\n",
            "\n",
            "  Average training loss: 0.09\n",
            "  Accuracy: 0.98\n",
            "Category: 0\n",
            "  Precision: 0.98\n",
            "  Recall: 1.00\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.38\n",
            "  Recall: 0.34\n",
            "  F1: 0.35\n",
            "The average precision is: 0.6802\n",
            "The average recall is: 0.6674\n",
            "The average f1 is: 0.6688\n",
            "  Training epcoh took: 0:00:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9578\n",
            "  Recall: 0.9928\n",
            "  F1: 0.9738\n",
            "Category: 1\n",
            "  Precision: 0.1923\n",
            "  Recall: 0.1250\n",
            "  F1: 0.1436\n",
            "The average precision is: 0.5750\n",
            "The average recall is: 0.5589\n",
            "The average f1 is: 0.5587\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    103.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    103.    Elapsed: 0:00:17.\n",
            "\n",
            "  Average training loss: 0.05\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 1.00\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 0.53\n",
            "  Recall: 0.50\n",
            "  F1: 0.51\n",
            "The average precision is: 0.7592\n",
            "The average recall is: 0.7496\n",
            "The average f1 is: 0.7513\n",
            "  Training epcoh took: 0:00:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9633\n",
            "  Recall: 0.9904\n",
            "  F1: 0.9758\n",
            "Category: 1\n",
            "  Precision: 0.2308\n",
            "  Recall: 0.1795\n",
            "  F1: 0.1974\n",
            "The average precision is: 0.5970\n",
            "The average recall is: 0.5849\n",
            "The average f1 is: 0.5866\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9727\n",
            "  Recall: 0.9900\n",
            "  F1: 0.9806\n",
            "Category: 1\n",
            "  Precision: 0.2727\n",
            "  Recall: 0.2424\n",
            "  F1: 0.2475\n",
            "The average precision is: 0.6227\n",
            "The average recall is: 0.6162\n",
            "The average f1 is: 0.6140\n",
            "  Testing took: 0:00:02\n",
            "Current increase 10 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 87 sampled in this category.\n",
            "After up-sample, there are 2518 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1561\n",
            "0.6199364575059572\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "957\n",
            "0.3800635424940429\n",
            "\n",
            "(2518, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 09:19:16.132469 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 09:19:16.133558 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 09:19:16.624287 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 09:19:19.151187 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 09:19:19.151917 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    158.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    158.    Elapsed: 0:00:16.\n",
            "  Batch   120  of    158.    Elapsed: 0:00:25.\n",
            "\n",
            "  Average training loss: 0.31\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.87\n",
            "  Recall: 0.95\n",
            "  F1: 0.90\n",
            "Category: 1\n",
            "  Precision: 0.80\n",
            "  Recall: 0.72\n",
            "  F1: 0.74\n",
            "The average precision is: 0.8364\n",
            "The average recall is: 0.8363\n",
            "The average f1 is: 0.8194\n",
            "  Training epcoh took: 0:00:32\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9636\n",
            "  Recall: 0.9865\n",
            "  F1: 0.9741\n",
            "Category: 1\n",
            "  Precision: 0.1987\n",
            "  Recall: 0.2308\n",
            "  F1: 0.2103\n",
            "The average precision is: 0.5812\n",
            "The average recall is: 0.6086\n",
            "The average f1 is: 0.5922\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    158.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    158.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    158.    Elapsed: 0:00:25.\n",
            "\n",
            "  Average training loss: 0.03\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "The average precision is: 0.9931\n",
            "The average recall is: 0.9940\n",
            "The average f1 is: 0.9929\n",
            "  Training epcoh took: 0:00:33\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9607\n",
            "  Recall: 0.9950\n",
            "  F1: 0.9770\n",
            "Category: 1\n",
            "  Precision: 0.1923\n",
            "  Recall: 0.1410\n",
            "  F1: 0.1590\n",
            "The average precision is: 0.5765\n",
            "The average recall is: 0.5680\n",
            "The average f1 is: 0.5680\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    158.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    158.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    158.    Elapsed: 0:00:25.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9990\n",
            "The average recall is: 0.9987\n",
            "The average f1 is: 0.9988\n",
            "  Training epcoh took: 0:00:33\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9629\n",
            "  Recall: 0.9949\n",
            "  F1: 0.9781\n",
            "Category: 1\n",
            "  Precision: 0.1731\n",
            "  Recall: 0.1538\n",
            "  F1: 0.1538\n",
            "The average precision is: 0.5680\n",
            "The average recall is: 0.5744\n",
            "The average f1 is: 0.5660\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    158.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    158.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    158.    Elapsed: 0:00:25.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9995\n",
            "The average recall is: 0.9997\n",
            "The average f1 is: 0.9996\n",
            "  Training epcoh took: 0:00:33\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9606\n",
            "  Recall: 0.9949\n",
            "  F1: 0.9770\n",
            "Category: 1\n",
            "  Precision: 0.2308\n",
            "  Recall: 0.1667\n",
            "  F1: 0.1859\n",
            "The average precision is: 0.5957\n",
            "The average recall is: 0.5808\n",
            "The average f1 is: 0.5814\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.97\n",
            "Category: 0\n",
            "  Precision: 0.9704\n",
            "  Recall: 0.9939\n",
            "  F1: 0.9815\n",
            "Category: 1\n",
            "  Precision: 0.2727\n",
            "  Recall: 0.2020\n",
            "  F1: 0.2172\n",
            "The average precision is: 0.6216\n",
            "The average recall is: 0.5980\n",
            "The average f1 is: 0.5993\n",
            "  Testing took: 0:00:02\n",
            "Current increase 20 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 87 sampled in this category.\n",
            "After up-sample, there are 3388 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1561\n",
            "0.4607438016528926\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1827\n",
            "0.5392561983471075\n",
            "\n",
            "(3388, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 09:21:37.419603 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 09:21:37.420725 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 09:21:37.464476 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 09:21:40.179473 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 09:21:40.181149 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    212.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    212.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    212.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    212.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    212.    Elapsed: 0:00:41.\n",
            "\n",
            "  Average training loss: 0.24\n",
            "  Accuracy: 0.90\n",
            "Category: 0\n",
            "  Precision: 0.90\n",
            "  Recall: 0.89\n",
            "  F1: 0.88\n",
            "Category: 1\n",
            "  Precision: 0.91\n",
            "  Recall: 0.92\n",
            "  F1: 0.91\n",
            "The average precision is: 0.9091\n",
            "The average recall is: 0.9028\n",
            "The average f1 is: 0.8963\n",
            "  Training epcoh took: 0:00:44\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9676\n",
            "  Recall: 0.9798\n",
            "  F1: 0.9725\n",
            "Category: 1\n",
            "  Precision: 0.2821\n",
            "  Recall: 0.2788\n",
            "  F1: 0.2590\n",
            "The average precision is: 0.6248\n",
            "The average recall is: 0.6293\n",
            "The average f1 is: 0.6158\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    212.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    212.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    212.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    212.    Elapsed: 0:00:34.\n",
            "  Batch   200  of    212.    Elapsed: 0:00:42.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9953\n",
            "The average recall is: 0.9946\n",
            "The average f1 is: 0.9945\n",
            "  Training epcoh took: 0:00:44\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9631\n",
            "  Recall: 0.9872\n",
            "  F1: 0.9745\n",
            "Category: 1\n",
            "  Precision: 0.2308\n",
            "  Recall: 0.2308\n",
            "  F1: 0.2244\n",
            "The average precision is: 0.5969\n",
            "The average recall is: 0.6090\n",
            "The average f1 is: 0.5994\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    212.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    212.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    212.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    212.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    212.    Elapsed: 0:00:42.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9995\n",
            "The average recall is: 0.9993\n",
            "The average f1 is: 0.9994\n",
            "  Training epcoh took: 0:00:44\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9701\n",
            "  Recall: 0.9824\n",
            "  F1: 0.9752\n",
            "Category: 1\n",
            "  Precision: 0.2628\n",
            "  Recall: 0.2885\n",
            "  F1: 0.2628\n",
            "The average precision is: 0.6165\n",
            "The average recall is: 0.6354\n",
            "The average f1 is: 0.6190\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    212.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    212.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    212.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    212.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    212.    Elapsed: 0:00:42.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 1.0000\n",
            "The average recall is: 1.0000\n",
            "The average f1 is: 1.0000\n",
            "  Training epcoh took: 0:00:44\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9635\n",
            "  Recall: 0.9902\n",
            "  F1: 0.9757\n",
            "Category: 1\n",
            "  Precision: 0.2500\n",
            "  Recall: 0.2244\n",
            "  F1: 0.2244\n",
            "The average precision is: 0.6067\n",
            "The average recall is: 0.6073\n",
            "The average f1 is: 0.6001\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9683\n",
            "  Recall: 0.9917\n",
            "  F1: 0.9794\n",
            "Category: 1\n",
            "  Precision: 0.2323\n",
            "  Recall: 0.1818\n",
            "  F1: 0.1991\n",
            "The average precision is: 0.6003\n",
            "The average recall is: 0.5867\n",
            "The average f1 is: 0.5893\n",
            "  Testing took: 0:00:02\n",
            "Current increase 30 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 87 sampled in this category.\n",
            "After up-sample, there are 4258 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1561\n",
            "0.36660403945514325\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "2697\n",
            "0.6333959605448567\n",
            "\n",
            "(4258, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 09:24:44.011939 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 09:24:44.013019 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 09:24:44.100619 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 09:24:46.659103 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 09:24:46.660496 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    267.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    267.    Elapsed: 0:00:16.\n",
            "  Batch   120  of    267.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    267.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    267.    Elapsed: 0:00:41.\n",
            "  Batch   240  of    267.    Elapsed: 0:00:50.\n",
            "\n",
            "  Average training loss: 0.15\n",
            "  Accuracy: 0.93\n",
            "Category: 0\n",
            "  Precision: 0.91\n",
            "  Recall: 0.85\n",
            "  F1: 0.87\n",
            "Category: 1\n",
            "  Precision: 0.94\n",
            "  Recall: 0.98\n",
            "  F1: 0.95\n",
            "The average precision is: 0.9217\n",
            "The average recall is: 0.9183\n",
            "The average f1 is: 0.9100\n",
            "  Training epcoh took: 0:00:55\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9701\n",
            "  Recall: 0.9897\n",
            "  F1: 0.9789\n",
            "Category: 1\n",
            "  Precision: 0.2628\n",
            "  Recall: 0.2692\n",
            "  F1: 0.2500\n",
            "The average precision is: 0.6165\n",
            "The average recall is: 0.6295\n",
            "The average f1 is: 0.6145\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    267.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    267.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    267.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    267.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    267.    Elapsed: 0:00:42.\n",
            "  Batch   240  of    267.    Elapsed: 0:00:50.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9990\n",
            "The average recall is: 0.9984\n",
            "The average f1 is: 0.9986\n",
            "  Training epcoh took: 0:00:56\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.94\n",
            "Category: 0\n",
            "  Precision: 0.9695\n",
            "  Recall: 0.9667\n",
            "  F1: 0.9672\n",
            "Category: 1\n",
            "  Precision: 0.2885\n",
            "  Recall: 0.3077\n",
            "  F1: 0.2808\n",
            "The average precision is: 0.6290\n",
            "The average recall is: 0.6372\n",
            "The average f1 is: 0.6240\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    267.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    267.    Elapsed: 0:00:16.\n",
            "  Batch   120  of    267.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    267.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    267.    Elapsed: 0:00:41.\n",
            "  Batch   240  of    267.    Elapsed: 0:00:50.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9995\n",
            "The average recall is: 0.9990\n",
            "The average f1 is: 0.9992\n",
            "  Training epcoh took: 0:00:55\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9626\n",
            "  Recall: 0.9952\n",
            "  F1: 0.9781\n",
            "Category: 1\n",
            "  Precision: 0.2308\n",
            "  Recall: 0.1603\n",
            "  F1: 0.1846\n",
            "The average precision is: 0.5967\n",
            "The average recall is: 0.5777\n",
            "The average f1 is: 0.5814\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    267.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    267.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    267.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    267.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    267.    Elapsed: 0:00:41.\n",
            "  Batch   240  of    267.    Elapsed: 0:00:50.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 1.0000\n",
            "The average recall is: 1.0000\n",
            "The average f1 is: 1.0000\n",
            "  Training epcoh took: 0:00:55\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9638\n",
            "  Recall: 0.9950\n",
            "  F1: 0.9782\n",
            "Category: 1\n",
            "  Precision: 0.1923\n",
            "  Recall: 0.1923\n",
            "  F1: 0.1923\n",
            "The average precision is: 0.5780\n",
            "The average recall is: 0.5937\n",
            "The average f1 is: 0.5853\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9692\n",
            "  Recall: 0.9901\n",
            "  F1: 0.9789\n",
            "Category: 1\n",
            "  Precision: 0.2424\n",
            "  Recall: 0.2273\n",
            "  F1: 0.2273\n",
            "The average precision is: 0.6058\n",
            "The average recall is: 0.6087\n",
            "The average f1 is: 0.6031\n",
            "  Testing took: 0:00:02\n",
            "Current increase 40 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 87 sampled in this category.\n",
            "After up-sample, there are 5128 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1561\n",
            "0.3044071762870515\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "3567\n",
            "0.6955928237129485\n",
            "\n",
            "(5128, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 09:28:35.011200 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 09:28:35.012255 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 09:28:35.060902 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 09:28:37.553363 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 09:28:37.554132 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    321.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    321.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    321.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    321.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    321.    Elapsed: 0:00:41.\n",
            "  Batch   240  of    321.    Elapsed: 0:00:49.\n",
            "  Batch   280  of    321.    Elapsed: 0:00:58.\n",
            "  Batch   320  of    321.    Elapsed: 0:01:06.\n",
            "\n",
            "  Average training loss: 0.13\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.92\n",
            "  Recall: 0.87\n",
            "  F1: 0.88\n",
            "Category: 1\n",
            "  Precision: 0.96\n",
            "  Recall: 0.98\n",
            "  F1: 0.97\n",
            "The average precision is: 0.9380\n",
            "The average recall is: 0.9286\n",
            "The average f1 is: 0.9250\n",
            "  Training epcoh took: 0:01:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.94\n",
            "Category: 0\n",
            "  Precision: 0.9640\n",
            "  Recall: 0.9766\n",
            "  F1: 0.9694\n",
            "Category: 1\n",
            "  Precision: 0.1987\n",
            "  Recall: 0.1667\n",
            "  F1: 0.1744\n",
            "The average precision is: 0.5813\n",
            "The average recall is: 0.5716\n",
            "The average f1 is: 0.5719\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    321.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    321.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    321.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    321.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    321.    Elapsed: 0:00:42.\n",
            "  Batch   240  of    321.    Elapsed: 0:00:50.\n",
            "  Batch   280  of    321.    Elapsed: 0:00:58.\n",
            "  Batch   320  of    321.    Elapsed: 0:01:07.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9943\n",
            "The average recall is: 0.9935\n",
            "The average f1 is: 0.9938\n",
            "  Training epcoh took: 0:01:07\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9624\n",
            "  Recall: 0.9902\n",
            "  F1: 0.9754\n",
            "Category: 1\n",
            "  Precision: 0.2308\n",
            "  Recall: 0.1474\n",
            "  F1: 0.1731\n",
            "The average precision is: 0.5966\n",
            "The average recall is: 0.5688\n",
            "The average f1 is: 0.5742\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    321.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    321.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    321.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    321.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    321.    Elapsed: 0:00:42.\n",
            "  Batch   240  of    321.    Elapsed: 0:00:50.\n",
            "  Batch   280  of    321.    Elapsed: 0:00:59.\n",
            "  Batch   320  of    321.    Elapsed: 0:01:07.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9980\n",
            "The average recall is: 0.9977\n",
            "The average f1 is: 0.9978\n",
            "  Training epcoh took: 0:01:07\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9654\n",
            "  Recall: 0.9921\n",
            "  F1: 0.9780\n",
            "Category: 1\n",
            "  Precision: 0.2500\n",
            "  Recall: 0.2115\n",
            "  F1: 0.2244\n",
            "The average precision is: 0.6077\n",
            "The average recall is: 0.6018\n",
            "The average f1 is: 0.6012\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    321.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    321.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    321.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    321.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    321.    Elapsed: 0:00:42.\n",
            "  Batch   240  of    321.    Elapsed: 0:00:50.\n",
            "  Batch   280  of    321.    Elapsed: 0:00:58.\n",
            "  Batch   320  of    321.    Elapsed: 0:01:07.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9983\n",
            "The average recall is: 0.9979\n",
            "The average f1 is: 0.9981\n",
            "  Training epcoh took: 0:01:07\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9686\n",
            "  Recall: 0.9925\n",
            "  F1: 0.9799\n",
            "Category: 1\n",
            "  Precision: 0.2115\n",
            "  Recall: 0.2308\n",
            "  F1: 0.2179\n",
            "The average precision is: 0.5901\n",
            "The average recall is: 0.6116\n",
            "The average f1 is: 0.5989\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9705\n",
            "  Recall: 0.9841\n",
            "  F1: 0.9766\n",
            "Category: 1\n",
            "  Precision: 0.1970\n",
            "  Recall: 0.1869\n",
            "  F1: 0.1808\n",
            "The average precision is: 0.5838\n",
            "The average recall is: 0.5855\n",
            "The average f1 is: 0.5787\n",
            "  Testing took: 0:00:02\n",
            "Current increase 50 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 87 sampled in this category.\n",
            "After up-sample, there are 5998 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1561\n",
            "0.2602534178059353\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "4437\n",
            "0.7397465821940646\n",
            "\n",
            "(5998, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 09:33:12.041308 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 09:33:12.042299 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 09:33:12.142649 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 09:33:14.635422 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 09:33:14.636152 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    375.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    375.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    375.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    375.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    375.    Elapsed: 0:00:41.\n",
            "  Batch   240  of    375.    Elapsed: 0:00:50.\n",
            "  Batch   280  of    375.    Elapsed: 0:00:58.\n",
            "  Batch   320  of    375.    Elapsed: 0:01:06.\n",
            "  Batch   360  of    375.    Elapsed: 0:01:15.\n",
            "\n",
            "  Average training loss: 0.11\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.89\n",
            "  Recall: 0.87\n",
            "  F1: 0.87\n",
            "Category: 1\n",
            "  Precision: 0.96\n",
            "  Recall: 0.99\n",
            "  F1: 0.97\n",
            "The average precision is: 0.9275\n",
            "The average recall is: 0.9290\n",
            "The average f1 is: 0.9222\n",
            "  Training epcoh took: 0:01:18\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9642\n",
            "  Recall: 0.9873\n",
            "  F1: 0.9749\n",
            "Category: 1\n",
            "  Precision: 0.2692\n",
            "  Recall: 0.1795\n",
            "  F1: 0.2051\n",
            "The average precision is: 0.6167\n",
            "The average recall is: 0.5834\n",
            "The average f1 is: 0.5900\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    375.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    375.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    375.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    375.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    375.    Elapsed: 0:00:41.\n",
            "  Batch   240  of    375.    Elapsed: 0:00:50.\n",
            "  Batch   280  of    375.    Elapsed: 0:00:58.\n",
            "  Batch   320  of    375.    Elapsed: 0:01:06.\n",
            "  Batch   360  of    375.    Elapsed: 0:01:15.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9994\n",
            "The average recall is: 0.9976\n",
            "The average f1 is: 0.9982\n",
            "  Training epcoh took: 0:01:18\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9580\n",
            "  Recall: 0.9920\n",
            "  F1: 0.9740\n",
            "Category: 1\n",
            "  Precision: 0.1923\n",
            "  Recall: 0.1538\n",
            "  F1: 0.1667\n",
            "The average precision is: 0.5752\n",
            "The average recall is: 0.5729\n",
            "The average f1 is: 0.5703\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    375.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    375.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    375.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    375.    Elapsed: 0:00:34.\n",
            "  Batch   200  of    375.    Elapsed: 0:00:42.\n",
            "  Batch   240  of    375.    Elapsed: 0:00:50.\n",
            "  Batch   280  of    375.    Elapsed: 0:00:59.\n",
            "  Batch   320  of    375.    Elapsed: 0:01:08.\n",
            "  Batch   360  of    375.    Elapsed: 0:01:16.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9958\n",
            "The average recall is: 0.9953\n",
            "The average f1 is: 0.9955\n",
            "  Training epcoh took: 0:01:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9602\n",
            "  Recall: 0.9926\n",
            "  F1: 0.9754\n",
            "Category: 1\n",
            "  Precision: 0.1923\n",
            "  Recall: 0.1282\n",
            "  F1: 0.1474\n",
            "The average precision is: 0.5762\n",
            "The average recall is: 0.5604\n",
            "The average f1 is: 0.5614\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    375.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    375.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    375.    Elapsed: 0:00:26.\n",
            "  Batch   160  of    375.    Elapsed: 0:00:35.\n",
            "  Batch   200  of    375.    Elapsed: 0:00:43.\n",
            "  Batch   240  of    375.    Elapsed: 0:00:52.\n",
            "  Batch   280  of    375.    Elapsed: 0:01:01.\n",
            "  Batch   320  of    375.    Elapsed: 0:01:10.\n",
            "  Batch   360  of    375.    Elapsed: 0:01:19.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9972\n",
            "The average recall is: 0.9971\n",
            "The average f1 is: 0.9971\n",
            "  Training epcoh took: 0:01:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9601\n",
            "  Recall: 0.9944\n",
            "  F1: 0.9762\n",
            "Category: 1\n",
            "  Precision: 0.2308\n",
            "  Recall: 0.1795\n",
            "  F1: 0.1923\n",
            "The average precision is: 0.5954\n",
            "The average recall is: 0.5869\n",
            "The average f1 is: 0.5842\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9688\n",
            "  Recall: 0.9923\n",
            "  F1: 0.9799\n",
            "Category: 1\n",
            "  Precision: 0.2727\n",
            "  Recall: 0.1919\n",
            "  F1: 0.2172\n",
            "The average precision is: 0.6208\n",
            "The average recall is: 0.5921\n",
            "The average f1 is: 0.5985\n",
            "  Testing took: 0:00:02\n",
            "Current increase 60 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 87 sampled in this category.\n",
            "After up-sample, there are 6868 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1561\n",
            "0.2272859638905067\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "5307\n",
            "0.7727140361094933\n",
            "\n",
            "(6868, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 09:38:39.584251 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 09:38:39.586734 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 09:38:40.104500 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 09:38:42.626182 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 09:38:42.626910 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    430.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    430.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    430.    Elapsed: 0:00:27.\n",
            "  Batch   160  of    430.    Elapsed: 0:00:35.\n",
            "  Batch   200  of    430.    Elapsed: 0:00:43.\n",
            "  Batch   240  of    430.    Elapsed: 0:00:56.\n",
            "  Batch   280  of    430.    Elapsed: 0:01:06.\n",
            "  Batch   320  of    430.    Elapsed: 0:01:15.\n",
            "  Batch   360  of    430.    Elapsed: 0:01:24.\n",
            "  Batch   400  of    430.    Elapsed: 0:01:33.\n",
            "\n",
            "  Average training loss: 0.14\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.88\n",
            "  Recall: 0.81\n",
            "  F1: 0.82\n",
            "Category: 1\n",
            "  Precision: 0.95\n",
            "  Recall: 0.99\n",
            "  F1: 0.97\n",
            "The average precision is: 0.9161\n",
            "The average recall is: 0.8979\n",
            "The average f1 is: 0.8961\n",
            "  Training epcoh took: 0:01:40\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9602\n",
            "  Recall: 0.9899\n",
            "  F1: 0.9741\n",
            "Category: 1\n",
            "  Precision: 0.2115\n",
            "  Recall: 0.1410\n",
            "  F1: 0.1603\n",
            "The average precision is: 0.5859\n",
            "The average recall is: 0.5655\n",
            "The average f1 is: 0.5672\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    430.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    430.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    430.    Elapsed: 0:00:27.\n",
            "  Batch   160  of    430.    Elapsed: 0:00:37.\n",
            "  Batch   200  of    430.    Elapsed: 0:00:46.\n",
            "  Batch   240  of    430.    Elapsed: 0:00:55.\n",
            "  Batch   280  of    430.    Elapsed: 0:01:04.\n",
            "  Batch   320  of    430.    Elapsed: 0:01:14.\n",
            "  Batch   360  of    430.    Elapsed: 0:01:23.\n",
            "  Batch   400  of    430.    Elapsed: 0:01:32.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.98\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9928\n",
            "The average recall is: 0.9919\n",
            "The average f1 is: 0.9920\n",
            "  Training epcoh took: 0:01:39\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9603\n",
            "  Recall: 0.9923\n",
            "  F1: 0.9752\n",
            "Category: 1\n",
            "  Precision: 0.2115\n",
            "  Recall: 0.1923\n",
            "  F1: 0.1987\n",
            "The average precision is: 0.5859\n",
            "The average recall is: 0.5923\n",
            "The average f1 is: 0.5869\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    430.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    430.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    430.    Elapsed: 0:00:27.\n",
            "  Batch   160  of    430.    Elapsed: 0:00:37.\n",
            "  Batch   200  of    430.    Elapsed: 0:00:46.\n",
            "  Batch   240  of    430.    Elapsed: 0:00:55.\n",
            "  Batch   280  of    430.    Elapsed: 0:01:04.\n",
            "  Batch   320  of    430.    Elapsed: 0:01:13.\n",
            "  Batch   360  of    430.    Elapsed: 0:01:22.\n",
            "  Batch   400  of    430.    Elapsed: 0:01:31.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.98\n",
            "  Recall: 0.98\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9876\n",
            "The average recall is: 0.9877\n",
            "The average f1 is: 0.9875\n",
            "  Training epcoh took: 0:01:38\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9724\n",
            "  Recall: 0.9841\n",
            "  F1: 0.9777\n",
            "Category: 1\n",
            "  Precision: 0.3462\n",
            "  Recall: 0.3205\n",
            "  F1: 0.3295\n",
            "The average precision is: 0.6593\n",
            "The average recall is: 0.6523\n",
            "The average f1 is: 0.6536\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    430.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    430.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    430.    Elapsed: 0:00:28.\n",
            "  Batch   160  of    430.    Elapsed: 0:00:37.\n",
            "  Batch   200  of    430.    Elapsed: 0:00:46.\n",
            "  Batch   240  of    430.    Elapsed: 0:00:54.\n",
            "  Batch   280  of    430.    Elapsed: 0:01:05.\n",
            "  Batch   320  of    430.    Elapsed: 0:01:15.\n",
            "  Batch   360  of    430.    Elapsed: 0:01:24.\n",
            "  Batch   400  of    430.    Elapsed: 0:01:33.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9930\n",
            "The average recall is: 0.9930\n",
            "The average f1 is: 0.9930\n",
            "  Training epcoh took: 0:01:40\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9711\n",
            "  Recall: 0.9818\n",
            "  F1: 0.9755\n",
            "Category: 1\n",
            "  Precision: 0.2885\n",
            "  Recall: 0.2628\n",
            "  F1: 0.2577\n",
            "The average precision is: 0.6298\n",
            "The average recall is: 0.6223\n",
            "The average f1 is: 0.6166\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9740\n",
            "  Recall: 0.9784\n",
            "  F1: 0.9757\n",
            "Category: 1\n",
            "  Precision: 0.2424\n",
            "  Recall: 0.2197\n",
            "  F1: 0.2229\n",
            "The average precision is: 0.6082\n",
            "The average recall is: 0.5990\n",
            "The average f1 is: 0.5993\n",
            "  Testing took: 0:00:02\n",
            "Current increase 70 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 87 sampled in this category.\n",
            "After up-sample, there are 7738 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1561\n",
            "0.2017317136210907\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "6177\n",
            "0.7982682863789092\n",
            "\n",
            "(7738, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 09:45:27.019836 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 09:45:27.020987 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 09:45:27.087433 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 09:45:29.585003 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 09:45:29.585716 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    484.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    484.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    484.    Elapsed: 0:00:27.\n",
            "  Batch   160  of    484.    Elapsed: 0:00:37.\n",
            "  Batch   200  of    484.    Elapsed: 0:00:46.\n",
            "  Batch   240  of    484.    Elapsed: 0:00:55.\n",
            "  Batch   280  of    484.    Elapsed: 0:01:05.\n",
            "  Batch   320  of    484.    Elapsed: 0:01:14.\n",
            "  Batch   360  of    484.    Elapsed: 0:01:23.\n",
            "  Batch   400  of    484.    Elapsed: 0:01:32.\n",
            "  Batch   440  of    484.    Elapsed: 0:01:42.\n",
            "  Batch   480  of    484.    Elapsed: 0:01:51.\n",
            "\n",
            "  Average training loss: 0.10\n",
            "  Accuracy: 0.97\n",
            "Category: 0\n",
            "  Precision: 0.86\n",
            "  Recall: 0.81\n",
            "  F1: 0.82\n",
            "Category: 1\n",
            "  Precision: 0.97\n",
            "  Recall: 0.99\n",
            "  F1: 0.98\n",
            "The average precision is: 0.9134\n",
            "The average recall is: 0.9023\n",
            "The average f1 is: 0.9017\n",
            "  Training epcoh took: 0:01:51\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9636\n",
            "  Recall: 0.9926\n",
            "  F1: 0.9772\n",
            "Category: 1\n",
            "  Precision: 0.2500\n",
            "  Recall: 0.2308\n",
            "  F1: 0.2308\n",
            "The average precision is: 0.6068\n",
            "The average recall is: 0.6117\n",
            "The average f1 is: 0.6040\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    484.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    484.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    484.    Elapsed: 0:00:27.\n",
            "  Batch   160  of    484.    Elapsed: 0:00:37.\n",
            "  Batch   200  of    484.    Elapsed: 0:00:47.\n",
            "  Batch   240  of    484.    Elapsed: 0:00:56.\n",
            "  Batch   280  of    484.    Elapsed: 0:01:06.\n",
            "  Batch   320  of    484.    Elapsed: 0:01:15.\n",
            "  Batch   360  of    484.    Elapsed: 0:01:24.\n",
            "  Batch   400  of    484.    Elapsed: 0:01:33.\n",
            "  Batch   440  of    484.    Elapsed: 0:01:43.\n",
            "  Batch   480  of    484.    Elapsed: 0:01:52.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.97\n",
            "  Recall: 0.96\n",
            "  F1: 0.97\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9833\n",
            "The average recall is: 0.9819\n",
            "The average f1 is: 0.9823\n",
            "  Training epcoh took: 0:01:53\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9715\n",
            "  Recall: 0.9794\n",
            "  F1: 0.9747\n",
            "Category: 1\n",
            "  Precision: 0.3141\n",
            "  Recall: 0.2821\n",
            "  F1: 0.2744\n",
            "The average precision is: 0.6428\n",
            "The average recall is: 0.6307\n",
            "The average f1 is: 0.6245\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    484.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    484.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    484.    Elapsed: 0:00:28.\n",
            "  Batch   160  of    484.    Elapsed: 0:00:37.\n",
            "  Batch   200  of    484.    Elapsed: 0:00:46.\n",
            "  Batch   240  of    484.    Elapsed: 0:00:56.\n",
            "  Batch   280  of    484.    Elapsed: 0:01:04.\n",
            "  Batch   320  of    484.    Elapsed: 0:01:13.\n",
            "  Batch   360  of    484.    Elapsed: 0:01:21.\n",
            "  Batch   400  of    484.    Elapsed: 0:01:31.\n",
            "  Batch   440  of    484.    Elapsed: 0:01:40.\n",
            "  Batch   480  of    484.    Elapsed: 0:01:48.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.97\n",
            "  Recall: 0.97\n",
            "  F1: 0.97\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9832\n",
            "The average recall is: 0.9827\n",
            "The average f1 is: 0.9829\n",
            "  Training epcoh took: 0:01:49\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9755\n",
            "  Recall: 0.9748\n",
            "  F1: 0.9740\n",
            "Category: 1\n",
            "  Precision: 0.3526\n",
            "  Recall: 0.3462\n",
            "  F1: 0.3385\n",
            "The average precision is: 0.6640\n",
            "The average recall is: 0.6605\n",
            "The average f1 is: 0.6562\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    484.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    484.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    484.    Elapsed: 0:00:26.\n",
            "  Batch   160  of    484.    Elapsed: 0:00:34.\n",
            "  Batch   200  of    484.    Elapsed: 0:00:43.\n",
            "  Batch   240  of    484.    Elapsed: 0:00:51.\n",
            "  Batch   280  of    484.    Elapsed: 0:01:00.\n",
            "  Batch   320  of    484.    Elapsed: 0:01:08.\n",
            "  Batch   360  of    484.    Elapsed: 0:01:16.\n",
            "  Batch   400  of    484.    Elapsed: 0:01:25.\n",
            "  Batch   440  of    484.    Elapsed: 0:01:33.\n",
            "  Batch   480  of    484.    Elapsed: 0:01:41.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.97\n",
            "  Recall: 0.97\n",
            "  F1: 0.97\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9844\n",
            "The average recall is: 0.9842\n",
            "The average f1 is: 0.9843\n",
            "  Training epcoh took: 0:01:42\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9726\n",
            "  Recall: 0.9825\n",
            "  F1: 0.9765\n",
            "Category: 1\n",
            "  Precision: 0.3269\n",
            "  Recall: 0.3013\n",
            "  F1: 0.2949\n",
            "The average precision is: 0.6497\n",
            "The average recall is: 0.6419\n",
            "The average f1 is: 0.6357\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9724\n",
            "  Recall: 0.9765\n",
            "  F1: 0.9735\n",
            "Category: 1\n",
            "  Precision: 0.2323\n",
            "  Recall: 0.2121\n",
            "  F1: 0.2071\n",
            "The average precision is: 0.6024\n",
            "The average recall is: 0.5943\n",
            "The average f1 is: 0.5903\n",
            "  Testing took: 0:00:02\n",
            "Current increase 80 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 87 sampled in this category.\n",
            "After up-sample, there are 8608 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1561\n",
            "0.18134293680297398\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "7047\n",
            "0.818657063197026\n",
            "\n",
            "(8608, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 09:52:52.720164 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 09:52:52.721528 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 09:52:53.611905 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 09:52:56.111864 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 09:52:56.112595 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    538.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    538.    Elapsed: 0:00:16.\n",
            "  Batch   120  of    538.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    538.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    538.    Elapsed: 0:00:41.\n",
            "  Batch   240  of    538.    Elapsed: 0:00:49.\n",
            "  Batch   280  of    538.    Elapsed: 0:00:57.\n",
            "  Batch   320  of    538.    Elapsed: 0:01:06.\n",
            "  Batch   360  of    538.    Elapsed: 0:01:14.\n",
            "  Batch   400  of    538.    Elapsed: 0:01:22.\n",
            "  Batch   440  of    538.    Elapsed: 0:01:30.\n",
            "  Batch   480  of    538.    Elapsed: 0:01:38.\n",
            "  Batch   520  of    538.    Elapsed: 0:01:47.\n",
            "\n",
            "  Average training loss: 0.09\n",
            "  Accuracy: 0.97\n",
            "Category: 0\n",
            "  Precision: 0.82\n",
            "  Recall: 0.78\n",
            "  F1: 0.79\n",
            "Category: 1\n",
            "  Precision: 0.97\n",
            "  Recall: 1.00\n",
            "  F1: 0.98\n",
            "The average precision is: 0.8920\n",
            "The average recall is: 0.8899\n",
            "The average f1 is: 0.8865\n",
            "  Training epcoh took: 0:01:50\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.94\n",
            "Category: 0\n",
            "  Precision: 0.9709\n",
            "  Recall: 0.9616\n",
            "  F1: 0.9653\n",
            "Category: 1\n",
            "  Precision: 0.3365\n",
            "  Recall: 0.3462\n",
            "  F1: 0.3231\n",
            "The average precision is: 0.6537\n",
            "The average recall is: 0.6539\n",
            "The average f1 is: 0.6442\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    538.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    538.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    538.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    538.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    538.    Elapsed: 0:00:41.\n",
            "  Batch   240  of    538.    Elapsed: 0:00:49.\n",
            "  Batch   280  of    538.    Elapsed: 0:00:57.\n",
            "  Batch   320  of    538.    Elapsed: 0:01:06.\n",
            "  Batch   360  of    538.    Elapsed: 0:01:14.\n",
            "  Batch   400  of    538.    Elapsed: 0:01:22.\n",
            "  Batch   440  of    538.    Elapsed: 0:01:30.\n",
            "  Batch   480  of    538.    Elapsed: 0:01:38.\n",
            "  Batch   520  of    538.    Elapsed: 0:01:47.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.95\n",
            "  Recall: 0.95\n",
            "  F1: 0.95\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9770\n",
            "The average recall is: 0.9760\n",
            "The average f1 is: 0.9763\n",
            "  Training epcoh took: 0:01:50\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.94\n",
            "Category: 0\n",
            "  Precision: 0.9742\n",
            "  Recall: 0.9568\n",
            "  F1: 0.9646\n",
            "Category: 1\n",
            "  Precision: 0.2692\n",
            "  Recall: 0.3077\n",
            "  F1: 0.2718\n",
            "The average precision is: 0.6217\n",
            "The average recall is: 0.6323\n",
            "The average f1 is: 0.6182\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    538.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    538.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    538.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    538.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    538.    Elapsed: 0:00:41.\n",
            "  Batch   240  of    538.    Elapsed: 0:00:49.\n",
            "  Batch   280  of    538.    Elapsed: 0:00:57.\n",
            "  Batch   320  of    538.    Elapsed: 0:01:06.\n",
            "  Batch   360  of    538.    Elapsed: 0:01:14.\n",
            "  Batch   400  of    538.    Elapsed: 0:01:22.\n",
            "  Batch   440  of    538.    Elapsed: 0:01:30.\n",
            "  Batch   480  of    538.    Elapsed: 0:01:39.\n",
            "  Batch   520  of    538.    Elapsed: 0:01:47.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.95\n",
            "  Recall: 0.95\n",
            "  F1: 0.95\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9765\n",
            "The average recall is: 0.9757\n",
            "The average f1 is: 0.9760\n",
            "  Training epcoh took: 0:01:51\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9617\n",
            "  Recall: 0.9950\n",
            "  F1: 0.9773\n",
            "Category: 1\n",
            "  Precision: 0.2692\n",
            "  Recall: 0.1667\n",
            "  F1: 0.1987\n",
            "The average precision is: 0.6155\n",
            "The average recall is: 0.5808\n",
            "The average f1 is: 0.5880\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    538.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    538.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    538.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    538.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    538.    Elapsed: 0:00:42.\n",
            "  Batch   240  of    538.    Elapsed: 0:00:50.\n",
            "  Batch   280  of    538.    Elapsed: 0:00:58.\n",
            "  Batch   320  of    538.    Elapsed: 0:01:07.\n",
            "  Batch   360  of    538.    Elapsed: 0:01:15.\n",
            "  Batch   400  of    538.    Elapsed: 0:01:24.\n",
            "  Batch   440  of    538.    Elapsed: 0:01:32.\n",
            "  Batch   480  of    538.    Elapsed: 0:01:41.\n",
            "  Batch   520  of    538.    Elapsed: 0:01:49.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.96\n",
            "  Recall: 0.95\n",
            "  F1: 0.95\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9776\n",
            "The average recall is: 0.9772\n",
            "The average f1 is: 0.9774\n",
            "  Training epcoh took: 0:01:53\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9676\n",
            "  Recall: 0.9945\n",
            "  F1: 0.9805\n",
            "Category: 1\n",
            "  Precision: 0.3077\n",
            "  Recall: 0.2756\n",
            "  F1: 0.2872\n",
            "The average precision is: 0.6376\n",
            "The average recall is: 0.6351\n",
            "The average f1 is: 0.6338\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9687\n",
            "  Recall: 0.9918\n",
            "  F1: 0.9791\n",
            "Category: 1\n",
            "  Precision: 0.2727\n",
            "  Recall: 0.2475\n",
            "  F1: 0.2475\n",
            "The average precision is: 0.6207\n",
            "The average recall is: 0.6196\n",
            "The average f1 is: 0.6133\n",
            "  Testing took: 0:00:02\n",
            "Current increase 90 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 87 sampled in this category.\n",
            "After up-sample, there are 9478 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1561\n",
            "0.16469719350073855\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "7917\n",
            "0.8353028064992615\n",
            "\n",
            "(9478, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 10:00:27.964368 140575546472256 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 10:00:27.965423 140575546472256 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 10:00:28.048061 140575546472256 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 10:00:30.532949 140575546472256 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 10:00:30.533679 140575546472256 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    593.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    593.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    593.    Elapsed: 0:00:26.\n",
            "  Batch   160  of    593.    Elapsed: 0:00:34.\n",
            "  Batch   200  of    593.    Elapsed: 0:00:43.\n",
            "  Batch   240  of    593.    Elapsed: 0:00:52.\n",
            "  Batch   280  of    593.    Elapsed: 0:01:01.\n",
            "  Batch   320  of    593.    Elapsed: 0:01:09.\n",
            "  Batch   360  of    593.    Elapsed: 0:01:18.\n",
            "  Batch   400  of    593.    Elapsed: 0:01:27.\n",
            "  Batch   440  of    593.    Elapsed: 0:01:36.\n",
            "  Batch   480  of    593.    Elapsed: 0:01:45.\n",
            "  Batch   520  of    593.    Elapsed: 0:01:54.\n",
            "  Batch   560  of    593.    Elapsed: 0:02:02.\n",
            "\n",
            "  Average training loss: 0.07\n",
            "  Accuracy: 0.98\n",
            "Category: 0\n",
            "  Precision: 0.84\n",
            "  Recall: 0.82\n",
            "  F1: 0.83\n",
            "Category: 1\n",
            "  Precision: 0.98\n",
            "  Recall: 1.00\n",
            "  F1: 0.99\n",
            "The average precision is: 0.9102\n",
            "The average recall is: 0.9081\n",
            "The average f1 is: 0.9055\n",
            "  Training epcoh took: 0:02:09\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "Category: 0\n",
            "  Precision: 0.9664\n",
            "  Recall: 0.9765\n",
            "  F1: 0.9709\n",
            "Category: 1\n",
            "  Precision: 0.2500\n",
            "  Recall: 0.2051\n",
            "  F1: 0.2141\n",
            "The average precision is: 0.6082\n",
            "The average recall is: 0.5908\n",
            "The average f1 is: 0.5925\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    593.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    593.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    593.    Elapsed: 0:00:27.\n",
            "  Batch   160  of    593.    Elapsed: 0:00:36.\n",
            "  Batch   200  of    593.    Elapsed: 0:00:45.\n",
            "  Batch   240  of    593.    Elapsed: 0:00:54.\n",
            "  Batch   280  of    593.    Elapsed: 0:01:03.\n",
            "  Batch   320  of    593.    Elapsed: 0:01:11.\n",
            "  Batch   360  of    593.    Elapsed: 0:01:20.\n",
            "  Batch   400  of    593.    Elapsed: 0:01:29.\n",
            "  Batch   440  of    593.    Elapsed: 0:01:38.\n",
            "  Batch   480  of    593.    Elapsed: 0:01:47.\n",
            "  Batch   520  of    593.    Elapsed: 0:01:56.\n",
            "  Batch   560  of    593.    Elapsed: 0:02:05.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.93\n",
            "  Recall: 0.93\n",
            "  F1: 0.93\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9650\n",
            "The average recall is: 0.9637\n",
            "The average f1 is: 0.9640\n",
            "  Training epcoh took: 0:02:12\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9678\n",
            "  Recall: 0.9896\n",
            "  F1: 0.9781\n",
            "Category: 1\n",
            "  Precision: 0.2308\n",
            "  Recall: 0.2115\n",
            "  F1: 0.2115\n",
            "The average precision is: 0.5993\n",
            "The average recall is: 0.6005\n",
            "The average f1 is: 0.5948\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    593.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    593.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    593.    Elapsed: 0:00:27.\n",
            "  Batch   160  of    593.    Elapsed: 0:00:36.\n",
            "  Batch   200  of    593.    Elapsed: 0:00:45.\n",
            "  Batch   240  of    593.    Elapsed: 0:00:54.\n",
            "  Batch   280  of    593.    Elapsed: 0:01:03.\n",
            "  Batch   320  of    593.    Elapsed: 0:01:12.\n",
            "  Batch   360  of    593.    Elapsed: 0:01:20.\n",
            "  Batch   400  of    593.    Elapsed: 0:01:29.\n",
            "  Batch   440  of    593.    Elapsed: 0:01:39.\n",
            "  Batch   480  of    593.    Elapsed: 0:01:48.\n",
            "  Batch   520  of    593.    Elapsed: 0:01:57.\n",
            "  Batch   560  of    593.    Elapsed: 0:02:06.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.94\n",
            "  Recall: 0.94\n",
            "  F1: 0.94\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9693\n",
            "The average recall is: 0.9687\n",
            "The average f1 is: 0.9689\n",
            "  Training epcoh took: 0:02:13\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9646\n",
            "  Recall: 0.9897\n",
            "  F1: 0.9762\n",
            "Category: 1\n",
            "  Precision: 0.2308\n",
            "  Recall: 0.1859\n",
            "  F1: 0.1923\n",
            "The average precision is: 0.5977\n",
            "The average recall is: 0.5878\n",
            "The average f1 is: 0.5842\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    593.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    593.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    593.    Elapsed: 0:00:27.\n",
            "  Batch   160  of    593.    Elapsed: 0:00:36.\n",
            "  Batch   200  of    593.    Elapsed: 0:00:46.\n",
            "  Batch   240  of    593.    Elapsed: 0:00:55.\n",
            "  Batch   280  of    593.    Elapsed: 0:01:04.\n",
            "  Batch   320  of    593.    Elapsed: 0:01:13.\n",
            "  Batch   360  of    593.    Elapsed: 0:01:22.\n",
            "  Batch   400  of    593.    Elapsed: 0:01:31.\n",
            "  Batch   440  of    593.    Elapsed: 0:01:40.\n",
            "  Batch   480  of    593.    Elapsed: 0:01:49.\n",
            "  Batch   520  of    593.    Elapsed: 0:01:59.\n",
            "  Batch   560  of    593.    Elapsed: 0:02:08.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.94\n",
            "  Recall: 0.94\n",
            "  F1: 0.94\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9713\n",
            "The average recall is: 0.9713\n",
            "The average f1 is: 0.9713\n",
            "  Training epcoh took: 0:02:15\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.9654\n",
            "  Recall: 0.9917\n",
            "  F1: 0.9776\n",
            "Category: 1\n",
            "  Precision: 0.2885\n",
            "  Recall: 0.2436\n",
            "  F1: 0.2564\n",
            "The average precision is: 0.6269\n",
            "The average recall is: 0.6177\n",
            "The average f1 is: 0.6170\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.97\n",
            "Category: 0\n",
            "  Precision: 0.9688\n",
            "  Recall: 0.9959\n",
            "  F1: 0.9816\n",
            "Category: 1\n",
            "  Precision: 0.2273\n",
            "  Recall: 0.1717\n",
            "  F1: 0.1869\n",
            "The average precision is: 0.5980\n",
            "The average recall is: 0.5838\n",
            "The average f1 is: 0.5842\n",
            "  Testing took: 0:00:02\n",
            "Successfully save file ./BertSearchResult/6_16_2e-05_6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y3lqlmMyWeDi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "outputId": "203b4107-6a44-4a39-d1ce-f5ea357bf42a"
      },
      "source": [
        "all_metrics_one"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: defaultdict(None,\n",
              "             {'train_loss_values': [0.02451061978212838,\n",
              "               0.02451061978212838,\n",
              "               0.014020035567792874,\n",
              "               0.014020035567792874,\n",
              "               0.014816705897016433,\n",
              "               0.014816705897016433,\n",
              "               0.012088468786582205,\n",
              "               0.012088468786582205],\n",
              "              'train_acc_all': [0.9981796116504854,\n",
              "               0.9981796116504854,\n",
              "               0.9981796116504854,\n",
              "               0.9981796116504854],\n",
              "              'train_precision_all': [{0: 0.9981796116504854, 1: 0.0},\n",
              "               {0: 0.9981796116504854, 1: 0.0},\n",
              "               {0: 0.9981796116504854, 1: 0.0},\n",
              "               {0: 0.9981796116504854, 1: 0.0}],\n",
              "              'train_recall_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}],\n",
              "              'train_f1_all': [{0: 0.9990291262135923, 1: 0.0},\n",
              "               {0: 0.9990291262135923, 1: 0.0},\n",
              "               {0: 0.9990291262135923, 1: 0.0},\n",
              "               {0: 0.9990291262135923, 1: 0.0}],\n",
              "              'val_acc_all': [1.0, 1.0, 1.0, 1.0],\n",
              "              'val_precision_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}],\n",
              "              'val_recall_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}],\n",
              "              'val_f1_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}]})}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tBhLVv1YJR3O"
      },
      "source": [
        "#### Incremental recitfied training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "YD_vdAnMZirB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "batch_size = 32\n",
        "lr = 3e-5\n",
        "test_batch = [test_inputs,test_labels,test_masks]\n",
        "Bert = Bertnn_rectified_info(train_inputs,train_labels,train_masks, validation_inputs,validation_labels,validation_masks,test_batch,batch_size=batch_size,lr=lr)\n",
        "all_metrics_one, all_tesst_metrics = Bert.searchUpsample(100)\n",
        "all_metrics_one['test'] = all_tesst_metrics\n",
        "all_metrics_all_category[section_category] = all_metrics_one\n",
        "if not os.path.exists('BertSearchResult'):\n",
        "  os.makedirs('BertSearchResult')\n",
        "\n",
        "filename = './BertSearchResult/'+'rectified'+'_'+str(section_category)+'_'+str(batch_size) + '_' + str(lr) + '_'  + str(section_category)\n",
        "with open(filename,'w') as file_obj:\n",
        "  json.dump(all_metrics_one,file_obj)\n",
        "  print('Successfully save file %s'%(filename))\n",
        "\n",
        "del Bert\n",
        "torch.cuda.empty_cache() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "bKG-GPVXZirE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "outputId": "203b4107-6a44-4a39-d1ce-f5ea357bf42a"
      },
      "source": [
        "all_metrics_one"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: defaultdict(None,\n",
              "             {'train_loss_values': [0.02451061978212838,\n",
              "               0.02451061978212838,\n",
              "               0.014020035567792874,\n",
              "               0.014020035567792874,\n",
              "               0.014816705897016433,\n",
              "               0.014816705897016433,\n",
              "               0.012088468786582205,\n",
              "               0.012088468786582205],\n",
              "              'train_acc_all': [0.9981796116504854,\n",
              "               0.9981796116504854,\n",
              "               0.9981796116504854,\n",
              "               0.9981796116504854],\n",
              "              'train_precision_all': [{0: 0.9981796116504854, 1: 0.0},\n",
              "               {0: 0.9981796116504854, 1: 0.0},\n",
              "               {0: 0.9981796116504854, 1: 0.0},\n",
              "               {0: 0.9981796116504854, 1: 0.0}],\n",
              "              'train_recall_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}],\n",
              "              'train_f1_all': [{0: 0.9990291262135923, 1: 0.0},\n",
              "               {0: 0.9990291262135923, 1: 0.0},\n",
              "               {0: 0.9990291262135923, 1: 0.0},\n",
              "               {0: 0.9990291262135923, 1: 0.0}],\n",
              "              'val_acc_all': [1.0, 1.0, 1.0, 1.0],\n",
              "              'val_precision_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}],\n",
              "              'val_recall_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}],\n",
              "              'val_f1_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}]})}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Pjh_EA9rWTqR"
      },
      "source": [
        "### For 'Advice'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wGbqnJyhWejl"
      },
      "source": [
        "#### Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4Vl3z0MGWejl",
        "colab": {}
      },
      "source": [
        "# Use train_test_split to split our data into train and validation and test sets for\n",
        "# training\n",
        "section_category = 0\n",
        "labels = labels_single[section_category]\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 80% for training and 20% for validation.\n",
        "temp_inputs, test_inputs,  temp_labels, test_labels = train_test_split(input_ids, labels, random_state=1999, test_size=0.2)\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(temp_inputs, temp_labels,random_state=1999, test_size=0.2)\n",
        "\n",
        "# Do the same for the masks.\n",
        "temp_masks, test_masks, temp_labels, _ = train_test_split(attention_masks, labels,random_state=1999, test_size=0.2)\n",
        "\n",
        "train_masks, validation_masks, _, _ = train_test_split(temp_masks, temp_labels,random_state=1999, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qpGYEq3GJYXZ"
      },
      "source": [
        "#### Normal training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "pMl-2VJlZirM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7156f0ab-6c8e-4ea4-9b68-849e5642e802"
      },
      "source": [
        "import json\n",
        "batch_size = 16\n",
        "lr = 2e-5\n",
        "test_batch = [test_inputs,test_labels,test_masks]\n",
        "Bert = Bertnn_info(train_inputs,train_labels,train_masks, validation_inputs,validation_labels,validation_masks,test_batch,batch_size=batch_size,lr=lr)\n",
        "all_metrics_one, all_tesst_metrics = Bert.searchUpsample(100)\n",
        "all_metrics_one['test'] = all_tesst_metrics\n",
        "all_metrics_all_category[section_category] = all_metrics_one\n",
        "if not os.path.exists('BertSearchResult'):\n",
        "  os.makedirs('BertSearchResult')\n",
        "\n",
        "filename = './BertSearchResult/'+str(section_category)+'_'+str(batch_size) + '_' + str(lr) + '_'  + str(section_category)\n",
        "with open(filename,'w') as file_obj:\n",
        "  json.dump(all_metrics_one,file_obj)\n",
        "  print('Successfully save file %s'%(filename))\n",
        "\n",
        "del Bert\n",
        "torch.cuda.empty_cache() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Batch    80  of    228.    Elapsed: 0:00:16.\n",
            "  Batch   120  of    228.    Elapsed: 0:00:24.\n",
            "  Batch   160  of    228.    Elapsed: 0:00:32.\n",
            "  Batch   200  of    228.    Elapsed: 0:00:40.\n",
            "\n",
            "  Average training loss: 0.44\n",
            "  Accuracy: 0.79\n",
            "Category: 0\n",
            "  Precision: 0.75\n",
            "  Recall: 0.67\n",
            "  F1: 0.67\n",
            "Category: 1\n",
            "  Precision: 0.81\n",
            "  Recall: 0.88\n",
            "  F1: 0.83\n",
            "The average precision is: 0.7788\n",
            "The average recall is: 0.7743\n",
            "The average f1 is: 0.7464\n",
            "  Training epcoh took: 0:00:45\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.75\n",
            "Category: 0\n",
            "  Precision: 0.9277\n",
            "  Recall: 0.7688\n",
            "  F1: 0.8353\n",
            "Category: 1\n",
            "  Precision: 0.3406\n",
            "  Recall: 0.6135\n",
            "  F1: 0.4162\n",
            "The average precision is: 0.6342\n",
            "The average recall is: 0.6911\n",
            "The average f1 is: 0.6258\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    228.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    228.    Elapsed: 0:00:16.\n",
            "  Batch   120  of    228.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    228.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    228.    Elapsed: 0:00:41.\n",
            "\n",
            "  Average training loss: 0.08\n",
            "  Accuracy: 0.98\n",
            "Category: 0\n",
            "  Precision: 0.98\n",
            "  Recall: 0.96\n",
            "  F1: 0.97\n",
            "Category: 1\n",
            "  Precision: 0.98\n",
            "  Recall: 0.98\n",
            "  F1: 0.98\n",
            "The average precision is: 0.9759\n",
            "The average recall is: 0.9740\n",
            "The average f1 is: 0.9725\n",
            "  Training epcoh took: 0:00:47\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8767\n",
            "  Recall: 0.9689\n",
            "  F1: 0.9178\n",
            "Category: 1\n",
            "  Precision: 0.4231\n",
            "  Recall: 0.2301\n",
            "  F1: 0.2788\n",
            "The average precision is: 0.6499\n",
            "The average recall is: 0.5995\n",
            "The average f1 is: 0.5983\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    228.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    228.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    228.    Elapsed: 0:00:26.\n",
            "  Batch   160  of    228.    Elapsed: 0:00:35.\n",
            "  Batch   200  of    228.    Elapsed: 0:00:43.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 0.99\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 0.99\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9970\n",
            "The average recall is: 0.9964\n",
            "The average f1 is: 0.9964\n",
            "  Training epcoh took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8720\n",
            "  Recall: 0.9712\n",
            "  F1: 0.9168\n",
            "Category: 1\n",
            "  Precision: 0.3365\n",
            "  Recall: 0.1801\n",
            "  F1: 0.2240\n",
            "The average precision is: 0.6043\n",
            "The average recall is: 0.5757\n",
            "The average f1 is: 0.5704\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    228.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    228.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    228.    Elapsed: 0:00:27.\n",
            "  Batch   160  of    228.    Elapsed: 0:00:36.\n",
            "  Batch   200  of    228.    Elapsed: 0:00:45.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 1.00\n",
            "  Recall: 0.99\n",
            "  F1: 1.00\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9978\n",
            "The average recall is: 0.9972\n",
            "The average f1 is: 0.9973\n",
            "  Training epcoh took: 0:00:51\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8866\n",
            "  Recall: 0.9390\n",
            "  F1: 0.9099\n",
            "Category: 1\n",
            "  Precision: 0.3917\n",
            "  Recall: 0.2423\n",
            "  F1: 0.2804\n",
            "The average precision is: 0.6392\n",
            "The average recall is: 0.5907\n",
            "The average f1 is: 0.5952\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.88\n",
            "Category: 0\n",
            "  Precision: 0.9201\n",
            "  Recall: 0.9490\n",
            "  F1: 0.9318\n",
            "Category: 1\n",
            "  Precision: 0.3687\n",
            "  Recall: 0.3561\n",
            "  F1: 0.3359\n",
            "The average precision is: 0.6444\n",
            "The average recall is: 0.6525\n",
            "The average f1 is: 0.6338\n",
            "  Testing took: 0:00:02\n",
            "Current increase 20 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 199 sampled in this category.\n",
            "After up-sample, there are 5628 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1449\n",
            "0.2574626865671642\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "4179\n",
            "0.7425373134328358\n",
            "\n",
            "(5628, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 13:33:32.426645 140498471425856 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 13:33:32.428748 140498471425856 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 13:33:32.472086 140498471425856 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 13:33:35.107221 140498471425856 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 13:33:35.108014 140498471425856 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    352.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    352.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    352.    Elapsed: 0:00:27.\n",
            "  Batch   160  of    352.    Elapsed: 0:00:36.\n",
            "  Batch   200  of    352.    Elapsed: 0:00:45.\n",
            "  Batch   240  of    352.    Elapsed: 0:00:54.\n",
            "  Batch   280  of    352.    Elapsed: 0:01:03.\n",
            "  Batch   320  of    352.    Elapsed: 0:01:14.\n",
            "\n",
            "  Average training loss: 0.34\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.77\n",
            "  Recall: 0.56\n",
            "  F1: 0.61\n",
            "Category: 1\n",
            "  Precision: 0.87\n",
            "  Recall: 0.97\n",
            "  F1: 0.91\n",
            "The average precision is: 0.8206\n",
            "The average recall is: 0.7649\n",
            "The average f1 is: 0.7604\n",
            "  Training epcoh took: 0:01:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.9109\n",
            "  Recall: 0.8985\n",
            "  F1: 0.9012\n",
            "Category: 1\n",
            "  Precision: 0.4487\n",
            "  Recall: 0.4904\n",
            "  F1: 0.4382\n",
            "The average precision is: 0.6798\n",
            "The average recall is: 0.6944\n",
            "The average f1 is: 0.6697\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    352.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    352.    Elapsed: 0:00:18.\n",
            "  Batch   120  of    352.    Elapsed: 0:00:28.\n",
            "  Batch   160  of    352.    Elapsed: 0:00:37.\n",
            "  Batch   200  of    352.    Elapsed: 0:00:46.\n",
            "  Batch   240  of    352.    Elapsed: 0:00:56.\n",
            "  Batch   280  of    352.    Elapsed: 0:01:05.\n",
            "  Batch   320  of    352.    Elapsed: 0:01:14.\n",
            "\n",
            "  Average training loss: 0.06\n",
            "  Accuracy: 0.99\n",
            "Category: 0\n",
            "  Precision: 0.98\n",
            "  Recall: 0.95\n",
            "  F1: 0.96\n",
            "Category: 1\n",
            "  Precision: 0.99\n",
            "  Recall: 1.00\n",
            "  F1: 0.99\n",
            "The average precision is: 0.9814\n",
            "The average recall is: 0.9715\n",
            "The average f1 is: 0.9739\n",
            "  Training epcoh took: 0:01:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8924\n",
            "  Recall: 0.9356\n",
            "  F1: 0.9107\n",
            "Category: 1\n",
            "  Precision: 0.4301\n",
            "  Recall: 0.3654\n",
            "  F1: 0.3639\n",
            "The average precision is: 0.6612\n",
            "The average recall is: 0.6505\n",
            "The average f1 is: 0.6373\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    352.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    352.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    352.    Elapsed: 0:00:26.\n",
            "  Batch   160  of    352.    Elapsed: 0:00:35.\n",
            "  Batch   200  of    352.    Elapsed: 0:00:44.\n",
            "  Batch   240  of    352.    Elapsed: 0:00:52.\n",
            "  Batch   280  of    352.    Elapsed: 0:01:01.\n",
            "  Batch   320  of    352.    Elapsed: 0:01:09.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.98\n",
            "  Recall: 0.97\n",
            "  F1: 0.97\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9888\n",
            "The average recall is: 0.9845\n",
            "The average f1 is: 0.9859\n",
            "  Training epcoh took: 0:01:16\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8870\n",
            "  Recall: 0.9722\n",
            "  F1: 0.9250\n",
            "Category: 1\n",
            "  Precision: 0.5064\n",
            "  Recall: 0.3263\n",
            "  F1: 0.3733\n",
            "The average precision is: 0.6967\n",
            "The average recall is: 0.6492\n",
            "The average f1 is: 0.6491\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    352.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    352.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    352.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    352.    Elapsed: 0:00:34.\n",
            "  Batch   200  of    352.    Elapsed: 0:00:42.\n",
            "  Batch   240  of    352.    Elapsed: 0:00:51.\n",
            "  Batch   280  of    352.    Elapsed: 0:00:59.\n",
            "  Batch   320  of    352.    Elapsed: 0:01:08.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "  F1: 0.99\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9962\n",
            "The average recall is: 0.9947\n",
            "The average f1 is: 0.9953\n",
            "  Training epcoh took: 0:01:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8873\n",
            "  Recall: 0.9602\n",
            "  F1: 0.9210\n",
            "Category: 1\n",
            "  Precision: 0.4936\n",
            "  Recall: 0.3186\n",
            "  F1: 0.3637\n",
            "The average precision is: 0.6905\n",
            "The average recall is: 0.6394\n",
            "The average f1 is: 0.6423\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.89\n",
            "Category: 0\n",
            "  Precision: 0.9211\n",
            "  Recall: 0.9603\n",
            "  F1: 0.9369\n",
            "Category: 1\n",
            "  Precision: 0.4924\n",
            "  Recall: 0.3712\n",
            "  F1: 0.3916\n",
            "The average precision is: 0.7068\n",
            "The average recall is: 0.6658\n",
            "The average f1 is: 0.6642\n",
            "  Testing took: 0:00:02\n",
            "Current increase 30 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 199 sampled in this category.\n",
            "After up-sample, there are 7618 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1449\n",
            "0.19020740351798374\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "6169\n",
            "0.8097925964820163\n",
            "\n",
            "(7618, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 13:38:55.621675 140498471425856 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 13:38:55.623096 140498471425856 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 13:38:56.117106 140498471425856 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 13:38:58.638047 140498471425856 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 13:38:58.639390 140498471425856 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    477.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    477.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    477.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    477.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    477.    Elapsed: 0:00:41.\n",
            "  Batch   240  of    477.    Elapsed: 0:00:50.\n",
            "  Batch   280  of    477.    Elapsed: 0:00:59.\n",
            "  Batch   320  of    477.    Elapsed: 0:01:07.\n",
            "  Batch   360  of    477.    Elapsed: 0:01:15.\n",
            "  Batch   400  of    477.    Elapsed: 0:01:24.\n",
            "  Batch   440  of    477.    Elapsed: 0:01:32.\n",
            "\n",
            "  Average training loss: 0.22\n",
            "  Accuracy: 0.92\n",
            "Category: 0\n",
            "  Precision: 0.73\n",
            "  Recall: 0.64\n",
            "  F1: 0.66\n",
            "Category: 1\n",
            "  Precision: 0.93\n",
            "  Recall: 0.99\n",
            "  F1: 0.95\n",
            "The average precision is: 0.8308\n",
            "The average recall is: 0.8116\n",
            "The average f1 is: 0.8048\n",
            "  Training epcoh took: 0:01:40\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "Category: 0\n",
            "  Precision: 0.8983\n",
            "  Recall: 0.8946\n",
            "  F1: 0.8933\n",
            "Category: 1\n",
            "  Precision: 0.3872\n",
            "  Recall: 0.4808\n",
            "  F1: 0.3879\n",
            "The average precision is: 0.6428\n",
            "The average recall is: 0.6877\n",
            "The average f1 is: 0.6406\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    477.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    477.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    477.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    477.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    477.    Elapsed: 0:00:42.\n",
            "  Batch   320  of    477.    Elapsed: 0:01:06.\n",
            "  Batch   360  of    477.    Elapsed: 0:01:15.\n",
            "  Batch   400  of    477.    Elapsed: 0:01:23.\n",
            "  Batch   440  of    477.    Elapsed: 0:01:31.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.96\n",
            "  Recall: 0.96\n",
            "  F1: 0.96\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9816\n",
            "The average recall is: 0.9801\n",
            "The average f1 is: 0.9807\n",
            "  Training epcoh took: 0:01:39\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8778\n",
            "  Recall: 0.9654\n",
            "  F1: 0.9163\n",
            "Category: 1\n",
            "  Precision: 0.3654\n",
            "  Recall: 0.2622\n",
            "  F1: 0.2699\n",
            "The average precision is: 0.6216\n",
            "The average recall is: 0.6138\n",
            "The average f1 is: 0.5931\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    477.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    477.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    477.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    477.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    477.    Elapsed: 0:00:42.\n",
            "  Batch   240  of    477.    Elapsed: 0:00:50.\n",
            "  Batch   280  of    477.    Elapsed: 0:00:58.\n",
            "  Batch   320  of    477.    Elapsed: 0:01:07.\n",
            "  Batch   360  of    477.    Elapsed: 0:01:15.\n",
            "  Batch   400  of    477.    Elapsed: 0:01:23.\n",
            "  Batch   440  of    477.    Elapsed: 0:01:31.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.98\n",
            "  Recall: 0.98\n",
            "  F1: 0.98\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9879\n",
            "The average recall is: 0.9877\n",
            "The average f1 is: 0.9877\n",
            "  Training epcoh took: 0:01:39\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8785\n",
            "  Recall: 0.9558\n",
            "  F1: 0.9130\n",
            "Category: 1\n",
            "  Precision: 0.3590\n",
            "  Recall: 0.2244\n",
            "  F1: 0.2573\n",
            "The average precision is: 0.6188\n",
            "The average recall is: 0.5901\n",
            "The average f1 is: 0.5851\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.88\n",
            "Category: 0\n",
            "  Precision: 0.9199\n",
            "  Recall: 0.9462\n",
            "  F1: 0.9299\n",
            "Category: 1\n",
            "  Precision: 0.3485\n",
            "  Recall: 0.3303\n",
            "  F1: 0.3078\n",
            "The average precision is: 0.6342\n",
            "The average recall is: 0.6383\n",
            "The average f1 is: 0.6189\n",
            "  Testing took: 0:00:02\n",
            "Current increase 40 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 199 sampled in this category.\n",
            "After up-sample, there are 9608 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1449\n",
            "0.15081182348043298\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "8159\n",
            "0.849188176519567\n",
            "\n",
            "(9608, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 13:45:43.672270 140498471425856 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 13:45:43.673966 140498471425856 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 13:45:43.780955 140498471425856 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 13:45:46.327061 140498471425856 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 13:45:46.327804 140498471425856 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    601.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    601.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    601.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    601.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    601.    Elapsed: 0:00:41.\n",
            "  Batch   240  of    601.    Elapsed: 0:00:50.\n",
            "  Batch   280  of    601.    Elapsed: 0:00:58.\n",
            "  Batch   320  of    601.    Elapsed: 0:01:06.\n",
            "  Batch   360  of    601.    Elapsed: 0:01:15.\n",
            "  Batch   400  of    601.    Elapsed: 0:01:23.\n",
            "  Batch   440  of    601.    Elapsed: 0:01:32.\n",
            "  Batch   480  of    601.    Elapsed: 0:01:40.\n",
            "  Batch   520  of    601.    Elapsed: 0:01:48.\n",
            "  Batch   560  of    601.    Elapsed: 0:01:57.\n",
            "  Batch   600  of    601.    Elapsed: 0:02:06.\n",
            "\n",
            "  Average training loss: 0.17\n",
            "  Accuracy: 0.94\n",
            "Category: 0\n",
            "  Precision: 0.68\n",
            "  Recall: 0.60\n",
            "  F1: 0.62\n",
            "Category: 1\n",
            "  Precision: 0.95\n",
            "  Recall: 0.99\n",
            "  F1: 0.97\n",
            "The average precision is: 0.8136\n",
            "The average recall is: 0.7984\n",
            "The average f1 is: 0.7952\n",
            "  Training epcoh took: 0:02:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8689\n",
            "  Recall: 0.9794\n",
            "  F1: 0.9178\n",
            "Category: 1\n",
            "  Precision: 0.3397\n",
            "  Recall: 0.2263\n",
            "  F1: 0.2513\n",
            "The average precision is: 0.6043\n",
            "The average recall is: 0.6028\n",
            "The average f1 is: 0.5845\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    601.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    601.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    601.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    601.    Elapsed: 0:00:34.\n",
            "  Batch   200  of    601.    Elapsed: 0:00:42.\n",
            "  Batch   240  of    601.    Elapsed: 0:00:50.\n",
            "  Batch   280  of    601.    Elapsed: 0:00:58.\n",
            "  Batch   320  of    601.    Elapsed: 0:01:07.\n",
            "  Batch   360  of    601.    Elapsed: 0:01:15.\n",
            "  Batch   400  of    601.    Elapsed: 0:01:23.\n",
            "  Batch   440  of    601.    Elapsed: 0:01:32.\n",
            "  Batch   480  of    601.    Elapsed: 0:01:40.\n",
            "  Batch   520  of    601.    Elapsed: 0:01:48.\n",
            "  Batch   560  of    601.    Elapsed: 0:01:57.\n",
            "  Batch   600  of    601.    Elapsed: 0:02:05.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.92\n",
            "  Recall: 0.92\n",
            "  F1: 0.92\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9604\n",
            "The average recall is: 0.9573\n",
            "The average f1 is: 0.9575\n",
            "  Training epcoh took: 0:02:05\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8714\n",
            "  Recall: 0.9690\n",
            "  F1: 0.9149\n",
            "Category: 1\n",
            "  Precision: 0.3462\n",
            "  Recall: 0.1859\n",
            "  F1: 0.2282\n",
            "The average precision is: 0.6088\n",
            "The average recall is: 0.5775\n",
            "The average f1 is: 0.5715\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    601.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    601.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    601.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    601.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    601.    Elapsed: 0:00:42.\n",
            "  Batch   240  of    601.    Elapsed: 0:00:50.\n",
            "  Batch   280  of    601.    Elapsed: 0:00:59.\n",
            "  Batch   320  of    601.    Elapsed: 0:01:07.\n",
            "  Batch   360  of    601.    Elapsed: 0:01:15.\n",
            "  Batch   400  of    601.    Elapsed: 0:01:23.\n",
            "  Batch   440  of    601.    Elapsed: 0:01:32.\n",
            "  Batch   480  of    601.    Elapsed: 0:01:40.\n",
            "  Batch   520  of    601.    Elapsed: 0:01:49.\n",
            "  Batch   560  of    601.    Elapsed: 0:01:57.\n",
            "  Batch   600  of    601.    Elapsed: 0:02:05.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.90\n",
            "  Recall: 0.90\n",
            "  F1: 0.90\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9514\n",
            "The average recall is: 0.9500\n",
            "The average f1 is: 0.9503\n",
            "  Training epcoh took: 0:02:05\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "Category: 0\n",
            "  Precision: 0.8739\n",
            "  Recall: 0.9890\n",
            "  F1: 0.9258\n",
            "Category: 1\n",
            "  Precision: 0.3333\n",
            "  Recall: 0.1724\n",
            "  F1: 0.2244\n",
            "The average precision is: 0.6036\n",
            "The average recall is: 0.5807\n",
            "The average f1 is: 0.5751\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    601.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    601.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    601.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    601.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    601.    Elapsed: 0:00:42.\n",
            "  Batch   240  of    601.    Elapsed: 0:00:50.\n",
            "  Batch   280  of    601.    Elapsed: 0:00:58.\n",
            "  Batch   320  of    601.    Elapsed: 0:01:07.\n",
            "  Batch   360  of    601.    Elapsed: 0:01:15.\n",
            "  Batch   400  of    601.    Elapsed: 0:01:24.\n",
            "  Batch   440  of    601.    Elapsed: 0:01:32.\n",
            "  Batch   480  of    601.    Elapsed: 0:01:41.\n",
            "  Batch   520  of    601.    Elapsed: 0:01:49.\n",
            "  Batch   560  of    601.    Elapsed: 0:01:57.\n",
            "  Batch   600  of    601.    Elapsed: 0:02:06.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.93\n",
            "  Recall: 0.93\n",
            "  F1: 0.93\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9642\n",
            "The average recall is: 0.9647\n",
            "The average f1 is: 0.9643\n",
            "  Training epcoh took: 0:02:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8752\n",
            "  Recall: 0.9787\n",
            "  F1: 0.9206\n",
            "Category: 1\n",
            "  Precision: 0.3590\n",
            "  Recall: 0.2590\n",
            "  F1: 0.2625\n",
            "The average precision is: 0.6171\n",
            "The average recall is: 0.6189\n",
            "The average f1 is: 0.5915\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.90\n",
            "Category: 0\n",
            "  Precision: 0.9201\n",
            "  Recall: 0.9692\n",
            "  F1: 0.9429\n",
            "Category: 1\n",
            "  Precision: 0.4444\n",
            "  Recall: 0.3460\n",
            "  F1: 0.3662\n",
            "The average precision is: 0.6823\n",
            "The average recall is: 0.6576\n",
            "The average f1 is: 0.6546\n",
            "  Testing took: 0:00:02\n",
            "Current increase 50 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 199 sampled in this category.\n",
            "After up-sample, there are 11598 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1449\n",
            "0.12493533367822038\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "10149\n",
            "0.8750646663217796\n",
            "\n",
            "(11598, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 13:54:16.156310 140498471425856 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 13:54:16.157714 140498471425856 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 13:54:16.238157 140498471425856 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 13:54:18.762751 140498471425856 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 13:54:18.764130 140498471425856 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    725.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    725.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    725.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    725.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    725.    Elapsed: 0:00:42.\n",
            "  Batch   240  of    725.    Elapsed: 0:00:50.\n",
            "  Batch   280  of    725.    Elapsed: 0:00:58.\n",
            "  Batch   320  of    725.    Elapsed: 0:01:07.\n",
            "  Batch   360  of    725.    Elapsed: 0:01:15.\n",
            "  Batch   400  of    725.    Elapsed: 0:01:24.\n",
            "  Batch   440  of    725.    Elapsed: 0:01:32.\n",
            "  Batch   480  of    725.    Elapsed: 0:01:41.\n",
            "  Batch   520  of    725.    Elapsed: 0:01:49.\n",
            "  Batch   560  of    725.    Elapsed: 0:01:57.\n",
            "  Batch   600  of    725.    Elapsed: 0:02:06.\n",
            "  Batch   640  of    725.    Elapsed: 0:02:14.\n",
            "  Batch   680  of    725.    Elapsed: 0:02:22.\n",
            "  Batch   720  of    725.    Elapsed: 0:02:31.\n",
            "\n",
            "  Average training loss: 0.14\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.68\n",
            "  Recall: 0.63\n",
            "  F1: 0.64\n",
            "Category: 1\n",
            "  Precision: 0.96\n",
            "  Recall: 0.99\n",
            "  F1: 0.98\n",
            "The average precision is: 0.8222\n",
            "The average recall is: 0.8096\n",
            "The average f1 is: 0.8067\n",
            "  Training epcoh took: 0:02:32\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8759\n",
            "  Recall: 0.9720\n",
            "  F1: 0.9168\n",
            "Category: 1\n",
            "  Precision: 0.4192\n",
            "  Recall: 0.2641\n",
            "  F1: 0.2919\n",
            "The average precision is: 0.6476\n",
            "The average recall is: 0.6180\n",
            "The average f1 is: 0.6044\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    725.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    725.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    725.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    725.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    725.    Elapsed: 0:00:42.\n",
            "  Batch   240  of    725.    Elapsed: 0:00:50.\n",
            "  Batch   280  of    725.    Elapsed: 0:00:58.\n",
            "  Batch   320  of    725.    Elapsed: 0:01:07.\n",
            "  Batch   360  of    725.    Elapsed: 0:01:15.\n",
            "  Batch   400  of    725.    Elapsed: 0:01:24.\n",
            "  Batch   440  of    725.    Elapsed: 0:01:32.\n",
            "  Batch   480  of    725.    Elapsed: 0:01:40.\n",
            "  Batch   520  of    725.    Elapsed: 0:01:48.\n",
            "  Batch   560  of    725.    Elapsed: 0:01:57.\n",
            "  Batch   600  of    725.    Elapsed: 0:02:05.\n",
            "  Batch   640  of    725.    Elapsed: 0:02:13.\n",
            "  Batch   680  of    725.    Elapsed: 0:02:22.\n",
            "  Batch   720  of    725.    Elapsed: 0:02:30.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.89\n",
            "  Recall: 0.88\n",
            "  F1: 0.89\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9456\n",
            "The average recall is: 0.9416\n",
            "The average f1 is: 0.9427\n",
            "  Training epcoh took: 0:02:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8709\n",
            "  Recall: 0.9796\n",
            "  F1: 0.9205\n",
            "Category: 1\n",
            "  Precision: 0.3526\n",
            "  Recall: 0.2000\n",
            "  F1: 0.2436\n",
            "The average precision is: 0.6117\n",
            "The average recall is: 0.5898\n",
            "The average f1 is: 0.5820\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    725.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    725.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    725.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    725.    Elapsed: 0:00:34.\n",
            "  Batch   200  of    725.    Elapsed: 0:00:42.\n",
            "  Batch   240  of    725.    Elapsed: 0:00:50.\n",
            "  Batch   280  of    725.    Elapsed: 0:00:59.\n",
            "  Batch   320  of    725.    Elapsed: 0:01:07.\n",
            "  Batch   360  of    725.    Elapsed: 0:01:15.\n",
            "  Batch   400  of    725.    Elapsed: 0:01:23.\n",
            "  Batch   440  of    725.    Elapsed: 0:01:32.\n",
            "  Batch   480  of    725.    Elapsed: 0:01:40.\n",
            "  Batch   520  of    725.    Elapsed: 0:01:49.\n",
            "  Batch   560  of    725.    Elapsed: 0:01:57.\n",
            "  Batch   600  of    725.    Elapsed: 0:02:05.\n",
            "  Batch   640  of    725.    Elapsed: 0:02:14.\n",
            "  Batch   680  of    725.    Elapsed: 0:02:22.\n",
            "  Batch   720  of    725.    Elapsed: 0:02:30.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.89\n",
            "  Recall: 0.88\n",
            "  F1: 0.88\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9422\n",
            "The average recall is: 0.9416\n",
            "The average f1 is: 0.9416\n",
            "  Training epcoh took: 0:02:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.8735\n",
            "  Recall: 0.9572\n",
            "  F1: 0.9086\n",
            "Category: 1\n",
            "  Precision: 0.4423\n",
            "  Recall: 0.2449\n",
            "  F1: 0.2892\n",
            "The average precision is: 0.6579\n",
            "The average recall is: 0.6010\n",
            "The average f1 is: 0.5989\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    725.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    725.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    725.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    725.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    725.    Elapsed: 0:00:42.\n",
            "  Batch   240  of    725.    Elapsed: 0:00:50.\n",
            "  Batch   280  of    725.    Elapsed: 0:00:58.\n",
            "  Batch   320  of    725.    Elapsed: 0:01:07.\n",
            "  Batch   360  of    725.    Elapsed: 0:01:15.\n",
            "  Batch   400  of    725.    Elapsed: 0:01:23.\n",
            "  Batch   440  of    725.    Elapsed: 0:01:32.\n",
            "  Batch   480  of    725.    Elapsed: 0:01:40.\n",
            "  Batch   520  of    725.    Elapsed: 0:01:48.\n",
            "  Batch   560  of    725.    Elapsed: 0:01:57.\n",
            "  Batch   600  of    725.    Elapsed: 0:02:05.\n",
            "  Batch   640  of    725.    Elapsed: 0:02:13.\n",
            "  Batch   680  of    725.    Elapsed: 0:02:22.\n",
            "  Batch   720  of    725.    Elapsed: 0:02:30.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.88\n",
            "  Recall: 0.88\n",
            "  F1: 0.88\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9420\n",
            "The average recall is: 0.9417\n",
            "The average f1 is: 0.9418\n",
            "  Training epcoh took: 0:02:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.8783\n",
            "  Recall: 0.9442\n",
            "  F1: 0.9058\n",
            "Category: 1\n",
            "  Precision: 0.2885\n",
            "  Recall: 0.2647\n",
            "  F1: 0.2500\n",
            "The average precision is: 0.5834\n",
            "The average recall is: 0.6044\n",
            "The average f1 is: 0.5779\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.88\n",
            "Category: 0\n",
            "  Precision: 0.9212\n",
            "  Recall: 0.9484\n",
            "  F1: 0.9325\n",
            "Category: 1\n",
            "  Precision: 0.3965\n",
            "  Recall: 0.3424\n",
            "  F1: 0.3365\n",
            "The average precision is: 0.6588\n",
            "The average recall is: 0.6454\n",
            "The average f1 is: 0.6345\n",
            "  Testing took: 0:00:02\n",
            "Current increase 60 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 199 sampled in this category.\n",
            "After up-sample, there are 13588 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1449\n",
            "0.10663821018545776\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "12139\n",
            "0.8933617898145423\n",
            "\n",
            "(13588, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 14:04:31.876816 140498471425856 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 14:04:31.878347 140498471425856 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 14:04:32.368475 140498471425856 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 14:04:34.905485 140498471425856 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 14:04:34.906205 140498471425856 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    850.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    850.    Elapsed: 0:00:16.\n",
            "  Batch   120  of    850.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    850.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    850.    Elapsed: 0:00:41.\n",
            "  Batch   240  of    850.    Elapsed: 0:00:50.\n",
            "  Batch   280  of    850.    Elapsed: 0:00:58.\n",
            "  Batch   320  of    850.    Elapsed: 0:01:06.\n",
            "  Batch   360  of    850.    Elapsed: 0:01:15.\n",
            "  Batch   400  of    850.    Elapsed: 0:01:23.\n",
            "  Batch   440  of    850.    Elapsed: 0:01:32.\n",
            "  Batch   480  of    850.    Elapsed: 0:01:40.\n",
            "  Batch   520  of    850.    Elapsed: 0:01:49.\n",
            "  Batch   560  of    850.    Elapsed: 0:01:57.\n",
            "  Batch   600  of    850.    Elapsed: 0:02:05.\n",
            "  Batch   640  of    850.    Elapsed: 0:02:13.\n",
            "  Batch   680  of    850.    Elapsed: 0:02:22.\n",
            "  Batch   720  of    850.    Elapsed: 0:02:30.\n",
            "  Batch   760  of    850.    Elapsed: 0:02:38.\n",
            "  Batch   800  of    850.    Elapsed: 0:02:47.\n",
            "  Batch   840  of    850.    Elapsed: 0:02:55.\n",
            "\n",
            "  Average training loss: 0.14\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.62\n",
            "  Recall: 0.57\n",
            "  F1: 0.58\n",
            "Category: 1\n",
            "  Precision: 0.96\n",
            "  Recall: 0.99\n",
            "  F1: 0.98\n",
            "The average precision is: 0.7934\n",
            "The average recall is: 0.7809\n",
            "The average f1 is: 0.7783\n",
            "  Training epcoh took: 0:02:57\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "Category: 0\n",
            "  Precision: 0.8970\n",
            "  Recall: 0.8998\n",
            "  F1: 0.8959\n",
            "Category: 1\n",
            "  Precision: 0.4083\n",
            "  Recall: 0.4090\n",
            "  F1: 0.3814\n",
            "The average precision is: 0.6527\n",
            "The average recall is: 0.6544\n",
            "The average f1 is: 0.6386\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    850.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    850.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    850.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    850.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    850.    Elapsed: 0:00:42.\n",
            "  Batch   240  of    850.    Elapsed: 0:00:50.\n",
            "  Batch   280  of    850.    Elapsed: 0:00:58.\n",
            "  Batch   320  of    850.    Elapsed: 0:01:07.\n",
            "  Batch   360  of    850.    Elapsed: 0:01:15.\n",
            "  Batch   400  of    850.    Elapsed: 0:01:24.\n",
            "  Batch   440  of    850.    Elapsed: 0:01:32.\n",
            "  Batch   480  of    850.    Elapsed: 0:01:40.\n",
            "  Batch   520  of    850.    Elapsed: 0:01:49.\n",
            "  Batch   560  of    850.    Elapsed: 0:01:57.\n",
            "  Batch   600  of    850.    Elapsed: 0:02:06.\n",
            "  Batch   640  of    850.    Elapsed: 0:02:14.\n",
            "  Batch   680  of    850.    Elapsed: 0:02:22.\n",
            "  Batch   720  of    850.    Elapsed: 0:02:30.\n",
            "  Batch   760  of    850.    Elapsed: 0:02:39.\n",
            "  Batch   800  of    850.    Elapsed: 0:02:47.\n",
            "  Batch   840  of    850.    Elapsed: 0:02:55.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.82\n",
            "  Recall: 0.81\n",
            "  F1: 0.81\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9072\n",
            "The average recall is: 0.9035\n",
            "The average f1 is: 0.9042\n",
            "  Training epcoh took: 0:02:57\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8766\n",
            "  Recall: 0.9689\n",
            "  F1: 0.9172\n",
            "Category: 1\n",
            "  Precision: 0.3141\n",
            "  Recall: 0.2429\n",
            "  F1: 0.2500\n",
            "The average precision is: 0.5953\n",
            "The average recall is: 0.6059\n",
            "The average f1 is: 0.5836\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    850.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    850.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    850.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    850.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    850.    Elapsed: 0:00:42.\n",
            "  Batch   240  of    850.    Elapsed: 0:00:50.\n",
            "  Batch   280  of    850.    Elapsed: 0:00:58.\n",
            "  Batch   320  of    850.    Elapsed: 0:01:07.\n",
            "  Batch   360  of    850.    Elapsed: 0:01:15.\n",
            "  Batch   400  of    850.    Elapsed: 0:01:23.\n",
            "  Batch   440  of    850.    Elapsed: 0:01:32.\n",
            "  Batch   480  of    850.    Elapsed: 0:01:40.\n",
            "  Batch   520  of    850.    Elapsed: 0:01:49.\n",
            "  Batch   560  of    850.    Elapsed: 0:01:57.\n",
            "  Batch   600  of    850.    Elapsed: 0:02:05.\n",
            "  Batch   640  of    850.    Elapsed: 0:02:14.\n",
            "  Batch   680  of    850.    Elapsed: 0:02:22.\n",
            "  Batch   720  of    850.    Elapsed: 0:02:30.\n",
            "  Batch   760  of    850.    Elapsed: 0:02:39.\n",
            "  Batch   800  of    850.    Elapsed: 0:02:47.\n",
            "  Batch   840  of    850.    Elapsed: 0:02:55.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.83\n",
            "  Recall: 0.83\n",
            "  F1: 0.83\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9145\n",
            "The average recall is: 0.9138\n",
            "The average f1 is: 0.9139\n",
            "  Training epcoh took: 0:02:57\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8826\n",
            "  Recall: 0.9462\n",
            "  F1: 0.9095\n",
            "Category: 1\n",
            "  Precision: 0.3526\n",
            "  Recall: 0.3128\n",
            "  F1: 0.3168\n",
            "The average precision is: 0.6176\n",
            "The average recall is: 0.6295\n",
            "The average f1 is: 0.6131\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    850.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    850.    Elapsed: 0:00:16.\n",
            "  Batch   120  of    850.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    850.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    850.    Elapsed: 0:00:42.\n",
            "  Batch   240  of    850.    Elapsed: 0:00:50.\n",
            "  Batch   280  of    850.    Elapsed: 0:00:58.\n",
            "  Batch   320  of    850.    Elapsed: 0:01:07.\n",
            "  Batch   360  of    850.    Elapsed: 0:01:15.\n",
            "  Batch   400  of    850.    Elapsed: 0:01:23.\n",
            "  Batch   440  of    850.    Elapsed: 0:01:32.\n",
            "  Batch   480  of    850.    Elapsed: 0:01:40.\n",
            "  Batch   520  of    850.    Elapsed: 0:01:48.\n",
            "  Batch   560  of    850.    Elapsed: 0:01:57.\n",
            "  Batch   600  of    850.    Elapsed: 0:02:05.\n",
            "  Batch   640  of    850.    Elapsed: 0:02:14.\n",
            "  Batch   680  of    850.    Elapsed: 0:02:22.\n",
            "  Batch   720  of    850.    Elapsed: 0:02:30.\n",
            "  Batch   760  of    850.    Elapsed: 0:02:38.\n",
            "  Batch   800  of    850.    Elapsed: 0:02:47.\n",
            "  Batch   840  of    850.    Elapsed: 0:02:55.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.84\n",
            "  Recall: 0.84\n",
            "  F1: 0.84\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.9179\n",
            "The average recall is: 0.9179\n",
            "The average f1 is: 0.9178\n",
            "  Training epcoh took: 0:02:57\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8768\n",
            "  Recall: 0.9583\n",
            "  F1: 0.9137\n",
            "Category: 1\n",
            "  Precision: 0.3910\n",
            "  Recall: 0.1987\n",
            "  F1: 0.2502\n",
            "The average precision is: 0.6339\n",
            "The average recall is: 0.5785\n",
            "The average f1 is: 0.5820\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.90\n",
            "Category: 0\n",
            "  Precision: 0.9235\n",
            "  Recall: 0.9635\n",
            "  F1: 0.9412\n",
            "Category: 1\n",
            "  Precision: 0.4444\n",
            "  Recall: 0.3914\n",
            "  F1: 0.3766\n",
            "The average precision is: 0.6840\n",
            "The average recall is: 0.6775\n",
            "The average f1 is: 0.6589\n",
            "  Testing took: 0:00:02\n",
            "Current increase 70 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 199 sampled in this category.\n",
            "After up-sample, there are 15578 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1449\n",
            "0.09301579150083451\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "14129\n",
            "0.9069842084991655\n",
            "\n",
            "(15578, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 14:16:31.960122 140498471425856 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 14:16:31.961571 140498471425856 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 14:16:32.078107 140498471425856 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 14:16:34.578126 140498471425856 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 14:16:34.578857 140498471425856 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    974.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    974.    Elapsed: 0:00:16.\n",
            "  Batch   120  of    974.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    974.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    974.    Elapsed: 0:00:42.\n",
            "  Batch   240  of    974.    Elapsed: 0:00:50.\n",
            "  Batch   280  of    974.    Elapsed: 0:00:58.\n",
            "  Batch   320  of    974.    Elapsed: 0:01:07.\n",
            "  Batch   360  of    974.    Elapsed: 0:01:15.\n",
            "  Batch   400  of    974.    Elapsed: 0:01:24.\n",
            "  Batch   440  of    974.    Elapsed: 0:01:32.\n",
            "  Batch   480  of    974.    Elapsed: 0:01:40.\n",
            "  Batch   520  of    974.    Elapsed: 0:01:49.\n",
            "  Batch   560  of    974.    Elapsed: 0:01:57.\n",
            "  Batch   600  of    974.    Elapsed: 0:02:05.\n",
            "  Batch   640  of    974.    Elapsed: 0:02:14.\n",
            "  Batch   680  of    974.    Elapsed: 0:02:22.\n",
            "  Batch   720  of    974.    Elapsed: 0:02:31.\n",
            "  Batch   760  of    974.    Elapsed: 0:02:39.\n",
            "  Batch   800  of    974.    Elapsed: 0:02:47.\n",
            "  Batch   840  of    974.    Elapsed: 0:02:56.\n",
            "  Batch   880  of    974.    Elapsed: 0:03:04.\n",
            "  Batch   920  of    974.    Elapsed: 0:03:13.\n",
            "  Batch   960  of    974.    Elapsed: 0:03:21.\n",
            "\n",
            "  Average training loss: 0.14\n",
            "  Accuracy: 0.96\n",
            "Category: 0\n",
            "  Precision: 0.58\n",
            "  Recall: 0.53\n",
            "  F1: 0.54\n",
            "Category: 1\n",
            "  Precision: 0.96\n",
            "  Recall: 0.99\n",
            "  F1: 0.98\n",
            "The average precision is: 0.7715\n",
            "The average recall is: 0.7592\n",
            "The average f1 is: 0.7566\n",
            "  Training epcoh took: 0:03:24\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8726\n",
            "  Recall: 0.9566\n",
            "  F1: 0.9102\n",
            "Category: 1\n",
            "  Precision: 0.3910\n",
            "  Recall: 0.2449\n",
            "  F1: 0.2782\n",
            "The average precision is: 0.6318\n",
            "The average recall is: 0.6008\n",
            "The average f1 is: 0.5942\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    974.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    974.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    974.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    974.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    974.    Elapsed: 0:00:42.\n",
            "  Batch   240  of    974.    Elapsed: 0:00:50.\n",
            "  Batch   280  of    974.    Elapsed: 0:00:58.\n",
            "  Batch   320  of    974.    Elapsed: 0:01:07.\n",
            "  Batch   360  of    974.    Elapsed: 0:01:15.\n",
            "  Batch   400  of    974.    Elapsed: 0:01:23.\n",
            "  Batch   440  of    974.    Elapsed: 0:01:32.\n",
            "  Batch   480  of    974.    Elapsed: 0:01:40.\n",
            "  Batch   520  of    974.    Elapsed: 0:01:48.\n",
            "  Batch   560  of    974.    Elapsed: 0:01:57.\n",
            "  Batch   600  of    974.    Elapsed: 0:02:05.\n",
            "  Batch   640  of    974.    Elapsed: 0:02:13.\n",
            "  Batch   680  of    974.    Elapsed: 0:02:22.\n",
            "  Batch   720  of    974.    Elapsed: 0:02:30.\n",
            "  Batch   760  of    974.    Elapsed: 0:02:38.\n",
            "  Batch   800  of    974.    Elapsed: 0:02:47.\n",
            "  Batch   840  of    974.    Elapsed: 0:02:55.\n",
            "  Batch   880  of    974.    Elapsed: 0:03:03.\n",
            "  Batch   920  of    974.    Elapsed: 0:03:12.\n",
            "  Batch   960  of    974.    Elapsed: 0:03:20.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.80\n",
            "  Recall: 0.79\n",
            "  F1: 0.79\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.8971\n",
            "The average recall is: 0.8948\n",
            "The average f1 is: 0.8952\n",
            "  Training epcoh took: 0:03:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8863\n",
            "  Recall: 0.9401\n",
            "  F1: 0.9101\n",
            "Category: 1\n",
            "  Precision: 0.4006\n",
            "  Recall: 0.3288\n",
            "  F1: 0.3301\n",
            "The average precision is: 0.6435\n",
            "The average recall is: 0.6345\n",
            "The average f1 is: 0.6201\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    974.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    974.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    974.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    974.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    974.    Elapsed: 0:00:42.\n",
            "  Batch   240  of    974.    Elapsed: 0:00:50.\n",
            "  Batch   280  of    974.    Elapsed: 0:00:58.\n",
            "  Batch   320  of    974.    Elapsed: 0:01:07.\n",
            "  Batch   360  of    974.    Elapsed: 0:01:15.\n",
            "  Batch   400  of    974.    Elapsed: 0:01:23.\n",
            "  Batch   440  of    974.    Elapsed: 0:01:32.\n",
            "  Batch   480  of    974.    Elapsed: 0:01:40.\n",
            "  Batch   520  of    974.    Elapsed: 0:01:48.\n",
            "  Batch   560  of    974.    Elapsed: 0:01:57.\n",
            "  Batch   600  of    974.    Elapsed: 0:02:05.\n",
            "  Batch   640  of    974.    Elapsed: 0:02:13.\n",
            "  Batch   680  of    974.    Elapsed: 0:02:22.\n",
            "  Batch   720  of    974.    Elapsed: 0:02:30.\n",
            "  Batch   760  of    974.    Elapsed: 0:02:38.\n",
            "  Batch   800  of    974.    Elapsed: 0:02:46.\n",
            "  Batch   840  of    974.    Elapsed: 0:02:55.\n",
            "  Batch   880  of    974.    Elapsed: 0:03:03.\n",
            "  Batch   920  of    974.    Elapsed: 0:03:11.\n",
            "  Batch   960  of    974.    Elapsed: 0:03:20.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.78\n",
            "  Recall: 0.78\n",
            "  F1: 0.78\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.8881\n",
            "The average recall is: 0.8881\n",
            "The average f1 is: 0.8880\n",
            "  Training epcoh took: 0:03:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.8762\n",
            "  Recall: 0.9423\n",
            "  F1: 0.9058\n",
            "Category: 1\n",
            "  Precision: 0.3205\n",
            "  Recall: 0.2058\n",
            "  F1: 0.2385\n",
            "The average precision is: 0.5984\n",
            "The average recall is: 0.5740\n",
            "The average f1 is: 0.5721\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    974.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    974.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    974.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    974.    Elapsed: 0:00:33.\n",
            "  Batch   200  of    974.    Elapsed: 0:00:42.\n",
            "  Batch   240  of    974.    Elapsed: 0:00:50.\n",
            "  Batch   280  of    974.    Elapsed: 0:00:58.\n",
            "  Batch   320  of    974.    Elapsed: 0:01:07.\n",
            "  Batch   360  of    974.    Elapsed: 0:01:15.\n",
            "  Batch   400  of    974.    Elapsed: 0:01:23.\n",
            "  Batch   440  of    974.    Elapsed: 0:01:32.\n",
            "  Batch   480  of    974.    Elapsed: 0:01:40.\n",
            "  Batch   520  of    974.    Elapsed: 0:01:48.\n",
            "  Batch   560  of    974.    Elapsed: 0:01:57.\n",
            "  Batch   600  of    974.    Elapsed: 0:02:05.\n",
            "  Batch   640  of    974.    Elapsed: 0:02:13.\n",
            "  Batch   680  of    974.    Elapsed: 0:02:22.\n",
            "  Batch   720  of    974.    Elapsed: 0:02:30.\n",
            "  Batch   760  of    974.    Elapsed: 0:02:38.\n",
            "  Batch   800  of    974.    Elapsed: 0:02:46.\n",
            "  Batch   840  of    974.    Elapsed: 0:02:55.\n",
            "  Batch   880  of    974.    Elapsed: 0:03:03.\n",
            "  Batch   920  of    974.    Elapsed: 0:03:11.\n",
            "  Batch   960  of    974.    Elapsed: 0:03:20.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.77\n",
            "  Recall: 0.77\n",
            "  F1: 0.77\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.8844\n",
            "The average recall is: 0.8841\n",
            "The average f1 is: 0.8842\n",
            "  Training epcoh took: 0:03:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8788\n",
            "  Recall: 0.9650\n",
            "  F1: 0.9170\n",
            "Category: 1\n",
            "  Precision: 0.4103\n",
            "  Recall: 0.2654\n",
            "  F1: 0.2984\n",
            "The average precision is: 0.6445\n",
            "The average recall is: 0.6152\n",
            "The average f1 is: 0.6077\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.89\n",
            "Category: 0\n",
            "  Precision: 0.9170\n",
            "  Recall: 0.9653\n",
            "  F1: 0.9378\n",
            "Category: 1\n",
            "  Precision: 0.3687\n",
            "  Recall: 0.2394\n",
            "  F1: 0.2675\n",
            "The average precision is: 0.6428\n",
            "The average recall is: 0.6024\n",
            "The average f1 is: 0.6027\n",
            "  Testing took: 0:00:02\n",
            "Current increase 80 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 199 sampled in this category.\n",
            "After up-sample, there are 17568 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1449\n",
            "0.08247950819672131\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "16119\n",
            "0.9175204918032787\n",
            "\n",
            "(17568, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 14:30:14.235349 140498471425856 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 14:30:14.236701 140498471425856 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 14:30:16.434361 140498471425856 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 14:30:18.922382 140498471425856 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 14:30:18.923141 140498471425856 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  1,098.    Elapsed: 0:00:08.\n",
            "  Batch    80  of  1,098.    Elapsed: 0:00:16.\n",
            "  Batch   120  of  1,098.    Elapsed: 0:00:25.\n",
            "  Batch   160  of  1,098.    Elapsed: 0:00:33.\n",
            "  Batch   200  of  1,098.    Elapsed: 0:00:41.\n",
            "  Batch   240  of  1,098.    Elapsed: 0:00:50.\n",
            "  Batch   280  of  1,098.    Elapsed: 0:00:58.\n",
            "  Batch   320  of  1,098.    Elapsed: 0:01:06.\n",
            "  Batch   360  of  1,098.    Elapsed: 0:01:14.\n",
            "  Batch   400  of  1,098.    Elapsed: 0:01:23.\n",
            "  Batch   440  of  1,098.    Elapsed: 0:01:31.\n",
            "  Batch   480  of  1,098.    Elapsed: 0:01:40.\n",
            "  Batch   520  of  1,098.    Elapsed: 0:01:48.\n",
            "  Batch   560  of  1,098.    Elapsed: 0:01:56.\n",
            "  Batch   600  of  1,098.    Elapsed: 0:02:05.\n",
            "  Batch   640  of  1,098.    Elapsed: 0:02:13.\n",
            "  Batch   680  of  1,098.    Elapsed: 0:02:21.\n",
            "  Batch   720  of  1,098.    Elapsed: 0:02:30.\n",
            "  Batch   760  of  1,098.    Elapsed: 0:02:38.\n",
            "  Batch   800  of  1,098.    Elapsed: 0:02:47.\n",
            "  Batch   840  of  1,098.    Elapsed: 0:02:55.\n",
            "  Batch   880  of  1,098.    Elapsed: 0:03:03.\n",
            "  Batch   920  of  1,098.    Elapsed: 0:03:12.\n",
            "  Batch   960  of  1,098.    Elapsed: 0:03:20.\n",
            "  Batch 1,000  of  1,098.    Elapsed: 0:03:28.\n",
            "  Batch 1,040  of  1,098.    Elapsed: 0:03:37.\n",
            "  Batch 1,080  of  1,098.    Elapsed: 0:03:45.\n",
            "\n",
            "  Average training loss: 0.09\n",
            "  Accuracy: 0.98\n",
            "Category: 0\n",
            "  Precision: 0.55\n",
            "  Recall: 0.52\n",
            "  F1: 0.53\n",
            "Category: 1\n",
            "  Precision: 0.98\n",
            "  Recall: 1.00\n",
            "  F1: 0.99\n",
            "The average precision is: 0.7643\n",
            "The average recall is: 0.7580\n",
            "The average f1 is: 0.7574\n",
            "  Training epcoh took: 0:03:49\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8782\n",
            "  Recall: 0.9523\n",
            "  F1: 0.9112\n",
            "Category: 1\n",
            "  Precision: 0.3397\n",
            "  Recall: 0.2506\n",
            "  F1: 0.2650\n",
            "The average precision is: 0.6090\n",
            "The average recall is: 0.6015\n",
            "The average f1 is: 0.5881\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  1,098.    Elapsed: 0:00:09.\n",
            "  Batch    80  of  1,098.    Elapsed: 0:00:17.\n",
            "  Batch   120  of  1,098.    Elapsed: 0:00:25.\n",
            "  Batch   160  of  1,098.    Elapsed: 0:00:33.\n",
            "  Batch   200  of  1,098.    Elapsed: 0:00:42.\n",
            "  Batch   240  of  1,098.    Elapsed: 0:00:50.\n",
            "  Batch   280  of  1,098.    Elapsed: 0:00:58.\n",
            "  Batch   320  of  1,098.    Elapsed: 0:01:07.\n",
            "  Batch   360  of  1,098.    Elapsed: 0:01:15.\n",
            "  Batch   400  of  1,098.    Elapsed: 0:01:24.\n",
            "  Batch   440  of  1,098.    Elapsed: 0:01:32.\n",
            "  Batch   480  of  1,098.    Elapsed: 0:01:40.\n",
            "  Batch   520  of  1,098.    Elapsed: 0:01:49.\n",
            "  Batch   560  of  1,098.    Elapsed: 0:01:57.\n",
            "  Batch   600  of  1,098.    Elapsed: 0:02:06.\n",
            "  Batch   640  of  1,098.    Elapsed: 0:02:14.\n",
            "  Batch   680  of  1,098.    Elapsed: 0:02:22.\n",
            "  Batch   720  of  1,098.    Elapsed: 0:02:30.\n",
            "  Batch   760  of  1,098.    Elapsed: 0:02:39.\n",
            "  Batch   800  of  1,098.    Elapsed: 0:02:47.\n",
            "  Batch   840  of  1,098.    Elapsed: 0:02:56.\n",
            "  Batch   880  of  1,098.    Elapsed: 0:03:04.\n",
            "  Batch   920  of  1,098.    Elapsed: 0:03:13.\n",
            "  Batch   960  of  1,098.    Elapsed: 0:03:21.\n",
            "  Batch 1,000  of  1,098.    Elapsed: 0:03:29.\n",
            "  Batch 1,040  of  1,098.    Elapsed: 0:03:37.\n",
            "  Batch 1,080  of  1,098.    Elapsed: 0:03:46.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.73\n",
            "  Recall: 0.72\n",
            "  F1: 0.72\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.8630\n",
            "The average recall is: 0.8618\n",
            "The average f1 is: 0.8618\n",
            "  Training epcoh took: 0:03:50\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8816\n",
            "  Recall: 0.9633\n",
            "  F1: 0.9176\n",
            "Category: 1\n",
            "  Precision: 0.3942\n",
            "  Recall: 0.2692\n",
            "  F1: 0.2943\n",
            "The average precision is: 0.6379\n",
            "The average recall is: 0.6162\n",
            "The average f1 is: 0.6060\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  1,098.    Elapsed: 0:00:08.\n",
            "  Batch    80  of  1,098.    Elapsed: 0:00:17.\n",
            "  Batch   120  of  1,098.    Elapsed: 0:00:25.\n",
            "  Batch   160  of  1,098.    Elapsed: 0:00:33.\n",
            "  Batch   200  of  1,098.    Elapsed: 0:00:42.\n",
            "  Batch   240  of  1,098.    Elapsed: 0:00:50.\n",
            "  Batch   280  of  1,098.    Elapsed: 0:00:59.\n",
            "  Batch   320  of  1,098.    Elapsed: 0:01:07.\n",
            "  Batch   360  of  1,098.    Elapsed: 0:01:16.\n",
            "  Batch   400  of  1,098.    Elapsed: 0:01:24.\n",
            "  Batch   440  of  1,098.    Elapsed: 0:01:32.\n",
            "  Batch   480  of  1,098.    Elapsed: 0:01:41.\n",
            "  Batch   520  of  1,098.    Elapsed: 0:01:49.\n",
            "  Batch   560  of  1,098.    Elapsed: 0:01:57.\n",
            "  Batch   600  of  1,098.    Elapsed: 0:02:06.\n",
            "  Batch   640  of  1,098.    Elapsed: 0:02:14.\n",
            "  Batch   680  of  1,098.    Elapsed: 0:02:23.\n",
            "  Batch   720  of  1,098.    Elapsed: 0:02:31.\n",
            "  Batch   760  of  1,098.    Elapsed: 0:02:39.\n",
            "  Batch   800  of  1,098.    Elapsed: 0:02:48.\n",
            "  Batch   840  of  1,098.    Elapsed: 0:02:56.\n",
            "  Batch   880  of  1,098.    Elapsed: 0:03:04.\n",
            "  Batch   920  of  1,098.    Elapsed: 0:03:13.\n",
            "  Batch   960  of  1,098.    Elapsed: 0:03:21.\n",
            "  Batch 1,000  of  1,098.    Elapsed: 0:03:30.\n",
            "  Batch 1,040  of  1,098.    Elapsed: 0:03:38.\n",
            "  Batch 1,080  of  1,098.    Elapsed: 0:03:47.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.75\n",
            "  Recall: 0.75\n",
            "  F1: 0.75\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.8743\n",
            "The average recall is: 0.8737\n",
            "The average f1 is: 0.8738\n",
            "  Training epcoh took: 0:03:50\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8722\n",
            "  Recall: 0.9570\n",
            "  F1: 0.9106\n",
            "Category: 1\n",
            "  Precision: 0.3910\n",
            "  Recall: 0.2261\n",
            "  F1: 0.2789\n",
            "The average precision is: 0.6316\n",
            "The average recall is: 0.5916\n",
            "The average f1 is: 0.5948\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  1,098.    Elapsed: 0:00:08.\n",
            "  Batch    80  of  1,098.    Elapsed: 0:00:17.\n",
            "  Batch   120  of  1,098.    Elapsed: 0:00:25.\n",
            "  Batch   160  of  1,098.    Elapsed: 0:00:34.\n",
            "  Batch   200  of  1,098.    Elapsed: 0:00:42.\n",
            "  Batch   240  of  1,098.    Elapsed: 0:00:50.\n",
            "  Batch   280  of  1,098.    Elapsed: 0:00:59.\n",
            "  Batch   320  of  1,098.    Elapsed: 0:01:07.\n",
            "  Batch   360  of  1,098.    Elapsed: 0:01:15.\n",
            "  Batch   400  of  1,098.    Elapsed: 0:01:24.\n",
            "  Batch   440  of  1,098.    Elapsed: 0:01:32.\n",
            "  Batch   480  of  1,098.    Elapsed: 0:01:40.\n",
            "  Batch   520  of  1,098.    Elapsed: 0:01:49.\n",
            "  Batch   560  of  1,098.    Elapsed: 0:01:57.\n",
            "  Batch   600  of  1,098.    Elapsed: 0:02:05.\n",
            "  Batch   640  of  1,098.    Elapsed: 0:02:14.\n",
            "  Batch   680  of  1,098.    Elapsed: 0:02:22.\n",
            "  Batch   720  of  1,098.    Elapsed: 0:02:31.\n",
            "  Batch   760  of  1,098.    Elapsed: 0:02:39.\n",
            "  Batch   800  of  1,098.    Elapsed: 0:02:47.\n",
            "  Batch   840  of  1,098.    Elapsed: 0:02:56.\n",
            "  Batch   880  of  1,098.    Elapsed: 0:03:04.\n",
            "  Batch   920  of  1,098.    Elapsed: 0:03:13.\n",
            "  Batch   960  of  1,098.    Elapsed: 0:03:21.\n",
            "  Batch 1,000  of  1,098.    Elapsed: 0:03:29.\n",
            "  Batch 1,040  of  1,098.    Elapsed: 0:03:38.\n",
            "  Batch 1,080  of  1,098.    Elapsed: 0:03:46.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.76\n",
            "  Recall: 0.76\n",
            "  F1: 0.76\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.8782\n",
            "The average recall is: 0.8782\n",
            "The average f1 is: 0.8781\n",
            "  Training epcoh took: 0:03:50\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8766\n",
            "  Recall: 0.9601\n",
            "  F1: 0.9149\n",
            "Category: 1\n",
            "  Precision: 0.3333\n",
            "  Recall: 0.2212\n",
            "  F1: 0.2496\n",
            "The average precision is: 0.6050\n",
            "The average recall is: 0.5906\n",
            "The average f1 is: 0.5823\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.89\n",
            "Category: 0\n",
            "  Precision: 0.9219\n",
            "  Recall: 0.9549\n",
            "  F1: 0.9349\n",
            "Category: 1\n",
            "  Precision: 0.4919\n",
            "  Recall: 0.4263\n",
            "  F1: 0.4133\n",
            "The average precision is: 0.7069\n",
            "The average recall is: 0.6906\n",
            "The average f1 is: 0.6741\n",
            "  Testing took: 0:00:02\n",
            "Current increase 90 times\n",
            "Current is processing category 1\n",
            "Before up-sample, there are 1648 samples\n",
            "There are 199 sampled in this category.\n",
            "After up-sample, there are 19558 samples\n",
            "\n",
            "Currrent is processing on categorie GoodsServices\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "1449\n",
            "0.0740873299928418\n",
            "\n",
            "Currrent is processing on categorie InformationWanted\n",
            "\n",
            "Before up-sample, the ratio of current category and all samples\n",
            "0\n",
            "0.0\n",
            "\n",
            "After up-sample, the ratio of current category and all samples\n",
            "18109\n",
            "0.9259126700071582\n",
            "\n",
            "(19558, 144)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0903 14:45:45.599852 140498471425856 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I0903 14:45:45.601267 140498471425856 configuration_utils.py:300] Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I0903 14:45:46.090362 140498471425856 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "W0903 14:45:48.602275 140498471425856 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "W0903 14:45:48.603260 140498471425856 modeling_utils.py:768] Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  1,223.    Elapsed: 0:00:08.\n",
            "  Batch    80  of  1,223.    Elapsed: 0:00:17.\n",
            "  Batch   120  of  1,223.    Elapsed: 0:00:25.\n",
            "  Batch   160  of  1,223.    Elapsed: 0:00:33.\n",
            "  Batch   200  of  1,223.    Elapsed: 0:00:42.\n",
            "  Batch   240  of  1,223.    Elapsed: 0:00:50.\n",
            "  Batch   280  of  1,223.    Elapsed: 0:00:59.\n",
            "  Batch   320  of  1,223.    Elapsed: 0:01:07.\n",
            "  Batch   360  of  1,223.    Elapsed: 0:01:16.\n",
            "  Batch   400  of  1,223.    Elapsed: 0:01:24.\n",
            "  Batch   440  of  1,223.    Elapsed: 0:01:32.\n",
            "  Batch   480  of  1,223.    Elapsed: 0:01:41.\n",
            "  Batch   520  of  1,223.    Elapsed: 0:01:49.\n",
            "  Batch   560  of  1,223.    Elapsed: 0:01:58.\n",
            "  Batch   600  of  1,223.    Elapsed: 0:02:06.\n",
            "  Batch   640  of  1,223.    Elapsed: 0:02:14.\n",
            "  Batch   680  of  1,223.    Elapsed: 0:02:23.\n",
            "  Batch   720  of  1,223.    Elapsed: 0:02:31.\n",
            "  Batch   760  of  1,223.    Elapsed: 0:02:39.\n",
            "  Batch   800  of  1,223.    Elapsed: 0:02:48.\n",
            "  Batch   840  of  1,223.    Elapsed: 0:02:56.\n",
            "  Batch   880  of  1,223.    Elapsed: 0:03:04.\n",
            "  Batch   920  of  1,223.    Elapsed: 0:03:13.\n",
            "  Batch   960  of  1,223.    Elapsed: 0:03:21.\n",
            "  Batch 1,000  of  1,223.    Elapsed: 0:03:30.\n",
            "  Batch 1,040  of  1,223.    Elapsed: 0:03:38.\n",
            "  Batch 1,080  of  1,223.    Elapsed: 0:03:46.\n",
            "  Batch 1,120  of  1,223.    Elapsed: 0:03:55.\n",
            "  Batch 1,160  of  1,223.    Elapsed: 0:04:03.\n",
            "  Batch 1,200  of  1,223.    Elapsed: 0:04:12.\n",
            "\n",
            "  Average training loss: 0.09\n",
            "  Accuracy: 0.98\n",
            "Category: 0\n",
            "  Precision: 0.54\n",
            "  Recall: 0.50\n",
            "  F1: 0.51\n",
            "Category: 1\n",
            "  Precision: 0.98\n",
            "  Recall: 1.00\n",
            "  F1: 0.99\n",
            "The average precision is: 0.7597\n",
            "The average recall is: 0.7486\n",
            "The average f1 is: 0.7490\n",
            "  Training epcoh took: 0:04:17\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "Category: 0\n",
            "  Precision: 0.8744\n",
            "  Recall: 0.9772\n",
            "  F1: 0.9207\n",
            "Category: 1\n",
            "  Precision: 0.3846\n",
            "  Recall: 0.1987\n",
            "  F1: 0.2468\n",
            "The average precision is: 0.6295\n",
            "The average recall is: 0.5880\n",
            "The average f1 is: 0.5837\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  1,223.    Elapsed: 0:00:08.\n",
            "  Batch    80  of  1,223.    Elapsed: 0:00:17.\n",
            "  Batch   120  of  1,223.    Elapsed: 0:00:25.\n",
            "  Batch   160  of  1,223.    Elapsed: 0:00:33.\n",
            "  Batch   200  of  1,223.    Elapsed: 0:00:42.\n",
            "  Batch   240  of  1,223.    Elapsed: 0:00:50.\n",
            "  Batch   280  of  1,223.    Elapsed: 0:00:59.\n",
            "  Batch   320  of  1,223.    Elapsed: 0:01:07.\n",
            "  Batch   360  of  1,223.    Elapsed: 0:01:16.\n",
            "  Batch   400  of  1,223.    Elapsed: 0:01:24.\n",
            "  Batch   440  of  1,223.    Elapsed: 0:01:32.\n",
            "  Batch   480  of  1,223.    Elapsed: 0:01:41.\n",
            "  Batch   520  of  1,223.    Elapsed: 0:01:49.\n",
            "  Batch   560  of  1,223.    Elapsed: 0:01:57.\n",
            "  Batch   600  of  1,223.    Elapsed: 0:02:06.\n",
            "  Batch   640  of  1,223.    Elapsed: 0:02:15.\n",
            "  Batch   680  of  1,223.    Elapsed: 0:02:23.\n",
            "  Batch   720  of  1,223.    Elapsed: 0:02:31.\n",
            "  Batch   760  of  1,223.    Elapsed: 0:02:40.\n",
            "  Batch   800  of  1,223.    Elapsed: 0:02:48.\n",
            "  Batch   840  of  1,223.    Elapsed: 0:02:57.\n",
            "  Batch   880  of  1,223.    Elapsed: 0:03:05.\n",
            "  Batch   920  of  1,223.    Elapsed: 0:03:13.\n",
            "  Batch   960  of  1,223.    Elapsed: 0:03:22.\n",
            "  Batch 1,000  of  1,223.    Elapsed: 0:03:30.\n",
            "  Batch 1,040  of  1,223.    Elapsed: 0:03:39.\n",
            "  Batch 1,080  of  1,223.    Elapsed: 0:03:47.\n",
            "  Batch 1,120  of  1,223.    Elapsed: 0:03:56.\n",
            "  Batch 1,160  of  1,223.    Elapsed: 0:04:04.\n",
            "  Batch 1,200  of  1,223.    Elapsed: 0:04:12.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.69\n",
            "  Recall: 0.69\n",
            "  F1: 0.69\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.8465\n",
            "The average recall is: 0.8466\n",
            "The average f1 is: 0.8461\n",
            "  Training epcoh took: 0:04:17\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "Category: 0\n",
            "  Precision: 0.8721\n",
            "  Recall: 0.9427\n",
            "  F1: 0.9018\n",
            "Category: 1\n",
            "  Precision: 0.4423\n",
            "  Recall: 0.2612\n",
            "  F1: 0.3042\n",
            "The average precision is: 0.6572\n",
            "The average recall is: 0.6020\n",
            "The average f1 is: 0.6030\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  1,223.    Elapsed: 0:00:08.\n",
            "  Batch    80  of  1,223.    Elapsed: 0:00:17.\n",
            "  Batch   120  of  1,223.    Elapsed: 0:00:25.\n",
            "  Batch   160  of  1,223.    Elapsed: 0:00:33.\n",
            "  Batch   200  of  1,223.    Elapsed: 0:00:42.\n",
            "  Batch   240  of  1,223.    Elapsed: 0:00:50.\n",
            "  Batch   280  of  1,223.    Elapsed: 0:00:59.\n",
            "  Batch   320  of  1,223.    Elapsed: 0:01:07.\n",
            "  Batch   360  of  1,223.    Elapsed: 0:01:16.\n",
            "  Batch   400  of  1,223.    Elapsed: 0:01:24.\n",
            "  Batch   440  of  1,223.    Elapsed: 0:01:32.\n",
            "  Batch   480  of  1,223.    Elapsed: 0:01:41.\n",
            "  Batch   520  of  1,223.    Elapsed: 0:01:49.\n",
            "  Batch   560  of  1,223.    Elapsed: 0:01:58.\n",
            "  Batch   600  of  1,223.    Elapsed: 0:02:06.\n",
            "  Batch   640  of  1,223.    Elapsed: 0:02:14.\n",
            "  Batch   680  of  1,223.    Elapsed: 0:02:23.\n",
            "  Batch   720  of  1,223.    Elapsed: 0:02:31.\n",
            "  Batch   760  of  1,223.    Elapsed: 0:02:40.\n",
            "  Batch   800  of  1,223.    Elapsed: 0:02:48.\n",
            "  Batch   840  of  1,223.    Elapsed: 0:02:56.\n",
            "  Batch   880  of  1,223.    Elapsed: 0:03:05.\n",
            "  Batch   920  of  1,223.    Elapsed: 0:03:13.\n",
            "  Batch   960  of  1,223.    Elapsed: 0:03:21.\n",
            "  Batch 1,000  of  1,223.    Elapsed: 0:03:30.\n",
            "  Batch 1,040  of  1,223.    Elapsed: 0:03:38.\n",
            "  Batch 1,080  of  1,223.    Elapsed: 0:03:47.\n",
            "  Batch 1,120  of  1,223.    Elapsed: 0:03:55.\n",
            "  Batch 1,160  of  1,223.    Elapsed: 0:04:04.\n",
            "  Batch 1,200  of  1,223.    Elapsed: 0:04:12.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.70\n",
            "  Recall: 0.70\n",
            "  F1: 0.70\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.8509\n",
            "The average recall is: 0.8506\n",
            "The average f1 is: 0.8507\n",
            "  Training epcoh took: 0:04:17\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8723\n",
            "  Recall: 0.9602\n",
            "  F1: 0.9111\n",
            "Category: 1\n",
            "  Precision: 0.3590\n",
            "  Recall: 0.2565\n",
            "  F1: 0.2839\n",
            "The average precision is: 0.6156\n",
            "The average recall is: 0.6083\n",
            "The average f1 is: 0.5975\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  1,223.    Elapsed: 0:00:08.\n",
            "  Batch    80  of  1,223.    Elapsed: 0:00:17.\n",
            "  Batch   120  of  1,223.    Elapsed: 0:00:25.\n",
            "  Batch   160  of  1,223.    Elapsed: 0:00:34.\n",
            "  Batch   200  of  1,223.    Elapsed: 0:00:42.\n",
            "  Batch   240  of  1,223.    Elapsed: 0:00:51.\n",
            "  Batch   280  of  1,223.    Elapsed: 0:00:59.\n",
            "  Batch   320  of  1,223.    Elapsed: 0:01:07.\n",
            "  Batch   360  of  1,223.    Elapsed: 0:01:16.\n",
            "  Batch   400  of  1,223.    Elapsed: 0:01:24.\n",
            "  Batch   440  of  1,223.    Elapsed: 0:01:33.\n",
            "  Batch   480  of  1,223.    Elapsed: 0:01:41.\n",
            "  Batch   520  of  1,223.    Elapsed: 0:01:50.\n",
            "  Batch   560  of  1,223.    Elapsed: 0:01:58.\n",
            "  Batch   600  of  1,223.    Elapsed: 0:02:06.\n",
            "  Batch   640  of  1,223.    Elapsed: 0:02:15.\n",
            "  Batch   680  of  1,223.    Elapsed: 0:02:23.\n",
            "  Batch   720  of  1,223.    Elapsed: 0:02:32.\n",
            "  Batch   760  of  1,223.    Elapsed: 0:02:40.\n",
            "  Batch   800  of  1,223.    Elapsed: 0:02:48.\n",
            "  Batch   840  of  1,223.    Elapsed: 0:02:57.\n",
            "  Batch   880  of  1,223.    Elapsed: 0:03:05.\n",
            "  Batch   920  of  1,223.    Elapsed: 0:03:14.\n",
            "  Batch   960  of  1,223.    Elapsed: 0:03:22.\n",
            "  Batch 1,000  of  1,223.    Elapsed: 0:03:30.\n",
            "  Batch 1,040  of  1,223.    Elapsed: 0:03:39.\n",
            "  Batch 1,080  of  1,223.    Elapsed: 0:03:47.\n",
            "  Batch 1,120  of  1,223.    Elapsed: 0:03:55.\n",
            "  Batch 1,160  of  1,223.    Elapsed: 0:04:04.\n",
            "  Batch 1,200  of  1,223.    Elapsed: 0:04:12.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "Category: 0\n",
            "  Precision: 0.72\n",
            "  Recall: 0.72\n",
            "  F1: 0.72\n",
            "Category: 1\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "  F1: 1.00\n",
            "The average precision is: 0.8577\n",
            "The average recall is: 0.8575\n",
            "The average f1 is: 0.8576\n",
            "  Training epcoh took: 0:04:17\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "Category: 0\n",
            "  Precision: 0.8756\n",
            "  Recall: 0.9594\n",
            "  F1: 0.9130\n",
            "Category: 1\n",
            "  Precision: 0.3141\n",
            "  Recall: 0.2654\n",
            "  F1: 0.2656\n",
            "The average precision is: 0.5948\n",
            "The average recall is: 0.6124\n",
            "The average f1 is: 0.5893\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Testing...\n",
            "  Accuracy: 0.90\n",
            "Category: 0\n",
            "  Precision: 0.9150\n",
            "  Recall: 0.9777\n",
            "  F1: 0.9439\n",
            "Category: 1\n",
            "  Precision: 0.4596\n",
            "  Recall: 0.3359\n",
            "  F1: 0.3616\n",
            "The average precision is: 0.6873\n",
            "The average recall is: 0.6568\n",
            "The average f1 is: 0.6528\n",
            "  Testing took: 0:00:02\n",
            "Successfully save file ./BertSearchResult/7_16_2e-05_7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L2DfmwSXWejr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "outputId": "203b4107-6a44-4a39-d1ce-f5ea357bf42a"
      },
      "source": [
        "all_metrics_one"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: defaultdict(None,\n",
              "             {'train_loss_values': [0.02451061978212838,\n",
              "               0.02451061978212838,\n",
              "               0.014020035567792874,\n",
              "               0.014020035567792874,\n",
              "               0.014816705897016433,\n",
              "               0.014816705897016433,\n",
              "               0.012088468786582205,\n",
              "               0.012088468786582205],\n",
              "              'train_acc_all': [0.9981796116504854,\n",
              "               0.9981796116504854,\n",
              "               0.9981796116504854,\n",
              "               0.9981796116504854],\n",
              "              'train_precision_all': [{0: 0.9981796116504854, 1: 0.0},\n",
              "               {0: 0.9981796116504854, 1: 0.0},\n",
              "               {0: 0.9981796116504854, 1: 0.0},\n",
              "               {0: 0.9981796116504854, 1: 0.0}],\n",
              "              'train_recall_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}],\n",
              "              'train_f1_all': [{0: 0.9990291262135923, 1: 0.0},\n",
              "               {0: 0.9990291262135923, 1: 0.0},\n",
              "               {0: 0.9990291262135923, 1: 0.0},\n",
              "               {0: 0.9990291262135923, 1: 0.0}],\n",
              "              'val_acc_all': [1.0, 1.0, 1.0, 1.0],\n",
              "              'val_precision_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}],\n",
              "              'val_recall_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}],\n",
              "              'val_f1_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}]})}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kyJhEtOoJScG"
      },
      "source": [
        "#### Incremental recitfied training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "l7CJocKtZirO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "batch_size = 32\n",
        "lr = 3e-5\n",
        "test_batch = [test_inputs,test_labels,test_masks]\n",
        "Bert = Bertnn_rectified_info(train_inputs,train_labels,train_masks, validation_inputs,validation_labels,validation_masks,test_batch,batch_size=batch_size,lr=lr)\n",
        "all_metrics_one, all_tesst_metrics = Bert.searchUpsample(100)\n",
        "all_metrics_one['test'] = all_tesst_metrics\n",
        "all_metrics_all_category[section_category] = all_metrics_one\n",
        "if not os.path.exists('BertSearchResult'):\n",
        "  os.makedirs('BertSearchResult')\n",
        "\n",
        "filename = './BertSearchResult/'+'rectified'+'_'+str(section_category)+'_'+str(batch_size) + '_' + str(lr) + '_'  + str(section_category)\n",
        "with open(filename,'w') as file_obj:\n",
        "  json.dump(all_metrics_one,file_obj)\n",
        "  print('Successfully save file %s'%(filename))\n",
        "\n",
        "del Bert\n",
        "torch.cuda.empty_cache() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "U9SxZACXZirQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "outputId": "203b4107-6a44-4a39-d1ce-f5ea357bf42a"
      },
      "source": [
        "all_metrics_one"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: defaultdict(None,\n",
              "             {'train_loss_values': [0.02451061978212838,\n",
              "               0.02451061978212838,\n",
              "               0.014020035567792874,\n",
              "               0.014020035567792874,\n",
              "               0.014816705897016433,\n",
              "               0.014816705897016433,\n",
              "               0.012088468786582205,\n",
              "               0.012088468786582205],\n",
              "              'train_acc_all': [0.9981796116504854,\n",
              "               0.9981796116504854,\n",
              "               0.9981796116504854,\n",
              "               0.9981796116504854],\n",
              "              'train_precision_all': [{0: 0.9981796116504854, 1: 0.0},\n",
              "               {0: 0.9981796116504854, 1: 0.0},\n",
              "               {0: 0.9981796116504854, 1: 0.0},\n",
              "               {0: 0.9981796116504854, 1: 0.0}],\n",
              "              'train_recall_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}],\n",
              "              'train_f1_all': [{0: 0.9990291262135923, 1: 0.0},\n",
              "               {0: 0.9990291262135923, 1: 0.0},\n",
              "               {0: 0.9990291262135923, 1: 0.0},\n",
              "               {0: 0.9990291262135923, 1: 0.0}],\n",
              "              'val_acc_all': [1.0, 1.0, 1.0, 1.0],\n",
              "              'val_precision_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}],\n",
              "              'val_recall_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}],\n",
              "              'val_f1_all': [{0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0},\n",
              "               {0: 1.0, 1: 0.0}]})}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    }
  ]
}